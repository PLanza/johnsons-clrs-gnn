{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8omnFWsJ1i8",
        "outputId": "2775f968-9766-43d4-9f77-d54d3f085354"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/PLanza/johnsons-clrs-gnn.git@bfs-dijkstra\n",
            "  Cloning https://github.com/PLanza/johnsons-clrs-gnn.git (to revision bfs-dijkstra) to /tmp/pip-req-build-t___z1ki\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/PLanza/johnsons-clrs-gnn.git /tmp/pip-req-build-t___z1ki\n",
            "  Running command git checkout -b bfs-dijkstra --track origin/bfs-dijkstra\n",
            "  Switched to a new branch 'bfs-dijkstra'\n",
            "  Branch 'bfs-dijkstra' set up to track remote branch 'bfs-dijkstra' from 'origin'.\n",
            "  Resolved https://github.com/PLanza/johnsons-clrs-gnn.git to commit 01aaf92337c0d2c9e98cd15e8acb87c1dee7cf3d\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from dm-clrs==1.0.0) (1.4.0)\n",
            "Requirement already satisfied: attrs>=21.4.0 in /usr/local/lib/python3.10/dist-packages (from dm-clrs==1.0.0) (23.2.0)\n",
            "Requirement already satisfied: chex>=0.0.8 in /usr/local/lib/python3.10/dist-packages (from dm-clrs==1.0.0) (0.1.85)\n",
            "Requirement already satisfied: dm-haiku>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from dm-clrs==1.0.0) (0.0.12)\n",
            "Requirement already satisfied: jax>=0.2.18 in /usr/local/lib/python3.10/dist-packages (from dm-clrs==1.0.0) (0.4.23)\n",
            "Requirement already satisfied: jaxlib>=0.1.69 in /usr/local/lib/python3.10/dist-packages (from dm-clrs==1.0.0) (0.4.23+cuda12.cudnn89)\n",
            "Requirement already satisfied: numpy>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from dm-clrs==1.0.0) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from dm-clrs==1.0.0) (3.3.0)\n",
            "Requirement already satisfied: optax>=0.0.9 in /usr/local/lib/python3.10/dist-packages (from dm-clrs==1.0.0) (0.2.1)\n",
            "Requirement already satisfied: six>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from dm-clrs==1.0.0) (1.16.0)\n",
            "Requirement already satisfied: tensorflow>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from dm-clrs==1.0.0) (2.15.0)\n",
            "Requirement already satisfied: tfds-nightly==4.5.2.dev202204190046 in /usr/local/lib/python3.10/dist-packages (from dm-clrs==1.0.0) (4.5.2.dev202204190046)\n",
            "Requirement already satisfied: toolz>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from dm-clrs==1.0.0) (0.12.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from tfds-nightly==4.5.2.dev202204190046->dm-clrs==1.0.0) (0.3.8)\n",
            "Requirement already satisfied: etils[epath-no-tf] in /usr/local/lib/python3.10/dist-packages (from tfds-nightly==4.5.2.dev202204190046->dm-clrs==1.0.0) (1.7.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tfds-nightly==4.5.2.dev202204190046->dm-clrs==1.0.0) (2.3)\n",
            "Requirement already satisfied: protobuf>=3.12.2 in /usr/local/lib/python3.10/dist-packages (from tfds-nightly==4.5.2.dev202204190046->dm-clrs==1.0.0) (3.20.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from tfds-nightly==4.5.2.dev202204190046->dm-clrs==1.0.0) (2.31.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tfds-nightly==4.5.2.dev202204190046->dm-clrs==1.0.0) (1.14.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from tfds-nightly==4.5.2.dev202204190046->dm-clrs==1.0.0) (2.4.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tfds-nightly==4.5.2.dev202204190046->dm-clrs==1.0.0) (0.10.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from tfds-nightly==4.5.2.dev202204190046->dm-clrs==1.0.0) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from chex>=0.0.8->dm-clrs==1.0.0) (4.10.0)\n",
            "Requirement already satisfied: jmp>=0.0.2 in /usr/local/lib/python3.10/dist-packages (from dm-haiku>=0.0.4->dm-clrs==1.0.0) (0.0.4)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from dm-haiku>=0.0.4->dm-clrs==1.0.0) (0.9.0)\n",
            "Requirement already satisfied: flax>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from dm-haiku>=0.0.4->dm-clrs==1.0.0) (0.8.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.2.18->dm-clrs==1.0.0) (0.2.0)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax>=0.2.18->dm-clrs==1.0.0) (1.11.4)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->dm-clrs==1.0.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->dm-clrs==1.0.0) (24.3.7)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->dm-clrs==1.0.0) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->dm-clrs==1.0.0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->dm-clrs==1.0.0) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->dm-clrs==1.0.0) (16.0.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->dm-clrs==1.0.0) (24.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->dm-clrs==1.0.0) (67.7.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->dm-clrs==1.0.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->dm-clrs==1.0.0) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->dm-clrs==1.0.0) (1.62.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->dm-clrs==1.0.0) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->dm-clrs==1.0.0) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->dm-clrs==1.0.0) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=2.9.0->dm-clrs==1.0.0) (0.43.0)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.1->dm-haiku>=0.0.4->dm-clrs==1.0.0) (1.0.8)\n",
            "Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.1->dm-haiku>=0.0.4->dm-clrs==1.0.0) (0.4.4)\n",
            "Requirement already satisfied: tensorstore in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.1->dm-haiku>=0.0.4->dm-clrs==1.0.0) (0.1.45)\n",
            "Requirement already satisfied: rich>=11.1 in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.1->dm-haiku>=0.0.4->dm-clrs==1.0.0) (13.7.1)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.1->dm-haiku>=0.0.4->dm-clrs==1.0.0) (6.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tfds-nightly==4.5.2.dev202204190046->dm-clrs==1.0.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tfds-nightly==4.5.2.dev202204190046->dm-clrs==1.0.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tfds-nightly==4.5.2.dev202204190046->dm-clrs==1.0.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tfds-nightly==4.5.2.dev202204190046->dm-clrs==1.0.0) (2024.2.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.9.0->dm-clrs==1.0.0) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.9.0->dm-clrs==1.0.0) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.9.0->dm-clrs==1.0.0) (3.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.9.0->dm-clrs==1.0.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.9.0->dm-clrs==1.0.0) (3.0.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-metadata->tfds-nightly==4.5.2.dev202204190046->dm-clrs==1.0.0) (1.63.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.9.0->dm-clrs==1.0.0) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.9.0->dm-clrs==1.0.0) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.9.0->dm-clrs==1.0.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=2.9.0->dm-clrs==1.0.0) (1.4.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax>=0.7.1->dm-haiku>=0.0.4->dm-clrs==1.0.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax>=0.7.1->dm-haiku>=0.0.4->dm-clrs==1.0.0) (2.16.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow>=2.9.0->dm-clrs==1.0.0) (2.1.5)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax>=0.7.1->dm-haiku>=0.0.4->dm-clrs==1.0.0) (1.6.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax>=0.7.1->dm-haiku>=0.0.4->dm-clrs==1.0.0) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.9.0->dm-clrs==1.0.0) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=2.9.0->dm-clrs==1.0.0) (3.2.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[epath-no-tf]->tfds-nightly==4.5.2.dev202204190046->dm-clrs==1.0.0) (2023.6.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[epath-no-tf]->tfds-nightly==4.5.2.dev202204190046->dm-clrs==1.0.0) (6.1.3)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[epath-no-tf]->tfds-nightly==4.5.2.dev202204190046->dm-clrs==1.0.0) (3.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/PLanza/johnsons-clrs-gnn.git@bf-dijkstra"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from clrs.examples import run\n",
        "import numpy as np\n",
        "import jax\n",
        "import clrs\n",
        "import functools\n",
        "import random\n",
        "import sys"
      ],
      "metadata": {
        "id": "9ENyEo_sjkqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(algorithms):\n",
        "\n",
        "  seed = random.randint(0,1000)\n",
        "\n",
        "  run.FLAGS([sys.argv])\n",
        "  run.FLAGS.seed = seed\n",
        "\n",
        "  run.FLAGS.algorithms = [algorithms]\n",
        "\n",
        "  train_lengths = [int(x) for x in run.FLAGS.train_lengths]\n",
        "\n",
        "  rng = np.random.RandomState(run.FLAGS.seed)\n",
        "  rng_key = jax.random.PRNGKey(rng.randint(2**32))\n",
        "\n",
        "  FLAGS = run.FLAGS\n",
        "  print(FLAGS.algorithms)\n",
        "  encode_hints = True\n",
        "  decode_hints = True\n",
        "\n",
        "  processor_factory = clrs.get_processor_factory(\n",
        "      FLAGS.processor_type,\n",
        "      use_ln=FLAGS.use_ln,\n",
        "      nb_triplet_fts=FLAGS.nb_triplet_fts,\n",
        "      nb_heads=FLAGS.nb_heads\n",
        "  )\n",
        "  model_params = dict(\n",
        "      processor_factory=processor_factory,\n",
        "      hidden_dim=FLAGS.hidden_size,\n",
        "      encode_hints=encode_hints,\n",
        "      decode_hints=decode_hints,\n",
        "      encoder_init=FLAGS.encoder_init,\n",
        "      use_lstm=FLAGS.use_lstm,\n",
        "      learning_rate=FLAGS.learning_rate,\n",
        "      grad_clip_max_norm=FLAGS.grad_clip_max_norm,\n",
        "      checkpoint_path=FLAGS.checkpoint_path,\n",
        "      freeze_processor=FLAGS.freeze_processor,\n",
        "      dropout_prob=FLAGS.dropout_prob,\n",
        "      hint_teacher_forcing=FLAGS.hint_teacher_forcing,\n",
        "      hint_repred_mode=FLAGS.hint_repred_mode,\n",
        "      nb_msg_passing_steps=FLAGS.nb_msg_passing_steps,\n",
        "      )\n",
        "\n",
        "  (train_samplers,\n",
        "    val_samplers, val_sample_counts,\n",
        "    test_samplers, test_sample_counts,\n",
        "    spec_list) = run.create_samplers(rng, train_lengths)\n",
        "\n",
        "  eval_model = clrs.models.BaselineModel(\n",
        "      spec=spec_list,\n",
        "      dummy_trajectory=[next(train_samplers[0])],\n",
        "      **model_params\n",
        "  )\n",
        "  train_model = eval_model\n",
        "\n",
        "  # Training loop.\n",
        "  best_score = -1.0\n",
        "  current_train_items = [0]\n",
        "  step = 0\n",
        "  next_eval = 0\n",
        "  # Make sure scores improve on first step, but not overcome best score\n",
        "  # until all algos have had at least one evaluation.\n",
        "  val_scores = [-99999.9]\n",
        "  length_idx = 0\n",
        "\n",
        "  losses = { name: [] for name in FLAGS.algorithms }\n",
        "  evals = { name: [] for name in FLAGS.algorithms }\n",
        "\n",
        "  algo_idx = 0\n",
        "\n",
        "  while step < FLAGS.train_steps:\n",
        "    feedback_list = [next(train_samplers[algo_idx])]\n",
        "\n",
        "    # Initialize model.\n",
        "    if step == 0:\n",
        "      all_features = [f.features for f in feedback_list]\n",
        "      train_model.init(all_features, FLAGS.seed + 1)\n",
        "\n",
        "    # Training step.\n",
        "    feedback = feedback_list[0]\n",
        "    rng_key, new_rng_key = jax.random.split(rng_key)\n",
        "    length_and_algo_idx = algo_idx\n",
        "    cur_loss = train_model.feedback(rng_key, feedback, length_and_algo_idx)\n",
        "    rng_key = new_rng_key\n",
        "    losses[FLAGS.algorithms[algo_idx]].append(cur_loss.item())\n",
        "\n",
        "    examples_in_chunk = len(feedback.features.lengths)\n",
        "    current_train_items[algo_idx] += examples_in_chunk\n",
        "    print(f'Algo {FLAGS.algorithms[algo_idx]} step {step} current loss {cur_loss}, current_train_items {current_train_items[algo_idx]}.')\n",
        "\n",
        "    # Periodically evaluate model\n",
        "    if step >= next_eval:\n",
        "      eval_model.params = train_model.params\n",
        "      for algo_idx in range(len(train_samplers)):\n",
        "        common_extras = {'examples_seen': current_train_items[algo_idx],\n",
        "                          'step': step,\n",
        "                          'algorithm': FLAGS.algorithms[algo_idx]}\n",
        "\n",
        "        # Validation info.\n",
        "        new_rng_key, rng_key = jax.random.split(rng_key)\n",
        "        val_stats = run.collect_and_eval(\n",
        "            val_samplers[algo_idx],\n",
        "            functools.partial(eval_model.predict, algorithm_index=algo_idx),\n",
        "            val_sample_counts[algo_idx],\n",
        "            new_rng_key,\n",
        "            extras=common_extras)\n",
        "        print(f'(val) algo {FLAGS.algorithms[algo_idx]} step {step}: {val_stats}')\n",
        "        val_scores[algo_idx] = val_stats['score']\n",
        "        evals[FLAGS.algorithms[algo_idx]].append(val_stats['score'])\n",
        "\n",
        "      next_eval += FLAGS.eval_every\n",
        "\n",
        "      # If best total score, update best checkpoint.\n",
        "      # Also save a best checkpoint on the first step.\n",
        "      msg = (f'best avg val score was '\n",
        "              f'{best_score/len(FLAGS.algorithms):.3f}, '\n",
        "              f'current avg val score is {np.mean(val_scores):.3f}, '\n",
        "              f'val scores are: ')\n",
        "      msg += ', '.join(\n",
        "          ['%s: %.3f' % (x, y) for (x, y) in zip(FLAGS.algorithms, val_scores)])\n",
        "      if (sum(val_scores) > best_score) or step == 0:\n",
        "        best_score = sum(val_scores)\n",
        "        print('Checkpointing best model, ', msg)\n",
        "        train_model.save_model('best' + str(algorithms) + '.pkl')\n",
        "      else:\n",
        "        print('Not saving new best model, ', msg)\n",
        "\n",
        "    step += 1\n",
        "    length_idx = (length_idx + 1) % len(train_lengths)\n",
        "\n",
        "  return eval_model"
      ],
      "metadata": {
        "id": "7UQXMGQr26UK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bf_model = train_model('bellman_ford')\n",
        "dijkstra_model = train_model('dijkstra')"
      ],
      "metadata": {
        "id": "FXN-4MKZ8B_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rng = np.random.RandomState(run.FLAGS.seed)\n",
        "\n",
        "def get_test_sampler(algorithm):\n",
        "  common_sampler_args = dict(\n",
        "    algorithm=algorithm,\n",
        "    rng=rng,\n",
        "    enforce_pred_as_input=True,\n",
        "    enforce_permutations=True,\n",
        "    chunk_length=16,\n",
        "    )\n",
        "  test_args = dict(sizes=[64],\n",
        "                   split='test',\n",
        "                   batch_size=32,\n",
        "                   multiplier=2,\n",
        "                   randomize_pos=False,\n",
        "                   chunked=False,\n",
        "                   sampler_kwargs={},\n",
        "                   **common_sampler_args)\n",
        "\n",
        "  return run.make_multi_sampler(**test_args)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AOShxUZpOTIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bf_sampler, bf_num_samples, bf_spec = get_test_sampler('bellman_ford')"
      ],
      "metadata": {
        "id": "6aMlAZPJPrPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_rewritten_A(A, pi):\n",
        "  d = np.zeros(pi.shape)\n",
        "  for i in range(pi.shape[-1]):\n",
        "    prev_node = i\n",
        "    node = int(pi[prev_node])\n",
        "    d[i] += A[node, prev_node]\n",
        "    while node != pi.shape[-1] - 1:\n",
        "      prev_node = node\n",
        "      node = int(pi[prev_node])\n",
        "      d[i] += A[node, prev_node]\n",
        "  assert(np.all(d < 0.0001))\n",
        "\n",
        "  A_rw = A.copy()\n",
        "  for i in range(A_rw.shape[0]):\n",
        "    for j in range(A_rw.shape[1]):\n",
        "      if A[i, j] != 0:\n",
        "        A_rw[i, j] += d[i] - d[j]\n",
        "\n",
        "  assert(np.all(A_rw >= -1e6))\n",
        "  return A_rw[:-1,:-1]\n"
      ],
      "metadata": {
        "id": "8hzwRfNhM2A0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rng = np.random.RandomState(run.FLAGS.seed)\n",
        "rng_key = jax.random.PRNGKey(rng.randint(2**32))\n",
        "\n",
        "import pickle\n",
        "import haiku as hk\n",
        "from clrs._src import algorithms\n",
        "\n",
        "with open(\"/tmp/CLRS30/bestbellman_ford.pkl\", 'rb') as f:\n",
        "  restored_state = pickle.load(f)\n",
        "  bf_model.params = restored_state['params']\n",
        "  bf_model.params = hk.data_structures.merge(bf_model.params, restored_state['params'])\n",
        "  bf_model.opt_state = restored_state['opt_state']\n",
        "\n",
        "predict_fn = functools.partial(bf_model.predict, algorithm_index=0)\n",
        "\n",
        "processed_samples = 0\n",
        "bf_truths = []\n",
        "outputs = []\n",
        "A_rws = []\n",
        "As = []\n",
        "bf_preds = []\n",
        "\n",
        "while processed_samples < bf_num_samples:\n",
        "  feedback = next(bf_sampler)\n",
        "  A = feedback.features.inputs[2].data\n",
        "  batch_size = feedback.outputs[0].data.shape[0]\n",
        "  bf_truths.append(feedback.outputs)\n",
        "  new_rng_key, rng_key = jax.random.split(rng_key)\n",
        "  cur_preds, _ = predict_fn(new_rng_key, feedback.features)\n",
        "  for i in range(len(A)):\n",
        "    outputs.append(algorithms.johnsons(A[i][:-1,:-1])[0])\n",
        "    A_rws.append(get_rewritten_A(A[i], cur_preds['pi'].data[i]))\n",
        "    As.append(A[i])\n",
        "  bf_preds.append(cur_preds)\n",
        "  processed_samples += batch_size\n"
      ],
      "metadata": {
        "id": "PBrvrcqtYlxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bf_truths = run._concat(bf_truths, axis=0)\n",
        "bf_preds = run._concat(bf_preds, axis=0)\n",
        "clrs.evaluate(bf_truths, bf_preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d86MwtgLISuc",
        "outputId": "0a43327f-7d1c-45f8-a879-02644ae29d91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'pi': 0.971923828125, 'score': 0.971923828125}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d_sampler, d_num_samples, d_spec = get_test_sampler('dijkstra')"
      ],
      "metadata": {
        "id": "yXn4hJ2hKGep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run.collect_and_eval(d_sampler, functools.partial(dijkstra_model.predict, algorithm_index=0), d_num_samples, rng_key, {})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4W8KQLcBLhBc",
        "outputId": "d546a8b4-f9b8-4998-d718-d6ca97699552"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'pi': 0.93505859375, 'score': 0.93505859375}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from clrs._src import probing\n",
        "\n",
        "with open(\"/tmp/CLRS30/bestdijkstra.pkl\", 'rb') as f:\n",
        "  restored_state = pickle.load(f)\n",
        "  dijkstra_model.params = restored_state['params']\n",
        "  dijkstra_model.params = hk.data_structures.merge(dijkstra_model.params, restored_state['params'])\n",
        "  dijkstra_model.opt_state = restored_state['opt_state']\n",
        "predict_fn = functools.partial(dijkstra_model.predict, algorithm_index=0)\n",
        "\n",
        "preds = []\n",
        "d_preds = []\n",
        "d_truths = []\n",
        "for A_rw in A_rws:\n",
        "  result = []\n",
        "  for s in range(len(A_rw)):\n",
        "    dijkstra_out = algorithms.dijkstra(A_rw, s)[1]\n",
        "    inp, outp, hint = probing.split_stages(dijkstra_out, clrs.SPECS['dijkstra'])\n",
        "    d_truths.append(outp)\n",
        "\n",
        "    features = clrs._src.samplers.Features(tuple(inp), tuple(hint), np.array([len(hint)]))\n",
        "    new_rng_key, rng_key = jax.random.split(rng_key)\n",
        "    cur_preds, _ = predict_fn(new_rng_key, features)\n",
        "    d_preds.append(cur_preds)\n",
        "    result.append(cur_preds['pi'].data[0])\n",
        "  preds.append(result)"
      ],
      "metadata": {
        "id": "8oFwDurY2o6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d_truths = run._concat(d_truths, axis=0)\n",
        "d_preds = run._concat(d_preds, axis=0)"
      ],
      "metadata": {
        "id": "FysPQMbTK2N0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clrs.evaluate(d_truths, d_preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zjkT6olauk9",
        "outputId": "8f73e19a-6e3d-44ba-a3ae-472e8ea1b7e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'pi': 0.48778423406399596, 'score': 0.48778423406399596}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = probing.DataPoint(\"Pi\",\"edge\",\"pointer\",np.array(preds))\n",
        "outputs = probing.DataPoint(\"Pi\",\"edge\",\"pointer\",np.array(outputs))"
      ],
      "metadata": {
        "id": "oHbRxmzZ7M6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clrs._src.evaluation.evaluate([outputs], {\"Pi\": preds})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fK5WP3jz4fCx",
        "outputId": "60974039-ae2e-43aa-ebda-382381a48a1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Pi': 0.19944019274376418, 'score': 0.19944019274376418}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}