{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/PLanza/johnsons-clrs-gnn.git"
      ],
      "metadata": {
        "id": "nLHnrLfHYwZU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fcb211e-2638-41aa-ed69-df2d8b7fb7fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'johnsons-clrs-gnn'...\n",
            "remote: Enumerating objects: 1004, done.\u001b[K\n",
            "remote: Counting objects: 100% (580/580), done.\u001b[K\n",
            "remote: Compressing objects: 100% (219/219), done.\u001b[K\n",
            "remote: Total 1004 (delta 467), reused 428 (delta 353), pack-reused 424\u001b[K\n",
            "Receiving objects: 100% (1004/1004), 326.13 KiB | 7.41 MiB/s, done.\n",
            "Resolving deltas: 100% (706/706), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r johnsons-clrs-gnn/requirements/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekziFKLrZLjr",
        "outputId": "57e81b2d-c1a2-45c0-90cf-b1700eced208"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: absl-py>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from -r johnsons-clrs-gnn/requirements/requirements.txt (line 1)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=21.4.0 in /usr/local/lib/python3.10/dist-packages (from -r johnsons-clrs-gnn/requirements/requirements.txt (line 2)) (23.2.0)\n",
            "Requirement already satisfied: chex>=0.0.8 in /usr/local/lib/python3.10/dist-packages (from -r johnsons-clrs-gnn/requirements/requirements.txt (line 3)) (0.1.85)\n",
            "Collecting dm-haiku>=0.0.4 (from -r johnsons-clrs-gnn/requirements/requirements.txt (line 4))\n",
            "  Downloading dm_haiku-0.0.12-py3-none-any.whl (371 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m371.7/371.7 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jax>=0.2.18 in /usr/local/lib/python3.10/dist-packages (from -r johnsons-clrs-gnn/requirements/requirements.txt (line 5)) (0.4.23)\n",
            "Requirement already satisfied: jaxlib>=0.1.69 in /usr/local/lib/python3.10/dist-packages (from -r johnsons-clrs-gnn/requirements/requirements.txt (line 6)) (0.4.23+cuda12.cudnn89)\n",
            "Requirement already satisfied: numpy>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from -r johnsons-clrs-gnn/requirements/requirements.txt (line 7)) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from -r johnsons-clrs-gnn/requirements/requirements.txt (line 8)) (3.3.0)\n",
            "Requirement already satisfied: optax>=0.0.9 in /usr/local/lib/python3.10/dist-packages (from -r johnsons-clrs-gnn/requirements/requirements.txt (line 9)) (0.2.1)\n",
            "Requirement already satisfied: six>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from -r johnsons-clrs-gnn/requirements/requirements.txt (line 10)) (1.16.0)\n",
            "Requirement already satisfied: tensorflow>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from -r johnsons-clrs-gnn/requirements/requirements.txt (line 11)) (2.15.0)\n",
            "Collecting tfds-nightly==4.5.2.dev202204190046 (from -r johnsons-clrs-gnn/requirements/requirements.txt (line 12))\n",
            "  Downloading tfds_nightly-4.5.2.dev202204190046-py3-none-any.whl (4.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: toolz>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from -r johnsons-clrs-gnn/requirements/requirements.txt (line 13)) (0.12.1)\n",
            "Collecting dill (from tfds-nightly==4.5.2.dev202204190046->-r johnsons-clrs-gnn/requirements/requirements.txt (line 12))\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: etils[epath-no-tf] in /usr/local/lib/python3.10/dist-packages (from tfds-nightly==4.5.2.dev202204190046->-r johnsons-clrs-gnn/requirements/requirements.txt (line 12)) (1.7.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tfds-nightly==4.5.2.dev202204190046->-r johnsons-clrs-gnn/requirements/requirements.txt (line 12)) (2.3)\n",
            "Requirement already satisfied: protobuf>=3.12.2 in /usr/local/lib/python3.10/dist-packages (from tfds-nightly==4.5.2.dev202204190046->-r johnsons-clrs-gnn/requirements/requirements.txt (line 12)) (3.20.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from tfds-nightly==4.5.2.dev202204190046->-r johnsons-clrs-gnn/requirements/requirements.txt (line 12)) (2.31.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tfds-nightly==4.5.2.dev202204190046->-r johnsons-clrs-gnn/requirements/requirements.txt (line 12)) (1.14.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from tfds-nightly==4.5.2.dev202204190046->-r johnsons-clrs-gnn/requirements/requirements.txt (line 12)) (2.4.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tfds-nightly==4.5.2.dev202204190046->-r johnsons-clrs-gnn/requirements/requirements.txt (line 12)) (0.10.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from tfds-nightly==4.5.2.dev202204190046->-r johnsons-clrs-gnn/requirements/requirements.txt (line 12)) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from chex>=0.0.8->-r johnsons-clrs-gnn/requirements/requirements.txt (line 3)) (4.10.0)\n",
            "Collecting jmp>=0.0.2 (from dm-haiku>=0.0.4->-r johnsons-clrs-gnn/requirements/requirements.txt (line 4))\n",
            "  Downloading jmp-0.0.4-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from dm-haiku>=0.0.4->-r johnsons-clrs-gnn/requirements/requirements.txt (line 4)) (0.9.0)\n",
            "Requirement already satisfied: flax>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from dm-haiku>=0.0.4->-r johnsons-clrs-gnn/requirements/requirements.txt (line 4)) (0.8.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.2.18->-r johnsons-clrs-gnn/requirements/requirements.txt (line 5)) (0.2.0)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax>=0.2.18->-r johnsons-clrs-gnn/requirements/requirements.txt (line 5)) (1.11.4)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->-r johnsons-clrs-gnn/requirements/requirements.txt (line 11)) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->-r johnsons-clrs-gnn/requirements/requirements.txt (line 11)) (24.3.7)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->-r johnsons-clrs-gnn/requirements/requirements.txt (line 11)) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->-r johnsons-clrs-gnn/requirements/requirements.txt (line 11)) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->-r johnsons-clrs-gnn/requirements/requirements.txt (line 11)) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->-r johnsons-clrs-gnn/requirements/requirements.txt (line 11)) (16.0.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->-r johnsons-clrs-gnn/requirements/requirements.txt (line 11)) (24.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->-r johnsons-clrs-gnn/requirements/requirements.txt (line 11)) (67.7.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->-r johnsons-clrs-gnn/requirements/requirements.txt (line 11)) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->-r johnsons-clrs-gnn/requirements/requirements.txt (line 11)) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->-r johnsons-clrs-gnn/requirements/requirements.txt (line 11)) (1.62.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->-r johnsons-clrs-gnn/requirements/requirements.txt (line 11)) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->-r johnsons-clrs-gnn/requirements/requirements.txt (line 11)) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.9.0->-r johnsons-clrs-gnn/requirements/requirements.txt (line 11)) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=2.9.0->-r johnsons-clrs-gnn/requirements/requirements.txt (line 11)) (0.43.0)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.1->dm-haiku>=0.0.4->-r johnsons-clrs-gnn/requirements/requirements.txt (line 4)) (1.0.8)\n",
            "Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.1->dm-haiku>=0.0.4->-r johnsons-clrs-gnn/requirements/requirements.txt (line 4)) (0.4.4)\n",
            "Requirement already satisfied: tensorstore in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.1->dm-haiku>=0.0.4->-r johnsons-clrs-gnn/requirements/requirements.txt (line 4)) (0.1.45)\n",
            "Requirement already satisfied: rich>=11.1 in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.1->dm-haiku>=0.0.4->-r johnsons-clrs-gnn/requirements/requirements.txt (line 4)) (13.7.1)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.1->dm-haiku>=0.0.4->-r johnsons-clrs-gnn/requirements/requirements.txt (line 4)) (6.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tfds-nightly==4.5.2.dev202204190046->-r johnsons-clrs-gnn/requirements/requirements.txt (line 12)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tfds-nightly==4.5.2.dev202204190046->-r johnsons-clrs-gnn/requirements/requirements.txt (line 12)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tfds-nightly==4.5.2.dev202204190046->-r johnsons-clrs-gnn/requirements/requirements.txt (line 12)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tfds-nightly==4.5.2.dev202204190046->-r johnsons-clrs-gnn/requirements/requirements.txt (line 12)) (2024.2.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.9.0->-r johnsons-clrs-gnn/requirements/requirements.txt (line 11)) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.9.0->-r johnsons-clrs-gnn/requirements/requirements.txt (line 11)) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.9.0->-r johnsons-clrs-gnn/requirements/requirements.txt (line 11)) (3.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.9.0->-r johnsons-clrs-gnn/requirements/requirements.txt (line 11)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.9.0->-r johnsons-clrs-gnn/requirements/requirements.txt (line 11)) (3.0.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-metadata->tfds-nightly==4.5.2.dev202204190046->-r johnsons-clrs-gnn/requirements/requirements.txt (line 12)) (1.63.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.9.0->-r johnsons-clrs-gnn/requirements/requirements.txt (line 11)) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.9.0->-r johnsons-clrs-gnn/requirements/requirements.txt (line 11)) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.9.0->-r johnsons-clrs-gnn/requirements/requirements.txt (line 11)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=2.9.0->-r johnsons-clrs-gnn/requirements/requirements.txt (line 11)) (1.4.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax>=0.7.1->dm-haiku>=0.0.4->-r johnsons-clrs-gnn/requirements/requirements.txt (line 4)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax>=0.7.1->dm-haiku>=0.0.4->-r johnsons-clrs-gnn/requirements/requirements.txt (line 4)) (2.16.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow>=2.9.0->-r johnsons-clrs-gnn/requirements/requirements.txt (line 11)) (2.1.5)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax>=0.7.1->dm-haiku>=0.0.4->-r johnsons-clrs-gnn/requirements/requirements.txt (line 4)) (1.6.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax>=0.7.1->dm-haiku>=0.0.4->-r johnsons-clrs-gnn/requirements/requirements.txt (line 4)) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.9.0->-r johnsons-clrs-gnn/requirements/requirements.txt (line 11)) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=2.9.0->-r johnsons-clrs-gnn/requirements/requirements.txt (line 11)) (3.2.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[epath-no-tf]->tfds-nightly==4.5.2.dev202204190046->-r johnsons-clrs-gnn/requirements/requirements.txt (line 12)) (2023.6.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[epath-no-tf]->tfds-nightly==4.5.2.dev202204190046->-r johnsons-clrs-gnn/requirements/requirements.txt (line 12)) (6.1.3)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[epath-no-tf]->tfds-nightly==4.5.2.dev202204190046->-r johnsons-clrs-gnn/requirements/requirements.txt (line 12)) (3.17.0)\n",
            "Installing collected packages: jmp, dill, tfds-nightly, dm-haiku\n",
            "Successfully installed dill-0.3.8 dm-haiku-0.0.12 jmp-0.0.4 tfds-nightly-4.5.2.dev202204190046\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd johnsons-clrs-gnn/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oB1ejK-8dGSg",
        "outputId": "a2453841-870d-47ba-8c06-4c8be3298d41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/johnsons-clrs-gnn\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git checkout floydwarshall-test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhjR9-MOjwjr",
        "outputId": "109a1882-179e-4347-c4d7-2c4acefb8077"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Branch 'floydwarshall-test' set up to track remote branch 'floydwarshall-test' from 'origin'.\n",
            "Switched to a new branch 'floydwarshall-test'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gvGzWyhNdxi",
        "outputId": "6ba89a3a-9ec0-4ed2-d0ca-1aac9b74b96e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /conent/drive/L65-pickles"
      ],
      "metadata": {
        "id": "I8Do-p2na9rM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "8cO7z1j-cNOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# trial run to force download of dataset\n",
        "!python -m clrs.examples.run \"--algorithms\" \"johnsons\" \"--batch_size\" \"8\" \"--train_steps\" \"10\" \"--train_lengths\" \"4\" \"--eval_every\" \"10\""
      ],
      "metadata": {
        "id": "ZXNqWmIkeJ1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /tmp/CLRS30/CLRS30_v1.0.0/clrs_dataset/floyd_warshall_train\n",
        "!rm -rf /tmp/CLRS30/CLRS30_v1.0.0/clrs_dataset/floyd_warshall_test\n",
        "!rm -rf /tmp/CLRS30/CLRS30_v1.0.0/clrs_dataset/floyd_warshall_val"
      ],
      "metadata": {
        "id": "JVV_tg09MbL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /tmp/CLRS30/CLRS30_v1.0.0/clrs_dataset/johnsons_test"
      ],
      "metadata": {
        "id": "BOyuKqQloSF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(3):\n",
        "  !python -m clrs.examples.run \"--algorithms\" \"floyd_warshall\" \"--nb_msg_passing_steps\" \"2\" \"--p\" \"0.1,0.2,0.3\" # \"--batch_size\" \"8\" \"--train_steps\" \"100\" \"--train_lengths\" \"4\" \"--eval_every\" \"10\"\n",
        "  !mv losses.pickle /content/drive/MyDrive/L65-pickles/fw-sparse$i-losses.pickle\n",
        "  !mv evals.pickle /content/drive/MyDrive/L65-pickles/fw-sparse$i-evals.pickle\n",
        "  !mv tests.pickle /content/drive/MyDrive/L65-pickles/fw-sparse$i-tests.pickle"
      ],
      "metadata": {
        "id": "MNeL1TP4c5-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(3):\n",
        "  with open(f'/content/drive/MyDrive/L65-pickles/fw-sparse{i}-tests.pickle','rb') as f:\n",
        "    print(pickle.load(f))"
      ],
      "metadata": {
        "id": "e28l0k61cclZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(3):\n",
        "  !python -m clrs.examples.run \"--algorithms\" \"johnsons\" \"--p\" \"0.1,0.2,0.3\" # \"--batch_size\" \"8\" \"--train_steps\" \"100\" \"--train_lengths\" \"4\" \"--eval_every\" \"10\"\n",
        "  !mv losses.pickle /content/drive/MyDrive/L65-pickles/js-sparse$i-losses.pickle\n",
        "  !mv evals.pickle /content/drive/MyDrive/L65-pickles/js-sparse$i-evals.pickle\n",
        "  !mv tests.pickle /content/drive/MyDrive/L65-pickles/js-sparse$i-tests.pickle"
      ],
      "metadata": {
        "id": "Km4n79tPoW1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(3):\n",
        "  with open(f'/content/drive/MyDrive/L65-pickles/js-sparse{i}-tests.pickle','rb') as f:\n",
        "    print(pickle.load(f))"
      ],
      "metadata": {
        "id": "ICbFQ07Scxxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import output\n",
        "output.eval_js('new Audio(\"https://upload.wikimedia.org/wikipedia/commons/0/05/Beep-09.ogg\").play()')"
      ],
      "metadata": {
        "id": "YXMgKtFZ1QOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /tmp/CLRS30/CLRS30_v1.0.0/clrs_dataset/floyd_warshall_test"
      ],
      "metadata": {
        "id": "8LSjAxHidB6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(3):\n",
        "  !python -m clrs.examples.run \"--algorithms\" \"floyd_warshall\" \"--nb_msg_passing_steps\" \"2\" # \"--batch_size\" \"8\" \"--train_steps\" \"100\" \"--train_lengths\" \"4\" \"--eval_every\" \"10\"\n",
        "  !mv losses.pickle /content/drive/MyDrive/L65-pickles/fw$i-losses.pickle\n",
        "  !mv evals.pickle /content/drive/MyDrive/L65-pickles/fw$i-evals.pickle\n",
        "  !mv tests.pickle /content/drive/MyDrive/L65-pickles/fw$i-tests.pickle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eOLvWt3oDr3",
        "outputId": "0369ff76-e81f-4af4-a57c-93c23f817208"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "I0314 02:59:16.850243 138313941204992 run.py:479] Algo floyd_warshall step 3547 current loss 0.502781, current_train_items 113536.\n",
            "I0314 02:59:17.123352 138313941204992 run.py:479] Algo floyd_warshall step 3548 current loss 0.649531, current_train_items 113568.\n",
            "I0314 02:59:17.614460 138313941204992 run.py:479] Algo floyd_warshall step 3549 current loss 1.026976, current_train_items 113600.\n",
            "I0314 02:59:17.650856 138313941204992 run.py:479] Algo floyd_warshall step 3550 current loss 0.046144, current_train_items 113632.\n",
            "I0314 02:59:17.755714 138313941204992 run.py:499] (val) algo floyd_warshall step 3550: {'Pi': 0.87298583984375, 'score': 0.87298583984375, 'examples_seen': 113632, 'step': 3550, 'algorithm': 'floyd_warshall'}\n",
            "I0314 02:59:17.756108 138313941204992 run.py:516] Checkpointing best model, best avg val score was 0.857, current avg val score is 0.873, val scores are: floyd_warshall: 0.873\n",
            "I0314 02:59:17.876849 138313941204992 run.py:479] Algo floyd_warshall step 3551 current loss 0.104924, current_train_items 113664.\n",
            "I0314 02:59:18.041530 138313941204992 run.py:479] Algo floyd_warshall step 3552 current loss 0.413744, current_train_items 113696.\n",
            "I0314 02:59:18.290415 138313941204992 run.py:479] Algo floyd_warshall step 3553 current loss 0.531645, current_train_items 113728.\n",
            "I0314 02:59:18.771831 138313941204992 run.py:479] Algo floyd_warshall step 3554 current loss 0.861404, current_train_items 113760.\n",
            "I0314 02:59:18.810551 138313941204992 run.py:479] Algo floyd_warshall step 3555 current loss 0.044178, current_train_items 113792.\n",
            "I0314 02:59:18.873905 138313941204992 run.py:479] Algo floyd_warshall step 3556 current loss 0.105515, current_train_items 113824.\n",
            "I0314 02:59:19.036819 138313941204992 run.py:479] Algo floyd_warshall step 3557 current loss 0.421706, current_train_items 113856.\n",
            "I0314 02:59:19.295988 138313941204992 run.py:479] Algo floyd_warshall step 3558 current loss 0.564689, current_train_items 113888.\n",
            "I0314 02:59:19.787603 138313941204992 run.py:479] Algo floyd_warshall step 3559 current loss 0.920727, current_train_items 113920.\n",
            "I0314 02:59:19.812932 138313941204992 run.py:479] Algo floyd_warshall step 3560 current loss 0.014915, current_train_items 113952.\n",
            "I0314 02:59:19.857355 138313941204992 run.py:479] Algo floyd_warshall step 3561 current loss 0.125596, current_train_items 113984.\n",
            "I0314 02:59:19.986680 138313941204992 run.py:479] Algo floyd_warshall step 3562 current loss 0.467899, current_train_items 114016.\n",
            "I0314 02:59:20.214012 138313941204992 run.py:479] Algo floyd_warshall step 3563 current loss 0.653721, current_train_items 114048.\n",
            "I0314 02:59:20.644993 138313941204992 run.py:479] Algo floyd_warshall step 3564 current loss 1.074389, current_train_items 114080.\n",
            "I0314 02:59:20.676133 138313941204992 run.py:479] Algo floyd_warshall step 3565 current loss 0.045971, current_train_items 114112.\n",
            "I0314 02:59:20.721024 138313941204992 run.py:479] Algo floyd_warshall step 3566 current loss 0.158546, current_train_items 114144.\n",
            "I0314 02:59:20.851074 138313941204992 run.py:479] Algo floyd_warshall step 3567 current loss 0.346139, current_train_items 114176.\n",
            "I0314 02:59:21.072879 138313941204992 run.py:479] Algo floyd_warshall step 3568 current loss 0.626021, current_train_items 114208.\n",
            "I0314 02:59:21.490170 138313941204992 run.py:479] Algo floyd_warshall step 3569 current loss 0.985692, current_train_items 114240.\n",
            "I0314 02:59:21.513736 138313941204992 run.py:479] Algo floyd_warshall step 3570 current loss 0.013805, current_train_items 114272.\n",
            "I0314 02:59:21.557072 138313941204992 run.py:479] Algo floyd_warshall step 3571 current loss 0.110735, current_train_items 114304.\n",
            "I0314 02:59:21.686268 138313941204992 run.py:479] Algo floyd_warshall step 3572 current loss 0.515618, current_train_items 114336.\n",
            "I0314 02:59:21.914106 138313941204992 run.py:479] Algo floyd_warshall step 3573 current loss 0.650316, current_train_items 114368.\n",
            "I0314 02:59:22.327135 138313941204992 run.py:479] Algo floyd_warshall step 3574 current loss 0.983039, current_train_items 114400.\n",
            "I0314 02:59:22.350087 138313941204992 run.py:479] Algo floyd_warshall step 3575 current loss 0.047654, current_train_items 114432.\n",
            "I0314 02:59:22.394075 138313941204992 run.py:479] Algo floyd_warshall step 3576 current loss 0.173712, current_train_items 114464.\n",
            "I0314 02:59:22.524365 138313941204992 run.py:479] Algo floyd_warshall step 3577 current loss 0.534058, current_train_items 114496.\n",
            "I0314 02:59:22.741301 138313941204992 run.py:479] Algo floyd_warshall step 3578 current loss 0.865801, current_train_items 114528.\n",
            "I0314 02:59:23.151694 138313941204992 run.py:479] Algo floyd_warshall step 3579 current loss 0.958694, current_train_items 114560.\n",
            "I0314 02:59:23.175290 138313941204992 run.py:479] Algo floyd_warshall step 3580 current loss 0.029131, current_train_items 114592.\n",
            "I0314 02:59:23.221970 138313941204992 run.py:479] Algo floyd_warshall step 3581 current loss 0.106795, current_train_items 114624.\n",
            "I0314 02:59:23.352830 138313941204992 run.py:479] Algo floyd_warshall step 3582 current loss 0.477406, current_train_items 114656.\n",
            "I0314 02:59:23.583314 138313941204992 run.py:479] Algo floyd_warshall step 3583 current loss 0.665154, current_train_items 114688.\n",
            "I0314 02:59:23.997988 138313941204992 run.py:479] Algo floyd_warshall step 3584 current loss 1.115045, current_train_items 114720.\n",
            "I0314 02:59:24.022107 138313941204992 run.py:479] Algo floyd_warshall step 3585 current loss 0.068066, current_train_items 114752.\n",
            "I0314 02:59:24.070679 138313941204992 run.py:479] Algo floyd_warshall step 3586 current loss 0.104339, current_train_items 114784.\n",
            "I0314 02:59:24.199846 138313941204992 run.py:479] Algo floyd_warshall step 3587 current loss 0.406905, current_train_items 114816.\n",
            "I0314 02:59:24.429300 138313941204992 run.py:479] Algo floyd_warshall step 3588 current loss 0.670996, current_train_items 114848.\n",
            "I0314 02:59:24.839381 138313941204992 run.py:479] Algo floyd_warshall step 3589 current loss 0.738029, current_train_items 114880.\n",
            "I0314 02:59:24.864082 138313941204992 run.py:479] Algo floyd_warshall step 3590 current loss 0.027116, current_train_items 114912.\n",
            "I0314 02:59:24.909458 138313941204992 run.py:479] Algo floyd_warshall step 3591 current loss 0.177722, current_train_items 114944.\n",
            "I0314 02:59:25.038101 138313941204992 run.py:479] Algo floyd_warshall step 3592 current loss 0.442076, current_train_items 114976.\n",
            "I0314 02:59:25.257309 138313941204992 run.py:479] Algo floyd_warshall step 3593 current loss 0.765488, current_train_items 115008.\n",
            "I0314 02:59:25.677991 138313941204992 run.py:479] Algo floyd_warshall step 3594 current loss 1.206856, current_train_items 115040.\n",
            "I0314 02:59:25.700668 138313941204992 run.py:479] Algo floyd_warshall step 3595 current loss 0.028990, current_train_items 115072.\n",
            "I0314 02:59:25.744803 138313941204992 run.py:479] Algo floyd_warshall step 3596 current loss 0.184300, current_train_items 115104.\n",
            "I0314 02:59:25.884887 138313941204992 run.py:479] Algo floyd_warshall step 3597 current loss 0.448870, current_train_items 115136.\n",
            "I0314 02:59:26.112911 138313941204992 run.py:479] Algo floyd_warshall step 3598 current loss 0.732864, current_train_items 115168.\n",
            "I0314 02:59:26.535626 138313941204992 run.py:479] Algo floyd_warshall step 3599 current loss 1.062251, current_train_items 115200.\n",
            "I0314 02:59:26.558868 138313941204992 run.py:479] Algo floyd_warshall step 3600 current loss 0.050199, current_train_items 115232.\n",
            "I0314 02:59:26.648540 138313941204992 run.py:499] (val) algo floyd_warshall step 3600: {'Pi': 0.85748291015625, 'score': 0.85748291015625, 'examples_seen': 115232, 'step': 3600, 'algorithm': 'floyd_warshall'}\n",
            "I0314 02:59:26.648828 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.873, current avg val score is 0.857, val scores are: floyd_warshall: 0.857\n",
            "I0314 02:59:26.696943 138313941204992 run.py:479] Algo floyd_warshall step 3601 current loss 0.172554, current_train_items 115264.\n",
            "I0314 02:59:26.828154 138313941204992 run.py:479] Algo floyd_warshall step 3602 current loss 0.454235, current_train_items 115296.\n",
            "I0314 02:59:27.054199 138313941204992 run.py:479] Algo floyd_warshall step 3603 current loss 0.578304, current_train_items 115328.\n",
            "I0314 02:59:27.477851 138313941204992 run.py:479] Algo floyd_warshall step 3604 current loss 0.940959, current_train_items 115360.\n",
            "I0314 02:59:27.502572 138313941204992 run.py:479] Algo floyd_warshall step 3605 current loss 0.024431, current_train_items 115392.\n",
            "I0314 02:59:27.546236 138313941204992 run.py:479] Algo floyd_warshall step 3606 current loss 0.173266, current_train_items 115424.\n",
            "I0314 02:59:27.677105 138313941204992 run.py:479] Algo floyd_warshall step 3607 current loss 0.365099, current_train_items 115456.\n",
            "I0314 02:59:27.894630 138313941204992 run.py:479] Algo floyd_warshall step 3608 current loss 0.567071, current_train_items 115488.\n",
            "I0314 02:59:28.290463 138313941204992 run.py:479] Algo floyd_warshall step 3609 current loss 0.824539, current_train_items 115520.\n",
            "I0314 02:59:28.315628 138313941204992 run.py:479] Algo floyd_warshall step 3610 current loss 0.062043, current_train_items 115552.\n",
            "I0314 02:59:28.360606 138313941204992 run.py:479] Algo floyd_warshall step 3611 current loss 0.098351, current_train_items 115584.\n",
            "I0314 02:59:28.490459 138313941204992 run.py:479] Algo floyd_warshall step 3612 current loss 0.373536, current_train_items 115616.\n",
            "I0314 02:59:28.716501 138313941204992 run.py:479] Algo floyd_warshall step 3613 current loss 0.562938, current_train_items 115648.\n",
            "I0314 02:59:29.135058 138313941204992 run.py:479] Algo floyd_warshall step 3614 current loss 1.084957, current_train_items 115680.\n",
            "I0314 02:59:29.158551 138313941204992 run.py:479] Algo floyd_warshall step 3615 current loss 0.038778, current_train_items 115712.\n",
            "I0314 02:59:29.203512 138313941204992 run.py:479] Algo floyd_warshall step 3616 current loss 0.193435, current_train_items 115744.\n",
            "I0314 02:59:29.337851 138313941204992 run.py:479] Algo floyd_warshall step 3617 current loss 0.551017, current_train_items 115776.\n",
            "I0314 02:59:29.557825 138313941204992 run.py:479] Algo floyd_warshall step 3618 current loss 0.713339, current_train_items 115808.\n",
            "I0314 02:59:30.051749 138313941204992 run.py:479] Algo floyd_warshall step 3619 current loss 1.410892, current_train_items 115840.\n",
            "I0314 02:59:30.086881 138313941204992 run.py:479] Algo floyd_warshall step 3620 current loss 0.050975, current_train_items 115872.\n",
            "I0314 02:59:30.142257 138313941204992 run.py:479] Algo floyd_warshall step 3621 current loss 0.129415, current_train_items 115904.\n",
            "I0314 02:59:30.303308 138313941204992 run.py:479] Algo floyd_warshall step 3622 current loss 0.587743, current_train_items 115936.\n",
            "I0314 02:59:30.591223 138313941204992 run.py:479] Algo floyd_warshall step 3623 current loss 0.669840, current_train_items 115968.\n",
            "I0314 02:59:31.096156 138313941204992 run.py:479] Algo floyd_warshall step 3624 current loss 1.188905, current_train_items 116000.\n",
            "I0314 02:59:31.128957 138313941204992 run.py:479] Algo floyd_warshall step 3625 current loss 0.036055, current_train_items 116032.\n",
            "I0314 02:59:31.188060 138313941204992 run.py:479] Algo floyd_warshall step 3626 current loss 0.159639, current_train_items 116064.\n",
            "I0314 02:59:31.343649 138313941204992 run.py:479] Algo floyd_warshall step 3627 current loss 0.307512, current_train_items 116096.\n",
            "I0314 02:59:31.599684 138313941204992 run.py:479] Algo floyd_warshall step 3628 current loss 0.612257, current_train_items 116128.\n",
            "I0314 02:59:32.101334 138313941204992 run.py:479] Algo floyd_warshall step 3629 current loss 1.074823, current_train_items 116160.\n",
            "I0314 02:59:32.136790 138313941204992 run.py:479] Algo floyd_warshall step 3630 current loss 0.038966, current_train_items 116192.\n",
            "I0314 02:59:32.199743 138313941204992 run.py:479] Algo floyd_warshall step 3631 current loss 0.277032, current_train_items 116224.\n",
            "I0314 02:59:32.363535 138313941204992 run.py:479] Algo floyd_warshall step 3632 current loss 0.434628, current_train_items 116256.\n",
            "I0314 02:59:32.616370 138313941204992 run.py:479] Algo floyd_warshall step 3633 current loss 0.539666, current_train_items 116288.\n",
            "I0314 02:59:33.049640 138313941204992 run.py:479] Algo floyd_warshall step 3634 current loss 0.854385, current_train_items 116320.\n",
            "I0314 02:59:33.074419 138313941204992 run.py:479] Algo floyd_warshall step 3635 current loss 0.119180, current_train_items 116352.\n",
            "I0314 02:59:33.119876 138313941204992 run.py:479] Algo floyd_warshall step 3636 current loss 0.115436, current_train_items 116384.\n",
            "I0314 02:59:33.249854 138313941204992 run.py:479] Algo floyd_warshall step 3637 current loss 0.419447, current_train_items 116416.\n",
            "I0314 02:59:33.483661 138313941204992 run.py:479] Algo floyd_warshall step 3638 current loss 0.740294, current_train_items 116448.\n",
            "I0314 02:59:33.888931 138313941204992 run.py:479] Algo floyd_warshall step 3639 current loss 1.011486, current_train_items 116480.\n",
            "I0314 02:59:33.911792 138313941204992 run.py:479] Algo floyd_warshall step 3640 current loss 0.039819, current_train_items 116512.\n",
            "I0314 02:59:33.957342 138313941204992 run.py:479] Algo floyd_warshall step 3641 current loss 0.162462, current_train_items 116544.\n",
            "I0314 02:59:34.087308 138313941204992 run.py:479] Algo floyd_warshall step 3642 current loss 0.467397, current_train_items 116576.\n",
            "I0314 02:59:34.302859 138313941204992 run.py:479] Algo floyd_warshall step 3643 current loss 0.492639, current_train_items 116608.\n",
            "I0314 02:59:34.731533 138313941204992 run.py:479] Algo floyd_warshall step 3644 current loss 1.011094, current_train_items 116640.\n",
            "I0314 02:59:34.756331 138313941204992 run.py:479] Algo floyd_warshall step 3645 current loss 0.033213, current_train_items 116672.\n",
            "I0314 02:59:34.803008 138313941204992 run.py:479] Algo floyd_warshall step 3646 current loss 0.136439, current_train_items 116704.\n",
            "I0314 02:59:34.935361 138313941204992 run.py:479] Algo floyd_warshall step 3647 current loss 0.422845, current_train_items 116736.\n",
            "I0314 02:59:35.159575 138313941204992 run.py:479] Algo floyd_warshall step 3648 current loss 0.656791, current_train_items 116768.\n",
            "I0314 02:59:35.578537 138313941204992 run.py:479] Algo floyd_warshall step 3649 current loss 0.973270, current_train_items 116800.\n",
            "I0314 02:59:35.603211 138313941204992 run.py:479] Algo floyd_warshall step 3650 current loss 0.035669, current_train_items 116832.\n",
            "I0314 02:59:35.691217 138313941204992 run.py:499] (val) algo floyd_warshall step 3650: {'Pi': 0.81549072265625, 'score': 0.81549072265625, 'examples_seen': 116832, 'step': 3650, 'algorithm': 'floyd_warshall'}\n",
            "I0314 02:59:35.691454 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.873, current avg val score is 0.815, val scores are: floyd_warshall: 0.815\n",
            "I0314 02:59:35.738436 138313941204992 run.py:479] Algo floyd_warshall step 3651 current loss 0.114875, current_train_items 116864.\n",
            "I0314 02:59:35.868477 138313941204992 run.py:479] Algo floyd_warshall step 3652 current loss 0.391661, current_train_items 116896.\n",
            "I0314 02:59:36.089947 138313941204992 run.py:479] Algo floyd_warshall step 3653 current loss 0.636284, current_train_items 116928.\n",
            "I0314 02:59:36.509551 138313941204992 run.py:479] Algo floyd_warshall step 3654 current loss 0.954538, current_train_items 116960.\n",
            "I0314 02:59:36.534465 138313941204992 run.py:479] Algo floyd_warshall step 3655 current loss 0.020326, current_train_items 116992.\n",
            "I0314 02:59:36.579553 138313941204992 run.py:479] Algo floyd_warshall step 3656 current loss 0.258425, current_train_items 117024.\n",
            "I0314 02:59:36.709825 138313941204992 run.py:479] Algo floyd_warshall step 3657 current loss 0.546286, current_train_items 117056.\n",
            "I0314 02:59:36.926164 138313941204992 run.py:479] Algo floyd_warshall step 3658 current loss 0.673428, current_train_items 117088.\n",
            "I0314 02:59:37.336466 138313941204992 run.py:479] Algo floyd_warshall step 3659 current loss 1.027180, current_train_items 117120.\n",
            "I0314 02:59:37.362979 138313941204992 run.py:479] Algo floyd_warshall step 3660 current loss 0.022706, current_train_items 117152.\n",
            "I0314 02:59:37.407323 138313941204992 run.py:479] Algo floyd_warshall step 3661 current loss 0.176276, current_train_items 117184.\n",
            "I0314 02:59:37.531910 138313941204992 run.py:479] Algo floyd_warshall step 3662 current loss 0.302907, current_train_items 117216.\n",
            "I0314 02:59:37.753401 138313941204992 run.py:479] Algo floyd_warshall step 3663 current loss 0.569933, current_train_items 117248.\n",
            "I0314 02:59:38.164417 138313941204992 run.py:479] Algo floyd_warshall step 3664 current loss 0.979863, current_train_items 117280.\n",
            "I0314 02:59:38.189104 138313941204992 run.py:479] Algo floyd_warshall step 3665 current loss 0.032519, current_train_items 117312.\n",
            "I0314 02:59:38.234522 138313941204992 run.py:479] Algo floyd_warshall step 3666 current loss 0.216780, current_train_items 117344.\n",
            "I0314 02:59:38.361689 138313941204992 run.py:479] Algo floyd_warshall step 3667 current loss 0.393517, current_train_items 117376.\n",
            "I0314 02:59:38.587796 138313941204992 run.py:479] Algo floyd_warshall step 3668 current loss 0.654366, current_train_items 117408.\n",
            "I0314 02:59:39.007976 138313941204992 run.py:479] Algo floyd_warshall step 3669 current loss 1.100676, current_train_items 117440.\n",
            "I0314 02:59:39.030956 138313941204992 run.py:479] Algo floyd_warshall step 3670 current loss 0.035476, current_train_items 117472.\n",
            "I0314 02:59:39.076630 138313941204992 run.py:479] Algo floyd_warshall step 3671 current loss 0.122478, current_train_items 117504.\n",
            "I0314 02:59:39.207895 138313941204992 run.py:479] Algo floyd_warshall step 3672 current loss 0.421324, current_train_items 117536.\n",
            "I0314 02:59:39.427529 138313941204992 run.py:479] Algo floyd_warshall step 3673 current loss 0.719280, current_train_items 117568.\n",
            "I0314 02:59:39.849897 138313941204992 run.py:479] Algo floyd_warshall step 3674 current loss 0.942852, current_train_items 117600.\n",
            "I0314 02:59:39.873222 138313941204992 run.py:479] Algo floyd_warshall step 3675 current loss 0.025203, current_train_items 117632.\n",
            "I0314 02:59:39.917964 138313941204992 run.py:479] Algo floyd_warshall step 3676 current loss 0.122423, current_train_items 117664.\n",
            "I0314 02:59:40.045232 138313941204992 run.py:479] Algo floyd_warshall step 3677 current loss 0.425838, current_train_items 117696.\n",
            "I0314 02:59:40.270514 138313941204992 run.py:479] Algo floyd_warshall step 3678 current loss 0.697664, current_train_items 117728.\n",
            "I0314 02:59:40.682266 138313941204992 run.py:479] Algo floyd_warshall step 3679 current loss 0.968144, current_train_items 117760.\n",
            "I0314 02:59:40.706412 138313941204992 run.py:479] Algo floyd_warshall step 3680 current loss 0.079493, current_train_items 117792.\n",
            "I0314 02:59:40.751460 138313941204992 run.py:479] Algo floyd_warshall step 3681 current loss 0.135530, current_train_items 117824.\n",
            "I0314 02:59:40.884031 138313941204992 run.py:479] Algo floyd_warshall step 3682 current loss 0.359688, current_train_items 117856.\n",
            "I0314 02:59:41.101710 138313941204992 run.py:479] Algo floyd_warshall step 3683 current loss 0.579395, current_train_items 117888.\n",
            "I0314 02:59:41.515027 138313941204992 run.py:479] Algo floyd_warshall step 3684 current loss 0.836332, current_train_items 117920.\n",
            "I0314 02:59:41.539493 138313941204992 run.py:479] Algo floyd_warshall step 3685 current loss 0.020163, current_train_items 117952.\n",
            "I0314 02:59:41.584687 138313941204992 run.py:479] Algo floyd_warshall step 3686 current loss 0.136217, current_train_items 117984.\n",
            "I0314 02:59:41.715688 138313941204992 run.py:479] Algo floyd_warshall step 3687 current loss 0.483646, current_train_items 118016.\n",
            "I0314 02:59:41.926859 138313941204992 run.py:479] Algo floyd_warshall step 3688 current loss 0.710679, current_train_items 118048.\n",
            "I0314 02:59:42.326021 138313941204992 run.py:479] Algo floyd_warshall step 3689 current loss 1.185613, current_train_items 118080.\n",
            "I0314 02:59:42.348693 138313941204992 run.py:479] Algo floyd_warshall step 3690 current loss 0.032144, current_train_items 118112.\n",
            "I0314 02:59:42.397536 138313941204992 run.py:479] Algo floyd_warshall step 3691 current loss 0.078182, current_train_items 118144.\n",
            "I0314 02:59:42.526834 138313941204992 run.py:479] Algo floyd_warshall step 3692 current loss 0.513628, current_train_items 118176.\n",
            "I0314 02:59:42.740557 138313941204992 run.py:479] Algo floyd_warshall step 3693 current loss 0.564677, current_train_items 118208.\n",
            "I0314 02:59:43.235944 138313941204992 run.py:479] Algo floyd_warshall step 3694 current loss 0.900389, current_train_items 118240.\n",
            "I0314 02:59:43.277631 138313941204992 run.py:479] Algo floyd_warshall step 3695 current loss 0.047366, current_train_items 118272.\n",
            "I0314 02:59:43.332039 138313941204992 run.py:479] Algo floyd_warshall step 3696 current loss 0.086255, current_train_items 118304.\n",
            "I0314 02:59:43.495289 138313941204992 run.py:479] Algo floyd_warshall step 3697 current loss 0.432011, current_train_items 118336.\n",
            "I0314 02:59:43.761429 138313941204992 run.py:479] Algo floyd_warshall step 3698 current loss 0.635501, current_train_items 118368.\n",
            "I0314 02:59:44.253994 138313941204992 run.py:479] Algo floyd_warshall step 3699 current loss 0.923269, current_train_items 118400.\n",
            "I0314 02:59:44.290666 138313941204992 run.py:479] Algo floyd_warshall step 3700 current loss 0.030943, current_train_items 118432.\n",
            "I0314 02:59:44.413016 138313941204992 run.py:499] (val) algo floyd_warshall step 3700: {'Pi': 0.84613037109375, 'score': 0.84613037109375, 'examples_seen': 118432, 'step': 3700, 'algorithm': 'floyd_warshall'}\n",
            "I0314 02:59:44.413422 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.873, current avg val score is 0.846, val scores are: floyd_warshall: 0.846\n",
            "I0314 02:59:44.474151 138313941204992 run.py:479] Algo floyd_warshall step 3701 current loss 0.111064, current_train_items 118464.\n",
            "I0314 02:59:44.651034 138313941204992 run.py:479] Algo floyd_warshall step 3702 current loss 0.559124, current_train_items 118496.\n",
            "I0314 02:59:44.919969 138313941204992 run.py:479] Algo floyd_warshall step 3703 current loss 0.724959, current_train_items 118528.\n",
            "I0314 02:59:45.442794 138313941204992 run.py:479] Algo floyd_warshall step 3704 current loss 0.972949, current_train_items 118560.\n",
            "I0314 02:59:45.484492 138313941204992 run.py:479] Algo floyd_warshall step 3705 current loss 0.143495, current_train_items 118592.\n",
            "I0314 02:59:45.552217 138313941204992 run.py:479] Algo floyd_warshall step 3706 current loss 0.113768, current_train_items 118624.\n",
            "I0314 02:59:45.716241 138313941204992 run.py:479] Algo floyd_warshall step 3707 current loss 0.516904, current_train_items 118656.\n",
            "I0314 02:59:45.940964 138313941204992 run.py:479] Algo floyd_warshall step 3708 current loss 0.561557, current_train_items 118688.\n",
            "I0314 02:59:46.367114 138313941204992 run.py:479] Algo floyd_warshall step 3709 current loss 1.052123, current_train_items 118720.\n",
            "I0314 02:59:46.389749 138313941204992 run.py:479] Algo floyd_warshall step 3710 current loss 0.013659, current_train_items 118752.\n",
            "I0314 02:59:46.438070 138313941204992 run.py:479] Algo floyd_warshall step 3711 current loss 0.234541, current_train_items 118784.\n",
            "I0314 02:59:46.565501 138313941204992 run.py:479] Algo floyd_warshall step 3712 current loss 0.417525, current_train_items 118816.\n",
            "I0314 02:59:46.784296 138313941204992 run.py:479] Algo floyd_warshall step 3713 current loss 0.680568, current_train_items 118848.\n",
            "I0314 02:59:47.186503 138313941204992 run.py:479] Algo floyd_warshall step 3714 current loss 0.931670, current_train_items 118880.\n",
            "I0314 02:59:47.211353 138313941204992 run.py:479] Algo floyd_warshall step 3715 current loss 0.067621, current_train_items 118912.\n",
            "I0314 02:59:47.255822 138313941204992 run.py:479] Algo floyd_warshall step 3716 current loss 0.113858, current_train_items 118944.\n",
            "I0314 02:59:47.384083 138313941204992 run.py:479] Algo floyd_warshall step 3717 current loss 0.339867, current_train_items 118976.\n",
            "I0314 02:59:47.604045 138313941204992 run.py:479] Algo floyd_warshall step 3718 current loss 0.597185, current_train_items 119008.\n",
            "I0314 02:59:48.022825 138313941204992 run.py:479] Algo floyd_warshall step 3719 current loss 0.915625, current_train_items 119040.\n",
            "I0314 02:59:48.045928 138313941204992 run.py:479] Algo floyd_warshall step 3720 current loss 0.010518, current_train_items 119072.\n",
            "I0314 02:59:48.090496 138313941204992 run.py:479] Algo floyd_warshall step 3721 current loss 0.086455, current_train_items 119104.\n",
            "I0314 02:59:48.220350 138313941204992 run.py:479] Algo floyd_warshall step 3722 current loss 0.530578, current_train_items 119136.\n",
            "I0314 02:59:48.446453 138313941204992 run.py:479] Algo floyd_warshall step 3723 current loss 0.814493, current_train_items 119168.\n",
            "I0314 02:59:48.886432 138313941204992 run.py:479] Algo floyd_warshall step 3724 current loss 0.942521, current_train_items 119200.\n",
            "I0314 02:59:48.910499 138313941204992 run.py:479] Algo floyd_warshall step 3725 current loss 0.045988, current_train_items 119232.\n",
            "I0314 02:59:48.955320 138313941204992 run.py:479] Algo floyd_warshall step 3726 current loss 0.231650, current_train_items 119264.\n",
            "I0314 02:59:49.083261 138313941204992 run.py:479] Algo floyd_warshall step 3727 current loss 0.337545, current_train_items 119296.\n",
            "I0314 02:59:49.296341 138313941204992 run.py:479] Algo floyd_warshall step 3728 current loss 0.525422, current_train_items 119328.\n",
            "I0314 02:59:49.711638 138313941204992 run.py:479] Algo floyd_warshall step 3729 current loss 0.971088, current_train_items 119360.\n",
            "I0314 02:59:49.736035 138313941204992 run.py:479] Algo floyd_warshall step 3730 current loss 0.102749, current_train_items 119392.\n",
            "I0314 02:59:49.784354 138313941204992 run.py:479] Algo floyd_warshall step 3731 current loss 0.184232, current_train_items 119424.\n",
            "I0314 02:59:49.914325 138313941204992 run.py:479] Algo floyd_warshall step 3732 current loss 0.376034, current_train_items 119456.\n",
            "I0314 02:59:50.138652 138313941204992 run.py:479] Algo floyd_warshall step 3733 current loss 0.579049, current_train_items 119488.\n",
            "I0314 02:59:50.555977 138313941204992 run.py:479] Algo floyd_warshall step 3734 current loss 0.747380, current_train_items 119520.\n",
            "I0314 02:59:50.580419 138313941204992 run.py:479] Algo floyd_warshall step 3735 current loss 0.013689, current_train_items 119552.\n",
            "I0314 02:59:50.624463 138313941204992 run.py:479] Algo floyd_warshall step 3736 current loss 0.099436, current_train_items 119584.\n",
            "I0314 02:59:50.753285 138313941204992 run.py:479] Algo floyd_warshall step 3737 current loss 0.406651, current_train_items 119616.\n",
            "I0314 02:59:50.985297 138313941204992 run.py:479] Algo floyd_warshall step 3738 current loss 0.653636, current_train_items 119648.\n",
            "I0314 02:59:51.390594 138313941204992 run.py:479] Algo floyd_warshall step 3739 current loss 0.806999, current_train_items 119680.\n",
            "I0314 02:59:51.415747 138313941204992 run.py:479] Algo floyd_warshall step 3740 current loss 0.021162, current_train_items 119712.\n",
            "I0314 02:59:51.463056 138313941204992 run.py:479] Algo floyd_warshall step 3741 current loss 0.121523, current_train_items 119744.\n",
            "I0314 02:59:51.596165 138313941204992 run.py:479] Algo floyd_warshall step 3742 current loss 0.488134, current_train_items 119776.\n",
            "I0314 02:59:51.818689 138313941204992 run.py:479] Algo floyd_warshall step 3743 current loss 0.690117, current_train_items 119808.\n",
            "I0314 02:59:52.233127 138313941204992 run.py:479] Algo floyd_warshall step 3744 current loss 0.937311, current_train_items 119840.\n",
            "I0314 02:59:52.256764 138313941204992 run.py:479] Algo floyd_warshall step 3745 current loss 0.033737, current_train_items 119872.\n",
            "I0314 02:59:52.303020 138313941204992 run.py:479] Algo floyd_warshall step 3746 current loss 0.117799, current_train_items 119904.\n",
            "I0314 02:59:52.431498 138313941204992 run.py:479] Algo floyd_warshall step 3747 current loss 0.316365, current_train_items 119936.\n",
            "I0314 02:59:52.664247 138313941204992 run.py:479] Algo floyd_warshall step 3748 current loss 0.666019, current_train_items 119968.\n",
            "I0314 02:59:53.071066 138313941204992 run.py:479] Algo floyd_warshall step 3749 current loss 0.905827, current_train_items 120000.\n",
            "I0314 02:59:53.096030 138313941204992 run.py:479] Algo floyd_warshall step 3750 current loss 0.032365, current_train_items 120032.\n",
            "I0314 02:59:53.184377 138313941204992 run.py:499] (val) algo floyd_warshall step 3750: {'Pi': 0.85791015625, 'score': 0.85791015625, 'examples_seen': 120032, 'step': 3750, 'algorithm': 'floyd_warshall'}\n",
            "I0314 02:59:53.184606 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.873, current avg val score is 0.858, val scores are: floyd_warshall: 0.858\n",
            "I0314 02:59:53.232129 138313941204992 run.py:479] Algo floyd_warshall step 3751 current loss 0.129826, current_train_items 120064.\n",
            "I0314 02:59:53.362007 138313941204992 run.py:479] Algo floyd_warshall step 3752 current loss 0.334191, current_train_items 120096.\n",
            "I0314 02:59:53.588939 138313941204992 run.py:479] Algo floyd_warshall step 3753 current loss 0.699376, current_train_items 120128.\n",
            "I0314 02:59:54.021005 138313941204992 run.py:479] Algo floyd_warshall step 3754 current loss 1.050311, current_train_items 120160.\n",
            "I0314 02:59:54.047581 138313941204992 run.py:479] Algo floyd_warshall step 3755 current loss 0.040644, current_train_items 120192.\n",
            "I0314 02:59:54.094292 138313941204992 run.py:479] Algo floyd_warshall step 3756 current loss 0.118279, current_train_items 120224.\n",
            "I0314 02:59:54.226047 138313941204992 run.py:479] Algo floyd_warshall step 3757 current loss 0.421565, current_train_items 120256.\n",
            "I0314 02:59:54.448708 138313941204992 run.py:479] Algo floyd_warshall step 3758 current loss 0.572142, current_train_items 120288.\n",
            "I0314 02:59:54.855997 138313941204992 run.py:479] Algo floyd_warshall step 3759 current loss 0.852250, current_train_items 120320.\n",
            "I0314 02:59:54.879809 138313941204992 run.py:479] Algo floyd_warshall step 3760 current loss 0.025731, current_train_items 120352.\n",
            "I0314 02:59:54.924273 138313941204992 run.py:479] Algo floyd_warshall step 3761 current loss 0.113814, current_train_items 120384.\n",
            "I0314 02:59:55.055181 138313941204992 run.py:479] Algo floyd_warshall step 3762 current loss 0.462629, current_train_items 120416.\n",
            "I0314 02:59:55.277223 138313941204992 run.py:479] Algo floyd_warshall step 3763 current loss 0.547126, current_train_items 120448.\n",
            "I0314 02:59:55.688429 138313941204992 run.py:479] Algo floyd_warshall step 3764 current loss 1.019106, current_train_items 120480.\n",
            "I0314 02:59:55.726225 138313941204992 run.py:479] Algo floyd_warshall step 3765 current loss 0.090027, current_train_items 120512.\n",
            "I0314 02:59:55.785788 138313941204992 run.py:479] Algo floyd_warshall step 3766 current loss 0.089807, current_train_items 120544.\n",
            "I0314 02:59:55.946607 138313941204992 run.py:479] Algo floyd_warshall step 3767 current loss 0.339343, current_train_items 120576.\n",
            "I0314 02:59:56.221691 138313941204992 run.py:479] Algo floyd_warshall step 3768 current loss 0.680699, current_train_items 120608.\n",
            "I0314 02:59:56.730360 138313941204992 run.py:479] Algo floyd_warshall step 3769 current loss 0.997942, current_train_items 120640.\n",
            "I0314 02:59:56.767882 138313941204992 run.py:479] Algo floyd_warshall step 3770 current loss 0.050855, current_train_items 120672.\n",
            "I0314 02:59:56.829351 138313941204992 run.py:479] Algo floyd_warshall step 3771 current loss 0.148282, current_train_items 120704.\n",
            "I0314 02:59:56.981077 138313941204992 run.py:479] Algo floyd_warshall step 3772 current loss 0.399043, current_train_items 120736.\n",
            "I0314 02:59:57.236344 138313941204992 run.py:479] Algo floyd_warshall step 3773 current loss 0.640198, current_train_items 120768.\n",
            "I0314 02:59:57.724708 138313941204992 run.py:479] Algo floyd_warshall step 3774 current loss 0.959789, current_train_items 120800.\n",
            "I0314 02:59:57.761677 138313941204992 run.py:479] Algo floyd_warshall step 3775 current loss 0.038947, current_train_items 120832.\n",
            "I0314 02:59:57.825776 138313941204992 run.py:479] Algo floyd_warshall step 3776 current loss 0.124961, current_train_items 120864.\n",
            "I0314 02:59:57.977188 138313941204992 run.py:479] Algo floyd_warshall step 3777 current loss 0.284350, current_train_items 120896.\n",
            "I0314 02:59:58.242003 138313941204992 run.py:479] Algo floyd_warshall step 3778 current loss 0.513829, current_train_items 120928.\n",
            "I0314 02:59:58.721791 138313941204992 run.py:479] Algo floyd_warshall step 3779 current loss 0.831490, current_train_items 120960.\n",
            "I0314 02:59:58.760308 138313941204992 run.py:479] Algo floyd_warshall step 3780 current loss 0.038596, current_train_items 120992.\n",
            "I0314 02:59:58.805025 138313941204992 run.py:479] Algo floyd_warshall step 3781 current loss 0.092481, current_train_items 121024.\n",
            "I0314 02:59:58.944553 138313941204992 run.py:479] Algo floyd_warshall step 3782 current loss 0.427472, current_train_items 121056.\n",
            "I0314 02:59:59.163907 138313941204992 run.py:479] Algo floyd_warshall step 3783 current loss 0.612307, current_train_items 121088.\n",
            "I0314 02:59:59.565670 138313941204992 run.py:479] Algo floyd_warshall step 3784 current loss 0.810427, current_train_items 121120.\n",
            "I0314 02:59:59.589524 138313941204992 run.py:479] Algo floyd_warshall step 3785 current loss 0.026976, current_train_items 121152.\n",
            "I0314 02:59:59.634671 138313941204992 run.py:479] Algo floyd_warshall step 3786 current loss 0.102859, current_train_items 121184.\n",
            "I0314 02:59:59.767333 138313941204992 run.py:479] Algo floyd_warshall step 3787 current loss 0.481512, current_train_items 121216.\n",
            "I0314 02:59:59.995001 138313941204992 run.py:479] Algo floyd_warshall step 3788 current loss 0.619577, current_train_items 121248.\n",
            "I0314 03:00:00.403655 138313941204992 run.py:479] Algo floyd_warshall step 3789 current loss 0.993893, current_train_items 121280.\n",
            "I0314 03:00:00.427558 138313941204992 run.py:479] Algo floyd_warshall step 3790 current loss 0.034834, current_train_items 121312.\n",
            "I0314 03:00:00.470530 138313941204992 run.py:479] Algo floyd_warshall step 3791 current loss 0.138436, current_train_items 121344.\n",
            "I0314 03:00:00.597276 138313941204992 run.py:479] Algo floyd_warshall step 3792 current loss 0.328619, current_train_items 121376.\n",
            "I0314 03:00:00.822664 138313941204992 run.py:479] Algo floyd_warshall step 3793 current loss 0.610286, current_train_items 121408.\n",
            "I0314 03:00:01.243988 138313941204992 run.py:479] Algo floyd_warshall step 3794 current loss 1.007383, current_train_items 121440.\n",
            "I0314 03:00:01.267526 138313941204992 run.py:479] Algo floyd_warshall step 3795 current loss 0.023971, current_train_items 121472.\n",
            "I0314 03:00:01.310548 138313941204992 run.py:479] Algo floyd_warshall step 3796 current loss 0.085419, current_train_items 121504.\n",
            "I0314 03:00:01.439187 138313941204992 run.py:479] Algo floyd_warshall step 3797 current loss 0.360042, current_train_items 121536.\n",
            "I0314 03:00:01.652754 138313941204992 run.py:479] Algo floyd_warshall step 3798 current loss 0.560535, current_train_items 121568.\n",
            "I0314 03:00:02.060914 138313941204992 run.py:479] Algo floyd_warshall step 3799 current loss 0.890878, current_train_items 121600.\n",
            "I0314 03:00:02.083563 138313941204992 run.py:479] Algo floyd_warshall step 3800 current loss 0.092565, current_train_items 121632.\n",
            "I0314 03:00:02.170595 138313941204992 run.py:499] (val) algo floyd_warshall step 3800: {'Pi': 0.85137939453125, 'score': 0.85137939453125, 'examples_seen': 121632, 'step': 3800, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:00:02.170913 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.873, current avg val score is 0.851, val scores are: floyd_warshall: 0.851\n",
            "I0314 03:00:02.219471 138313941204992 run.py:479] Algo floyd_warshall step 3801 current loss 0.126018, current_train_items 121664.\n",
            "I0314 03:00:02.352958 138313941204992 run.py:479] Algo floyd_warshall step 3802 current loss 0.367537, current_train_items 121696.\n",
            "I0314 03:00:02.572675 138313941204992 run.py:479] Algo floyd_warshall step 3803 current loss 0.674499, current_train_items 121728.\n",
            "I0314 03:00:02.985445 138313941204992 run.py:479] Algo floyd_warshall step 3804 current loss 0.919831, current_train_items 121760.\n",
            "I0314 03:00:03.010872 138313941204992 run.py:479] Algo floyd_warshall step 3805 current loss 0.009957, current_train_items 121792.\n",
            "I0314 03:00:03.055015 138313941204992 run.py:479] Algo floyd_warshall step 3806 current loss 0.087508, current_train_items 121824.\n",
            "I0314 03:00:03.190520 138313941204992 run.py:479] Algo floyd_warshall step 3807 current loss 0.420477, current_train_items 121856.\n",
            "I0314 03:00:03.415229 138313941204992 run.py:479] Algo floyd_warshall step 3808 current loss 0.527893, current_train_items 121888.\n",
            "I0314 03:00:03.839890 138313941204992 run.py:479] Algo floyd_warshall step 3809 current loss 0.992257, current_train_items 121920.\n",
            "I0314 03:00:03.864138 138313941204992 run.py:479] Algo floyd_warshall step 3810 current loss 0.030963, current_train_items 121952.\n",
            "I0314 03:00:03.908643 138313941204992 run.py:479] Algo floyd_warshall step 3811 current loss 0.148258, current_train_items 121984.\n",
            "I0314 03:00:04.048125 138313941204992 run.py:479] Algo floyd_warshall step 3812 current loss 0.400349, current_train_items 122016.\n",
            "I0314 03:00:04.263396 138313941204992 run.py:479] Algo floyd_warshall step 3813 current loss 0.589941, current_train_items 122048.\n",
            "I0314 03:00:04.673635 138313941204992 run.py:479] Algo floyd_warshall step 3814 current loss 0.960855, current_train_items 122080.\n",
            "I0314 03:00:04.697949 138313941204992 run.py:479] Algo floyd_warshall step 3815 current loss 0.016051, current_train_items 122112.\n",
            "I0314 03:00:04.743193 138313941204992 run.py:479] Algo floyd_warshall step 3816 current loss 0.103495, current_train_items 122144.\n",
            "I0314 03:00:04.875319 138313941204992 run.py:479] Algo floyd_warshall step 3817 current loss 0.420434, current_train_items 122176.\n",
            "I0314 03:00:05.085629 138313941204992 run.py:479] Algo floyd_warshall step 3818 current loss 0.448631, current_train_items 122208.\n",
            "I0314 03:00:05.501358 138313941204992 run.py:479] Algo floyd_warshall step 3819 current loss 1.202752, current_train_items 122240.\n",
            "I0314 03:00:05.525290 138313941204992 run.py:479] Algo floyd_warshall step 3820 current loss 0.022893, current_train_items 122272.\n",
            "I0314 03:00:05.569620 138313941204992 run.py:479] Algo floyd_warshall step 3821 current loss 0.105193, current_train_items 122304.\n",
            "I0314 03:00:05.700168 138313941204992 run.py:479] Algo floyd_warshall step 3822 current loss 0.355704, current_train_items 122336.\n",
            "I0314 03:00:05.930653 138313941204992 run.py:479] Algo floyd_warshall step 3823 current loss 0.629537, current_train_items 122368.\n",
            "I0314 03:00:06.357103 138313941204992 run.py:479] Algo floyd_warshall step 3824 current loss 0.965253, current_train_items 122400.\n",
            "I0314 03:00:06.379845 138313941204992 run.py:479] Algo floyd_warshall step 3825 current loss 0.014745, current_train_items 122432.\n",
            "I0314 03:00:06.425819 138313941204992 run.py:479] Algo floyd_warshall step 3826 current loss 0.210501, current_train_items 122464.\n",
            "I0314 03:00:06.557233 138313941204992 run.py:479] Algo floyd_warshall step 3827 current loss 0.507266, current_train_items 122496.\n",
            "I0314 03:00:06.773283 138313941204992 run.py:479] Algo floyd_warshall step 3828 current loss 0.592714, current_train_items 122528.\n",
            "I0314 03:00:07.193364 138313941204992 run.py:479] Algo floyd_warshall step 3829 current loss 0.960648, current_train_items 122560.\n",
            "I0314 03:00:07.218063 138313941204992 run.py:479] Algo floyd_warshall step 3830 current loss 0.080678, current_train_items 122592.\n",
            "I0314 03:00:07.261935 138313941204992 run.py:479] Algo floyd_warshall step 3831 current loss 0.165704, current_train_items 122624.\n",
            "I0314 03:00:07.391376 138313941204992 run.py:479] Algo floyd_warshall step 3832 current loss 0.356335, current_train_items 122656.\n",
            "I0314 03:00:07.611059 138313941204992 run.py:479] Algo floyd_warshall step 3833 current loss 0.565612, current_train_items 122688.\n",
            "I0314 03:00:08.034658 138313941204992 run.py:479] Algo floyd_warshall step 3834 current loss 0.921694, current_train_items 122720.\n",
            "I0314 03:00:08.067886 138313941204992 run.py:479] Algo floyd_warshall step 3835 current loss 0.022732, current_train_items 122752.\n",
            "I0314 03:00:08.112308 138313941204992 run.py:479] Algo floyd_warshall step 3836 current loss 0.111722, current_train_items 122784.\n",
            "I0314 03:00:08.241687 138313941204992 run.py:479] Algo floyd_warshall step 3837 current loss 0.356373, current_train_items 122816.\n",
            "I0314 03:00:08.470353 138313941204992 run.py:479] Algo floyd_warshall step 3838 current loss 0.578685, current_train_items 122848.\n",
            "I0314 03:00:08.880132 138313941204992 run.py:479] Algo floyd_warshall step 3839 current loss 0.897989, current_train_items 122880.\n",
            "I0314 03:00:08.912690 138313941204992 run.py:479] Algo floyd_warshall step 3840 current loss 0.023974, current_train_items 122912.\n",
            "I0314 03:00:08.970052 138313941204992 run.py:479] Algo floyd_warshall step 3841 current loss 0.101034, current_train_items 122944.\n",
            "I0314 03:00:09.134168 138313941204992 run.py:479] Algo floyd_warshall step 3842 current loss 0.363274, current_train_items 122976.\n",
            "I0314 03:00:09.414266 138313941204992 run.py:479] Algo floyd_warshall step 3843 current loss 0.593159, current_train_items 123008.\n",
            "I0314 03:00:09.908300 138313941204992 run.py:479] Algo floyd_warshall step 3844 current loss 0.880422, current_train_items 123040.\n",
            "I0314 03:00:09.946448 138313941204992 run.py:479] Algo floyd_warshall step 3845 current loss 0.029193, current_train_items 123072.\n",
            "I0314 03:00:10.005370 138313941204992 run.py:479] Algo floyd_warshall step 3846 current loss 0.124794, current_train_items 123104.\n",
            "I0314 03:00:10.163850 138313941204992 run.py:479] Algo floyd_warshall step 3847 current loss 0.347221, current_train_items 123136.\n",
            "I0314 03:00:10.447203 138313941204992 run.py:479] Algo floyd_warshall step 3848 current loss 0.481156, current_train_items 123168.\n",
            "I0314 03:00:10.944787 138313941204992 run.py:479] Algo floyd_warshall step 3849 current loss 0.904313, current_train_items 123200.\n",
            "I0314 03:00:10.981893 138313941204992 run.py:479] Algo floyd_warshall step 3850 current loss 0.029066, current_train_items 123232.\n",
            "I0314 03:00:11.096517 138313941204992 run.py:499] (val) algo floyd_warshall step 3850: {'Pi': 0.84808349609375, 'score': 0.84808349609375, 'examples_seen': 123232, 'step': 3850, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:00:11.096829 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.873, current avg val score is 0.848, val scores are: floyd_warshall: 0.848\n",
            "I0314 03:00:11.156993 138313941204992 run.py:479] Algo floyd_warshall step 3851 current loss 0.166812, current_train_items 123264.\n",
            "I0314 03:00:11.332687 138313941204992 run.py:479] Algo floyd_warshall step 3852 current loss 0.357100, current_train_items 123296.\n",
            "I0314 03:00:11.606032 138313941204992 run.py:479] Algo floyd_warshall step 3853 current loss 0.725002, current_train_items 123328.\n",
            "I0314 03:00:12.082277 138313941204992 run.py:479] Algo floyd_warshall step 3854 current loss 0.842174, current_train_items 123360.\n",
            "I0314 03:00:12.107001 138313941204992 run.py:479] Algo floyd_warshall step 3855 current loss 0.071678, current_train_items 123392.\n",
            "I0314 03:00:12.151816 138313941204992 run.py:479] Algo floyd_warshall step 3856 current loss 0.139164, current_train_items 123424.\n",
            "I0314 03:00:12.279639 138313941204992 run.py:479] Algo floyd_warshall step 3857 current loss 0.344877, current_train_items 123456.\n",
            "I0314 03:00:12.488699 138313941204992 run.py:479] Algo floyd_warshall step 3858 current loss 0.454009, current_train_items 123488.\n",
            "I0314 03:00:12.898284 138313941204992 run.py:479] Algo floyd_warshall step 3859 current loss 0.863237, current_train_items 123520.\n",
            "I0314 03:00:12.921429 138313941204992 run.py:479] Algo floyd_warshall step 3860 current loss 0.053521, current_train_items 123552.\n",
            "I0314 03:00:12.965431 138313941204992 run.py:479] Algo floyd_warshall step 3861 current loss 0.099073, current_train_items 123584.\n",
            "I0314 03:00:13.094999 138313941204992 run.py:479] Algo floyd_warshall step 3862 current loss 0.447027, current_train_items 123616.\n",
            "I0314 03:00:13.307654 138313941204992 run.py:479] Algo floyd_warshall step 3863 current loss 0.550571, current_train_items 123648.\n",
            "I0314 03:00:13.719551 138313941204992 run.py:479] Algo floyd_warshall step 3864 current loss 0.992243, current_train_items 123680.\n",
            "I0314 03:00:13.743299 138313941204992 run.py:479] Algo floyd_warshall step 3865 current loss 0.011591, current_train_items 123712.\n",
            "I0314 03:00:13.789139 138313941204992 run.py:479] Algo floyd_warshall step 3866 current loss 0.167054, current_train_items 123744.\n",
            "I0314 03:00:13.919905 138313941204992 run.py:479] Algo floyd_warshall step 3867 current loss 0.425465, current_train_items 123776.\n",
            "I0314 03:00:14.129825 138313941204992 run.py:479] Algo floyd_warshall step 3868 current loss 0.555383, current_train_items 123808.\n",
            "I0314 03:00:14.548427 138313941204992 run.py:479] Algo floyd_warshall step 3869 current loss 1.066219, current_train_items 123840.\n",
            "I0314 03:00:14.571336 138313941204992 run.py:479] Algo floyd_warshall step 3870 current loss 0.019781, current_train_items 123872.\n",
            "I0314 03:00:14.617347 138313941204992 run.py:479] Algo floyd_warshall step 3871 current loss 0.149945, current_train_items 123904.\n",
            "I0314 03:00:14.745773 138313941204992 run.py:479] Algo floyd_warshall step 3872 current loss 0.368827, current_train_items 123936.\n",
            "I0314 03:00:14.981408 138313941204992 run.py:479] Algo floyd_warshall step 3873 current loss 0.807205, current_train_items 123968.\n",
            "I0314 03:00:15.395581 138313941204992 run.py:479] Algo floyd_warshall step 3874 current loss 1.024126, current_train_items 124000.\n",
            "I0314 03:00:15.420297 138313941204992 run.py:479] Algo floyd_warshall step 3875 current loss 0.010101, current_train_items 124032.\n",
            "I0314 03:00:15.464881 138313941204992 run.py:479] Algo floyd_warshall step 3876 current loss 0.132400, current_train_items 124064.\n",
            "I0314 03:00:15.598834 138313941204992 run.py:479] Algo floyd_warshall step 3877 current loss 0.512445, current_train_items 124096.\n",
            "I0314 03:00:15.816463 138313941204992 run.py:479] Algo floyd_warshall step 3878 current loss 0.621487, current_train_items 124128.\n",
            "I0314 03:00:16.220446 138313941204992 run.py:479] Algo floyd_warshall step 3879 current loss 0.870602, current_train_items 124160.\n",
            "I0314 03:00:16.244804 138313941204992 run.py:479] Algo floyd_warshall step 3880 current loss 0.035390, current_train_items 124192.\n",
            "I0314 03:00:16.288940 138313941204992 run.py:479] Algo floyd_warshall step 3881 current loss 0.130853, current_train_items 124224.\n",
            "I0314 03:00:16.433100 138313941204992 run.py:479] Algo floyd_warshall step 3882 current loss 0.410476, current_train_items 124256.\n",
            "I0314 03:00:16.650538 138313941204992 run.py:479] Algo floyd_warshall step 3883 current loss 0.613293, current_train_items 124288.\n",
            "I0314 03:00:17.063444 138313941204992 run.py:479] Algo floyd_warshall step 3884 current loss 1.005221, current_train_items 124320.\n",
            "I0314 03:00:17.086471 138313941204992 run.py:479] Algo floyd_warshall step 3885 current loss 0.021037, current_train_items 124352.\n",
            "I0314 03:00:17.131303 138313941204992 run.py:479] Algo floyd_warshall step 3886 current loss 0.117204, current_train_items 124384.\n",
            "I0314 03:00:17.263914 138313941204992 run.py:479] Algo floyd_warshall step 3887 current loss 0.428421, current_train_items 124416.\n",
            "I0314 03:00:17.491310 138313941204992 run.py:479] Algo floyd_warshall step 3888 current loss 0.638898, current_train_items 124448.\n",
            "I0314 03:00:17.914894 138313941204992 run.py:479] Algo floyd_warshall step 3889 current loss 0.919731, current_train_items 124480.\n",
            "I0314 03:00:17.937307 138313941204992 run.py:479] Algo floyd_warshall step 3890 current loss 0.032868, current_train_items 124512.\n",
            "I0314 03:00:17.980061 138313941204992 run.py:479] Algo floyd_warshall step 3891 current loss 0.080548, current_train_items 124544.\n",
            "I0314 03:00:18.111025 138313941204992 run.py:479] Algo floyd_warshall step 3892 current loss 0.458649, current_train_items 124576.\n",
            "I0314 03:00:18.323175 138313941204992 run.py:479] Algo floyd_warshall step 3893 current loss 0.498681, current_train_items 124608.\n",
            "I0314 03:00:18.757290 138313941204992 run.py:479] Algo floyd_warshall step 3894 current loss 0.999776, current_train_items 124640.\n",
            "I0314 03:00:18.780995 138313941204992 run.py:479] Algo floyd_warshall step 3895 current loss 0.032257, current_train_items 124672.\n",
            "I0314 03:00:18.827507 138313941204992 run.py:479] Algo floyd_warshall step 3896 current loss 0.147514, current_train_items 124704.\n",
            "I0314 03:00:18.956811 138313941204992 run.py:479] Algo floyd_warshall step 3897 current loss 0.395407, current_train_items 124736.\n",
            "I0314 03:00:19.178088 138313941204992 run.py:479] Algo floyd_warshall step 3898 current loss 0.627921, current_train_items 124768.\n",
            "I0314 03:00:19.588553 138313941204992 run.py:479] Algo floyd_warshall step 3899 current loss 0.938471, current_train_items 124800.\n",
            "I0314 03:00:19.612372 138313941204992 run.py:479] Algo floyd_warshall step 3900 current loss 0.035572, current_train_items 124832.\n",
            "I0314 03:00:19.702230 138313941204992 run.py:499] (val) algo floyd_warshall step 3900: {'Pi': 0.8546142578125, 'score': 0.8546142578125, 'examples_seen': 124832, 'step': 3900, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:00:19.702478 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.873, current avg val score is 0.855, val scores are: floyd_warshall: 0.855\n",
            "I0314 03:00:19.750770 138313941204992 run.py:479] Algo floyd_warshall step 3901 current loss 0.105895, current_train_items 124864.\n",
            "I0314 03:00:19.881948 138313941204992 run.py:479] Algo floyd_warshall step 3902 current loss 0.466464, current_train_items 124896.\n",
            "I0314 03:00:20.101910 138313941204992 run.py:479] Algo floyd_warshall step 3903 current loss 0.667869, current_train_items 124928.\n",
            "I0314 03:00:20.514276 138313941204992 run.py:479] Algo floyd_warshall step 3904 current loss 0.842869, current_train_items 124960.\n",
            "I0314 03:00:20.538748 138313941204992 run.py:479] Algo floyd_warshall step 3905 current loss 0.037680, current_train_items 124992.\n",
            "I0314 03:00:20.584217 138313941204992 run.py:479] Algo floyd_warshall step 3906 current loss 0.136944, current_train_items 125024.\n",
            "I0314 03:00:20.714922 138313941204992 run.py:479] Algo floyd_warshall step 3907 current loss 0.545633, current_train_items 125056.\n",
            "I0314 03:00:20.936276 138313941204992 run.py:479] Algo floyd_warshall step 3908 current loss 0.740120, current_train_items 125088.\n",
            "I0314 03:00:21.354968 138313941204992 run.py:479] Algo floyd_warshall step 3909 current loss 0.836770, current_train_items 125120.\n",
            "I0314 03:00:21.378349 138313941204992 run.py:479] Algo floyd_warshall step 3910 current loss 0.065297, current_train_items 125152.\n",
            "I0314 03:00:21.424503 138313941204992 run.py:479] Algo floyd_warshall step 3911 current loss 0.048294, current_train_items 125184.\n",
            "I0314 03:00:21.557590 138313941204992 run.py:479] Algo floyd_warshall step 3912 current loss 0.387286, current_train_items 125216.\n",
            "I0314 03:00:21.784709 138313941204992 run.py:479] Algo floyd_warshall step 3913 current loss 0.754063, current_train_items 125248.\n",
            "I0314 03:00:22.245250 138313941204992 run.py:479] Algo floyd_warshall step 3914 current loss 0.871101, current_train_items 125280.\n",
            "I0314 03:00:22.279486 138313941204992 run.py:479] Algo floyd_warshall step 3915 current loss 0.063917, current_train_items 125312.\n",
            "I0314 03:00:22.336067 138313941204992 run.py:479] Algo floyd_warshall step 3916 current loss 0.141515, current_train_items 125344.\n",
            "I0314 03:00:22.492333 138313941204992 run.py:479] Algo floyd_warshall step 3917 current loss 0.412643, current_train_items 125376.\n",
            "I0314 03:00:22.769870 138313941204992 run.py:479] Algo floyd_warshall step 3918 current loss 0.664097, current_train_items 125408.\n",
            "I0314 03:00:23.281558 138313941204992 run.py:479] Algo floyd_warshall step 3919 current loss 1.050845, current_train_items 125440.\n",
            "I0314 03:00:23.316230 138313941204992 run.py:479] Algo floyd_warshall step 3920 current loss 0.095200, current_train_items 125472.\n",
            "I0314 03:00:23.374442 138313941204992 run.py:479] Algo floyd_warshall step 3921 current loss 0.106414, current_train_items 125504.\n",
            "I0314 03:00:23.530560 138313941204992 run.py:479] Algo floyd_warshall step 3922 current loss 0.323694, current_train_items 125536.\n",
            "I0314 03:00:23.791807 138313941204992 run.py:479] Algo floyd_warshall step 3923 current loss 0.465935, current_train_items 125568.\n",
            "I0314 03:00:24.316746 138313941204992 run.py:479] Algo floyd_warshall step 3924 current loss 1.080129, current_train_items 125600.\n",
            "I0314 03:00:24.348017 138313941204992 run.py:479] Algo floyd_warshall step 3925 current loss 0.020555, current_train_items 125632.\n",
            "I0314 03:00:24.403488 138313941204992 run.py:479] Algo floyd_warshall step 3926 current loss 0.121302, current_train_items 125664.\n",
            "I0314 03:00:24.562171 138313941204992 run.py:479] Algo floyd_warshall step 3927 current loss 0.399226, current_train_items 125696.\n",
            "I0314 03:00:24.829774 138313941204992 run.py:479] Algo floyd_warshall step 3928 current loss 0.572812, current_train_items 125728.\n",
            "I0314 03:00:25.272711 138313941204992 run.py:479] Algo floyd_warshall step 3929 current loss 1.263873, current_train_items 125760.\n",
            "I0314 03:00:25.296524 138313941204992 run.py:479] Algo floyd_warshall step 3930 current loss 0.030800, current_train_items 125792.\n",
            "I0314 03:00:25.341362 138313941204992 run.py:479] Algo floyd_warshall step 3931 current loss 0.125108, current_train_items 125824.\n",
            "I0314 03:00:25.470668 138313941204992 run.py:479] Algo floyd_warshall step 3932 current loss 0.338393, current_train_items 125856.\n",
            "I0314 03:00:25.687701 138313941204992 run.py:479] Algo floyd_warshall step 3933 current loss 0.582115, current_train_items 125888.\n",
            "I0314 03:00:26.113526 138313941204992 run.py:479] Algo floyd_warshall step 3934 current loss 1.023391, current_train_items 125920.\n",
            "I0314 03:00:26.138932 138313941204992 run.py:479] Algo floyd_warshall step 3935 current loss 0.025311, current_train_items 125952.\n",
            "I0314 03:00:26.184102 138313941204992 run.py:479] Algo floyd_warshall step 3936 current loss 0.066527, current_train_items 125984.\n",
            "I0314 03:00:26.313054 138313941204992 run.py:479] Algo floyd_warshall step 3937 current loss 0.312392, current_train_items 126016.\n",
            "I0314 03:00:26.540120 138313941204992 run.py:479] Algo floyd_warshall step 3938 current loss 0.565600, current_train_items 126048.\n",
            "I0314 03:00:26.959379 138313941204992 run.py:479] Algo floyd_warshall step 3939 current loss 0.888960, current_train_items 126080.\n",
            "I0314 03:00:26.982460 138313941204992 run.py:479] Algo floyd_warshall step 3940 current loss 0.038128, current_train_items 126112.\n",
            "I0314 03:00:27.028210 138313941204992 run.py:479] Algo floyd_warshall step 3941 current loss 0.103916, current_train_items 126144.\n",
            "I0314 03:00:27.165763 138313941204992 run.py:479] Algo floyd_warshall step 3942 current loss 0.335012, current_train_items 126176.\n",
            "I0314 03:00:27.382667 138313941204992 run.py:479] Algo floyd_warshall step 3943 current loss 0.614786, current_train_items 126208.\n",
            "I0314 03:00:27.789975 138313941204992 run.py:479] Algo floyd_warshall step 3944 current loss 0.832063, current_train_items 126240.\n",
            "I0314 03:00:27.815398 138313941204992 run.py:479] Algo floyd_warshall step 3945 current loss 0.033564, current_train_items 126272.\n",
            "I0314 03:00:27.860636 138313941204992 run.py:479] Algo floyd_warshall step 3946 current loss 0.141529, current_train_items 126304.\n",
            "I0314 03:00:27.993206 138313941204992 run.py:479] Algo floyd_warshall step 3947 current loss 0.465112, current_train_items 126336.\n",
            "I0314 03:00:28.223205 138313941204992 run.py:479] Algo floyd_warshall step 3948 current loss 0.593802, current_train_items 126368.\n",
            "I0314 03:00:28.631330 138313941204992 run.py:479] Algo floyd_warshall step 3949 current loss 0.903234, current_train_items 126400.\n",
            "I0314 03:00:28.656740 138313941204992 run.py:479] Algo floyd_warshall step 3950 current loss 0.085000, current_train_items 126432.\n",
            "I0314 03:00:28.743937 138313941204992 run.py:499] (val) algo floyd_warshall step 3950: {'Pi': 0.87884521484375, 'score': 0.87884521484375, 'examples_seen': 126432, 'step': 3950, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:00:28.744189 138313941204992 run.py:516] Checkpointing best model, best avg val score was 0.873, current avg val score is 0.879, val scores are: floyd_warshall: 0.879\n",
            "I0314 03:00:28.839547 138313941204992 run.py:479] Algo floyd_warshall step 3951 current loss 0.089343, current_train_items 126464.\n",
            "I0314 03:00:28.981371 138313941204992 run.py:479] Algo floyd_warshall step 3952 current loss 0.348222, current_train_items 126496.\n",
            "I0314 03:00:29.201781 138313941204992 run.py:479] Algo floyd_warshall step 3953 current loss 0.712450, current_train_items 126528.\n",
            "I0314 03:00:29.611923 138313941204992 run.py:479] Algo floyd_warshall step 3954 current loss 0.981093, current_train_items 126560.\n",
            "I0314 03:00:29.639660 138313941204992 run.py:479] Algo floyd_warshall step 3955 current loss 0.013946, current_train_items 126592.\n",
            "I0314 03:00:29.686065 138313941204992 run.py:479] Algo floyd_warshall step 3956 current loss 0.105662, current_train_items 126624.\n",
            "I0314 03:00:29.813109 138313941204992 run.py:479] Algo floyd_warshall step 3957 current loss 0.319035, current_train_items 126656.\n",
            "I0314 03:00:30.041389 138313941204992 run.py:479] Algo floyd_warshall step 3958 current loss 0.598789, current_train_items 126688.\n",
            "I0314 03:00:30.449399 138313941204992 run.py:479] Algo floyd_warshall step 3959 current loss 1.062904, current_train_items 126720.\n",
            "I0314 03:00:30.472841 138313941204992 run.py:479] Algo floyd_warshall step 3960 current loss 0.051997, current_train_items 126752.\n",
            "I0314 03:00:30.517132 138313941204992 run.py:479] Algo floyd_warshall step 3961 current loss 0.115511, current_train_items 126784.\n",
            "I0314 03:00:30.646830 138313941204992 run.py:479] Algo floyd_warshall step 3962 current loss 0.358863, current_train_items 126816.\n",
            "I0314 03:00:30.861751 138313941204992 run.py:479] Algo floyd_warshall step 3963 current loss 0.528999, current_train_items 126848.\n",
            "I0314 03:00:31.272019 138313941204992 run.py:479] Algo floyd_warshall step 3964 current loss 0.969795, current_train_items 126880.\n",
            "I0314 03:00:31.294271 138313941204992 run.py:479] Algo floyd_warshall step 3965 current loss 0.094367, current_train_items 126912.\n",
            "I0314 03:00:31.337680 138313941204992 run.py:479] Algo floyd_warshall step 3966 current loss 0.082702, current_train_items 126944.\n",
            "I0314 03:00:31.467233 138313941204992 run.py:479] Algo floyd_warshall step 3967 current loss 0.371858, current_train_items 126976.\n",
            "I0314 03:00:31.683770 138313941204992 run.py:479] Algo floyd_warshall step 3968 current loss 0.560317, current_train_items 127008.\n",
            "I0314 03:00:32.101670 138313941204992 run.py:479] Algo floyd_warshall step 3969 current loss 1.235324, current_train_items 127040.\n",
            "I0314 03:00:32.124711 138313941204992 run.py:479] Algo floyd_warshall step 3970 current loss 0.035531, current_train_items 127072.\n",
            "I0314 03:00:32.170300 138313941204992 run.py:479] Algo floyd_warshall step 3971 current loss 0.146125, current_train_items 127104.\n",
            "I0314 03:00:32.302640 138313941204992 run.py:479] Algo floyd_warshall step 3972 current loss 0.556914, current_train_items 127136.\n",
            "I0314 03:00:32.528040 138313941204992 run.py:479] Algo floyd_warshall step 3973 current loss 0.608118, current_train_items 127168.\n",
            "I0314 03:00:32.929811 138313941204992 run.py:479] Algo floyd_warshall step 3974 current loss 0.933280, current_train_items 127200.\n",
            "I0314 03:00:32.952891 138313941204992 run.py:479] Algo floyd_warshall step 3975 current loss 0.028286, current_train_items 127232.\n",
            "I0314 03:00:32.997987 138313941204992 run.py:479] Algo floyd_warshall step 3976 current loss 0.162466, current_train_items 127264.\n",
            "I0314 03:00:33.125385 138313941204992 run.py:479] Algo floyd_warshall step 3977 current loss 0.354312, current_train_items 127296.\n",
            "I0314 03:00:33.352078 138313941204992 run.py:479] Algo floyd_warshall step 3978 current loss 0.560137, current_train_items 127328.\n",
            "I0314 03:00:33.774576 138313941204992 run.py:479] Algo floyd_warshall step 3979 current loss 0.993551, current_train_items 127360.\n",
            "I0314 03:00:33.798547 138313941204992 run.py:479] Algo floyd_warshall step 3980 current loss 0.077301, current_train_items 127392.\n",
            "I0314 03:00:33.844251 138313941204992 run.py:479] Algo floyd_warshall step 3981 current loss 0.109126, current_train_items 127424.\n",
            "I0314 03:00:33.978060 138313941204992 run.py:479] Algo floyd_warshall step 3982 current loss 0.487461, current_train_items 127456.\n",
            "I0314 03:00:34.190016 138313941204992 run.py:479] Algo floyd_warshall step 3983 current loss 0.524141, current_train_items 127488.\n",
            "I0314 03:00:34.600019 138313941204992 run.py:479] Algo floyd_warshall step 3984 current loss 0.952748, current_train_items 127520.\n",
            "I0314 03:00:34.624119 138313941204992 run.py:479] Algo floyd_warshall step 3985 current loss 0.020759, current_train_items 127552.\n",
            "I0314 03:00:34.670700 138313941204992 run.py:479] Algo floyd_warshall step 3986 current loss 0.088598, current_train_items 127584.\n",
            "I0314 03:00:34.799308 138313941204992 run.py:479] Algo floyd_warshall step 3987 current loss 0.416205, current_train_items 127616.\n",
            "I0314 03:00:35.011888 138313941204992 run.py:479] Algo floyd_warshall step 3988 current loss 0.633094, current_train_items 127648.\n",
            "I0314 03:00:35.498589 138313941204992 run.py:479] Algo floyd_warshall step 3989 current loss 0.920920, current_train_items 127680.\n",
            "I0314 03:00:35.531892 138313941204992 run.py:479] Algo floyd_warshall step 3990 current loss 0.017144, current_train_items 127712.\n",
            "I0314 03:00:35.586959 138313941204992 run.py:479] Algo floyd_warshall step 3991 current loss 0.095264, current_train_items 127744.\n",
            "I0314 03:00:35.746593 138313941204992 run.py:479] Algo floyd_warshall step 3992 current loss 0.458692, current_train_items 127776.\n",
            "I0314 03:00:36.011765 138313941204992 run.py:479] Algo floyd_warshall step 3993 current loss 0.588410, current_train_items 127808.\n",
            "I0314 03:00:36.497531 138313941204992 run.py:479] Algo floyd_warshall step 3994 current loss 0.870751, current_train_items 127840.\n",
            "I0314 03:00:36.531765 138313941204992 run.py:479] Algo floyd_warshall step 3995 current loss 0.020652, current_train_items 127872.\n",
            "I0314 03:00:36.586997 138313941204992 run.py:479] Algo floyd_warshall step 3996 current loss 0.076797, current_train_items 127904.\n",
            "I0314 03:00:36.749082 138313941204992 run.py:479] Algo floyd_warshall step 3997 current loss 0.355173, current_train_items 127936.\n",
            "I0314 03:00:37.001512 138313941204992 run.py:479] Algo floyd_warshall step 3998 current loss 0.455425, current_train_items 127968.\n",
            "I0314 03:00:37.533881 138313941204992 run.py:479] Algo floyd_warshall step 3999 current loss 1.104388, current_train_items 128000.\n",
            "I0314 03:00:37.572182 138313941204992 run.py:479] Algo floyd_warshall step 4000 current loss 0.032933, current_train_items 128032.\n",
            "I0314 03:00:37.688239 138313941204992 run.py:499] (val) algo floyd_warshall step 4000: {'Pi': 0.85382080078125, 'score': 0.85382080078125, 'examples_seen': 128032, 'step': 4000, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:00:37.688562 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.879, current avg val score is 0.854, val scores are: floyd_warshall: 0.854\n",
            "I0314 03:00:37.750571 138313941204992 run.py:479] Algo floyd_warshall step 4001 current loss 0.084928, current_train_items 128064.\n",
            "I0314 03:00:37.913931 138313941204992 run.py:479] Algo floyd_warshall step 4002 current loss 0.392889, current_train_items 128096.\n",
            "I0314 03:00:38.138601 138313941204992 run.py:479] Algo floyd_warshall step 4003 current loss 0.603367, current_train_items 128128.\n",
            "I0314 03:00:38.552953 138313941204992 run.py:479] Algo floyd_warshall step 4004 current loss 0.787947, current_train_items 128160.\n",
            "I0314 03:00:38.577851 138313941204992 run.py:479] Algo floyd_warshall step 4005 current loss 0.020882, current_train_items 128192.\n",
            "I0314 03:00:38.625317 138313941204992 run.py:479] Algo floyd_warshall step 4006 current loss 0.109678, current_train_items 128224.\n",
            "I0314 03:00:38.757789 138313941204992 run.py:479] Algo floyd_warshall step 4007 current loss 0.389487, current_train_items 128256.\n",
            "I0314 03:00:38.985967 138313941204992 run.py:479] Algo floyd_warshall step 4008 current loss 0.576683, current_train_items 128288.\n",
            "I0314 03:00:39.390705 138313941204992 run.py:479] Algo floyd_warshall step 4009 current loss 0.818907, current_train_items 128320.\n",
            "I0314 03:00:39.417628 138313941204992 run.py:479] Algo floyd_warshall step 4010 current loss 0.046043, current_train_items 128352.\n",
            "I0314 03:00:39.462670 138313941204992 run.py:479] Algo floyd_warshall step 4011 current loss 0.099841, current_train_items 128384.\n",
            "I0314 03:00:39.591828 138313941204992 run.py:479] Algo floyd_warshall step 4012 current loss 0.394583, current_train_items 128416.\n",
            "I0314 03:00:39.812121 138313941204992 run.py:479] Algo floyd_warshall step 4013 current loss 0.617460, current_train_items 128448.\n",
            "I0314 03:00:40.226560 138313941204992 run.py:479] Algo floyd_warshall step 4014 current loss 0.831325, current_train_items 128480.\n",
            "I0314 03:00:40.250696 138313941204992 run.py:479] Algo floyd_warshall step 4015 current loss 0.033690, current_train_items 128512.\n",
            "I0314 03:00:40.295517 138313941204992 run.py:479] Algo floyd_warshall step 4016 current loss 0.158684, current_train_items 128544.\n",
            "I0314 03:00:40.424313 138313941204992 run.py:479] Algo floyd_warshall step 4017 current loss 0.438020, current_train_items 128576.\n",
            "I0314 03:00:40.638589 138313941204992 run.py:479] Algo floyd_warshall step 4018 current loss 0.496313, current_train_items 128608.\n",
            "I0314 03:00:41.059722 138313941204992 run.py:479] Algo floyd_warshall step 4019 current loss 1.022762, current_train_items 128640.\n",
            "I0314 03:00:41.083427 138313941204992 run.py:479] Algo floyd_warshall step 4020 current loss 0.022363, current_train_items 128672.\n",
            "I0314 03:00:41.128042 138313941204992 run.py:479] Algo floyd_warshall step 4021 current loss 0.091831, current_train_items 128704.\n",
            "I0314 03:00:41.270753 138313941204992 run.py:479] Algo floyd_warshall step 4022 current loss 0.622951, current_train_items 128736.\n",
            "I0314 03:00:41.499266 138313941204992 run.py:479] Algo floyd_warshall step 4023 current loss 0.529437, current_train_items 128768.\n",
            "I0314 03:00:41.912881 138313941204992 run.py:479] Algo floyd_warshall step 4024 current loss 1.078509, current_train_items 128800.\n",
            "I0314 03:00:41.936396 138313941204992 run.py:479] Algo floyd_warshall step 4025 current loss 0.026023, current_train_items 128832.\n",
            "I0314 03:00:41.980171 138313941204992 run.py:479] Algo floyd_warshall step 4026 current loss 0.094338, current_train_items 128864.\n",
            "I0314 03:00:42.109458 138313941204992 run.py:479] Algo floyd_warshall step 4027 current loss 0.425627, current_train_items 128896.\n",
            "I0314 03:00:42.325453 138313941204992 run.py:479] Algo floyd_warshall step 4028 current loss 0.531488, current_train_items 128928.\n",
            "I0314 03:00:42.740690 138313941204992 run.py:479] Algo floyd_warshall step 4029 current loss 0.890770, current_train_items 128960.\n",
            "I0314 03:00:42.764708 138313941204992 run.py:479] Algo floyd_warshall step 4030 current loss 0.052156, current_train_items 128992.\n",
            "I0314 03:00:42.808711 138313941204992 run.py:479] Algo floyd_warshall step 4031 current loss 0.093126, current_train_items 129024.\n",
            "I0314 03:00:42.939883 138313941204992 run.py:479] Algo floyd_warshall step 4032 current loss 0.379610, current_train_items 129056.\n",
            "I0314 03:00:43.156707 138313941204992 run.py:479] Algo floyd_warshall step 4033 current loss 0.538709, current_train_items 129088.\n",
            "I0314 03:00:43.589906 138313941204992 run.py:479] Algo floyd_warshall step 4034 current loss 0.862875, current_train_items 129120.\n",
            "I0314 03:00:43.617336 138313941204992 run.py:479] Algo floyd_warshall step 4035 current loss 0.023769, current_train_items 129152.\n",
            "I0314 03:00:43.665256 138313941204992 run.py:479] Algo floyd_warshall step 4036 current loss 0.101024, current_train_items 129184.\n",
            "I0314 03:00:43.805235 138313941204992 run.py:479] Algo floyd_warshall step 4037 current loss 0.351710, current_train_items 129216.\n",
            "I0314 03:00:44.037968 138313941204992 run.py:479] Algo floyd_warshall step 4038 current loss 0.518657, current_train_items 129248.\n",
            "I0314 03:00:44.454611 138313941204992 run.py:479] Algo floyd_warshall step 4039 current loss 0.981043, current_train_items 129280.\n",
            "I0314 03:00:44.478140 138313941204992 run.py:479] Algo floyd_warshall step 4040 current loss 0.025573, current_train_items 129312.\n",
            "I0314 03:00:44.523654 138313941204992 run.py:479] Algo floyd_warshall step 4041 current loss 0.176328, current_train_items 129344.\n",
            "I0314 03:00:44.654870 138313941204992 run.py:479] Algo floyd_warshall step 4042 current loss 0.522222, current_train_items 129376.\n",
            "I0314 03:00:44.881165 138313941204992 run.py:479] Algo floyd_warshall step 4043 current loss 0.721810, current_train_items 129408.\n",
            "I0314 03:00:45.288501 138313941204992 run.py:479] Algo floyd_warshall step 4044 current loss 1.047407, current_train_items 129440.\n",
            "I0314 03:00:45.320607 138313941204992 run.py:479] Algo floyd_warshall step 4045 current loss 0.018957, current_train_items 129472.\n",
            "I0314 03:00:45.366606 138313941204992 run.py:479] Algo floyd_warshall step 4046 current loss 0.098018, current_train_items 129504.\n",
            "I0314 03:00:45.496958 138313941204992 run.py:479] Algo floyd_warshall step 4047 current loss 0.380074, current_train_items 129536.\n",
            "I0314 03:00:45.729402 138313941204992 run.py:479] Algo floyd_warshall step 4048 current loss 0.609499, current_train_items 129568.\n",
            "I0314 03:00:46.151357 138313941204992 run.py:479] Algo floyd_warshall step 4049 current loss 0.929115, current_train_items 129600.\n",
            "I0314 03:00:46.176862 138313941204992 run.py:479] Algo floyd_warshall step 4050 current loss 0.032429, current_train_items 129632.\n",
            "I0314 03:00:46.264494 138313941204992 run.py:499] (val) algo floyd_warshall step 4050: {'Pi': 0.848388671875, 'score': 0.848388671875, 'examples_seen': 129632, 'step': 4050, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:00:46.264796 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.879, current avg val score is 0.848, val scores are: floyd_warshall: 0.848\n",
            "I0314 03:00:46.313988 138313941204992 run.py:479] Algo floyd_warshall step 4051 current loss 0.137591, current_train_items 129664.\n",
            "I0314 03:00:46.452382 138313941204992 run.py:479] Algo floyd_warshall step 4052 current loss 0.411067, current_train_items 129696.\n",
            "I0314 03:00:46.672044 138313941204992 run.py:479] Algo floyd_warshall step 4053 current loss 0.579076, current_train_items 129728.\n",
            "I0314 03:00:47.100347 138313941204992 run.py:479] Algo floyd_warshall step 4054 current loss 0.919978, current_train_items 129760.\n",
            "I0314 03:00:47.126777 138313941204992 run.py:479] Algo floyd_warshall step 4055 current loss 0.016176, current_train_items 129792.\n",
            "I0314 03:00:47.174082 138313941204992 run.py:479] Algo floyd_warshall step 4056 current loss 0.180594, current_train_items 129824.\n",
            "I0314 03:00:47.306349 138313941204992 run.py:479] Algo floyd_warshall step 4057 current loss 0.433803, current_train_items 129856.\n",
            "I0314 03:00:47.547377 138313941204992 run.py:479] Algo floyd_warshall step 4058 current loss 0.714439, current_train_items 129888.\n",
            "I0314 03:00:47.949542 138313941204992 run.py:479] Algo floyd_warshall step 4059 current loss 0.850984, current_train_items 129920.\n",
            "I0314 03:00:47.987653 138313941204992 run.py:479] Algo floyd_warshall step 4060 current loss 0.048452, current_train_items 129952.\n",
            "I0314 03:00:48.047221 138313941204992 run.py:479] Algo floyd_warshall step 4061 current loss 0.107521, current_train_items 129984.\n",
            "I0314 03:00:48.204694 138313941204992 run.py:479] Algo floyd_warshall step 4062 current loss 0.408009, current_train_items 130016.\n",
            "I0314 03:00:48.467526 138313941204992 run.py:479] Algo floyd_warshall step 4063 current loss 0.515735, current_train_items 130048.\n",
            "I0314 03:00:48.962713 138313941204992 run.py:479] Algo floyd_warshall step 4064 current loss 0.944378, current_train_items 130080.\n",
            "I0314 03:00:49.003399 138313941204992 run.py:479] Algo floyd_warshall step 4065 current loss 0.034209, current_train_items 130112.\n",
            "I0314 03:00:49.068801 138313941204992 run.py:479] Algo floyd_warshall step 4066 current loss 0.070112, current_train_items 130144.\n",
            "I0314 03:00:49.227002 138313941204992 run.py:479] Algo floyd_warshall step 4067 current loss 0.465985, current_train_items 130176.\n",
            "I0314 03:00:49.489331 138313941204992 run.py:479] Algo floyd_warshall step 4068 current loss 0.550494, current_train_items 130208.\n",
            "I0314 03:00:49.975556 138313941204992 run.py:479] Algo floyd_warshall step 4069 current loss 0.877366, current_train_items 130240.\n",
            "I0314 03:00:50.009551 138313941204992 run.py:479] Algo floyd_warshall step 4070 current loss 0.038370, current_train_items 130272.\n",
            "I0314 03:00:50.066932 138313941204992 run.py:479] Algo floyd_warshall step 4071 current loss 0.121554, current_train_items 130304.\n",
            "I0314 03:00:50.228607 138313941204992 run.py:479] Algo floyd_warshall step 4072 current loss 0.400480, current_train_items 130336.\n",
            "I0314 03:00:50.502050 138313941204992 run.py:479] Algo floyd_warshall step 4073 current loss 0.504942, current_train_items 130368.\n",
            "I0314 03:00:50.996824 138313941204992 run.py:479] Algo floyd_warshall step 4074 current loss 0.952127, current_train_items 130400.\n",
            "I0314 03:00:51.036243 138313941204992 run.py:479] Algo floyd_warshall step 4075 current loss 0.020665, current_train_items 130432.\n",
            "I0314 03:00:51.083730 138313941204992 run.py:479] Algo floyd_warshall step 4076 current loss 0.143873, current_train_items 130464.\n",
            "I0314 03:00:51.216915 138313941204992 run.py:479] Algo floyd_warshall step 4077 current loss 0.408925, current_train_items 130496.\n",
            "I0314 03:00:51.441978 138313941204992 run.py:479] Algo floyd_warshall step 4078 current loss 0.546189, current_train_items 130528.\n",
            "I0314 03:00:51.890083 138313941204992 run.py:479] Algo floyd_warshall step 4079 current loss 0.863509, current_train_items 130560.\n",
            "I0314 03:00:51.914327 138313941204992 run.py:479] Algo floyd_warshall step 4080 current loss 0.039199, current_train_items 130592.\n",
            "I0314 03:00:51.959653 138313941204992 run.py:479] Algo floyd_warshall step 4081 current loss 0.092651, current_train_items 130624.\n",
            "I0314 03:00:52.091344 138313941204992 run.py:479] Algo floyd_warshall step 4082 current loss 0.476082, current_train_items 130656.\n",
            "I0314 03:00:52.306092 138313941204992 run.py:479] Algo floyd_warshall step 4083 current loss 0.601448, current_train_items 130688.\n",
            "I0314 03:00:52.708653 138313941204992 run.py:479] Algo floyd_warshall step 4084 current loss 0.906661, current_train_items 130720.\n",
            "I0314 03:00:52.734103 138313941204992 run.py:479] Algo floyd_warshall step 4085 current loss 0.023905, current_train_items 130752.\n",
            "I0314 03:00:52.779725 138313941204992 run.py:479] Algo floyd_warshall step 4086 current loss 0.147938, current_train_items 130784.\n",
            "I0314 03:00:52.912540 138313941204992 run.py:479] Algo floyd_warshall step 4087 current loss 0.547144, current_train_items 130816.\n",
            "I0314 03:00:53.146999 138313941204992 run.py:479] Algo floyd_warshall step 4088 current loss 0.586966, current_train_items 130848.\n",
            "I0314 03:00:53.556194 138313941204992 run.py:479] Algo floyd_warshall step 4089 current loss 0.744299, current_train_items 130880.\n",
            "I0314 03:00:53.579824 138313941204992 run.py:479] Algo floyd_warshall step 4090 current loss 0.028425, current_train_items 130912.\n",
            "I0314 03:00:53.623653 138313941204992 run.py:479] Algo floyd_warshall step 4091 current loss 0.061461, current_train_items 130944.\n",
            "I0314 03:00:53.754489 138313941204992 run.py:479] Algo floyd_warshall step 4092 current loss 0.407584, current_train_items 130976.\n",
            "I0314 03:00:53.977676 138313941204992 run.py:479] Algo floyd_warshall step 4093 current loss 0.503699, current_train_items 131008.\n",
            "I0314 03:00:54.386389 138313941204992 run.py:479] Algo floyd_warshall step 4094 current loss 0.954376, current_train_items 131040.\n",
            "I0314 03:00:54.410161 138313941204992 run.py:479] Algo floyd_warshall step 4095 current loss 0.015009, current_train_items 131072.\n",
            "I0314 03:00:54.455160 138313941204992 run.py:479] Algo floyd_warshall step 4096 current loss 0.096155, current_train_items 131104.\n",
            "I0314 03:00:54.584766 138313941204992 run.py:479] Algo floyd_warshall step 4097 current loss 0.362491, current_train_items 131136.\n",
            "I0314 03:00:54.796098 138313941204992 run.py:479] Algo floyd_warshall step 4098 current loss 0.478801, current_train_items 131168.\n",
            "I0314 03:00:55.205487 138313941204992 run.py:479] Algo floyd_warshall step 4099 current loss 0.827032, current_train_items 131200.\n",
            "I0314 03:00:55.228929 138313941204992 run.py:479] Algo floyd_warshall step 4100 current loss 0.033227, current_train_items 131232.\n",
            "I0314 03:00:55.318326 138313941204992 run.py:499] (val) algo floyd_warshall step 4100: {'Pi': 0.84844970703125, 'score': 0.84844970703125, 'examples_seen': 131232, 'step': 4100, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:00:55.318558 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.879, current avg val score is 0.848, val scores are: floyd_warshall: 0.848\n",
            "I0314 03:00:55.366116 138313941204992 run.py:479] Algo floyd_warshall step 4101 current loss 0.105384, current_train_items 131264.\n",
            "I0314 03:00:55.497340 138313941204992 run.py:479] Algo floyd_warshall step 4102 current loss 0.352405, current_train_items 131296.\n",
            "I0314 03:00:55.714380 138313941204992 run.py:479] Algo floyd_warshall step 4103 current loss 0.591817, current_train_items 131328.\n",
            "I0314 03:00:56.141640 138313941204992 run.py:479] Algo floyd_warshall step 4104 current loss 0.863417, current_train_items 131360.\n",
            "I0314 03:00:56.166547 138313941204992 run.py:479] Algo floyd_warshall step 4105 current loss 0.028094, current_train_items 131392.\n",
            "I0314 03:00:56.212089 138313941204992 run.py:479] Algo floyd_warshall step 4106 current loss 0.109839, current_train_items 131424.\n",
            "I0314 03:00:56.342396 138313941204992 run.py:479] Algo floyd_warshall step 4107 current loss 0.231957, current_train_items 131456.\n",
            "I0314 03:00:56.566825 138313941204992 run.py:479] Algo floyd_warshall step 4108 current loss 0.451574, current_train_items 131488.\n",
            "I0314 03:00:57.000236 138313941204992 run.py:479] Algo floyd_warshall step 4109 current loss 0.841495, current_train_items 131520.\n",
            "I0314 03:00:57.023349 138313941204992 run.py:479] Algo floyd_warshall step 4110 current loss 0.016589, current_train_items 131552.\n",
            "I0314 03:00:57.067823 138313941204992 run.py:479] Algo floyd_warshall step 4111 current loss 0.065147, current_train_items 131584.\n",
            "I0314 03:00:57.198333 138313941204992 run.py:479] Algo floyd_warshall step 4112 current loss 0.366021, current_train_items 131616.\n",
            "I0314 03:00:57.411304 138313941204992 run.py:479] Algo floyd_warshall step 4113 current loss 0.506868, current_train_items 131648.\n",
            "I0314 03:00:57.823652 138313941204992 run.py:479] Algo floyd_warshall step 4114 current loss 0.782423, current_train_items 131680.\n",
            "I0314 03:00:57.849340 138313941204992 run.py:479] Algo floyd_warshall step 4115 current loss 0.055153, current_train_items 131712.\n",
            "I0314 03:00:57.896718 138313941204992 run.py:479] Algo floyd_warshall step 4116 current loss 0.107403, current_train_items 131744.\n",
            "I0314 03:00:58.029730 138313941204992 run.py:479] Algo floyd_warshall step 4117 current loss 0.361965, current_train_items 131776.\n",
            "I0314 03:00:58.243684 138313941204992 run.py:479] Algo floyd_warshall step 4118 current loss 0.339636, current_train_items 131808.\n",
            "I0314 03:00:58.670388 138313941204992 run.py:479] Algo floyd_warshall step 4119 current loss 0.931795, current_train_items 131840.\n",
            "I0314 03:00:58.710366 138313941204992 run.py:479] Algo floyd_warshall step 4120 current loss 0.012197, current_train_items 131872.\n",
            "I0314 03:00:58.773545 138313941204992 run.py:479] Algo floyd_warshall step 4121 current loss 0.178173, current_train_items 131904.\n",
            "I0314 03:00:58.934812 138313941204992 run.py:479] Algo floyd_warshall step 4122 current loss 0.348139, current_train_items 131936.\n",
            "I0314 03:00:59.185880 138313941204992 run.py:479] Algo floyd_warshall step 4123 current loss 0.558758, current_train_items 131968.\n",
            "I0314 03:00:59.705783 138313941204992 run.py:479] Algo floyd_warshall step 4124 current loss 0.912543, current_train_items 132000.\n",
            "I0314 03:00:59.747416 138313941204992 run.py:479] Algo floyd_warshall step 4125 current loss 0.023655, current_train_items 132032.\n",
            "I0314 03:00:59.810366 138313941204992 run.py:479] Algo floyd_warshall step 4126 current loss 0.137109, current_train_items 132064.\n",
            "I0314 03:00:59.966574 138313941204992 run.py:479] Algo floyd_warshall step 4127 current loss 0.315460, current_train_items 132096.\n",
            "I0314 03:01:00.235701 138313941204992 run.py:479] Algo floyd_warshall step 4128 current loss 0.616598, current_train_items 132128.\n",
            "I0314 03:01:00.731979 138313941204992 run.py:479] Algo floyd_warshall step 4129 current loss 1.113660, current_train_items 132160.\n",
            "I0314 03:01:00.772497 138313941204992 run.py:479] Algo floyd_warshall step 4130 current loss 0.139690, current_train_items 132192.\n",
            "I0314 03:01:00.843384 138313941204992 run.py:479] Algo floyd_warshall step 4131 current loss 0.088018, current_train_items 132224.\n",
            "I0314 03:01:01.010052 138313941204992 run.py:479] Algo floyd_warshall step 4132 current loss 0.338245, current_train_items 132256.\n",
            "I0314 03:01:01.274016 138313941204992 run.py:479] Algo floyd_warshall step 4133 current loss 0.513772, current_train_items 132288.\n",
            "I0314 03:01:01.817857 138313941204992 run.py:479] Algo floyd_warshall step 4134 current loss 0.893259, current_train_items 132320.\n",
            "I0314 03:01:01.868073 138313941204992 run.py:479] Algo floyd_warshall step 4135 current loss 0.025489, current_train_items 132352.\n",
            "I0314 03:01:01.942340 138313941204992 run.py:479] Algo floyd_warshall step 4136 current loss 0.107731, current_train_items 132384.\n",
            "I0314 03:01:02.110032 138313941204992 run.py:479] Algo floyd_warshall step 4137 current loss 0.350346, current_train_items 132416.\n",
            "I0314 03:01:02.376852 138313941204992 run.py:479] Algo floyd_warshall step 4138 current loss 0.625731, current_train_items 132448.\n",
            "I0314 03:01:02.866816 138313941204992 run.py:479] Algo floyd_warshall step 4139 current loss 1.147047, current_train_items 132480.\n",
            "I0314 03:01:02.901275 138313941204992 run.py:479] Algo floyd_warshall step 4140 current loss 0.034120, current_train_items 132512.\n",
            "I0314 03:01:02.969055 138313941204992 run.py:479] Algo floyd_warshall step 4141 current loss 0.093689, current_train_items 132544.\n",
            "I0314 03:01:03.129151 138313941204992 run.py:479] Algo floyd_warshall step 4142 current loss 0.445894, current_train_items 132576.\n",
            "I0314 03:01:03.406636 138313941204992 run.py:479] Algo floyd_warshall step 4143 current loss 0.574622, current_train_items 132608.\n",
            "I0314 03:01:03.911349 138313941204992 run.py:479] Algo floyd_warshall step 4144 current loss 0.995335, current_train_items 132640.\n",
            "I0314 03:01:03.948469 138313941204992 run.py:479] Algo floyd_warshall step 4145 current loss 0.047883, current_train_items 132672.\n",
            "I0314 03:01:04.005857 138313941204992 run.py:479] Algo floyd_warshall step 4146 current loss 0.111803, current_train_items 132704.\n",
            "I0314 03:01:04.179688 138313941204992 run.py:479] Algo floyd_warshall step 4147 current loss 0.510190, current_train_items 132736.\n",
            "I0314 03:01:04.441938 138313941204992 run.py:479] Algo floyd_warshall step 4148 current loss 0.522415, current_train_items 132768.\n",
            "I0314 03:01:04.903335 138313941204992 run.py:479] Algo floyd_warshall step 4149 current loss 0.960882, current_train_items 132800.\n",
            "I0314 03:01:04.928834 138313941204992 run.py:479] Algo floyd_warshall step 4150 current loss 0.027656, current_train_items 132832.\n",
            "I0314 03:01:05.016679 138313941204992 run.py:499] (val) algo floyd_warshall step 4150: {'Pi': 0.86822509765625, 'score': 0.86822509765625, 'examples_seen': 132832, 'step': 4150, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:01:05.016957 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.879, current avg val score is 0.868, val scores are: floyd_warshall: 0.868\n",
            "I0314 03:01:05.066170 138313941204992 run.py:479] Algo floyd_warshall step 4151 current loss 0.221288, current_train_items 132864.\n",
            "I0314 03:01:05.208431 138313941204992 run.py:479] Algo floyd_warshall step 4152 current loss 0.432115, current_train_items 132896.\n",
            "I0314 03:01:05.426748 138313941204992 run.py:479] Algo floyd_warshall step 4153 current loss 0.679579, current_train_items 132928.\n",
            "I0314 03:01:05.842971 138313941204992 run.py:479] Algo floyd_warshall step 4154 current loss 1.091992, current_train_items 132960.\n",
            "I0314 03:01:05.870661 138313941204992 run.py:479] Algo floyd_warshall step 4155 current loss 0.074556, current_train_items 132992.\n",
            "I0314 03:01:05.917140 138313941204992 run.py:479] Algo floyd_warshall step 4156 current loss 0.114820, current_train_items 133024.\n",
            "I0314 03:01:06.045403 138313941204992 run.py:479] Algo floyd_warshall step 4157 current loss 0.387764, current_train_items 133056.\n",
            "I0314 03:01:06.274618 138313941204992 run.py:479] Algo floyd_warshall step 4158 current loss 0.783189, current_train_items 133088.\n",
            "I0314 03:01:06.696708 138313941204992 run.py:479] Algo floyd_warshall step 4159 current loss 1.155261, current_train_items 133120.\n",
            "I0314 03:01:06.720708 138313941204992 run.py:479] Algo floyd_warshall step 4160 current loss 0.016962, current_train_items 133152.\n",
            "I0314 03:01:06.765911 138313941204992 run.py:479] Algo floyd_warshall step 4161 current loss 0.110662, current_train_items 133184.\n",
            "I0314 03:01:06.896885 138313941204992 run.py:479] Algo floyd_warshall step 4162 current loss 0.561462, current_train_items 133216.\n",
            "I0314 03:01:07.124182 138313941204992 run.py:479] Algo floyd_warshall step 4163 current loss 0.681415, current_train_items 133248.\n",
            "I0314 03:01:07.547975 138313941204992 run.py:479] Algo floyd_warshall step 4164 current loss 1.191141, current_train_items 133280.\n",
            "I0314 03:01:07.572378 138313941204992 run.py:479] Algo floyd_warshall step 4165 current loss 0.035469, current_train_items 133312.\n",
            "I0314 03:01:07.618102 138313941204992 run.py:479] Algo floyd_warshall step 4166 current loss 0.104741, current_train_items 133344.\n",
            "I0314 03:01:07.748322 138313941204992 run.py:479] Algo floyd_warshall step 4167 current loss 0.361884, current_train_items 133376.\n",
            "I0314 03:01:07.970595 138313941204992 run.py:479] Algo floyd_warshall step 4168 current loss 0.759253, current_train_items 133408.\n",
            "I0314 03:01:08.375256 138313941204992 run.py:479] Algo floyd_warshall step 4169 current loss 1.093590, current_train_items 133440.\n",
            "I0314 03:01:08.398921 138313941204992 run.py:479] Algo floyd_warshall step 4170 current loss 0.008603, current_train_items 133472.\n",
            "I0314 03:01:08.445032 138313941204992 run.py:479] Algo floyd_warshall step 4171 current loss 0.169069, current_train_items 133504.\n",
            "I0314 03:01:08.573734 138313941204992 run.py:479] Algo floyd_warshall step 4172 current loss 0.303243, current_train_items 133536.\n",
            "I0314 03:01:08.794082 138313941204992 run.py:479] Algo floyd_warshall step 4173 current loss 0.548829, current_train_items 133568.\n",
            "I0314 03:01:09.213838 138313941204992 run.py:479] Algo floyd_warshall step 4174 current loss 1.048200, current_train_items 133600.\n",
            "I0314 03:01:09.237692 138313941204992 run.py:479] Algo floyd_warshall step 4175 current loss 0.035948, current_train_items 133632.\n",
            "I0314 03:01:09.282960 138313941204992 run.py:479] Algo floyd_warshall step 4176 current loss 0.106584, current_train_items 133664.\n",
            "I0314 03:01:09.414193 138313941204992 run.py:479] Algo floyd_warshall step 4177 current loss 0.470648, current_train_items 133696.\n",
            "I0314 03:01:09.641866 138313941204992 run.py:479] Algo floyd_warshall step 4178 current loss 0.621462, current_train_items 133728.\n",
            "I0314 03:01:10.061872 138313941204992 run.py:479] Algo floyd_warshall step 4179 current loss 0.912175, current_train_items 133760.\n",
            "I0314 03:01:10.094813 138313941204992 run.py:479] Algo floyd_warshall step 4180 current loss 0.127654, current_train_items 133792.\n",
            "I0314 03:01:10.149615 138313941204992 run.py:479] Algo floyd_warshall step 4181 current loss 0.142241, current_train_items 133824.\n",
            "I0314 03:01:10.281546 138313941204992 run.py:479] Algo floyd_warshall step 4182 current loss 0.386660, current_train_items 133856.\n",
            "I0314 03:01:10.496920 138313941204992 run.py:479] Algo floyd_warshall step 4183 current loss 0.673847, current_train_items 133888.\n",
            "I0314 03:01:10.911634 138313941204992 run.py:479] Algo floyd_warshall step 4184 current loss 1.360294, current_train_items 133920.\n",
            "I0314 03:01:10.935005 138313941204992 run.py:479] Algo floyd_warshall step 4185 current loss 0.029933, current_train_items 133952.\n",
            "I0314 03:01:10.980727 138313941204992 run.py:479] Algo floyd_warshall step 4186 current loss 0.164927, current_train_items 133984.\n",
            "I0314 03:01:11.111233 138313941204992 run.py:479] Algo floyd_warshall step 4187 current loss 0.497740, current_train_items 134016.\n",
            "I0314 03:01:11.340341 138313941204992 run.py:479] Algo floyd_warshall step 4188 current loss 0.786135, current_train_items 134048.\n",
            "I0314 03:01:11.749044 138313941204992 run.py:479] Algo floyd_warshall step 4189 current loss 1.150843, current_train_items 134080.\n",
            "I0314 03:01:11.773447 138313941204992 run.py:479] Algo floyd_warshall step 4190 current loss 0.034787, current_train_items 134112.\n",
            "I0314 03:01:11.818671 138313941204992 run.py:479] Algo floyd_warshall step 4191 current loss 0.112838, current_train_items 134144.\n",
            "I0314 03:01:11.952235 138313941204992 run.py:479] Algo floyd_warshall step 4192 current loss 0.505394, current_train_items 134176.\n",
            "I0314 03:01:12.177722 138313941204992 run.py:479] Algo floyd_warshall step 4193 current loss 0.763137, current_train_items 134208.\n",
            "I0314 03:01:12.604527 138313941204992 run.py:479] Algo floyd_warshall step 4194 current loss 1.142878, current_train_items 134240.\n",
            "I0314 03:01:12.628008 138313941204992 run.py:479] Algo floyd_warshall step 4195 current loss 0.062460, current_train_items 134272.\n",
            "I0314 03:01:12.672623 138313941204992 run.py:479] Algo floyd_warshall step 4196 current loss 0.139908, current_train_items 134304.\n",
            "I0314 03:01:12.801035 138313941204992 run.py:479] Algo floyd_warshall step 4197 current loss 0.382882, current_train_items 134336.\n",
            "I0314 03:01:13.024748 138313941204992 run.py:479] Algo floyd_warshall step 4198 current loss 0.703148, current_train_items 134368.\n",
            "I0314 03:01:13.428302 138313941204992 run.py:479] Algo floyd_warshall step 4199 current loss 0.882752, current_train_items 134400.\n",
            "I0314 03:01:13.451484 138313941204992 run.py:479] Algo floyd_warshall step 4200 current loss 0.016640, current_train_items 134432.\n",
            "I0314 03:01:13.539899 138313941204992 run.py:499] (val) algo floyd_warshall step 4200: {'Pi': 0.83282470703125, 'score': 0.83282470703125, 'examples_seen': 134432, 'step': 4200, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:01:13.540211 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.879, current avg val score is 0.833, val scores are: floyd_warshall: 0.833\n",
            "I0314 03:01:13.589447 138313941204992 run.py:479] Algo floyd_warshall step 4201 current loss 0.137810, current_train_items 134464.\n",
            "I0314 03:01:13.719455 138313941204992 run.py:479] Algo floyd_warshall step 4202 current loss 0.405808, current_train_items 134496.\n",
            "I0314 03:01:13.938238 138313941204992 run.py:479] Algo floyd_warshall step 4203 current loss 0.649429, current_train_items 134528.\n",
            "I0314 03:01:14.356573 138313941204992 run.py:479] Algo floyd_warshall step 4204 current loss 1.190314, current_train_items 134560.\n",
            "I0314 03:01:14.384272 138313941204992 run.py:479] Algo floyd_warshall step 4205 current loss 0.082314, current_train_items 134592.\n",
            "I0314 03:01:14.433808 138313941204992 run.py:479] Algo floyd_warshall step 4206 current loss 0.129586, current_train_items 134624.\n",
            "I0314 03:01:14.569429 138313941204992 run.py:479] Algo floyd_warshall step 4207 current loss 0.354659, current_train_items 134656.\n",
            "I0314 03:01:14.832062 138313941204992 run.py:479] Algo floyd_warshall step 4208 current loss 0.513210, current_train_items 134688.\n",
            "I0314 03:01:15.342658 138313941204992 run.py:479] Algo floyd_warshall step 4209 current loss 1.107132, current_train_items 134720.\n",
            "I0314 03:01:15.377990 138313941204992 run.py:479] Algo floyd_warshall step 4210 current loss 0.018898, current_train_items 134752.\n",
            "I0314 03:01:15.436879 138313941204992 run.py:479] Algo floyd_warshall step 4211 current loss 0.068111, current_train_items 134784.\n",
            "I0314 03:01:15.594656 138313941204992 run.py:479] Algo floyd_warshall step 4212 current loss 0.347900, current_train_items 134816.\n",
            "I0314 03:01:15.864316 138313941204992 run.py:479] Algo floyd_warshall step 4213 current loss 0.537317, current_train_items 134848.\n",
            "I0314 03:01:16.360409 138313941204992 run.py:479] Algo floyd_warshall step 4214 current loss 1.000347, current_train_items 134880.\n",
            "I0314 03:01:16.408461 138313941204992 run.py:479] Algo floyd_warshall step 4215 current loss 0.015339, current_train_items 134912.\n",
            "I0314 03:01:16.470450 138313941204992 run.py:479] Algo floyd_warshall step 4216 current loss 0.103750, current_train_items 134944.\n",
            "I0314 03:01:16.633892 138313941204992 run.py:479] Algo floyd_warshall step 4217 current loss 0.564382, current_train_items 134976.\n",
            "I0314 03:01:16.902838 138313941204992 run.py:479] Algo floyd_warshall step 4218 current loss 0.608277, current_train_items 135008.\n",
            "I0314 03:01:17.416781 138313941204992 run.py:479] Algo floyd_warshall step 4219 current loss 1.126486, current_train_items 135040.\n",
            "I0314 03:01:17.467014 138313941204992 run.py:479] Algo floyd_warshall step 4220 current loss 0.019784, current_train_items 135072.\n",
            "I0314 03:01:17.527886 138313941204992 run.py:479] Algo floyd_warshall step 4221 current loss 0.129662, current_train_items 135104.\n",
            "I0314 03:01:17.687846 138313941204992 run.py:479] Algo floyd_warshall step 4222 current loss 0.506034, current_train_items 135136.\n",
            "I0314 03:01:17.909623 138313941204992 run.py:479] Algo floyd_warshall step 4223 current loss 0.882094, current_train_items 135168.\n",
            "I0314 03:01:18.333902 138313941204992 run.py:479] Algo floyd_warshall step 4224 current loss 1.292226, current_train_items 135200.\n",
            "I0314 03:01:18.357589 138313941204992 run.py:479] Algo floyd_warshall step 4225 current loss 0.031434, current_train_items 135232.\n",
            "I0314 03:01:18.406330 138313941204992 run.py:479] Algo floyd_warshall step 4226 current loss 0.181049, current_train_items 135264.\n",
            "I0314 03:01:18.538501 138313941204992 run.py:479] Algo floyd_warshall step 4227 current loss 0.552960, current_train_items 135296.\n",
            "I0314 03:01:18.760706 138313941204992 run.py:479] Algo floyd_warshall step 4228 current loss 0.737513, current_train_items 135328.\n",
            "I0314 03:01:19.182412 138313941204992 run.py:479] Algo floyd_warshall step 4229 current loss 1.141065, current_train_items 135360.\n",
            "I0314 03:01:19.207055 138313941204992 run.py:479] Algo floyd_warshall step 4230 current loss 0.015567, current_train_items 135392.\n",
            "I0314 03:01:19.251652 138313941204992 run.py:479] Algo floyd_warshall step 4231 current loss 0.154906, current_train_items 135424.\n",
            "I0314 03:01:19.383756 138313941204992 run.py:479] Algo floyd_warshall step 4232 current loss 0.438341, current_train_items 135456.\n",
            "I0314 03:01:19.617494 138313941204992 run.py:479] Algo floyd_warshall step 4233 current loss 0.802913, current_train_items 135488.\n",
            "I0314 03:01:20.029386 138313941204992 run.py:479] Algo floyd_warshall step 4234 current loss 0.933249, current_train_items 135520.\n",
            "I0314 03:01:20.054248 138313941204992 run.py:479] Algo floyd_warshall step 4235 current loss 0.049097, current_train_items 135552.\n",
            "I0314 03:01:20.099212 138313941204992 run.py:479] Algo floyd_warshall step 4236 current loss 0.173027, current_train_items 135584.\n",
            "I0314 03:01:20.229534 138313941204992 run.py:479] Algo floyd_warshall step 4237 current loss 0.450643, current_train_items 135616.\n",
            "I0314 03:01:20.446565 138313941204992 run.py:479] Algo floyd_warshall step 4238 current loss 0.737632, current_train_items 135648.\n",
            "I0314 03:01:20.868343 138313941204992 run.py:479] Algo floyd_warshall step 4239 current loss 0.925587, current_train_items 135680.\n",
            "I0314 03:01:20.892949 138313941204992 run.py:479] Algo floyd_warshall step 4240 current loss 0.017494, current_train_items 135712.\n",
            "I0314 03:01:20.939569 138313941204992 run.py:479] Algo floyd_warshall step 4241 current loss 0.084036, current_train_items 135744.\n",
            "I0314 03:01:21.068787 138313941204992 run.py:479] Algo floyd_warshall step 4242 current loss 0.326769, current_train_items 135776.\n",
            "I0314 03:01:21.296992 138313941204992 run.py:479] Algo floyd_warshall step 4243 current loss 0.586630, current_train_items 135808.\n",
            "I0314 03:01:21.709297 138313941204992 run.py:479] Algo floyd_warshall step 4244 current loss 0.874714, current_train_items 135840.\n",
            "I0314 03:01:21.736506 138313941204992 run.py:479] Algo floyd_warshall step 4245 current loss 0.015395, current_train_items 135872.\n",
            "I0314 03:01:21.783957 138313941204992 run.py:479] Algo floyd_warshall step 4246 current loss 0.082678, current_train_items 135904.\n",
            "I0314 03:01:21.919574 138313941204992 run.py:479] Algo floyd_warshall step 4247 current loss 0.355324, current_train_items 135936.\n",
            "I0314 03:01:22.135817 138313941204992 run.py:479] Algo floyd_warshall step 4248 current loss 0.451977, current_train_items 135968.\n",
            "I0314 03:01:22.543000 138313941204992 run.py:479] Algo floyd_warshall step 4249 current loss 0.775833, current_train_items 136000.\n",
            "I0314 03:01:22.573126 138313941204992 run.py:479] Algo floyd_warshall step 4250 current loss 0.034624, current_train_items 136032.\n",
            "I0314 03:01:22.668836 138313941204992 run.py:499] (val) algo floyd_warshall step 4250: {'Pi': 0.8590087890625, 'score': 0.8590087890625, 'examples_seen': 136032, 'step': 4250, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:01:22.669129 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.879, current avg val score is 0.859, val scores are: floyd_warshall: 0.859\n",
            "I0314 03:01:22.717730 138313941204992 run.py:479] Algo floyd_warshall step 4251 current loss 0.085762, current_train_items 136064.\n",
            "I0314 03:01:22.848488 138313941204992 run.py:479] Algo floyd_warshall step 4252 current loss 0.419491, current_train_items 136096.\n",
            "I0314 03:01:23.067852 138313941204992 run.py:479] Algo floyd_warshall step 4253 current loss 0.741857, current_train_items 136128.\n",
            "I0314 03:01:23.467292 138313941204992 run.py:479] Algo floyd_warshall step 4254 current loss 0.883924, current_train_items 136160.\n",
            "I0314 03:01:23.492417 138313941204992 run.py:479] Algo floyd_warshall step 4255 current loss 0.058399, current_train_items 136192.\n",
            "I0314 03:01:23.537560 138313941204992 run.py:479] Algo floyd_warshall step 4256 current loss 0.109385, current_train_items 136224.\n",
            "I0314 03:01:23.667001 138313941204992 run.py:479] Algo floyd_warshall step 4257 current loss 0.358314, current_train_items 136256.\n",
            "I0314 03:01:23.896997 138313941204992 run.py:479] Algo floyd_warshall step 4258 current loss 0.571900, current_train_items 136288.\n",
            "I0314 03:01:24.304924 138313941204992 run.py:479] Algo floyd_warshall step 4259 current loss 0.768667, current_train_items 136320.\n",
            "I0314 03:01:24.328819 138313941204992 run.py:479] Algo floyd_warshall step 4260 current loss 0.030802, current_train_items 136352.\n",
            "I0314 03:01:24.372524 138313941204992 run.py:479] Algo floyd_warshall step 4261 current loss 0.096629, current_train_items 136384.\n",
            "I0314 03:01:24.503567 138313941204992 run.py:479] Algo floyd_warshall step 4262 current loss 0.348761, current_train_items 136416.\n",
            "I0314 03:01:24.727766 138313941204992 run.py:479] Algo floyd_warshall step 4263 current loss 0.470940, current_train_items 136448.\n",
            "I0314 03:01:25.147627 138313941204992 run.py:479] Algo floyd_warshall step 4264 current loss 1.080895, current_train_items 136480.\n",
            "I0314 03:01:25.170809 138313941204992 run.py:479] Algo floyd_warshall step 4265 current loss 0.010792, current_train_items 136512.\n",
            "I0314 03:01:25.215061 138313941204992 run.py:479] Algo floyd_warshall step 4266 current loss 0.076219, current_train_items 136544.\n",
            "I0314 03:01:25.345084 138313941204992 run.py:479] Algo floyd_warshall step 4267 current loss 0.496967, current_train_items 136576.\n",
            "I0314 03:01:25.567696 138313941204992 run.py:479] Algo floyd_warshall step 4268 current loss 0.714515, current_train_items 136608.\n",
            "I0314 03:01:25.988051 138313941204992 run.py:479] Algo floyd_warshall step 4269 current loss 0.935256, current_train_items 136640.\n",
            "I0314 03:01:26.010874 138313941204992 run.py:479] Algo floyd_warshall step 4270 current loss 0.029137, current_train_items 136672.\n",
            "I0314 03:01:26.056952 138313941204992 run.py:479] Algo floyd_warshall step 4271 current loss 0.182306, current_train_items 136704.\n",
            "I0314 03:01:26.183737 138313941204992 run.py:479] Algo floyd_warshall step 4272 current loss 0.250304, current_train_items 136736.\n",
            "I0314 03:01:26.409932 138313941204992 run.py:479] Algo floyd_warshall step 4273 current loss 0.539650, current_train_items 136768.\n",
            "I0314 03:01:26.823042 138313941204992 run.py:479] Algo floyd_warshall step 4274 current loss 1.001849, current_train_items 136800.\n",
            "I0314 03:01:26.848097 138313941204992 run.py:479] Algo floyd_warshall step 4275 current loss 0.030485, current_train_items 136832.\n",
            "I0314 03:01:26.892934 138313941204992 run.py:479] Algo floyd_warshall step 4276 current loss 0.167540, current_train_items 136864.\n",
            "I0314 03:01:27.026220 138313941204992 run.py:479] Algo floyd_warshall step 4277 current loss 0.442387, current_train_items 136896.\n",
            "I0314 03:01:27.257468 138313941204992 run.py:479] Algo floyd_warshall step 4278 current loss 0.674900, current_train_items 136928.\n",
            "I0314 03:01:27.664749 138313941204992 run.py:479] Algo floyd_warshall step 4279 current loss 0.963226, current_train_items 136960.\n",
            "I0314 03:01:27.715251 138313941204992 run.py:479] Algo floyd_warshall step 4280 current loss 0.022060, current_train_items 136992.\n",
            "I0314 03:01:27.777736 138313941204992 run.py:479] Algo floyd_warshall step 4281 current loss 0.081684, current_train_items 137024.\n",
            "I0314 03:01:27.937762 138313941204992 run.py:479] Algo floyd_warshall step 4282 current loss 0.355720, current_train_items 137056.\n",
            "I0314 03:01:28.202723 138313941204992 run.py:479] Algo floyd_warshall step 4283 current loss 0.665331, current_train_items 137088.\n",
            "I0314 03:01:28.714413 138313941204992 run.py:479] Algo floyd_warshall step 4284 current loss 0.878144, current_train_items 137120.\n",
            "I0314 03:01:28.760118 138313941204992 run.py:479] Algo floyd_warshall step 4285 current loss 0.027589, current_train_items 137152.\n",
            "I0314 03:01:28.825098 138313941204992 run.py:479] Algo floyd_warshall step 4286 current loss 0.142431, current_train_items 137184.\n",
            "I0314 03:01:28.978142 138313941204992 run.py:479] Algo floyd_warshall step 4287 current loss 0.235297, current_train_items 137216.\n",
            "I0314 03:01:29.231129 138313941204992 run.py:479] Algo floyd_warshall step 4288 current loss 0.520867, current_train_items 137248.\n",
            "I0314 03:01:29.724330 138313941204992 run.py:479] Algo floyd_warshall step 4289 current loss 0.909243, current_train_items 137280.\n",
            "I0314 03:01:29.757472 138313941204992 run.py:479] Algo floyd_warshall step 4290 current loss 0.032425, current_train_items 137312.\n",
            "I0314 03:01:29.817611 138313941204992 run.py:479] Algo floyd_warshall step 4291 current loss 0.112002, current_train_items 137344.\n",
            "I0314 03:01:29.977980 138313941204992 run.py:479] Algo floyd_warshall step 4292 current loss 0.441319, current_train_items 137376.\n",
            "I0314 03:01:30.244907 138313941204992 run.py:479] Algo floyd_warshall step 4293 current loss 0.500247, current_train_items 137408.\n",
            "I0314 03:01:30.758896 138313941204992 run.py:479] Algo floyd_warshall step 4294 current loss 0.882527, current_train_items 137440.\n",
            "I0314 03:01:30.782856 138313941204992 run.py:479] Algo floyd_warshall step 4295 current loss 0.032641, current_train_items 137472.\n",
            "I0314 03:01:30.828076 138313941204992 run.py:479] Algo floyd_warshall step 4296 current loss 0.068242, current_train_items 137504.\n",
            "I0314 03:01:30.970690 138313941204992 run.py:479] Algo floyd_warshall step 4297 current loss 0.345204, current_train_items 137536.\n",
            "I0314 03:01:31.189848 138313941204992 run.py:479] Algo floyd_warshall step 4298 current loss 0.685464, current_train_items 137568.\n",
            "I0314 03:01:31.602074 138313941204992 run.py:479] Algo floyd_warshall step 4299 current loss 0.868244, current_train_items 137600.\n",
            "I0314 03:01:31.626694 138313941204992 run.py:479] Algo floyd_warshall step 4300 current loss 0.042244, current_train_items 137632.\n",
            "I0314 03:01:31.715131 138313941204992 run.py:499] (val) algo floyd_warshall step 4300: {'Pi': 0.86236572265625, 'score': 0.86236572265625, 'examples_seen': 137632, 'step': 4300, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:01:31.715451 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.879, current avg val score is 0.862, val scores are: floyd_warshall: 0.862\n",
            "I0314 03:01:31.764038 138313941204992 run.py:479] Algo floyd_warshall step 4301 current loss 0.086454, current_train_items 137664.\n",
            "I0314 03:01:31.895341 138313941204992 run.py:479] Algo floyd_warshall step 4302 current loss 0.314016, current_train_items 137696.\n",
            "I0314 03:01:32.113860 138313941204992 run.py:479] Algo floyd_warshall step 4303 current loss 0.540177, current_train_items 137728.\n",
            "I0314 03:01:32.527081 138313941204992 run.py:479] Algo floyd_warshall step 4304 current loss 0.890521, current_train_items 137760.\n",
            "I0314 03:01:32.553685 138313941204992 run.py:479] Algo floyd_warshall step 4305 current loss 0.024803, current_train_items 137792.\n",
            "I0314 03:01:32.600161 138313941204992 run.py:479] Algo floyd_warshall step 4306 current loss 0.206837, current_train_items 137824.\n",
            "I0314 03:01:32.732441 138313941204992 run.py:479] Algo floyd_warshall step 4307 current loss 0.364177, current_train_items 137856.\n",
            "I0314 03:01:32.965829 138313941204992 run.py:479] Algo floyd_warshall step 4308 current loss 0.608223, current_train_items 137888.\n",
            "I0314 03:01:33.389971 138313941204992 run.py:479] Algo floyd_warshall step 4309 current loss 0.862194, current_train_items 137920.\n",
            "I0314 03:01:33.415466 138313941204992 run.py:479] Algo floyd_warshall step 4310 current loss 0.022233, current_train_items 137952.\n",
            "I0314 03:01:33.460834 138313941204992 run.py:479] Algo floyd_warshall step 4311 current loss 0.113589, current_train_items 137984.\n",
            "I0314 03:01:33.589286 138313941204992 run.py:479] Algo floyd_warshall step 4312 current loss 0.332405, current_train_items 138016.\n",
            "I0314 03:01:33.810390 138313941204992 run.py:479] Algo floyd_warshall step 4313 current loss 0.584210, current_train_items 138048.\n",
            "I0314 03:01:34.218285 138313941204992 run.py:479] Algo floyd_warshall step 4314 current loss 0.728926, current_train_items 138080.\n",
            "I0314 03:01:34.243216 138313941204992 run.py:479] Algo floyd_warshall step 4315 current loss 0.021264, current_train_items 138112.\n",
            "I0314 03:01:34.289505 138313941204992 run.py:479] Algo floyd_warshall step 4316 current loss 0.087173, current_train_items 138144.\n",
            "I0314 03:01:34.420581 138313941204992 run.py:479] Algo floyd_warshall step 4317 current loss 0.386904, current_train_items 138176.\n",
            "I0314 03:01:34.639213 138313941204992 run.py:479] Algo floyd_warshall step 4318 current loss 0.539794, current_train_items 138208.\n",
            "I0314 03:01:35.066099 138313941204992 run.py:479] Algo floyd_warshall step 4319 current loss 0.883122, current_train_items 138240.\n",
            "I0314 03:01:35.089698 138313941204992 run.py:479] Algo floyd_warshall step 4320 current loss 0.019398, current_train_items 138272.\n",
            "I0314 03:01:35.134137 138313941204992 run.py:479] Algo floyd_warshall step 4321 current loss 0.126767, current_train_items 138304.\n",
            "I0314 03:01:35.262915 138313941204992 run.py:479] Algo floyd_warshall step 4322 current loss 0.320679, current_train_items 138336.\n",
            "I0314 03:01:35.488871 138313941204992 run.py:479] Algo floyd_warshall step 4323 current loss 0.597385, current_train_items 138368.\n",
            "I0314 03:01:35.899459 138313941204992 run.py:479] Algo floyd_warshall step 4324 current loss 0.810175, current_train_items 138400.\n",
            "I0314 03:01:35.924117 138313941204992 run.py:479] Algo floyd_warshall step 4325 current loss 0.035476, current_train_items 138432.\n",
            "I0314 03:01:35.969048 138313941204992 run.py:479] Algo floyd_warshall step 4326 current loss 0.093530, current_train_items 138464.\n",
            "I0314 03:01:36.111429 138313941204992 run.py:479] Algo floyd_warshall step 4327 current loss 0.409178, current_train_items 138496.\n",
            "I0314 03:01:36.326364 138313941204992 run.py:479] Algo floyd_warshall step 4328 current loss 0.527548, current_train_items 138528.\n",
            "I0314 03:01:36.740254 138313941204992 run.py:479] Algo floyd_warshall step 4329 current loss 0.951941, current_train_items 138560.\n",
            "I0314 03:01:36.765384 138313941204992 run.py:479] Algo floyd_warshall step 4330 current loss 0.020302, current_train_items 138592.\n",
            "I0314 03:01:36.809652 138313941204992 run.py:479] Algo floyd_warshall step 4331 current loss 0.084525, current_train_items 138624.\n",
            "I0314 03:01:36.940602 138313941204992 run.py:479] Algo floyd_warshall step 4332 current loss 0.386127, current_train_items 138656.\n",
            "I0314 03:01:37.160470 138313941204992 run.py:479] Algo floyd_warshall step 4333 current loss 0.565248, current_train_items 138688.\n",
            "I0314 03:01:37.583977 138313941204992 run.py:479] Algo floyd_warshall step 4334 current loss 0.954729, current_train_items 138720.\n",
            "I0314 03:01:37.614229 138313941204992 run.py:479] Algo floyd_warshall step 4335 current loss 0.078311, current_train_items 138752.\n",
            "I0314 03:01:37.659604 138313941204992 run.py:479] Algo floyd_warshall step 4336 current loss 0.108601, current_train_items 138784.\n",
            "I0314 03:01:37.791240 138313941204992 run.py:479] Algo floyd_warshall step 4337 current loss 0.308281, current_train_items 138816.\n",
            "I0314 03:01:38.021481 138313941204992 run.py:479] Algo floyd_warshall step 4338 current loss 0.484989, current_train_items 138848.\n",
            "I0314 03:01:38.454175 138313941204992 run.py:479] Algo floyd_warshall step 4339 current loss 1.011732, current_train_items 138880.\n",
            "I0314 03:01:38.477434 138313941204992 run.py:479] Algo floyd_warshall step 4340 current loss 0.034977, current_train_items 138912.\n",
            "I0314 03:01:38.526672 138313941204992 run.py:479] Algo floyd_warshall step 4341 current loss 0.180828, current_train_items 138944.\n",
            "I0314 03:01:38.658668 138313941204992 run.py:479] Algo floyd_warshall step 4342 current loss 0.401068, current_train_items 138976.\n",
            "I0314 03:01:38.889348 138313941204992 run.py:479] Algo floyd_warshall step 4343 current loss 0.562625, current_train_items 139008.\n",
            "I0314 03:01:39.308735 138313941204992 run.py:479] Algo floyd_warshall step 4344 current loss 0.868172, current_train_items 139040.\n",
            "I0314 03:01:39.338445 138313941204992 run.py:479] Algo floyd_warshall step 4345 current loss 0.048029, current_train_items 139072.\n",
            "I0314 03:01:39.384134 138313941204992 run.py:479] Algo floyd_warshall step 4346 current loss 0.067425, current_train_items 139104.\n",
            "I0314 03:01:39.519919 138313941204992 run.py:479] Algo floyd_warshall step 4347 current loss 0.376935, current_train_items 139136.\n",
            "I0314 03:01:39.741897 138313941204992 run.py:479] Algo floyd_warshall step 4348 current loss 0.436665, current_train_items 139168.\n",
            "I0314 03:01:40.170853 138313941204992 run.py:479] Algo floyd_warshall step 4349 current loss 0.934257, current_train_items 139200.\n",
            "I0314 03:01:40.211977 138313941204992 run.py:479] Algo floyd_warshall step 4350 current loss 0.049313, current_train_items 139232.\n",
            "I0314 03:01:40.304033 138313941204992 run.py:499] (val) algo floyd_warshall step 4350: {'Pi': 0.86651611328125, 'score': 0.86651611328125, 'examples_seen': 139232, 'step': 4350, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:01:40.304320 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.879, current avg val score is 0.867, val scores are: floyd_warshall: 0.867\n",
            "I0314 03:01:40.352084 138313941204992 run.py:479] Algo floyd_warshall step 4351 current loss 0.141976, current_train_items 139264.\n",
            "I0314 03:01:40.479227 138313941204992 run.py:479] Algo floyd_warshall step 4352 current loss 0.324849, current_train_items 139296.\n",
            "I0314 03:01:40.695015 138313941204992 run.py:479] Algo floyd_warshall step 4353 current loss 0.494762, current_train_items 139328.\n",
            "I0314 03:01:41.155770 138313941204992 run.py:479] Algo floyd_warshall step 4354 current loss 0.783740, current_train_items 139360.\n",
            "I0314 03:01:41.198947 138313941204992 run.py:479] Algo floyd_warshall step 4355 current loss 0.023402, current_train_items 139392.\n",
            "I0314 03:01:41.255382 138313941204992 run.py:479] Algo floyd_warshall step 4356 current loss 0.088892, current_train_items 139424.\n",
            "I0314 03:01:41.410049 138313941204992 run.py:479] Algo floyd_warshall step 4357 current loss 0.392895, current_train_items 139456.\n",
            "I0314 03:01:41.675644 138313941204992 run.py:479] Algo floyd_warshall step 4358 current loss 0.618559, current_train_items 139488.\n",
            "I0314 03:01:42.171611 138313941204992 run.py:479] Algo floyd_warshall step 4359 current loss 0.828818, current_train_items 139520.\n",
            "I0314 03:01:42.214401 138313941204992 run.py:479] Algo floyd_warshall step 4360 current loss 0.030376, current_train_items 139552.\n",
            "I0314 03:01:42.274985 138313941204992 run.py:479] Algo floyd_warshall step 4361 current loss 0.150468, current_train_items 139584.\n",
            "I0314 03:01:42.432696 138313941204992 run.py:479] Algo floyd_warshall step 4362 current loss 0.401435, current_train_items 139616.\n",
            "I0314 03:01:42.695125 138313941204992 run.py:479] Algo floyd_warshall step 4363 current loss 0.623200, current_train_items 139648.\n",
            "I0314 03:01:43.193975 138313941204992 run.py:479] Algo floyd_warshall step 4364 current loss 0.848451, current_train_items 139680.\n",
            "I0314 03:01:43.238919 138313941204992 run.py:479] Algo floyd_warshall step 4365 current loss 0.034964, current_train_items 139712.\n",
            "I0314 03:01:43.301155 138313941204992 run.py:479] Algo floyd_warshall step 4366 current loss 0.093355, current_train_items 139744.\n",
            "I0314 03:01:43.463107 138313941204992 run.py:479] Algo floyd_warshall step 4367 current loss 0.308430, current_train_items 139776.\n",
            "I0314 03:01:43.726021 138313941204992 run.py:479] Algo floyd_warshall step 4368 current loss 0.524189, current_train_items 139808.\n",
            "I0314 03:01:44.189219 138313941204992 run.py:479] Algo floyd_warshall step 4369 current loss 0.811256, current_train_items 139840.\n",
            "I0314 03:01:44.213802 138313941204992 run.py:479] Algo floyd_warshall step 4370 current loss 0.018273, current_train_items 139872.\n",
            "I0314 03:01:44.262450 138313941204992 run.py:479] Algo floyd_warshall step 4371 current loss 0.137479, current_train_items 139904.\n",
            "I0314 03:01:44.403522 138313941204992 run.py:479] Algo floyd_warshall step 4372 current loss 0.385480, current_train_items 139936.\n",
            "I0314 03:01:44.627684 138313941204992 run.py:479] Algo floyd_warshall step 4373 current loss 0.501412, current_train_items 139968.\n",
            "I0314 03:01:45.041245 138313941204992 run.py:479] Algo floyd_warshall step 4374 current loss 0.811149, current_train_items 140000.\n",
            "I0314 03:01:45.065088 138313941204992 run.py:479] Algo floyd_warshall step 4375 current loss 0.041433, current_train_items 140032.\n",
            "I0314 03:01:45.110207 138313941204992 run.py:479] Algo floyd_warshall step 4376 current loss 0.076100, current_train_items 140064.\n",
            "I0314 03:01:45.237736 138313941204992 run.py:479] Algo floyd_warshall step 4377 current loss 0.439080, current_train_items 140096.\n",
            "I0314 03:01:45.472872 138313941204992 run.py:479] Algo floyd_warshall step 4378 current loss 0.629674, current_train_items 140128.\n",
            "I0314 03:01:45.880506 138313941204992 run.py:479] Algo floyd_warshall step 4379 current loss 1.020207, current_train_items 140160.\n",
            "I0314 03:01:45.903944 138313941204992 run.py:479] Algo floyd_warshall step 4380 current loss 0.071043, current_train_items 140192.\n",
            "I0314 03:01:45.947730 138313941204992 run.py:479] Algo floyd_warshall step 4381 current loss 0.067139, current_train_items 140224.\n",
            "I0314 03:01:46.078254 138313941204992 run.py:479] Algo floyd_warshall step 4382 current loss 0.359139, current_train_items 140256.\n",
            "I0314 03:01:46.298421 138313941204992 run.py:479] Algo floyd_warshall step 4383 current loss 0.567811, current_train_items 140288.\n",
            "I0314 03:01:46.721311 138313941204992 run.py:479] Algo floyd_warshall step 4384 current loss 0.830590, current_train_items 140320.\n",
            "I0314 03:01:46.745257 138313941204992 run.py:479] Algo floyd_warshall step 4385 current loss 0.052507, current_train_items 140352.\n",
            "I0314 03:01:46.789181 138313941204992 run.py:479] Algo floyd_warshall step 4386 current loss 0.070106, current_train_items 140384.\n",
            "I0314 03:01:46.919642 138313941204992 run.py:479] Algo floyd_warshall step 4387 current loss 0.368496, current_train_items 140416.\n",
            "I0314 03:01:47.141036 138313941204992 run.py:479] Algo floyd_warshall step 4388 current loss 0.442739, current_train_items 140448.\n",
            "I0314 03:01:47.561020 138313941204992 run.py:479] Algo floyd_warshall step 4389 current loss 0.903299, current_train_items 140480.\n",
            "I0314 03:01:47.584535 138313941204992 run.py:479] Algo floyd_warshall step 4390 current loss 0.186625, current_train_items 140512.\n",
            "I0314 03:01:47.631648 138313941204992 run.py:479] Algo floyd_warshall step 4391 current loss 0.105663, current_train_items 140544.\n",
            "I0314 03:01:47.761575 138313941204992 run.py:479] Algo floyd_warshall step 4392 current loss 0.333868, current_train_items 140576.\n",
            "I0314 03:01:47.977950 138313941204992 run.py:479] Algo floyd_warshall step 4393 current loss 0.535338, current_train_items 140608.\n",
            "I0314 03:01:48.392068 138313941204992 run.py:479] Algo floyd_warshall step 4394 current loss 0.899905, current_train_items 140640.\n",
            "I0314 03:01:48.417738 138313941204992 run.py:479] Algo floyd_warshall step 4395 current loss 0.118709, current_train_items 140672.\n",
            "I0314 03:01:48.462630 138313941204992 run.py:479] Algo floyd_warshall step 4396 current loss 0.063976, current_train_items 140704.\n",
            "I0314 03:01:48.595802 138313941204992 run.py:479] Algo floyd_warshall step 4397 current loss 0.293809, current_train_items 140736.\n",
            "I0314 03:01:48.823156 138313941204992 run.py:479] Algo floyd_warshall step 4398 current loss 0.582838, current_train_items 140768.\n",
            "I0314 03:01:49.234316 138313941204992 run.py:479] Algo floyd_warshall step 4399 current loss 0.851725, current_train_items 140800.\n",
            "I0314 03:01:49.257754 138313941204992 run.py:479] Algo floyd_warshall step 4400 current loss 0.016828, current_train_items 140832.\n",
            "I0314 03:01:49.345736 138313941204992 run.py:499] (val) algo floyd_warshall step 4400: {'Pi': 0.85064697265625, 'score': 0.85064697265625, 'examples_seen': 140832, 'step': 4400, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:01:49.346017 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.879, current avg val score is 0.851, val scores are: floyd_warshall: 0.851\n",
            "I0314 03:01:49.395232 138313941204992 run.py:479] Algo floyd_warshall step 4401 current loss 0.144829, current_train_items 140864.\n",
            "I0314 03:01:49.536414 138313941204992 run.py:479] Algo floyd_warshall step 4402 current loss 0.414875, current_train_items 140896.\n",
            "I0314 03:01:49.754186 138313941204992 run.py:479] Algo floyd_warshall step 4403 current loss 0.557820, current_train_items 140928.\n",
            "I0314 03:01:50.173206 138313941204992 run.py:479] Algo floyd_warshall step 4404 current loss 0.902739, current_train_items 140960.\n",
            "I0314 03:01:50.198935 138313941204992 run.py:479] Algo floyd_warshall step 4405 current loss 0.031100, current_train_items 140992.\n",
            "I0314 03:01:50.244715 138313941204992 run.py:479] Algo floyd_warshall step 4406 current loss 0.172553, current_train_items 141024.\n",
            "I0314 03:01:50.376153 138313941204992 run.py:479] Algo floyd_warshall step 4407 current loss 0.392838, current_train_items 141056.\n",
            "I0314 03:01:50.604414 138313941204992 run.py:479] Algo floyd_warshall step 4408 current loss 0.615911, current_train_items 141088.\n",
            "I0314 03:01:51.018302 138313941204992 run.py:479] Algo floyd_warshall step 4409 current loss 0.926704, current_train_items 141120.\n",
            "I0314 03:01:51.042513 138313941204992 run.py:479] Algo floyd_warshall step 4410 current loss 0.071355, current_train_items 141152.\n",
            "I0314 03:01:51.087268 138313941204992 run.py:479] Algo floyd_warshall step 4411 current loss 0.110773, current_train_items 141184.\n",
            "I0314 03:01:51.218171 138313941204992 run.py:479] Algo floyd_warshall step 4412 current loss 0.319104, current_train_items 141216.\n",
            "I0314 03:01:51.445827 138313941204992 run.py:479] Algo floyd_warshall step 4413 current loss 0.543250, current_train_items 141248.\n",
            "I0314 03:01:51.861965 138313941204992 run.py:479] Algo floyd_warshall step 4414 current loss 0.785504, current_train_items 141280.\n",
            "I0314 03:01:51.888846 138313941204992 run.py:479] Algo floyd_warshall step 4415 current loss 0.018073, current_train_items 141312.\n",
            "I0314 03:01:51.934094 138313941204992 run.py:479] Algo floyd_warshall step 4416 current loss 0.081875, current_train_items 141344.\n",
            "I0314 03:01:52.063822 138313941204992 run.py:479] Algo floyd_warshall step 4417 current loss 0.314798, current_train_items 141376.\n",
            "I0314 03:01:52.294128 138313941204992 run.py:479] Algo floyd_warshall step 4418 current loss 0.487305, current_train_items 141408.\n",
            "I0314 03:01:52.699871 138313941204992 run.py:479] Algo floyd_warshall step 4419 current loss 0.784482, current_train_items 141440.\n",
            "I0314 03:01:52.724779 138313941204992 run.py:479] Algo floyd_warshall step 4420 current loss 0.034768, current_train_items 141472.\n",
            "I0314 03:01:52.771230 138313941204992 run.py:479] Algo floyd_warshall step 4421 current loss 0.117944, current_train_items 141504.\n",
            "I0314 03:01:52.900110 138313941204992 run.py:479] Algo floyd_warshall step 4422 current loss 0.187604, current_train_items 141536.\n",
            "I0314 03:01:53.112934 138313941204992 run.py:479] Algo floyd_warshall step 4423 current loss 0.447958, current_train_items 141568.\n",
            "I0314 03:01:53.532019 138313941204992 run.py:479] Algo floyd_warshall step 4424 current loss 0.917623, current_train_items 141600.\n",
            "I0314 03:01:53.553923 138313941204992 run.py:479] Algo floyd_warshall step 4425 current loss 0.022181, current_train_items 141632.\n",
            "I0314 03:01:53.598040 138313941204992 run.py:479] Algo floyd_warshall step 4426 current loss 0.085660, current_train_items 141664.\n",
            "I0314 03:01:53.726513 138313941204992 run.py:479] Algo floyd_warshall step 4427 current loss 0.306454, current_train_items 141696.\n",
            "I0314 03:01:53.942411 138313941204992 run.py:479] Algo floyd_warshall step 4428 current loss 0.464484, current_train_items 141728.\n",
            "I0314 03:01:54.429797 138313941204992 run.py:479] Algo floyd_warshall step 4429 current loss 0.763080, current_train_items 141760.\n",
            "I0314 03:01:54.466003 138313941204992 run.py:479] Algo floyd_warshall step 4430 current loss 0.038410, current_train_items 141792.\n",
            "I0314 03:01:54.520931 138313941204992 run.py:479] Algo floyd_warshall step 4431 current loss 0.081525, current_train_items 141824.\n",
            "I0314 03:01:54.678143 138313941204992 run.py:479] Algo floyd_warshall step 4432 current loss 0.326104, current_train_items 141856.\n",
            "I0314 03:01:54.944594 138313941204992 run.py:479] Algo floyd_warshall step 4433 current loss 0.469841, current_train_items 141888.\n",
            "I0314 03:01:55.442241 138313941204992 run.py:479] Algo floyd_warshall step 4434 current loss 0.751294, current_train_items 141920.\n",
            "I0314 03:01:55.477660 138313941204992 run.py:479] Algo floyd_warshall step 4435 current loss 0.205420, current_train_items 141952.\n",
            "I0314 03:01:55.534234 138313941204992 run.py:479] Algo floyd_warshall step 4436 current loss 0.084081, current_train_items 141984.\n",
            "I0314 03:01:55.704631 138313941204992 run.py:479] Algo floyd_warshall step 4437 current loss 0.288406, current_train_items 142016.\n",
            "I0314 03:01:55.988899 138313941204992 run.py:479] Algo floyd_warshall step 4438 current loss 0.548468, current_train_items 142048.\n",
            "I0314 03:01:56.464002 138313941204992 run.py:479] Algo floyd_warshall step 4439 current loss 0.678412, current_train_items 142080.\n",
            "I0314 03:01:56.500365 138313941204992 run.py:479] Algo floyd_warshall step 4440 current loss 0.040474, current_train_items 142112.\n",
            "I0314 03:01:56.556978 138313941204992 run.py:479] Algo floyd_warshall step 4441 current loss 0.110795, current_train_items 142144.\n",
            "I0314 03:01:56.725352 138313941204992 run.py:479] Algo floyd_warshall step 4442 current loss 0.413726, current_train_items 142176.\n",
            "I0314 03:01:56.992056 138313941204992 run.py:479] Algo floyd_warshall step 4443 current loss 0.541576, current_train_items 142208.\n",
            "I0314 03:01:57.415207 138313941204992 run.py:479] Algo floyd_warshall step 4444 current loss 0.863101, current_train_items 142240.\n",
            "I0314 03:01:57.438129 138313941204992 run.py:479] Algo floyd_warshall step 4445 current loss 0.029636, current_train_items 142272.\n",
            "I0314 03:01:57.483134 138313941204992 run.py:479] Algo floyd_warshall step 4446 current loss 0.144008, current_train_items 142304.\n",
            "I0314 03:01:57.613699 138313941204992 run.py:479] Algo floyd_warshall step 4447 current loss 0.425901, current_train_items 142336.\n",
            "I0314 03:01:57.839365 138313941204992 run.py:479] Algo floyd_warshall step 4448 current loss 0.610416, current_train_items 142368.\n",
            "I0314 03:01:58.241411 138313941204992 run.py:479] Algo floyd_warshall step 4449 current loss 0.739650, current_train_items 142400.\n",
            "I0314 03:01:58.265943 138313941204992 run.py:479] Algo floyd_warshall step 4450 current loss 0.023974, current_train_items 142432.\n",
            "I0314 03:01:58.348412 138313941204992 run.py:499] (val) algo floyd_warshall step 4450: {'Pi': 0.86328125, 'score': 0.86328125, 'examples_seen': 142432, 'step': 4450, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:01:58.348646 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.879, current avg val score is 0.863, val scores are: floyd_warshall: 0.863\n",
            "I0314 03:01:58.398498 138313941204992 run.py:479] Algo floyd_warshall step 4451 current loss 0.111435, current_train_items 142464.\n",
            "I0314 03:01:58.532925 138313941204992 run.py:479] Algo floyd_warshall step 4452 current loss 0.403239, current_train_items 142496.\n",
            "I0314 03:01:58.749692 138313941204992 run.py:479] Algo floyd_warshall step 4453 current loss 0.456776, current_train_items 142528.\n",
            "I0314 03:01:59.174718 138313941204992 run.py:479] Algo floyd_warshall step 4454 current loss 0.823931, current_train_items 142560.\n",
            "I0314 03:01:59.199558 138313941204992 run.py:479] Algo floyd_warshall step 4455 current loss 0.076211, current_train_items 142592.\n",
            "I0314 03:01:59.243782 138313941204992 run.py:479] Algo floyd_warshall step 4456 current loss 0.102216, current_train_items 142624.\n",
            "I0314 03:01:59.374722 138313941204992 run.py:479] Algo floyd_warshall step 4457 current loss 0.375813, current_train_items 142656.\n",
            "I0314 03:01:59.589782 138313941204992 run.py:479] Algo floyd_warshall step 4458 current loss 0.559678, current_train_items 142688.\n",
            "I0314 03:01:59.998656 138313941204992 run.py:479] Algo floyd_warshall step 4459 current loss 0.763442, current_train_items 142720.\n",
            "I0314 03:02:00.022954 138313941204992 run.py:479] Algo floyd_warshall step 4460 current loss 0.010350, current_train_items 142752.\n",
            "I0314 03:02:00.068431 138313941204992 run.py:479] Algo floyd_warshall step 4461 current loss 0.073617, current_train_items 142784.\n",
            "I0314 03:02:00.199585 138313941204992 run.py:479] Algo floyd_warshall step 4462 current loss 0.462184, current_train_items 142816.\n",
            "I0314 03:02:00.424377 138313941204992 run.py:479] Algo floyd_warshall step 4463 current loss 0.480576, current_train_items 142848.\n",
            "I0314 03:02:00.838312 138313941204992 run.py:479] Algo floyd_warshall step 4464 current loss 0.946626, current_train_items 142880.\n",
            "I0314 03:02:00.862436 138313941204992 run.py:479] Algo floyd_warshall step 4465 current loss 0.044515, current_train_items 142912.\n",
            "I0314 03:02:00.906100 138313941204992 run.py:479] Algo floyd_warshall step 4466 current loss 0.073050, current_train_items 142944.\n",
            "I0314 03:02:01.036203 138313941204992 run.py:479] Algo floyd_warshall step 4467 current loss 0.320575, current_train_items 142976.\n",
            "I0314 03:02:01.248801 138313941204992 run.py:479] Algo floyd_warshall step 4468 current loss 0.520937, current_train_items 143008.\n",
            "I0314 03:02:01.661084 138313941204992 run.py:479] Algo floyd_warshall step 4469 current loss 0.943517, current_train_items 143040.\n",
            "I0314 03:02:01.684582 138313941204992 run.py:479] Algo floyd_warshall step 4470 current loss 0.021802, current_train_items 143072.\n",
            "I0314 03:02:01.730459 138313941204992 run.py:479] Algo floyd_warshall step 4471 current loss 0.135327, current_train_items 143104.\n",
            "I0314 03:02:01.861281 138313941204992 run.py:479] Algo floyd_warshall step 4472 current loss 0.452265, current_train_items 143136.\n",
            "I0314 03:02:02.074935 138313941204992 run.py:479] Algo floyd_warshall step 4473 current loss 0.549349, current_train_items 143168.\n",
            "I0314 03:02:02.482981 138313941204992 run.py:479] Algo floyd_warshall step 4474 current loss 0.869000, current_train_items 143200.\n",
            "I0314 03:02:02.505593 138313941204992 run.py:479] Algo floyd_warshall step 4475 current loss 0.024986, current_train_items 143232.\n",
            "I0314 03:02:02.549966 138313941204992 run.py:479] Algo floyd_warshall step 4476 current loss 0.073011, current_train_items 143264.\n",
            "I0314 03:02:02.677002 138313941204992 run.py:479] Algo floyd_warshall step 4477 current loss 0.381907, current_train_items 143296.\n",
            "I0314 03:02:02.897109 138313941204992 run.py:479] Algo floyd_warshall step 4478 current loss 0.680610, current_train_items 143328.\n",
            "I0314 03:02:03.310236 138313941204992 run.py:479] Algo floyd_warshall step 4479 current loss 0.976116, current_train_items 143360.\n",
            "I0314 03:02:03.333056 138313941204992 run.py:479] Algo floyd_warshall step 4480 current loss 0.032322, current_train_items 143392.\n",
            "I0314 03:02:03.377240 138313941204992 run.py:479] Algo floyd_warshall step 4481 current loss 0.113180, current_train_items 143424.\n",
            "I0314 03:02:03.507817 138313941204992 run.py:479] Algo floyd_warshall step 4482 current loss 0.347404, current_train_items 143456.\n",
            "I0314 03:02:03.732613 138313941204992 run.py:479] Algo floyd_warshall step 4483 current loss 0.501617, current_train_items 143488.\n",
            "I0314 03:02:04.152583 138313941204992 run.py:479] Algo floyd_warshall step 4484 current loss 0.918125, current_train_items 143520.\n",
            "I0314 03:02:04.176502 138313941204992 run.py:479] Algo floyd_warshall step 4485 current loss 0.015708, current_train_items 143552.\n",
            "I0314 03:02:04.223982 138313941204992 run.py:479] Algo floyd_warshall step 4486 current loss 0.113811, current_train_items 143584.\n",
            "I0314 03:02:04.356171 138313941204992 run.py:479] Algo floyd_warshall step 4487 current loss 0.420727, current_train_items 143616.\n",
            "I0314 03:02:04.567184 138313941204992 run.py:479] Algo floyd_warshall step 4488 current loss 0.474158, current_train_items 143648.\n",
            "I0314 03:02:04.986534 138313941204992 run.py:479] Algo floyd_warshall step 4489 current loss 0.919003, current_train_items 143680.\n",
            "I0314 03:02:05.009554 138313941204992 run.py:479] Algo floyd_warshall step 4490 current loss 0.021942, current_train_items 143712.\n",
            "I0314 03:02:05.052788 138313941204992 run.py:479] Algo floyd_warshall step 4491 current loss 0.060816, current_train_items 143744.\n",
            "I0314 03:02:05.187927 138313941204992 run.py:479] Algo floyd_warshall step 4492 current loss 0.345233, current_train_items 143776.\n",
            "I0314 03:02:05.399609 138313941204992 run.py:479] Algo floyd_warshall step 4493 current loss 0.534464, current_train_items 143808.\n",
            "I0314 03:02:05.814955 138313941204992 run.py:479] Algo floyd_warshall step 4494 current loss 0.986051, current_train_items 143840.\n",
            "I0314 03:02:05.837790 138313941204992 run.py:479] Algo floyd_warshall step 4495 current loss 0.016974, current_train_items 143872.\n",
            "I0314 03:02:05.883683 138313941204992 run.py:479] Algo floyd_warshall step 4496 current loss 0.149360, current_train_items 143904.\n",
            "I0314 03:02:06.022411 138313941204992 run.py:479] Algo floyd_warshall step 4497 current loss 0.429562, current_train_items 143936.\n",
            "I0314 03:02:06.248783 138313941204992 run.py:479] Algo floyd_warshall step 4498 current loss 0.506940, current_train_items 143968.\n",
            "I0314 03:02:06.664925 138313941204992 run.py:479] Algo floyd_warshall step 4499 current loss 0.955533, current_train_items 144000.\n",
            "I0314 03:02:06.688575 138313941204992 run.py:479] Algo floyd_warshall step 4500 current loss 0.042119, current_train_items 144032.\n",
            "I0314 03:02:06.775312 138313941204992 run.py:499] (val) algo floyd_warshall step 4500: {'Pi': 0.85858154296875, 'score': 0.85858154296875, 'examples_seen': 144032, 'step': 4500, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:02:06.775560 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.879, current avg val score is 0.859, val scores are: floyd_warshall: 0.859\n",
            "I0314 03:02:06.823668 138313941204992 run.py:479] Algo floyd_warshall step 4501 current loss 0.209998, current_train_items 144064.\n",
            "I0314 03:02:06.956633 138313941204992 run.py:479] Algo floyd_warshall step 4502 current loss 0.421416, current_train_items 144096.\n",
            "I0314 03:02:07.232733 138313941204992 run.py:479] Algo floyd_warshall step 4503 current loss 0.584387, current_train_items 144128.\n",
            "I0314 03:02:07.735765 138313941204992 run.py:479] Algo floyd_warshall step 4504 current loss 1.041200, current_train_items 144160.\n",
            "I0314 03:02:07.773563 138313941204992 run.py:479] Algo floyd_warshall step 4505 current loss 0.022044, current_train_items 144192.\n",
            "I0314 03:02:07.830602 138313941204992 run.py:479] Algo floyd_warshall step 4506 current loss 0.111341, current_train_items 144224.\n",
            "I0314 03:02:07.992388 138313941204992 run.py:479] Algo floyd_warshall step 4507 current loss 0.381797, current_train_items 144256.\n",
            "I0314 03:02:08.268326 138313941204992 run.py:479] Algo floyd_warshall step 4508 current loss 0.542213, current_train_items 144288.\n",
            "I0314 03:02:08.744475 138313941204992 run.py:479] Algo floyd_warshall step 4509 current loss 0.761581, current_train_items 144320.\n",
            "I0314 03:02:08.783244 138313941204992 run.py:479] Algo floyd_warshall step 4510 current loss 0.030203, current_train_items 144352.\n",
            "I0314 03:02:08.840621 138313941204992 run.py:479] Algo floyd_warshall step 4511 current loss 0.122045, current_train_items 144384.\n",
            "I0314 03:02:09.003275 138313941204992 run.py:479] Algo floyd_warshall step 4512 current loss 0.467908, current_train_items 144416.\n",
            "I0314 03:02:09.276366 138313941204992 run.py:479] Algo floyd_warshall step 4513 current loss 0.618114, current_train_items 144448.\n",
            "I0314 03:02:09.762907 138313941204992 run.py:479] Algo floyd_warshall step 4514 current loss 0.739544, current_train_items 144480.\n",
            "I0314 03:02:09.801566 138313941204992 run.py:479] Algo floyd_warshall step 4515 current loss 0.097943, current_train_items 144512.\n",
            "I0314 03:02:09.862205 138313941204992 run.py:479] Algo floyd_warshall step 4516 current loss 0.090241, current_train_items 144544.\n",
            "I0314 03:02:10.026026 138313941204992 run.py:479] Algo floyd_warshall step 4517 current loss 0.409449, current_train_items 144576.\n",
            "I0314 03:02:10.259853 138313941204992 run.py:479] Algo floyd_warshall step 4518 current loss 0.560293, current_train_items 144608.\n",
            "I0314 03:02:10.696105 138313941204992 run.py:479] Algo floyd_warshall step 4519 current loss 0.772239, current_train_items 144640.\n",
            "I0314 03:02:10.720497 138313941204992 run.py:479] Algo floyd_warshall step 4520 current loss 0.022153, current_train_items 144672.\n",
            "I0314 03:02:10.767397 138313941204992 run.py:479] Algo floyd_warshall step 4521 current loss 0.142818, current_train_items 144704.\n",
            "I0314 03:02:10.896866 138313941204992 run.py:479] Algo floyd_warshall step 4522 current loss 0.343843, current_train_items 144736.\n",
            "I0314 03:02:11.115238 138313941204992 run.py:479] Algo floyd_warshall step 4523 current loss 0.701043, current_train_items 144768.\n",
            "I0314 03:02:11.529370 138313941204992 run.py:479] Algo floyd_warshall step 4524 current loss 0.727324, current_train_items 144800.\n",
            "I0314 03:02:11.553802 138313941204992 run.py:479] Algo floyd_warshall step 4525 current loss 0.027271, current_train_items 144832.\n",
            "I0314 03:02:11.598928 138313941204992 run.py:479] Algo floyd_warshall step 4526 current loss 0.103418, current_train_items 144864.\n",
            "I0314 03:02:11.730602 138313941204992 run.py:479] Algo floyd_warshall step 4527 current loss 0.294269, current_train_items 144896.\n",
            "I0314 03:02:11.950174 138313941204992 run.py:479] Algo floyd_warshall step 4528 current loss 0.490428, current_train_items 144928.\n",
            "I0314 03:02:12.364053 138313941204992 run.py:479] Algo floyd_warshall step 4529 current loss 0.976142, current_train_items 144960.\n",
            "I0314 03:02:12.388214 138313941204992 run.py:479] Algo floyd_warshall step 4530 current loss 0.024606, current_train_items 144992.\n",
            "I0314 03:02:12.434133 138313941204992 run.py:479] Algo floyd_warshall step 4531 current loss 0.075174, current_train_items 145024.\n",
            "I0314 03:02:12.563061 138313941204992 run.py:479] Algo floyd_warshall step 4532 current loss 0.327148, current_train_items 145056.\n",
            "I0314 03:02:12.790840 138313941204992 run.py:479] Algo floyd_warshall step 4533 current loss 0.528671, current_train_items 145088.\n",
            "I0314 03:02:13.210681 138313941204992 run.py:479] Algo floyd_warshall step 4534 current loss 0.809245, current_train_items 145120.\n",
            "I0314 03:02:13.236683 138313941204992 run.py:479] Algo floyd_warshall step 4535 current loss 0.035712, current_train_items 145152.\n",
            "I0314 03:02:13.280614 138313941204992 run.py:479] Algo floyd_warshall step 4536 current loss 0.079169, current_train_items 145184.\n",
            "I0314 03:02:13.409079 138313941204992 run.py:479] Algo floyd_warshall step 4537 current loss 0.244927, current_train_items 145216.\n",
            "I0314 03:02:13.633085 138313941204992 run.py:479] Algo floyd_warshall step 4538 current loss 0.597231, current_train_items 145248.\n",
            "I0314 03:02:14.061456 138313941204992 run.py:479] Algo floyd_warshall step 4539 current loss 0.945656, current_train_items 145280.\n",
            "I0314 03:02:14.084413 138313941204992 run.py:479] Algo floyd_warshall step 4540 current loss 0.024687, current_train_items 145312.\n",
            "I0314 03:02:14.128884 138313941204992 run.py:479] Algo floyd_warshall step 4541 current loss 0.085820, current_train_items 145344.\n",
            "I0314 03:02:14.258650 138313941204992 run.py:479] Algo floyd_warshall step 4542 current loss 0.324722, current_train_items 145376.\n",
            "I0314 03:02:14.489906 138313941204992 run.py:479] Algo floyd_warshall step 4543 current loss 0.480299, current_train_items 145408.\n",
            "I0314 03:02:14.920385 138313941204992 run.py:479] Algo floyd_warshall step 4544 current loss 0.891473, current_train_items 145440.\n",
            "I0314 03:02:14.945328 138313941204992 run.py:479] Algo floyd_warshall step 4545 current loss 0.035710, current_train_items 145472.\n",
            "I0314 03:02:14.990096 138313941204992 run.py:479] Algo floyd_warshall step 4546 current loss 0.089286, current_train_items 145504.\n",
            "I0314 03:02:15.122540 138313941204992 run.py:479] Algo floyd_warshall step 4547 current loss 0.383733, current_train_items 145536.\n",
            "I0314 03:02:15.336813 138313941204992 run.py:479] Algo floyd_warshall step 4548 current loss 0.416010, current_train_items 145568.\n",
            "I0314 03:02:15.757059 138313941204992 run.py:479] Algo floyd_warshall step 4549 current loss 0.956395, current_train_items 145600.\n",
            "I0314 03:02:15.782111 138313941204992 run.py:479] Algo floyd_warshall step 4550 current loss 0.023537, current_train_items 145632.\n",
            "I0314 03:02:15.872465 138313941204992 run.py:499] (val) algo floyd_warshall step 4550: {'Pi': 0.8477783203125, 'score': 0.8477783203125, 'examples_seen': 145632, 'step': 4550, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:02:15.872763 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.879, current avg val score is 0.848, val scores are: floyd_warshall: 0.848\n",
            "I0314 03:02:15.921136 138313941204992 run.py:479] Algo floyd_warshall step 4551 current loss 0.059199, current_train_items 145664.\n",
            "I0314 03:02:16.055308 138313941204992 run.py:479] Algo floyd_warshall step 4552 current loss 0.288434, current_train_items 145696.\n",
            "I0314 03:02:16.274350 138313941204992 run.py:479] Algo floyd_warshall step 4553 current loss 0.612808, current_train_items 145728.\n",
            "I0314 03:02:16.697595 138313941204992 run.py:479] Algo floyd_warshall step 4554 current loss 0.823612, current_train_items 145760.\n",
            "I0314 03:02:16.725558 138313941204992 run.py:479] Algo floyd_warshall step 4555 current loss 0.037280, current_train_items 145792.\n",
            "I0314 03:02:16.771230 138313941204992 run.py:479] Algo floyd_warshall step 4556 current loss 0.156495, current_train_items 145824.\n",
            "I0314 03:02:16.900099 138313941204992 run.py:479] Algo floyd_warshall step 4557 current loss 0.267720, current_train_items 145856.\n",
            "I0314 03:02:17.120616 138313941204992 run.py:479] Algo floyd_warshall step 4558 current loss 0.556476, current_train_items 145888.\n",
            "I0314 03:02:17.542875 138313941204992 run.py:479] Algo floyd_warshall step 4559 current loss 0.885228, current_train_items 145920.\n",
            "I0314 03:02:17.567553 138313941204992 run.py:479] Algo floyd_warshall step 4560 current loss 0.030942, current_train_items 145952.\n",
            "I0314 03:02:17.613831 138313941204992 run.py:479] Algo floyd_warshall step 4561 current loss 0.143046, current_train_items 145984.\n",
            "I0314 03:02:17.743419 138313941204992 run.py:479] Algo floyd_warshall step 4562 current loss 0.354019, current_train_items 146016.\n",
            "I0314 03:02:17.952402 138313941204992 run.py:479] Algo floyd_warshall step 4563 current loss 0.380562, current_train_items 146048.\n",
            "I0314 03:02:18.366593 138313941204992 run.py:479] Algo floyd_warshall step 4564 current loss 0.989727, current_train_items 146080.\n",
            "I0314 03:02:18.391212 138313941204992 run.py:479] Algo floyd_warshall step 4565 current loss 0.026610, current_train_items 146112.\n",
            "I0314 03:02:18.436993 138313941204992 run.py:479] Algo floyd_warshall step 4566 current loss 0.130769, current_train_items 146144.\n",
            "I0314 03:02:18.569361 138313941204992 run.py:479] Algo floyd_warshall step 4567 current loss 0.439099, current_train_items 146176.\n",
            "I0314 03:02:18.795944 138313941204992 run.py:479] Algo floyd_warshall step 4568 current loss 0.474761, current_train_items 146208.\n",
            "I0314 03:02:19.210875 138313941204992 run.py:479] Algo floyd_warshall step 4569 current loss 0.899421, current_train_items 146240.\n",
            "I0314 03:02:19.235427 138313941204992 run.py:479] Algo floyd_warshall step 4570 current loss 0.018567, current_train_items 146272.\n",
            "I0314 03:02:19.280722 138313941204992 run.py:479] Algo floyd_warshall step 4571 current loss 0.078596, current_train_items 146304.\n",
            "I0314 03:02:19.420560 138313941204992 run.py:479] Algo floyd_warshall step 4572 current loss 0.364391, current_train_items 146336.\n",
            "I0314 03:02:19.648319 138313941204992 run.py:479] Algo floyd_warshall step 4573 current loss 0.538330, current_train_items 146368.\n",
            "I0314 03:02:20.071518 138313941204992 run.py:479] Algo floyd_warshall step 4574 current loss 0.839508, current_train_items 146400.\n",
            "I0314 03:02:20.110044 138313941204992 run.py:479] Algo floyd_warshall step 4575 current loss 0.030511, current_train_items 146432.\n",
            "I0314 03:02:20.170125 138313941204992 run.py:479] Algo floyd_warshall step 4576 current loss 0.069366, current_train_items 146464.\n",
            "I0314 03:02:20.331357 138313941204992 run.py:479] Algo floyd_warshall step 4577 current loss 0.313652, current_train_items 146496.\n",
            "I0314 03:02:20.617223 138313941204992 run.py:479] Algo floyd_warshall step 4578 current loss 0.653157, current_train_items 146528.\n",
            "I0314 03:02:21.127198 138313941204992 run.py:479] Algo floyd_warshall step 4579 current loss 0.937515, current_train_items 146560.\n",
            "I0314 03:02:21.163878 138313941204992 run.py:479] Algo floyd_warshall step 4580 current loss 0.019861, current_train_items 146592.\n",
            "I0314 03:02:21.220593 138313941204992 run.py:479] Algo floyd_warshall step 4581 current loss 0.134519, current_train_items 146624.\n",
            "I0314 03:02:21.375598 138313941204992 run.py:479] Algo floyd_warshall step 4582 current loss 0.295919, current_train_items 146656.\n",
            "I0314 03:02:21.652572 138313941204992 run.py:479] Algo floyd_warshall step 4583 current loss 0.437229, current_train_items 146688.\n",
            "I0314 03:02:22.139594 138313941204992 run.py:479] Algo floyd_warshall step 4584 current loss 0.942155, current_train_items 146720.\n",
            "I0314 03:02:22.172520 138313941204992 run.py:479] Algo floyd_warshall step 4585 current loss 0.021622, current_train_items 146752.\n",
            "I0314 03:02:22.227173 138313941204992 run.py:479] Algo floyd_warshall step 4586 current loss 0.163060, current_train_items 146784.\n",
            "I0314 03:02:22.381540 138313941204992 run.py:479] Algo floyd_warshall step 4587 current loss 0.342399, current_train_items 146816.\n",
            "I0314 03:02:22.674975 138313941204992 run.py:479] Algo floyd_warshall step 4588 current loss 0.613650, current_train_items 146848.\n",
            "I0314 03:02:23.196418 138313941204992 run.py:479] Algo floyd_warshall step 4589 current loss 1.128192, current_train_items 146880.\n",
            "I0314 03:02:23.221199 138313941204992 run.py:479] Algo floyd_warshall step 4590 current loss 0.024847, current_train_items 146912.\n",
            "I0314 03:02:23.265828 138313941204992 run.py:479] Algo floyd_warshall step 4591 current loss 0.107343, current_train_items 146944.\n",
            "I0314 03:02:23.396087 138313941204992 run.py:479] Algo floyd_warshall step 4592 current loss 0.302365, current_train_items 146976.\n",
            "I0314 03:02:23.629986 138313941204992 run.py:479] Algo floyd_warshall step 4593 current loss 0.695028, current_train_items 147008.\n",
            "I0314 03:02:24.045945 138313941204992 run.py:479] Algo floyd_warshall step 4594 current loss 0.779240, current_train_items 147040.\n",
            "I0314 03:02:24.070142 138313941204992 run.py:479] Algo floyd_warshall step 4595 current loss 0.010737, current_train_items 147072.\n",
            "I0314 03:02:24.115442 138313941204992 run.py:479] Algo floyd_warshall step 4596 current loss 0.089772, current_train_items 147104.\n",
            "I0314 03:02:24.244884 138313941204992 run.py:479] Algo floyd_warshall step 4597 current loss 0.459787, current_train_items 147136.\n",
            "I0314 03:02:24.459268 138313941204992 run.py:479] Algo floyd_warshall step 4598 current loss 0.601775, current_train_items 147168.\n",
            "I0314 03:02:24.884573 138313941204992 run.py:479] Algo floyd_warshall step 4599 current loss 0.780661, current_train_items 147200.\n",
            "I0314 03:02:24.907290 138313941204992 run.py:479] Algo floyd_warshall step 4600 current loss 0.018938, current_train_items 147232.\n",
            "I0314 03:02:24.993175 138313941204992 run.py:499] (val) algo floyd_warshall step 4600: {'Pi': 0.87396240234375, 'score': 0.87396240234375, 'examples_seen': 147232, 'step': 4600, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:02:24.993463 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.879, current avg val score is 0.874, val scores are: floyd_warshall: 0.874\n",
            "I0314 03:02:25.040864 138313941204992 run.py:479] Algo floyd_warshall step 4601 current loss 0.080880, current_train_items 147264.\n",
            "I0314 03:02:25.172508 138313941204992 run.py:479] Algo floyd_warshall step 4602 current loss 0.327154, current_train_items 147296.\n",
            "I0314 03:02:25.387105 138313941204992 run.py:479] Algo floyd_warshall step 4603 current loss 0.466412, current_train_items 147328.\n",
            "I0314 03:02:25.809274 138313941204992 run.py:479] Algo floyd_warshall step 4604 current loss 0.864040, current_train_items 147360.\n",
            "I0314 03:02:25.834936 138313941204992 run.py:479] Algo floyd_warshall step 4605 current loss 0.016479, current_train_items 147392.\n",
            "I0314 03:02:25.882056 138313941204992 run.py:479] Algo floyd_warshall step 4606 current loss 0.109853, current_train_items 147424.\n",
            "I0314 03:02:26.014842 138313941204992 run.py:479] Algo floyd_warshall step 4607 current loss 0.459054, current_train_items 147456.\n",
            "I0314 03:02:26.244114 138313941204992 run.py:479] Algo floyd_warshall step 4608 current loss 0.455831, current_train_items 147488.\n",
            "I0314 03:02:26.659283 138313941204992 run.py:479] Algo floyd_warshall step 4609 current loss 1.005181, current_train_items 147520.\n",
            "I0314 03:02:26.683172 138313941204992 run.py:479] Algo floyd_warshall step 4610 current loss 0.039502, current_train_items 147552.\n",
            "I0314 03:02:26.730170 138313941204992 run.py:479] Algo floyd_warshall step 4611 current loss 0.105150, current_train_items 147584.\n",
            "I0314 03:02:26.857550 138313941204992 run.py:479] Algo floyd_warshall step 4612 current loss 0.316256, current_train_items 147616.\n",
            "I0314 03:02:27.074967 138313941204992 run.py:479] Algo floyd_warshall step 4613 current loss 0.560264, current_train_items 147648.\n",
            "I0314 03:02:27.486448 138313941204992 run.py:479] Algo floyd_warshall step 4614 current loss 0.796439, current_train_items 147680.\n",
            "I0314 03:02:27.511620 138313941204992 run.py:479] Algo floyd_warshall step 4615 current loss 0.038276, current_train_items 147712.\n",
            "I0314 03:02:27.556646 138313941204992 run.py:479] Algo floyd_warshall step 4616 current loss 0.105490, current_train_items 147744.\n",
            "I0314 03:02:27.689253 138313941204992 run.py:479] Algo floyd_warshall step 4617 current loss 0.410977, current_train_items 147776.\n",
            "I0314 03:02:27.907994 138313941204992 run.py:479] Algo floyd_warshall step 4618 current loss 0.542136, current_train_items 147808.\n",
            "I0314 03:02:28.311310 138313941204992 run.py:479] Algo floyd_warshall step 4619 current loss 0.681326, current_train_items 147840.\n",
            "I0314 03:02:28.336715 138313941204992 run.py:479] Algo floyd_warshall step 4620 current loss 0.013738, current_train_items 147872.\n",
            "I0314 03:02:28.380646 138313941204992 run.py:479] Algo floyd_warshall step 4621 current loss 0.067737, current_train_items 147904.\n",
            "I0314 03:02:28.508795 138313941204992 run.py:479] Algo floyd_warshall step 4622 current loss 0.303904, current_train_items 147936.\n",
            "I0314 03:02:28.733690 138313941204992 run.py:479] Algo floyd_warshall step 4623 current loss 0.545351, current_train_items 147968.\n",
            "I0314 03:02:29.144238 138313941204992 run.py:479] Algo floyd_warshall step 4624 current loss 0.910228, current_train_items 148000.\n",
            "I0314 03:02:29.167945 138313941204992 run.py:479] Algo floyd_warshall step 4625 current loss 0.013706, current_train_items 148032.\n",
            "I0314 03:02:29.213074 138313941204992 run.py:479] Algo floyd_warshall step 4626 current loss 0.074366, current_train_items 148064.\n",
            "I0314 03:02:29.340177 138313941204992 run.py:479] Algo floyd_warshall step 4627 current loss 0.204801, current_train_items 148096.\n",
            "I0314 03:02:29.575309 138313941204992 run.py:479] Algo floyd_warshall step 4628 current loss 0.533504, current_train_items 148128.\n",
            "I0314 03:02:29.988741 138313941204992 run.py:479] Algo floyd_warshall step 4629 current loss 0.844891, current_train_items 148160.\n",
            "I0314 03:02:30.013649 138313941204992 run.py:479] Algo floyd_warshall step 4630 current loss 0.073804, current_train_items 148192.\n",
            "I0314 03:02:30.058222 138313941204992 run.py:479] Algo floyd_warshall step 4631 current loss 0.093589, current_train_items 148224.\n",
            "I0314 03:02:30.185818 138313941204992 run.py:479] Algo floyd_warshall step 4632 current loss 0.265544, current_train_items 148256.\n",
            "I0314 03:02:30.398480 138313941204992 run.py:479] Algo floyd_warshall step 4633 current loss 0.503716, current_train_items 148288.\n",
            "I0314 03:02:30.802685 138313941204992 run.py:479] Algo floyd_warshall step 4634 current loss 0.690025, current_train_items 148320.\n",
            "I0314 03:02:30.827600 138313941204992 run.py:479] Algo floyd_warshall step 4635 current loss 0.019437, current_train_items 148352.\n",
            "I0314 03:02:30.874228 138313941204992 run.py:479] Algo floyd_warshall step 4636 current loss 0.088931, current_train_items 148384.\n",
            "I0314 03:02:31.006036 138313941204992 run.py:479] Algo floyd_warshall step 4637 current loss 0.362207, current_train_items 148416.\n",
            "I0314 03:02:31.222443 138313941204992 run.py:479] Algo floyd_warshall step 4638 current loss 0.499665, current_train_items 148448.\n",
            "I0314 03:02:31.628875 138313941204992 run.py:479] Algo floyd_warshall step 4639 current loss 0.762410, current_train_items 148480.\n",
            "I0314 03:02:31.652338 138313941204992 run.py:479] Algo floyd_warshall step 4640 current loss 0.020306, current_train_items 148512.\n",
            "I0314 03:02:31.697077 138313941204992 run.py:479] Algo floyd_warshall step 4641 current loss 0.083412, current_train_items 148544.\n",
            "I0314 03:02:31.837328 138313941204992 run.py:479] Algo floyd_warshall step 4642 current loss 0.270027, current_train_items 148576.\n",
            "I0314 03:02:32.064169 138313941204992 run.py:479] Algo floyd_warshall step 4643 current loss 0.537092, current_train_items 148608.\n",
            "I0314 03:02:32.498226 138313941204992 run.py:479] Algo floyd_warshall step 4644 current loss 0.927253, current_train_items 148640.\n",
            "I0314 03:02:32.521839 138313941204992 run.py:479] Algo floyd_warshall step 4645 current loss 0.022949, current_train_items 148672.\n",
            "I0314 03:02:32.567043 138313941204992 run.py:479] Algo floyd_warshall step 4646 current loss 0.117275, current_train_items 148704.\n",
            "I0314 03:02:32.696954 138313941204992 run.py:479] Algo floyd_warshall step 4647 current loss 0.267392, current_train_items 148736.\n",
            "I0314 03:02:32.924274 138313941204992 run.py:479] Algo floyd_warshall step 4648 current loss 0.513213, current_train_items 148768.\n",
            "I0314 03:02:33.326253 138313941204992 run.py:479] Algo floyd_warshall step 4649 current loss 0.688545, current_train_items 148800.\n",
            "I0314 03:02:33.365858 138313941204992 run.py:479] Algo floyd_warshall step 4650 current loss 0.107302, current_train_items 148832.\n",
            "I0314 03:02:33.474720 138313941204992 run.py:499] (val) algo floyd_warshall step 4650: {'Pi': 0.87860107421875, 'score': 0.87860107421875, 'examples_seen': 148832, 'step': 4650, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:02:33.474972 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.879, current avg val score is 0.879, val scores are: floyd_warshall: 0.879\n",
            "I0314 03:02:33.535068 138313941204992 run.py:479] Algo floyd_warshall step 4651 current loss 0.097055, current_train_items 148864.\n",
            "I0314 03:02:33.695650 138313941204992 run.py:479] Algo floyd_warshall step 4652 current loss 0.271821, current_train_items 148896.\n",
            "I0314 03:02:33.969175 138313941204992 run.py:479] Algo floyd_warshall step 4653 current loss 0.472811, current_train_items 148928.\n",
            "I0314 03:02:34.483292 138313941204992 run.py:479] Algo floyd_warshall step 4654 current loss 0.886645, current_train_items 148960.\n",
            "I0314 03:02:34.517809 138313941204992 run.py:479] Algo floyd_warshall step 4655 current loss 0.017344, current_train_items 148992.\n",
            "I0314 03:02:34.572010 138313941204992 run.py:479] Algo floyd_warshall step 4656 current loss 0.085659, current_train_items 149024.\n",
            "I0314 03:02:34.732105 138313941204992 run.py:479] Algo floyd_warshall step 4657 current loss 0.338991, current_train_items 149056.\n",
            "I0314 03:02:34.995285 138313941204992 run.py:479] Algo floyd_warshall step 4658 current loss 0.473196, current_train_items 149088.\n",
            "I0314 03:02:35.489427 138313941204992 run.py:479] Algo floyd_warshall step 4659 current loss 0.818364, current_train_items 149120.\n",
            "I0314 03:02:35.527184 138313941204992 run.py:479] Algo floyd_warshall step 4660 current loss 0.020518, current_train_items 149152.\n",
            "I0314 03:02:35.586164 138313941204992 run.py:479] Algo floyd_warshall step 4661 current loss 0.093196, current_train_items 149184.\n",
            "I0314 03:02:35.745647 138313941204992 run.py:479] Algo floyd_warshall step 4662 current loss 0.334125, current_train_items 149216.\n",
            "I0314 03:02:36.006133 138313941204992 run.py:479] Algo floyd_warshall step 4663 current loss 0.398293, current_train_items 149248.\n",
            "I0314 03:02:36.514770 138313941204992 run.py:479] Algo floyd_warshall step 4664 current loss 0.921306, current_train_items 149280.\n",
            "I0314 03:02:36.537549 138313941204992 run.py:479] Algo floyd_warshall step 4665 current loss 0.034499, current_train_items 149312.\n",
            "I0314 03:02:36.581260 138313941204992 run.py:479] Algo floyd_warshall step 4666 current loss 0.088950, current_train_items 149344.\n",
            "I0314 03:02:36.710186 138313941204992 run.py:479] Algo floyd_warshall step 4667 current loss 0.399814, current_train_items 149376.\n",
            "I0314 03:02:36.927957 138313941204992 run.py:479] Algo floyd_warshall step 4668 current loss 0.584200, current_train_items 149408.\n",
            "I0314 03:02:37.351966 138313941204992 run.py:479] Algo floyd_warshall step 4669 current loss 0.786282, current_train_items 149440.\n",
            "I0314 03:02:37.375408 138313941204992 run.py:479] Algo floyd_warshall step 4670 current loss 0.019439, current_train_items 149472.\n",
            "I0314 03:02:37.422376 138313941204992 run.py:479] Algo floyd_warshall step 4671 current loss 0.137448, current_train_items 149504.\n",
            "I0314 03:02:37.550943 138313941204992 run.py:479] Algo floyd_warshall step 4672 current loss 0.356456, current_train_items 149536.\n",
            "I0314 03:02:37.775903 138313941204992 run.py:479] Algo floyd_warshall step 4673 current loss 0.549752, current_train_items 149568.\n",
            "I0314 03:02:38.201846 138313941204992 run.py:479] Algo floyd_warshall step 4674 current loss 0.879914, current_train_items 149600.\n",
            "I0314 03:02:38.226245 138313941204992 run.py:479] Algo floyd_warshall step 4675 current loss 0.032449, current_train_items 149632.\n",
            "I0314 03:02:38.270268 138313941204992 run.py:479] Algo floyd_warshall step 4676 current loss 0.135030, current_train_items 149664.\n",
            "I0314 03:02:38.394526 138313941204992 run.py:479] Algo floyd_warshall step 4677 current loss 0.230602, current_train_items 149696.\n",
            "I0314 03:02:38.618851 138313941204992 run.py:479] Algo floyd_warshall step 4678 current loss 0.643233, current_train_items 149728.\n",
            "I0314 03:02:39.038413 138313941204992 run.py:479] Algo floyd_warshall step 4679 current loss 0.799124, current_train_items 149760.\n",
            "I0314 03:02:39.061943 138313941204992 run.py:479] Algo floyd_warshall step 4680 current loss 0.032013, current_train_items 149792.\n",
            "I0314 03:02:39.106986 138313941204992 run.py:479] Algo floyd_warshall step 4681 current loss 0.107239, current_train_items 149824.\n",
            "I0314 03:02:39.236732 138313941204992 run.py:479] Algo floyd_warshall step 4682 current loss 0.342799, current_train_items 149856.\n",
            "I0314 03:02:39.451312 138313941204992 run.py:479] Algo floyd_warshall step 4683 current loss 0.566420, current_train_items 149888.\n",
            "I0314 03:02:39.865430 138313941204992 run.py:479] Algo floyd_warshall step 4684 current loss 0.970914, current_train_items 149920.\n",
            "I0314 03:02:39.889056 138313941204992 run.py:479] Algo floyd_warshall step 4685 current loss 0.019702, current_train_items 149952.\n",
            "I0314 03:02:39.933533 138313941204992 run.py:479] Algo floyd_warshall step 4686 current loss 0.077229, current_train_items 149984.\n",
            "I0314 03:02:40.064944 138313941204992 run.py:479] Algo floyd_warshall step 4687 current loss 0.330721, current_train_items 150016.\n",
            "I0314 03:02:40.281056 138313941204992 run.py:479] Algo floyd_warshall step 4688 current loss 0.411435, current_train_items 150048.\n",
            "I0314 03:02:40.688894 138313941204992 run.py:479] Algo floyd_warshall step 4689 current loss 0.749958, current_train_items 150080.\n",
            "I0314 03:02:40.712479 138313941204992 run.py:479] Algo floyd_warshall step 4690 current loss 0.028851, current_train_items 150112.\n",
            "I0314 03:02:40.758951 138313941204992 run.py:479] Algo floyd_warshall step 4691 current loss 0.084753, current_train_items 150144.\n",
            "I0314 03:02:40.889011 138313941204992 run.py:479] Algo floyd_warshall step 4692 current loss 0.333621, current_train_items 150176.\n",
            "I0314 03:02:41.115217 138313941204992 run.py:479] Algo floyd_warshall step 4693 current loss 0.530403, current_train_items 150208.\n",
            "I0314 03:02:41.533041 138313941204992 run.py:479] Algo floyd_warshall step 4694 current loss 0.810066, current_train_items 150240.\n",
            "I0314 03:02:41.556394 138313941204992 run.py:479] Algo floyd_warshall step 4695 current loss 0.022384, current_train_items 150272.\n",
            "I0314 03:02:41.599566 138313941204992 run.py:479] Algo floyd_warshall step 4696 current loss 0.072372, current_train_items 150304.\n",
            "I0314 03:02:41.730662 138313941204992 run.py:479] Algo floyd_warshall step 4697 current loss 0.375027, current_train_items 150336.\n",
            "I0314 03:02:41.963196 138313941204992 run.py:479] Algo floyd_warshall step 4698 current loss 0.530643, current_train_items 150368.\n",
            "I0314 03:02:42.389675 138313941204992 run.py:479] Algo floyd_warshall step 4699 current loss 0.940647, current_train_items 150400.\n",
            "I0314 03:02:42.416513 138313941204992 run.py:479] Algo floyd_warshall step 4700 current loss 0.024558, current_train_items 150432.\n",
            "I0314 03:02:42.504216 138313941204992 run.py:499] (val) algo floyd_warshall step 4700: {'Pi': 0.87579345703125, 'score': 0.87579345703125, 'examples_seen': 150432, 'step': 4700, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:02:42.504447 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.879, current avg val score is 0.876, val scores are: floyd_warshall: 0.876\n",
            "I0314 03:02:42.552834 138313941204992 run.py:479] Algo floyd_warshall step 4701 current loss 0.067403, current_train_items 150464.\n",
            "I0314 03:02:42.683430 138313941204992 run.py:479] Algo floyd_warshall step 4702 current loss 0.313235, current_train_items 150496.\n",
            "I0314 03:02:42.903941 138313941204992 run.py:479] Algo floyd_warshall step 4703 current loss 0.491499, current_train_items 150528.\n",
            "I0314 03:02:43.333600 138313941204992 run.py:479] Algo floyd_warshall step 4704 current loss 0.922376, current_train_items 150560.\n",
            "I0314 03:02:43.358743 138313941204992 run.py:479] Algo floyd_warshall step 4705 current loss 0.023859, current_train_items 150592.\n",
            "I0314 03:02:43.405289 138313941204992 run.py:479] Algo floyd_warshall step 4706 current loss 0.069421, current_train_items 150624.\n",
            "I0314 03:02:43.541170 138313941204992 run.py:479] Algo floyd_warshall step 4707 current loss 0.364808, current_train_items 150656.\n",
            "I0314 03:02:43.761357 138313941204992 run.py:479] Algo floyd_warshall step 4708 current loss 0.401998, current_train_items 150688.\n",
            "I0314 03:02:44.185497 138313941204992 run.py:479] Algo floyd_warshall step 4709 current loss 0.936328, current_train_items 150720.\n",
            "I0314 03:02:44.208619 138313941204992 run.py:479] Algo floyd_warshall step 4710 current loss 0.045684, current_train_items 150752.\n",
            "I0314 03:02:44.256508 138313941204992 run.py:479] Algo floyd_warshall step 4711 current loss 0.116675, current_train_items 150784.\n",
            "I0314 03:02:44.392206 138313941204992 run.py:479] Algo floyd_warshall step 4712 current loss 0.452984, current_train_items 150816.\n",
            "I0314 03:02:44.617537 138313941204992 run.py:479] Algo floyd_warshall step 4713 current loss 0.625557, current_train_items 150848.\n",
            "I0314 03:02:45.055278 138313941204992 run.py:479] Algo floyd_warshall step 4714 current loss 1.076879, current_train_items 150880.\n",
            "I0314 03:02:45.081988 138313941204992 run.py:479] Algo floyd_warshall step 4715 current loss 0.022004, current_train_items 150912.\n",
            "I0314 03:02:45.128119 138313941204992 run.py:479] Algo floyd_warshall step 4716 current loss 0.205489, current_train_items 150944.\n",
            "I0314 03:02:45.275995 138313941204992 run.py:479] Algo floyd_warshall step 4717 current loss 0.523581, current_train_items 150976.\n",
            "I0314 03:02:45.501260 138313941204992 run.py:479] Algo floyd_warshall step 4718 current loss 0.720297, current_train_items 151008.\n",
            "I0314 03:02:45.929294 138313941204992 run.py:479] Algo floyd_warshall step 4719 current loss 1.081695, current_train_items 151040.\n",
            "I0314 03:02:45.957121 138313941204992 run.py:479] Algo floyd_warshall step 4720 current loss 0.014049, current_train_items 151072.\n",
            "I0314 03:02:46.004747 138313941204992 run.py:479] Algo floyd_warshall step 4721 current loss 0.163131, current_train_items 151104.\n",
            "I0314 03:02:46.139246 138313941204992 run.py:479] Algo floyd_warshall step 4722 current loss 0.287416, current_train_items 151136.\n",
            "I0314 03:02:46.395213 138313941204992 run.py:479] Algo floyd_warshall step 4723 current loss 0.590916, current_train_items 151168.\n",
            "I0314 03:02:46.887457 138313941204992 run.py:479] Algo floyd_warshall step 4724 current loss 0.849471, current_train_items 151200.\n",
            "I0314 03:02:46.920487 138313941204992 run.py:479] Algo floyd_warshall step 4725 current loss 0.089073, current_train_items 151232.\n",
            "I0314 03:02:46.978772 138313941204992 run.py:479] Algo floyd_warshall step 4726 current loss 0.097268, current_train_items 151264.\n",
            "I0314 03:02:47.135142 138313941204992 run.py:479] Algo floyd_warshall step 4727 current loss 0.356847, current_train_items 151296.\n",
            "I0314 03:02:47.426523 138313941204992 run.py:479] Algo floyd_warshall step 4728 current loss 0.496117, current_train_items 151328.\n",
            "I0314 03:02:47.928792 138313941204992 run.py:479] Algo floyd_warshall step 4729 current loss 0.874872, current_train_items 151360.\n",
            "I0314 03:02:47.963493 138313941204992 run.py:479] Algo floyd_warshall step 4730 current loss 0.013989, current_train_items 151392.\n",
            "I0314 03:02:48.018934 138313941204992 run.py:479] Algo floyd_warshall step 4731 current loss 0.145289, current_train_items 151424.\n",
            "I0314 03:02:48.188138 138313941204992 run.py:479] Algo floyd_warshall step 4732 current loss 0.409007, current_train_items 151456.\n",
            "I0314 03:02:48.453524 138313941204992 run.py:479] Algo floyd_warshall step 4733 current loss 0.434039, current_train_items 151488.\n",
            "I0314 03:02:48.976177 138313941204992 run.py:479] Algo floyd_warshall step 4734 current loss 0.764646, current_train_items 151520.\n",
            "I0314 03:02:49.016635 138313941204992 run.py:479] Algo floyd_warshall step 4735 current loss 0.022136, current_train_items 151552.\n",
            "I0314 03:02:49.078433 138313941204992 run.py:479] Algo floyd_warshall step 4736 current loss 0.093383, current_train_items 151584.\n",
            "I0314 03:02:49.239238 138313941204992 run.py:479] Algo floyd_warshall step 4737 current loss 0.466988, current_train_items 151616.\n",
            "I0314 03:02:49.493132 138313941204992 run.py:479] Algo floyd_warshall step 4738 current loss 0.434430, current_train_items 151648.\n",
            "I0314 03:02:49.922518 138313941204992 run.py:479] Algo floyd_warshall step 4739 current loss 1.048943, current_train_items 151680.\n",
            "I0314 03:02:49.945453 138313941204992 run.py:479] Algo floyd_warshall step 4740 current loss 0.017274, current_train_items 151712.\n",
            "I0314 03:02:49.990461 138313941204992 run.py:479] Algo floyd_warshall step 4741 current loss 0.085831, current_train_items 151744.\n",
            "I0314 03:02:50.124314 138313941204992 run.py:479] Algo floyd_warshall step 4742 current loss 0.778448, current_train_items 151776.\n",
            "I0314 03:02:50.338699 138313941204992 run.py:479] Algo floyd_warshall step 4743 current loss 0.434232, current_train_items 151808.\n",
            "I0314 03:02:50.766136 138313941204992 run.py:479] Algo floyd_warshall step 4744 current loss 0.872762, current_train_items 151840.\n",
            "I0314 03:02:50.794294 138313941204992 run.py:479] Algo floyd_warshall step 4745 current loss 0.027023, current_train_items 151872.\n",
            "I0314 03:02:50.840852 138313941204992 run.py:479] Algo floyd_warshall step 4746 current loss 0.099862, current_train_items 151904.\n",
            "I0314 03:02:50.973089 138313941204992 run.py:479] Algo floyd_warshall step 4747 current loss 0.294638, current_train_items 151936.\n",
            "I0314 03:02:51.202164 138313941204992 run.py:479] Algo floyd_warshall step 4748 current loss 0.540496, current_train_items 151968.\n",
            "I0314 03:02:51.624462 138313941204992 run.py:479] Algo floyd_warshall step 4749 current loss 0.835120, current_train_items 152000.\n",
            "I0314 03:02:51.650585 138313941204992 run.py:479] Algo floyd_warshall step 4750 current loss 0.043324, current_train_items 152032.\n",
            "I0314 03:02:51.740337 138313941204992 run.py:499] (val) algo floyd_warshall step 4750: {'Pi': 0.86181640625, 'score': 0.86181640625, 'examples_seen': 152032, 'step': 4750, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:02:51.740653 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.879, current avg val score is 0.862, val scores are: floyd_warshall: 0.862\n",
            "I0314 03:02:51.788882 138313941204992 run.py:479] Algo floyd_warshall step 4751 current loss 0.057338, current_train_items 152064.\n",
            "I0314 03:02:51.926860 138313941204992 run.py:479] Algo floyd_warshall step 4752 current loss 0.438559, current_train_items 152096.\n",
            "I0314 03:02:52.148196 138313941204992 run.py:479] Algo floyd_warshall step 4753 current loss 0.651772, current_train_items 152128.\n",
            "I0314 03:02:52.568390 138313941204992 run.py:479] Algo floyd_warshall step 4754 current loss 0.906608, current_train_items 152160.\n",
            "I0314 03:02:52.594842 138313941204992 run.py:479] Algo floyd_warshall step 4755 current loss 0.062296, current_train_items 152192.\n",
            "I0314 03:02:52.641008 138313941204992 run.py:479] Algo floyd_warshall step 4756 current loss 0.144858, current_train_items 152224.\n",
            "I0314 03:02:52.774916 138313941204992 run.py:479] Algo floyd_warshall step 4757 current loss 0.359689, current_train_items 152256.\n",
            "I0314 03:02:53.025497 138313941204992 run.py:479] Algo floyd_warshall step 4758 current loss 0.696292, current_train_items 152288.\n",
            "I0314 03:02:53.437090 138313941204992 run.py:479] Algo floyd_warshall step 4759 current loss 0.904286, current_train_items 152320.\n",
            "I0314 03:02:53.467942 138313941204992 run.py:479] Algo floyd_warshall step 4760 current loss 0.022318, current_train_items 152352.\n",
            "I0314 03:02:53.515598 138313941204992 run.py:479] Algo floyd_warshall step 4761 current loss 0.087975, current_train_items 152384.\n",
            "I0314 03:02:53.648383 138313941204992 run.py:479] Algo floyd_warshall step 4762 current loss 0.382208, current_train_items 152416.\n",
            "I0314 03:02:53.878318 138313941204992 run.py:479] Algo floyd_warshall step 4763 current loss 0.532533, current_train_items 152448.\n",
            "I0314 03:02:54.283405 138313941204992 run.py:479] Algo floyd_warshall step 4764 current loss 0.779073, current_train_items 152480.\n",
            "I0314 03:02:54.308232 138313941204992 run.py:479] Algo floyd_warshall step 4765 current loss 0.025595, current_train_items 152512.\n",
            "I0314 03:02:54.356522 138313941204992 run.py:479] Algo floyd_warshall step 4766 current loss 0.116606, current_train_items 152544.\n",
            "I0314 03:02:54.487790 138313941204992 run.py:479] Algo floyd_warshall step 4767 current loss 0.305997, current_train_items 152576.\n",
            "I0314 03:02:54.712718 138313941204992 run.py:479] Algo floyd_warshall step 4768 current loss 0.483381, current_train_items 152608.\n",
            "I0314 03:02:55.150228 138313941204992 run.py:479] Algo floyd_warshall step 4769 current loss 0.831469, current_train_items 152640.\n",
            "I0314 03:02:55.173994 138313941204992 run.py:479] Algo floyd_warshall step 4770 current loss 0.017625, current_train_items 152672.\n",
            "I0314 03:02:55.219035 138313941204992 run.py:479] Algo floyd_warshall step 4771 current loss 0.093232, current_train_items 152704.\n",
            "I0314 03:02:55.349144 138313941204992 run.py:479] Algo floyd_warshall step 4772 current loss 0.287973, current_train_items 152736.\n",
            "I0314 03:02:55.570211 138313941204992 run.py:479] Algo floyd_warshall step 4773 current loss 0.481494, current_train_items 152768.\n",
            "I0314 03:02:55.981512 138313941204992 run.py:479] Algo floyd_warshall step 4774 current loss 0.755398, current_train_items 152800.\n",
            "I0314 03:02:56.005289 138313941204992 run.py:479] Algo floyd_warshall step 4775 current loss 0.029133, current_train_items 152832.\n",
            "I0314 03:02:56.050041 138313941204992 run.py:479] Algo floyd_warshall step 4776 current loss 0.093411, current_train_items 152864.\n",
            "I0314 03:02:56.179417 138313941204992 run.py:479] Algo floyd_warshall step 4777 current loss 0.256440, current_train_items 152896.\n",
            "I0314 03:02:56.403235 138313941204992 run.py:479] Algo floyd_warshall step 4778 current loss 0.447660, current_train_items 152928.\n",
            "I0314 03:02:56.821602 138313941204992 run.py:479] Algo floyd_warshall step 4779 current loss 0.891716, current_train_items 152960.\n",
            "I0314 03:02:56.845789 138313941204992 run.py:479] Algo floyd_warshall step 4780 current loss 0.009748, current_train_items 152992.\n",
            "I0314 03:02:56.895463 138313941204992 run.py:479] Algo floyd_warshall step 4781 current loss 0.140669, current_train_items 153024.\n",
            "I0314 03:02:57.024320 138313941204992 run.py:479] Algo floyd_warshall step 4782 current loss 0.346349, current_train_items 153056.\n",
            "I0314 03:02:57.244196 138313941204992 run.py:479] Algo floyd_warshall step 4783 current loss 0.451127, current_train_items 153088.\n",
            "I0314 03:02:57.663503 138313941204992 run.py:479] Algo floyd_warshall step 4784 current loss 1.052515, current_train_items 153120.\n",
            "I0314 03:02:57.687706 138313941204992 run.py:479] Algo floyd_warshall step 4785 current loss 0.015316, current_train_items 153152.\n",
            "I0314 03:02:57.738364 138313941204992 run.py:479] Algo floyd_warshall step 4786 current loss 0.087444, current_train_items 153184.\n",
            "I0314 03:02:57.872437 138313941204992 run.py:479] Algo floyd_warshall step 4787 current loss 0.369854, current_train_items 153216.\n",
            "I0314 03:02:58.100608 138313941204992 run.py:479] Algo floyd_warshall step 4788 current loss 0.783697, current_train_items 153248.\n",
            "I0314 03:02:58.517657 138313941204992 run.py:479] Algo floyd_warshall step 4789 current loss 0.928474, current_train_items 153280.\n",
            "I0314 03:02:58.540876 138313941204992 run.py:479] Algo floyd_warshall step 4790 current loss 0.038015, current_train_items 153312.\n",
            "I0314 03:02:58.585892 138313941204992 run.py:479] Algo floyd_warshall step 4791 current loss 0.126012, current_train_items 153344.\n",
            "I0314 03:02:58.720250 138313941204992 run.py:479] Algo floyd_warshall step 4792 current loss 0.352554, current_train_items 153376.\n",
            "I0314 03:02:58.946344 138313941204992 run.py:479] Algo floyd_warshall step 4793 current loss 0.538097, current_train_items 153408.\n",
            "I0314 03:02:59.365177 138313941204992 run.py:479] Algo floyd_warshall step 4794 current loss 0.808430, current_train_items 153440.\n",
            "I0314 03:02:59.402772 138313941204992 run.py:479] Algo floyd_warshall step 4795 current loss 0.027096, current_train_items 153472.\n",
            "I0314 03:02:59.465192 138313941204992 run.py:479] Algo floyd_warshall step 4796 current loss 0.083969, current_train_items 153504.\n",
            "I0314 03:02:59.624097 138313941204992 run.py:479] Algo floyd_warshall step 4797 current loss 0.463488, current_train_items 153536.\n",
            "I0314 03:02:59.881047 138313941204992 run.py:479] Algo floyd_warshall step 4798 current loss 0.492630, current_train_items 153568.\n",
            "I0314 03:03:00.373707 138313941204992 run.py:479] Algo floyd_warshall step 4799 current loss 0.815341, current_train_items 153600.\n",
            "I0314 03:03:00.412177 138313941204992 run.py:479] Algo floyd_warshall step 4800 current loss 0.061492, current_train_items 153632.\n",
            "I0314 03:03:00.531920 138313941204992 run.py:499] (val) algo floyd_warshall step 4800: {'Pi': 0.8719482421875, 'score': 0.8719482421875, 'examples_seen': 153632, 'step': 4800, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:03:00.532248 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.879, current avg val score is 0.872, val scores are: floyd_warshall: 0.872\n",
            "I0314 03:03:00.592083 138313941204992 run.py:479] Algo floyd_warshall step 4801 current loss 0.106006, current_train_items 153664.\n",
            "I0314 03:03:00.761120 138313941204992 run.py:479] Algo floyd_warshall step 4802 current loss 0.258025, current_train_items 153696.\n",
            "I0314 03:03:01.025931 138313941204992 run.py:479] Algo floyd_warshall step 4803 current loss 0.587980, current_train_items 153728.\n",
            "I0314 03:03:01.553188 138313941204992 run.py:479] Algo floyd_warshall step 4804 current loss 0.962328, current_train_items 153760.\n",
            "I0314 03:03:01.587541 138313941204992 run.py:479] Algo floyd_warshall step 4805 current loss 0.016604, current_train_items 153792.\n",
            "I0314 03:03:01.643074 138313941204992 run.py:479] Algo floyd_warshall step 4806 current loss 0.075969, current_train_items 153824.\n",
            "I0314 03:03:01.800828 138313941204992 run.py:479] Algo floyd_warshall step 4807 current loss 0.323622, current_train_items 153856.\n",
            "I0314 03:03:02.048389 138313941204992 run.py:479] Algo floyd_warshall step 4808 current loss 0.413167, current_train_items 153888.\n",
            "I0314 03:03:02.543560 138313941204992 run.py:479] Algo floyd_warshall step 4809 current loss 0.956910, current_train_items 153920.\n",
            "I0314 03:03:02.566668 138313941204992 run.py:479] Algo floyd_warshall step 4810 current loss 0.029126, current_train_items 153952.\n",
            "I0314 03:03:02.610861 138313941204992 run.py:479] Algo floyd_warshall step 4811 current loss 0.135980, current_train_items 153984.\n",
            "I0314 03:03:02.738871 138313941204992 run.py:479] Algo floyd_warshall step 4812 current loss 0.292978, current_train_items 154016.\n",
            "I0314 03:03:02.982197 138313941204992 run.py:479] Algo floyd_warshall step 4813 current loss 0.531524, current_train_items 154048.\n",
            "I0314 03:03:03.396041 138313941204992 run.py:479] Algo floyd_warshall step 4814 current loss 0.846029, current_train_items 154080.\n",
            "I0314 03:03:03.421712 138313941204992 run.py:479] Algo floyd_warshall step 4815 current loss 0.014973, current_train_items 154112.\n",
            "I0314 03:03:03.465899 138313941204992 run.py:479] Algo floyd_warshall step 4816 current loss 0.089380, current_train_items 154144.\n",
            "I0314 03:03:03.593492 138313941204992 run.py:479] Algo floyd_warshall step 4817 current loss 0.398908, current_train_items 154176.\n",
            "I0314 03:03:03.805032 138313941204992 run.py:479] Algo floyd_warshall step 4818 current loss 0.453213, current_train_items 154208.\n",
            "I0314 03:03:04.218725 138313941204992 run.py:479] Algo floyd_warshall step 4819 current loss 0.871280, current_train_items 154240.\n",
            "I0314 03:03:04.243749 138313941204992 run.py:479] Algo floyd_warshall step 4820 current loss 0.021118, current_train_items 154272.\n",
            "I0314 03:03:04.288498 138313941204992 run.py:479] Algo floyd_warshall step 4821 current loss 0.158898, current_train_items 154304.\n",
            "I0314 03:03:04.417946 138313941204992 run.py:479] Algo floyd_warshall step 4822 current loss 0.371620, current_train_items 154336.\n",
            "I0314 03:03:04.633361 138313941204992 run.py:479] Algo floyd_warshall step 4823 current loss 0.564736, current_train_items 154368.\n",
            "I0314 03:03:05.056277 138313941204992 run.py:479] Algo floyd_warshall step 4824 current loss 0.937544, current_train_items 154400.\n",
            "I0314 03:03:05.079890 138313941204992 run.py:479] Algo floyd_warshall step 4825 current loss 0.010360, current_train_items 154432.\n",
            "I0314 03:03:05.124892 138313941204992 run.py:479] Algo floyd_warshall step 4826 current loss 0.147052, current_train_items 154464.\n",
            "I0314 03:03:05.251791 138313941204992 run.py:479] Algo floyd_warshall step 4827 current loss 0.294292, current_train_items 154496.\n",
            "I0314 03:03:05.477900 138313941204992 run.py:479] Algo floyd_warshall step 4828 current loss 0.482113, current_train_items 154528.\n",
            "I0314 03:03:05.888500 138313941204992 run.py:479] Algo floyd_warshall step 4829 current loss 0.810764, current_train_items 154560.\n",
            "I0314 03:03:05.912436 138313941204992 run.py:479] Algo floyd_warshall step 4830 current loss 0.026577, current_train_items 154592.\n",
            "I0314 03:03:05.956658 138313941204992 run.py:479] Algo floyd_warshall step 4831 current loss 0.046482, current_train_items 154624.\n",
            "I0314 03:03:06.086788 138313941204992 run.py:479] Algo floyd_warshall step 4832 current loss 0.301141, current_train_items 154656.\n",
            "I0314 03:03:06.307607 138313941204992 run.py:479] Algo floyd_warshall step 4833 current loss 0.504935, current_train_items 154688.\n",
            "I0314 03:03:06.717723 138313941204992 run.py:479] Algo floyd_warshall step 4834 current loss 0.889483, current_train_items 154720.\n",
            "I0314 03:03:06.741505 138313941204992 run.py:479] Algo floyd_warshall step 4835 current loss 0.022957, current_train_items 154752.\n",
            "I0314 03:03:06.785849 138313941204992 run.py:479] Algo floyd_warshall step 4836 current loss 0.093779, current_train_items 154784.\n",
            "I0314 03:03:06.917622 138313941204992 run.py:479] Algo floyd_warshall step 4837 current loss 0.320726, current_train_items 154816.\n",
            "I0314 03:03:07.133010 138313941204992 run.py:479] Algo floyd_warshall step 4838 current loss 0.554619, current_train_items 154848.\n",
            "I0314 03:03:07.540498 138313941204992 run.py:479] Algo floyd_warshall step 4839 current loss 0.707583, current_train_items 154880.\n",
            "I0314 03:03:07.565991 138313941204992 run.py:479] Algo floyd_warshall step 4840 current loss 0.019695, current_train_items 154912.\n",
            "I0314 03:03:07.611675 138313941204992 run.py:479] Algo floyd_warshall step 4841 current loss 0.093641, current_train_items 154944.\n",
            "I0314 03:03:07.741229 138313941204992 run.py:479] Algo floyd_warshall step 4842 current loss 0.312098, current_train_items 154976.\n",
            "I0314 03:03:07.963070 138313941204992 run.py:479] Algo floyd_warshall step 4843 current loss 0.497129, current_train_items 155008.\n",
            "I0314 03:03:08.388918 138313941204992 run.py:479] Algo floyd_warshall step 4844 current loss 0.876779, current_train_items 155040.\n",
            "I0314 03:03:08.414975 138313941204992 run.py:479] Algo floyd_warshall step 4845 current loss 0.031065, current_train_items 155072.\n",
            "I0314 03:03:08.459820 138313941204992 run.py:479] Algo floyd_warshall step 4846 current loss 0.074366, current_train_items 155104.\n",
            "I0314 03:03:08.590231 138313941204992 run.py:479] Algo floyd_warshall step 4847 current loss 0.273716, current_train_items 155136.\n",
            "I0314 03:03:08.814255 138313941204992 run.py:479] Algo floyd_warshall step 4848 current loss 0.530594, current_train_items 155168.\n",
            "I0314 03:03:09.230960 138313941204992 run.py:479] Algo floyd_warshall step 4849 current loss 0.760556, current_train_items 155200.\n",
            "I0314 03:03:09.254282 138313941204992 run.py:479] Algo floyd_warshall step 4850 current loss 0.023053, current_train_items 155232.\n",
            "I0314 03:03:09.342457 138313941204992 run.py:499] (val) algo floyd_warshall step 4850: {'Pi': 0.865478515625, 'score': 0.865478515625, 'examples_seen': 155232, 'step': 4850, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:03:09.342685 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.879, current avg val score is 0.865, val scores are: floyd_warshall: 0.865\n",
            "I0314 03:03:09.391282 138313941204992 run.py:479] Algo floyd_warshall step 4851 current loss 0.071944, current_train_items 155264.\n",
            "I0314 03:03:09.521282 138313941204992 run.py:479] Algo floyd_warshall step 4852 current loss 0.261823, current_train_items 155296.\n",
            "I0314 03:03:09.735822 138313941204992 run.py:479] Algo floyd_warshall step 4853 current loss 0.553034, current_train_items 155328.\n",
            "I0314 03:03:10.146057 138313941204992 run.py:479] Algo floyd_warshall step 4854 current loss 0.600648, current_train_items 155360.\n",
            "I0314 03:03:10.170873 138313941204992 run.py:479] Algo floyd_warshall step 4855 current loss 0.022577, current_train_items 155392.\n",
            "I0314 03:03:10.215105 138313941204992 run.py:479] Algo floyd_warshall step 4856 current loss 0.130130, current_train_items 155424.\n",
            "I0314 03:03:10.344217 138313941204992 run.py:479] Algo floyd_warshall step 4857 current loss 0.302237, current_train_items 155456.\n",
            "I0314 03:03:10.556331 138313941204992 run.py:479] Algo floyd_warshall step 4858 current loss 0.478685, current_train_items 155488.\n",
            "I0314 03:03:10.972805 138313941204992 run.py:479] Algo floyd_warshall step 4859 current loss 0.800281, current_train_items 155520.\n",
            "I0314 03:03:10.996403 138313941204992 run.py:479] Algo floyd_warshall step 4860 current loss 0.020738, current_train_items 155552.\n",
            "I0314 03:03:11.042120 138313941204992 run.py:479] Algo floyd_warshall step 4861 current loss 0.082465, current_train_items 155584.\n",
            "I0314 03:03:11.171404 138313941204992 run.py:479] Algo floyd_warshall step 4862 current loss 0.306454, current_train_items 155616.\n",
            "I0314 03:03:11.400660 138313941204992 run.py:479] Algo floyd_warshall step 4863 current loss 0.549590, current_train_items 155648.\n",
            "I0314 03:03:11.804271 138313941204992 run.py:479] Algo floyd_warshall step 4864 current loss 0.675104, current_train_items 155680.\n",
            "I0314 03:03:11.827603 138313941204992 run.py:479] Algo floyd_warshall step 4865 current loss 0.028570, current_train_items 155712.\n",
            "I0314 03:03:11.874352 138313941204992 run.py:479] Algo floyd_warshall step 4866 current loss 0.090367, current_train_items 155744.\n",
            "I0314 03:03:12.003561 138313941204992 run.py:479] Algo floyd_warshall step 4867 current loss 0.401676, current_train_items 155776.\n",
            "I0314 03:03:12.226918 138313941204992 run.py:479] Algo floyd_warshall step 4868 current loss 0.552035, current_train_items 155808.\n",
            "I0314 03:03:12.636593 138313941204992 run.py:479] Algo floyd_warshall step 4869 current loss 0.859116, current_train_items 155840.\n",
            "I0314 03:03:12.674014 138313941204992 run.py:479] Algo floyd_warshall step 4870 current loss 0.065715, current_train_items 155872.\n",
            "I0314 03:03:12.731543 138313941204992 run.py:479] Algo floyd_warshall step 4871 current loss 0.082617, current_train_items 155904.\n",
            "I0314 03:03:12.887854 138313941204992 run.py:479] Algo floyd_warshall step 4872 current loss 0.343602, current_train_items 155936.\n",
            "I0314 03:03:13.164609 138313941204992 run.py:479] Algo floyd_warshall step 4873 current loss 0.547268, current_train_items 155968.\n",
            "I0314 03:03:13.618552 138313941204992 run.py:479] Algo floyd_warshall step 4874 current loss 0.533073, current_train_items 156000.\n",
            "I0314 03:03:13.656750 138313941204992 run.py:479] Algo floyd_warshall step 4875 current loss 0.087461, current_train_items 156032.\n",
            "I0314 03:03:13.716365 138313941204992 run.py:479] Algo floyd_warshall step 4876 current loss 0.158785, current_train_items 156064.\n",
            "I0314 03:03:13.870451 138313941204992 run.py:479] Algo floyd_warshall step 4877 current loss 0.301791, current_train_items 156096.\n",
            "I0314 03:03:14.132986 138313941204992 run.py:479] Algo floyd_warshall step 4878 current loss 0.524059, current_train_items 156128.\n",
            "I0314 03:03:14.638347 138313941204992 run.py:479] Algo floyd_warshall step 4879 current loss 0.774915, current_train_items 156160.\n",
            "I0314 03:03:14.671981 138313941204992 run.py:479] Algo floyd_warshall step 4880 current loss 0.031414, current_train_items 156192.\n",
            "I0314 03:03:14.727841 138313941204992 run.py:479] Algo floyd_warshall step 4881 current loss 0.071989, current_train_items 156224.\n",
            "I0314 03:03:14.886068 138313941204992 run.py:479] Algo floyd_warshall step 4882 current loss 0.354116, current_train_items 156256.\n",
            "I0314 03:03:15.142858 138313941204992 run.py:479] Algo floyd_warshall step 4883 current loss 0.489054, current_train_items 156288.\n",
            "I0314 03:03:15.623015 138313941204992 run.py:479] Algo floyd_warshall step 4884 current loss 0.951906, current_train_items 156320.\n",
            "I0314 03:03:15.647089 138313941204992 run.py:479] Algo floyd_warshall step 4885 current loss 0.051223, current_train_items 156352.\n",
            "I0314 03:03:15.690756 138313941204992 run.py:479] Algo floyd_warshall step 4886 current loss 0.111438, current_train_items 156384.\n",
            "I0314 03:03:15.819340 138313941204992 run.py:479] Algo floyd_warshall step 4887 current loss 0.308764, current_train_items 156416.\n",
            "I0314 03:03:16.043201 138313941204992 run.py:479] Algo floyd_warshall step 4888 current loss 0.651429, current_train_items 156448.\n",
            "I0314 03:03:16.452798 138313941204992 run.py:479] Algo floyd_warshall step 4889 current loss 0.790174, current_train_items 156480.\n",
            "I0314 03:03:16.476057 138313941204992 run.py:479] Algo floyd_warshall step 4890 current loss 0.022659, current_train_items 156512.\n",
            "I0314 03:03:16.519902 138313941204992 run.py:479] Algo floyd_warshall step 4891 current loss 0.087137, current_train_items 156544.\n",
            "I0314 03:03:16.649533 138313941204992 run.py:479] Algo floyd_warshall step 4892 current loss 0.342008, current_train_items 156576.\n",
            "I0314 03:03:16.860397 138313941204992 run.py:479] Algo floyd_warshall step 4893 current loss 0.453108, current_train_items 156608.\n",
            "I0314 03:03:17.276195 138313941204992 run.py:479] Algo floyd_warshall step 4894 current loss 0.822776, current_train_items 156640.\n",
            "I0314 03:03:17.300293 138313941204992 run.py:479] Algo floyd_warshall step 4895 current loss 0.019296, current_train_items 156672.\n",
            "I0314 03:03:17.343573 138313941204992 run.py:479] Algo floyd_warshall step 4896 current loss 0.068497, current_train_items 156704.\n",
            "I0314 03:03:17.475053 138313941204992 run.py:479] Algo floyd_warshall step 4897 current loss 0.305834, current_train_items 156736.\n",
            "I0314 03:03:17.687339 138313941204992 run.py:479] Algo floyd_warshall step 4898 current loss 0.431211, current_train_items 156768.\n",
            "I0314 03:03:18.093281 138313941204992 run.py:479] Algo floyd_warshall step 4899 current loss 0.723752, current_train_items 156800.\n",
            "I0314 03:03:18.117784 138313941204992 run.py:479] Algo floyd_warshall step 4900 current loss 0.028589, current_train_items 156832.\n",
            "I0314 03:03:18.206403 138313941204992 run.py:499] (val) algo floyd_warshall step 4900: {'Pi': 0.8790283203125, 'score': 0.8790283203125, 'examples_seen': 156832, 'step': 4900, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:03:18.206801 138313941204992 run.py:516] Checkpointing best model, best avg val score was 0.879, current avg val score is 0.879, val scores are: floyd_warshall: 0.879\n",
            "I0314 03:03:18.305686 138313941204992 run.py:479] Algo floyd_warshall step 4901 current loss 0.091533, current_train_items 156864.\n",
            "I0314 03:03:18.437567 138313941204992 run.py:479] Algo floyd_warshall step 4902 current loss 0.267786, current_train_items 156896.\n",
            "I0314 03:03:18.659342 138313941204992 run.py:479] Algo floyd_warshall step 4903 current loss 0.504104, current_train_items 156928.\n",
            "I0314 03:03:19.075452 138313941204992 run.py:479] Algo floyd_warshall step 4904 current loss 0.803165, current_train_items 156960.\n",
            "I0314 03:03:19.101799 138313941204992 run.py:479] Algo floyd_warshall step 4905 current loss 0.051701, current_train_items 156992.\n",
            "I0314 03:03:19.146969 138313941204992 run.py:479] Algo floyd_warshall step 4906 current loss 0.088301, current_train_items 157024.\n",
            "I0314 03:03:19.279324 138313941204992 run.py:479] Algo floyd_warshall step 4907 current loss 0.421773, current_train_items 157056.\n",
            "I0314 03:03:19.494965 138313941204992 run.py:479] Algo floyd_warshall step 4908 current loss 0.422762, current_train_items 157088.\n",
            "I0314 03:03:19.905462 138313941204992 run.py:479] Algo floyd_warshall step 4909 current loss 0.774246, current_train_items 157120.\n",
            "I0314 03:03:19.928476 138313941204992 run.py:479] Algo floyd_warshall step 4910 current loss 0.030085, current_train_items 157152.\n",
            "I0314 03:03:19.973594 138313941204992 run.py:479] Algo floyd_warshall step 4911 current loss 0.101705, current_train_items 157184.\n",
            "I0314 03:03:20.102619 138313941204992 run.py:479] Algo floyd_warshall step 4912 current loss 0.263802, current_train_items 157216.\n",
            "I0314 03:03:20.320202 138313941204992 run.py:479] Algo floyd_warshall step 4913 current loss 0.459567, current_train_items 157248.\n",
            "I0314 03:03:20.739978 138313941204992 run.py:479] Algo floyd_warshall step 4914 current loss 0.827846, current_train_items 157280.\n",
            "I0314 03:03:20.766562 138313941204992 run.py:479] Algo floyd_warshall step 4915 current loss 0.026143, current_train_items 157312.\n",
            "I0314 03:03:20.812682 138313941204992 run.py:479] Algo floyd_warshall step 4916 current loss 0.066344, current_train_items 157344.\n",
            "I0314 03:03:20.944967 138313941204992 run.py:479] Algo floyd_warshall step 4917 current loss 0.370379, current_train_items 157376.\n",
            "I0314 03:03:21.172101 138313941204992 run.py:479] Algo floyd_warshall step 4918 current loss 0.541513, current_train_items 157408.\n",
            "I0314 03:03:21.578436 138313941204992 run.py:479] Algo floyd_warshall step 4919 current loss 0.649273, current_train_items 157440.\n",
            "I0314 03:03:21.602873 138313941204992 run.py:479] Algo floyd_warshall step 4920 current loss 0.055354, current_train_items 157472.\n",
            "I0314 03:03:21.648898 138313941204992 run.py:479] Algo floyd_warshall step 4921 current loss 0.140868, current_train_items 157504.\n",
            "I0314 03:03:21.779060 138313941204992 run.py:479] Algo floyd_warshall step 4922 current loss 0.307755, current_train_items 157536.\n",
            "I0314 03:03:21.996784 138313941204992 run.py:479] Algo floyd_warshall step 4923 current loss 0.514952, current_train_items 157568.\n",
            "I0314 03:03:22.411355 138313941204992 run.py:479] Algo floyd_warshall step 4924 current loss 0.773831, current_train_items 157600.\n",
            "I0314 03:03:22.435733 138313941204992 run.py:479] Algo floyd_warshall step 4925 current loss 0.012671, current_train_items 157632.\n",
            "I0314 03:03:22.484996 138313941204992 run.py:479] Algo floyd_warshall step 4926 current loss 0.104520, current_train_items 157664.\n",
            "I0314 03:03:22.615060 138313941204992 run.py:479] Algo floyd_warshall step 4927 current loss 0.259523, current_train_items 157696.\n",
            "I0314 03:03:22.841984 138313941204992 run.py:479] Algo floyd_warshall step 4928 current loss 0.513015, current_train_items 157728.\n",
            "I0314 03:03:23.263274 138313941204992 run.py:479] Algo floyd_warshall step 4929 current loss 0.884907, current_train_items 157760.\n",
            "I0314 03:03:23.289931 138313941204992 run.py:479] Algo floyd_warshall step 4930 current loss 0.019251, current_train_items 157792.\n",
            "I0314 03:03:23.337885 138313941204992 run.py:479] Algo floyd_warshall step 4931 current loss 0.104083, current_train_items 157824.\n",
            "I0314 03:03:23.479959 138313941204992 run.py:479] Algo floyd_warshall step 4932 current loss 0.357653, current_train_items 157856.\n",
            "I0314 03:03:23.705003 138313941204992 run.py:479] Algo floyd_warshall step 4933 current loss 0.420181, current_train_items 157888.\n",
            "I0314 03:03:24.121000 138313941204992 run.py:479] Algo floyd_warshall step 4934 current loss 0.891984, current_train_items 157920.\n",
            "I0314 03:03:24.145453 138313941204992 run.py:479] Algo floyd_warshall step 4935 current loss 0.026058, current_train_items 157952.\n",
            "I0314 03:03:24.188981 138313941204992 run.py:479] Algo floyd_warshall step 4936 current loss 0.055113, current_train_items 157984.\n",
            "I0314 03:03:24.319923 138313941204992 run.py:479] Algo floyd_warshall step 4937 current loss 0.263942, current_train_items 158016.\n",
            "I0314 03:03:24.551862 138313941204992 run.py:479] Algo floyd_warshall step 4938 current loss 0.535214, current_train_items 158048.\n",
            "I0314 03:03:24.970681 138313941204992 run.py:479] Algo floyd_warshall step 4939 current loss 0.866367, current_train_items 158080.\n",
            "I0314 03:03:24.995858 138313941204992 run.py:479] Algo floyd_warshall step 4940 current loss 0.030731, current_train_items 158112.\n",
            "I0314 03:03:25.040401 138313941204992 run.py:479] Algo floyd_warshall step 4941 current loss 0.075766, current_train_items 158144.\n",
            "I0314 03:03:25.169362 138313941204992 run.py:479] Algo floyd_warshall step 4942 current loss 0.353811, current_train_items 158176.\n",
            "I0314 03:03:25.392117 138313941204992 run.py:479] Algo floyd_warshall step 4943 current loss 0.383171, current_train_items 158208.\n",
            "I0314 03:03:25.820870 138313941204992 run.py:479] Algo floyd_warshall step 4944 current loss 0.758183, current_train_items 158240.\n",
            "I0314 03:03:25.857512 138313941204992 run.py:479] Algo floyd_warshall step 4945 current loss 0.029972, current_train_items 158272.\n",
            "I0314 03:03:25.916123 138313941204992 run.py:479] Algo floyd_warshall step 4946 current loss 0.117211, current_train_items 158304.\n",
            "I0314 03:03:26.078185 138313941204992 run.py:479] Algo floyd_warshall step 4947 current loss 0.321131, current_train_items 158336.\n",
            "I0314 03:03:26.348656 138313941204992 run.py:479] Algo floyd_warshall step 4948 current loss 0.460614, current_train_items 158368.\n",
            "I0314 03:03:26.860296 138313941204992 run.py:479] Algo floyd_warshall step 4949 current loss 0.818123, current_train_items 158400.\n",
            "I0314 03:03:26.899388 138313941204992 run.py:479] Algo floyd_warshall step 4950 current loss 0.027263, current_train_items 158432.\n",
            "I0314 03:03:26.996711 138313941204992 run.py:499] (val) algo floyd_warshall step 4950: {'Pi': 0.86749267578125, 'score': 0.86749267578125, 'examples_seen': 158432, 'step': 4950, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:03:26.997039 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.879, current avg val score is 0.867, val scores are: floyd_warshall: 0.867\n",
            "I0314 03:03:27.058194 138313941204992 run.py:479] Algo floyd_warshall step 4951 current loss 0.141800, current_train_items 158464.\n",
            "I0314 03:03:27.227448 138313941204992 run.py:479] Algo floyd_warshall step 4952 current loss 0.295271, current_train_items 158496.\n",
            "I0314 03:03:27.499487 138313941204992 run.py:479] Algo floyd_warshall step 4953 current loss 0.473609, current_train_items 158528.\n",
            "I0314 03:03:28.016855 138313941204992 run.py:479] Algo floyd_warshall step 4954 current loss 0.761269, current_train_items 158560.\n",
            "I0314 03:03:28.052644 138313941204992 run.py:479] Algo floyd_warshall step 4955 current loss 0.031343, current_train_items 158592.\n",
            "I0314 03:03:28.107495 138313941204992 run.py:479] Algo floyd_warshall step 4956 current loss 0.099130, current_train_items 158624.\n",
            "I0314 03:03:28.266625 138313941204992 run.py:479] Algo floyd_warshall step 4957 current loss 0.303472, current_train_items 158656.\n",
            "I0314 03:03:28.525940 138313941204992 run.py:479] Algo floyd_warshall step 4958 current loss 0.420646, current_train_items 158688.\n",
            "I0314 03:03:28.974494 138313941204992 run.py:479] Algo floyd_warshall step 4959 current loss 0.963386, current_train_items 158720.\n",
            "I0314 03:03:28.998395 138313941204992 run.py:479] Algo floyd_warshall step 4960 current loss 0.015950, current_train_items 158752.\n",
            "I0314 03:03:29.044249 138313941204992 run.py:479] Algo floyd_warshall step 4961 current loss 0.142897, current_train_items 158784.\n",
            "I0314 03:03:29.176522 138313941204992 run.py:479] Algo floyd_warshall step 4962 current loss 0.357705, current_train_items 158816.\n",
            "I0314 03:03:29.401908 138313941204992 run.py:479] Algo floyd_warshall step 4963 current loss 0.541483, current_train_items 158848.\n",
            "I0314 03:03:29.806857 138313941204992 run.py:479] Algo floyd_warshall step 4964 current loss 0.757133, current_train_items 158880.\n",
            "I0314 03:03:29.832429 138313941204992 run.py:479] Algo floyd_warshall step 4965 current loss 0.013160, current_train_items 158912.\n",
            "I0314 03:03:29.878162 138313941204992 run.py:479] Algo floyd_warshall step 4966 current loss 0.104448, current_train_items 158944.\n",
            "I0314 03:03:30.014036 138313941204992 run.py:479] Algo floyd_warshall step 4967 current loss 0.272135, current_train_items 158976.\n",
            "I0314 03:03:30.236771 138313941204992 run.py:479] Algo floyd_warshall step 4968 current loss 0.474348, current_train_items 159008.\n",
            "I0314 03:03:30.652402 138313941204992 run.py:479] Algo floyd_warshall step 4969 current loss 0.815566, current_train_items 159040.\n",
            "I0314 03:03:30.676861 138313941204992 run.py:479] Algo floyd_warshall step 4970 current loss 0.027546, current_train_items 159072.\n",
            "I0314 03:03:30.723602 138313941204992 run.py:479] Algo floyd_warshall step 4971 current loss 0.054014, current_train_items 159104.\n",
            "I0314 03:03:30.853849 138313941204992 run.py:479] Algo floyd_warshall step 4972 current loss 0.266854, current_train_items 159136.\n",
            "I0314 03:03:31.073788 138313941204992 run.py:479] Algo floyd_warshall step 4973 current loss 0.486227, current_train_items 159168.\n",
            "I0314 03:03:31.483342 138313941204992 run.py:479] Algo floyd_warshall step 4974 current loss 0.711189, current_train_items 159200.\n",
            "I0314 03:03:31.507159 138313941204992 run.py:479] Algo floyd_warshall step 4975 current loss 0.161248, current_train_items 159232.\n",
            "I0314 03:03:31.552305 138313941204992 run.py:479] Algo floyd_warshall step 4976 current loss 0.158398, current_train_items 159264.\n",
            "I0314 03:03:31.678583 138313941204992 run.py:479] Algo floyd_warshall step 4977 current loss 0.342126, current_train_items 159296.\n",
            "I0314 03:03:31.900240 138313941204992 run.py:479] Algo floyd_warshall step 4978 current loss 0.501317, current_train_items 159328.\n",
            "I0314 03:03:32.302632 138313941204992 run.py:479] Algo floyd_warshall step 4979 current loss 0.690382, current_train_items 159360.\n",
            "I0314 03:03:32.326168 138313941204992 run.py:479] Algo floyd_warshall step 4980 current loss 0.027596, current_train_items 159392.\n",
            "I0314 03:03:32.370552 138313941204992 run.py:479] Algo floyd_warshall step 4981 current loss 0.075260, current_train_items 159424.\n",
            "I0314 03:03:32.503786 138313941204992 run.py:479] Algo floyd_warshall step 4982 current loss 0.374000, current_train_items 159456.\n",
            "I0314 03:03:32.729873 138313941204992 run.py:479] Algo floyd_warshall step 4983 current loss 0.578452, current_train_items 159488.\n",
            "I0314 03:03:33.159287 138313941204992 run.py:479] Algo floyd_warshall step 4984 current loss 0.910559, current_train_items 159520.\n",
            "I0314 03:03:33.182976 138313941204992 run.py:479] Algo floyd_warshall step 4985 current loss 0.038678, current_train_items 159552.\n",
            "I0314 03:03:33.227735 138313941204992 run.py:479] Algo floyd_warshall step 4986 current loss 0.093073, current_train_items 159584.\n",
            "I0314 03:03:33.357620 138313941204992 run.py:479] Algo floyd_warshall step 4987 current loss 0.467649, current_train_items 159616.\n",
            "I0314 03:03:33.570926 138313941204992 run.py:479] Algo floyd_warshall step 4988 current loss 0.488933, current_train_items 159648.\n",
            "I0314 03:03:33.984660 138313941204992 run.py:479] Algo floyd_warshall step 4989 current loss 0.793454, current_train_items 159680.\n",
            "I0314 03:03:34.007607 138313941204992 run.py:479] Algo floyd_warshall step 4990 current loss 0.059164, current_train_items 159712.\n",
            "I0314 03:03:34.051497 138313941204992 run.py:479] Algo floyd_warshall step 4991 current loss 0.223177, current_train_items 159744.\n",
            "I0314 03:03:34.182609 138313941204992 run.py:479] Algo floyd_warshall step 4992 current loss 0.405770, current_train_items 159776.\n",
            "I0314 03:03:34.397268 138313941204992 run.py:479] Algo floyd_warshall step 4993 current loss 0.557291, current_train_items 159808.\n",
            "I0314 03:03:34.805590 138313941204992 run.py:479] Algo floyd_warshall step 4994 current loss 0.685687, current_train_items 159840.\n",
            "I0314 03:03:34.830254 138313941204992 run.py:479] Algo floyd_warshall step 4995 current loss 0.014645, current_train_items 159872.\n",
            "I0314 03:03:34.877807 138313941204992 run.py:479] Algo floyd_warshall step 4996 current loss 0.062397, current_train_items 159904.\n",
            "I0314 03:03:35.009927 138313941204992 run.py:479] Algo floyd_warshall step 4997 current loss 0.358623, current_train_items 159936.\n",
            "I0314 03:03:35.237637 138313941204992 run.py:479] Algo floyd_warshall step 4998 current loss 0.438364, current_train_items 159968.\n",
            "I0314 03:03:35.646082 138313941204992 run.py:479] Algo floyd_warshall step 4999 current loss 0.852655, current_train_items 160000.\n",
            "I0314 03:03:35.669917 138313941204992 run.py:479] Algo floyd_warshall step 5000 current loss 0.021788, current_train_items 160032.\n",
            "I0314 03:03:35.757126 138313941204992 run.py:499] (val) algo floyd_warshall step 5000: {'Pi': 0.8690185546875, 'score': 0.8690185546875, 'examples_seen': 160032, 'step': 5000, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:03:35.757448 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.879, current avg val score is 0.869, val scores are: floyd_warshall: 0.869\n",
            "I0314 03:03:35.806728 138313941204992 run.py:479] Algo floyd_warshall step 5001 current loss 0.032013, current_train_items 160064.\n",
            "I0314 03:03:35.941510 138313941204992 run.py:479] Algo floyd_warshall step 5002 current loss 0.214042, current_train_items 160096.\n",
            "I0314 03:03:36.160193 138313941204992 run.py:479] Algo floyd_warshall step 5003 current loss 0.490376, current_train_items 160128.\n",
            "I0314 03:03:36.565237 138313941204992 run.py:479] Algo floyd_warshall step 5004 current loss 0.681162, current_train_items 160160.\n",
            "I0314 03:03:36.590369 138313941204992 run.py:479] Algo floyd_warshall step 5005 current loss 0.143379, current_train_items 160192.\n",
            "I0314 03:03:36.638499 138313941204992 run.py:479] Algo floyd_warshall step 5006 current loss 0.068636, current_train_items 160224.\n",
            "I0314 03:03:36.770061 138313941204992 run.py:479] Algo floyd_warshall step 5007 current loss 0.304769, current_train_items 160256.\n",
            "I0314 03:03:36.983611 138313941204992 run.py:479] Algo floyd_warshall step 5008 current loss 0.445271, current_train_items 160288.\n",
            "I0314 03:03:37.399185 138313941204992 run.py:479] Algo floyd_warshall step 5009 current loss 0.857933, current_train_items 160320.\n",
            "I0314 03:03:37.424096 138313941204992 run.py:479] Algo floyd_warshall step 5010 current loss 0.036192, current_train_items 160352.\n",
            "I0314 03:03:37.469093 138313941204992 run.py:479] Algo floyd_warshall step 5011 current loss 0.050834, current_train_items 160384.\n",
            "I0314 03:03:37.595791 138313941204992 run.py:479] Algo floyd_warshall step 5012 current loss 0.260348, current_train_items 160416.\n",
            "I0314 03:03:37.816547 138313941204992 run.py:479] Algo floyd_warshall step 5013 current loss 0.509151, current_train_items 160448.\n",
            "I0314 03:03:38.210451 138313941204992 run.py:479] Algo floyd_warshall step 5014 current loss 0.447132, current_train_items 160480.\n",
            "I0314 03:03:38.235046 138313941204992 run.py:479] Algo floyd_warshall step 5015 current loss 0.021554, current_train_items 160512.\n",
            "I0314 03:03:38.280333 138313941204992 run.py:479] Algo floyd_warshall step 5016 current loss 0.052141, current_train_items 160544.\n",
            "I0314 03:03:38.411457 138313941204992 run.py:479] Algo floyd_warshall step 5017 current loss 0.228191, current_train_items 160576.\n",
            "I0314 03:03:38.630625 138313941204992 run.py:479] Algo floyd_warshall step 5018 current loss 0.486846, current_train_items 160608.\n",
            "I0314 03:03:39.132313 138313941204992 run.py:479] Algo floyd_warshall step 5019 current loss 0.712122, current_train_items 160640.\n",
            "I0314 03:03:39.168248 138313941204992 run.py:479] Algo floyd_warshall step 5020 current loss 0.029727, current_train_items 160672.\n",
            "I0314 03:03:39.227025 138313941204992 run.py:479] Algo floyd_warshall step 5021 current loss 0.057319, current_train_items 160704.\n",
            "I0314 03:03:39.385751 138313941204992 run.py:479] Algo floyd_warshall step 5022 current loss 0.320666, current_train_items 160736.\n",
            "I0314 03:03:39.648845 138313941204992 run.py:479] Algo floyd_warshall step 5023 current loss 0.327666, current_train_items 160768.\n",
            "I0314 03:03:40.158935 138313941204992 run.py:479] Algo floyd_warshall step 5024 current loss 0.672083, current_train_items 160800.\n",
            "I0314 03:03:40.193460 138313941204992 run.py:479] Algo floyd_warshall step 5025 current loss 0.027824, current_train_items 160832.\n",
            "I0314 03:03:40.251234 138313941204992 run.py:479] Algo floyd_warshall step 5026 current loss 0.129334, current_train_items 160864.\n",
            "I0314 03:03:40.410688 138313941204992 run.py:479] Algo floyd_warshall step 5027 current loss 0.335746, current_train_items 160896.\n",
            "I0314 03:03:40.666792 138313941204992 run.py:479] Algo floyd_warshall step 5028 current loss 0.386050, current_train_items 160928.\n",
            "I0314 03:03:41.155650 138313941204992 run.py:479] Algo floyd_warshall step 5029 current loss 0.669289, current_train_items 160960.\n",
            "I0314 03:03:41.192556 138313941204992 run.py:479] Algo floyd_warshall step 5030 current loss 0.022365, current_train_items 160992.\n",
            "I0314 03:03:41.248632 138313941204992 run.py:479] Algo floyd_warshall step 5031 current loss 0.105946, current_train_items 161024.\n",
            "I0314 03:03:41.412454 138313941204992 run.py:479] Algo floyd_warshall step 5032 current loss 0.349932, current_train_items 161056.\n",
            "I0314 03:03:41.678568 138313941204992 run.py:479] Algo floyd_warshall step 5033 current loss 0.383851, current_train_items 161088.\n",
            "I0314 03:03:42.124234 138313941204992 run.py:479] Algo floyd_warshall step 5034 current loss 0.769834, current_train_items 161120.\n",
            "I0314 03:03:42.148393 138313941204992 run.py:479] Algo floyd_warshall step 5035 current loss 0.029077, current_train_items 161152.\n",
            "I0314 03:03:42.192600 138313941204992 run.py:479] Algo floyd_warshall step 5036 current loss 0.104631, current_train_items 161184.\n",
            "I0314 03:03:42.324991 138313941204992 run.py:479] Algo floyd_warshall step 5037 current loss 0.344495, current_train_items 161216.\n",
            "I0314 03:03:42.541969 138313941204992 run.py:479] Algo floyd_warshall step 5038 current loss 0.500642, current_train_items 161248.\n",
            "I0314 03:03:42.958480 138313941204992 run.py:479] Algo floyd_warshall step 5039 current loss 0.799498, current_train_items 161280.\n",
            "I0314 03:03:42.982243 138313941204992 run.py:479] Algo floyd_warshall step 5040 current loss 0.035944, current_train_items 161312.\n",
            "I0314 03:03:43.027959 138313941204992 run.py:479] Algo floyd_warshall step 5041 current loss 0.122578, current_train_items 161344.\n",
            "I0314 03:03:43.159391 138313941204992 run.py:479] Algo floyd_warshall step 5042 current loss 0.205741, current_train_items 161376.\n",
            "I0314 03:03:43.385987 138313941204992 run.py:479] Algo floyd_warshall step 5043 current loss 0.412331, current_train_items 161408.\n",
            "I0314 03:03:43.802968 138313941204992 run.py:479] Algo floyd_warshall step 5044 current loss 0.723708, current_train_items 161440.\n",
            "I0314 03:03:43.827156 138313941204992 run.py:479] Algo floyd_warshall step 5045 current loss 0.065831, current_train_items 161472.\n",
            "I0314 03:03:43.874296 138313941204992 run.py:479] Algo floyd_warshall step 5046 current loss 0.115440, current_train_items 161504.\n",
            "I0314 03:03:44.008005 138313941204992 run.py:479] Algo floyd_warshall step 5047 current loss 0.330733, current_train_items 161536.\n",
            "I0314 03:03:44.225784 138313941204992 run.py:479] Algo floyd_warshall step 5048 current loss 0.539398, current_train_items 161568.\n",
            "I0314 03:03:44.645436 138313941204992 run.py:479] Algo floyd_warshall step 5049 current loss 0.991234, current_train_items 161600.\n",
            "I0314 03:03:44.669682 138313941204992 run.py:479] Algo floyd_warshall step 5050 current loss 0.012500, current_train_items 161632.\n",
            "I0314 03:03:44.759778 138313941204992 run.py:499] (val) algo floyd_warshall step 5050: {'Pi': 0.85589599609375, 'score': 0.85589599609375, 'examples_seen': 161632, 'step': 5050, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:03:44.760086 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.879, current avg val score is 0.856, val scores are: floyd_warshall: 0.856\n",
            "I0314 03:03:44.810865 138313941204992 run.py:479] Algo floyd_warshall step 5051 current loss 0.095174, current_train_items 161664.\n",
            "I0314 03:03:44.942890 138313941204992 run.py:479] Algo floyd_warshall step 5052 current loss 0.293550, current_train_items 161696.\n",
            "I0314 03:03:45.177424 138313941204992 run.py:479] Algo floyd_warshall step 5053 current loss 0.536104, current_train_items 161728.\n",
            "I0314 03:03:45.597281 138313941204992 run.py:479] Algo floyd_warshall step 5054 current loss 0.743617, current_train_items 161760.\n",
            "I0314 03:03:45.623772 138313941204992 run.py:479] Algo floyd_warshall step 5055 current loss 0.138252, current_train_items 161792.\n",
            "I0314 03:03:45.669187 138313941204992 run.py:479] Algo floyd_warshall step 5056 current loss 0.060367, current_train_items 161824.\n",
            "I0314 03:03:45.799824 138313941204992 run.py:479] Algo floyd_warshall step 5057 current loss 0.309090, current_train_items 161856.\n",
            "I0314 03:03:46.030842 138313941204992 run.py:479] Algo floyd_warshall step 5058 current loss 0.602060, current_train_items 161888.\n",
            "I0314 03:03:46.448685 138313941204992 run.py:479] Algo floyd_warshall step 5059 current loss 0.796849, current_train_items 161920.\n",
            "I0314 03:03:46.472490 138313941204992 run.py:479] Algo floyd_warshall step 5060 current loss 0.043017, current_train_items 161952.\n",
            "I0314 03:03:46.516174 138313941204992 run.py:479] Algo floyd_warshall step 5061 current loss 0.054295, current_train_items 161984.\n",
            "I0314 03:03:46.644916 138313941204992 run.py:479] Algo floyd_warshall step 5062 current loss 0.361394, current_train_items 162016.\n",
            "I0314 03:03:46.866400 138313941204992 run.py:479] Algo floyd_warshall step 5063 current loss 0.593104, current_train_items 162048.\n",
            "I0314 03:03:47.282097 138313941204992 run.py:479] Algo floyd_warshall step 5064 current loss 0.882874, current_train_items 162080.\n",
            "I0314 03:03:47.305482 138313941204992 run.py:479] Algo floyd_warshall step 5065 current loss 0.107223, current_train_items 162112.\n",
            "I0314 03:03:47.351026 138313941204992 run.py:479] Algo floyd_warshall step 5066 current loss 0.102288, current_train_items 162144.\n",
            "I0314 03:03:47.485106 138313941204992 run.py:479] Algo floyd_warshall step 5067 current loss 0.390113, current_train_items 162176.\n",
            "I0314 03:03:47.710019 138313941204992 run.py:479] Algo floyd_warshall step 5068 current loss 0.572408, current_train_items 162208.\n",
            "I0314 03:03:48.130525 138313941204992 run.py:479] Algo floyd_warshall step 5069 current loss 1.381051, current_train_items 162240.\n",
            "I0314 03:03:48.155427 138313941204992 run.py:479] Algo floyd_warshall step 5070 current loss 0.035331, current_train_items 162272.\n",
            "I0314 03:03:48.199818 138313941204992 run.py:479] Algo floyd_warshall step 5071 current loss 0.068968, current_train_items 162304.\n",
            "I0314 03:03:48.333394 138313941204992 run.py:479] Algo floyd_warshall step 5072 current loss 0.396913, current_train_items 162336.\n",
            "I0314 03:03:48.545082 138313941204992 run.py:479] Algo floyd_warshall step 5073 current loss 0.367343, current_train_items 162368.\n",
            "I0314 03:03:48.945268 138313941204992 run.py:479] Algo floyd_warshall step 5074 current loss 0.656486, current_train_items 162400.\n",
            "I0314 03:03:48.969061 138313941204992 run.py:479] Algo floyd_warshall step 5075 current loss 0.041590, current_train_items 162432.\n",
            "I0314 03:03:49.013078 138313941204992 run.py:479] Algo floyd_warshall step 5076 current loss 0.117192, current_train_items 162464.\n",
            "I0314 03:03:49.145700 138313941204992 run.py:479] Algo floyd_warshall step 5077 current loss 0.338796, current_train_items 162496.\n",
            "I0314 03:03:49.359995 138313941204992 run.py:479] Algo floyd_warshall step 5078 current loss 0.458557, current_train_items 162528.\n",
            "I0314 03:03:49.780665 138313941204992 run.py:479] Algo floyd_warshall step 5079 current loss 0.850695, current_train_items 162560.\n",
            "I0314 03:03:49.806757 138313941204992 run.py:479] Algo floyd_warshall step 5080 current loss 0.017667, current_train_items 162592.\n",
            "I0314 03:03:49.851223 138313941204992 run.py:479] Algo floyd_warshall step 5081 current loss 0.105197, current_train_items 162624.\n",
            "I0314 03:03:49.984606 138313941204992 run.py:479] Algo floyd_warshall step 5082 current loss 0.347783, current_train_items 162656.\n",
            "I0314 03:03:50.208350 138313941204992 run.py:479] Algo floyd_warshall step 5083 current loss 0.449099, current_train_items 162688.\n",
            "I0314 03:03:50.625137 138313941204992 run.py:479] Algo floyd_warshall step 5084 current loss 0.775280, current_train_items 162720.\n",
            "I0314 03:03:50.648930 138313941204992 run.py:479] Algo floyd_warshall step 5085 current loss 0.034926, current_train_items 162752.\n",
            "I0314 03:03:50.693469 138313941204992 run.py:479] Algo floyd_warshall step 5086 current loss 0.099310, current_train_items 162784.\n",
            "I0314 03:03:50.829550 138313941204992 run.py:479] Algo floyd_warshall step 5087 current loss 0.415406, current_train_items 162816.\n",
            "I0314 03:03:51.054660 138313941204992 run.py:479] Algo floyd_warshall step 5088 current loss 0.450464, current_train_items 162848.\n",
            "I0314 03:03:51.470007 138313941204992 run.py:479] Algo floyd_warshall step 5089 current loss 0.694349, current_train_items 162880.\n",
            "I0314 03:03:51.493973 138313941204992 run.py:479] Algo floyd_warshall step 5090 current loss 0.027342, current_train_items 162912.\n",
            "I0314 03:03:51.539759 138313941204992 run.py:479] Algo floyd_warshall step 5091 current loss 0.085277, current_train_items 162944.\n",
            "I0314 03:03:51.671553 138313941204992 run.py:479] Algo floyd_warshall step 5092 current loss 0.443359, current_train_items 162976.\n",
            "I0314 03:03:51.889940 138313941204992 run.py:479] Algo floyd_warshall step 5093 current loss 0.564889, current_train_items 163008.\n",
            "I0314 03:03:52.379344 138313941204992 run.py:479] Algo floyd_warshall step 5094 current loss 0.741806, current_train_items 163040.\n",
            "I0314 03:03:52.415865 138313941204992 run.py:479] Algo floyd_warshall step 5095 current loss 0.022850, current_train_items 163072.\n",
            "I0314 03:03:52.471859 138313941204992 run.py:479] Algo floyd_warshall step 5096 current loss 0.098814, current_train_items 163104.\n",
            "I0314 03:03:52.629419 138313941204992 run.py:479] Algo floyd_warshall step 5097 current loss 0.297892, current_train_items 163136.\n",
            "I0314 03:03:52.894506 138313941204992 run.py:479] Algo floyd_warshall step 5098 current loss 0.439547, current_train_items 163168.\n",
            "I0314 03:03:53.381799 138313941204992 run.py:479] Algo floyd_warshall step 5099 current loss 0.791363, current_train_items 163200.\n",
            "I0314 03:03:53.415107 138313941204992 run.py:479] Algo floyd_warshall step 5100 current loss 0.042469, current_train_items 163232.\n",
            "I0314 03:03:53.523895 138313941204992 run.py:499] (val) algo floyd_warshall step 5100: {'Pi': 0.88836669921875, 'score': 0.88836669921875, 'examples_seen': 163232, 'step': 5100, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:03:53.524270 138313941204992 run.py:516] Checkpointing best model, best avg val score was 0.879, current avg val score is 0.888, val scores are: floyd_warshall: 0.888\n",
            "I0314 03:03:53.692406 138313941204992 run.py:479] Algo floyd_warshall step 5101 current loss 0.089408, current_train_items 163264.\n",
            "I0314 03:03:53.863619 138313941204992 run.py:479] Algo floyd_warshall step 5102 current loss 0.184950, current_train_items 163296.\n",
            "I0314 03:03:54.159999 138313941204992 run.py:479] Algo floyd_warshall step 5103 current loss 0.626888, current_train_items 163328.\n",
            "I0314 03:03:54.696365 138313941204992 run.py:479] Algo floyd_warshall step 5104 current loss 0.791176, current_train_items 163360.\n",
            "I0314 03:03:54.739171 138313941204992 run.py:479] Algo floyd_warshall step 5105 current loss 0.016159, current_train_items 163392.\n",
            "I0314 03:03:54.799280 138313941204992 run.py:479] Algo floyd_warshall step 5106 current loss 0.105179, current_train_items 163424.\n",
            "I0314 03:03:54.965900 138313941204992 run.py:479] Algo floyd_warshall step 5107 current loss 0.340075, current_train_items 163456.\n",
            "I0314 03:03:55.240276 138313941204992 run.py:479] Algo floyd_warshall step 5108 current loss 0.394262, current_train_items 163488.\n",
            "I0314 03:03:55.762559 138313941204992 run.py:479] Algo floyd_warshall step 5109 current loss 0.789236, current_train_items 163520.\n",
            "I0314 03:03:55.808034 138313941204992 run.py:479] Algo floyd_warshall step 5110 current loss 0.032591, current_train_items 163552.\n",
            "I0314 03:03:55.873491 138313941204992 run.py:479] Algo floyd_warshall step 5111 current loss 0.174683, current_train_items 163584.\n",
            "I0314 03:03:56.043184 138313941204992 run.py:479] Algo floyd_warshall step 5112 current loss 0.373563, current_train_items 163616.\n",
            "I0314 03:03:56.302461 138313941204992 run.py:479] Algo floyd_warshall step 5113 current loss 0.411442, current_train_items 163648.\n",
            "I0314 03:03:56.819515 138313941204992 run.py:479] Algo floyd_warshall step 5114 current loss 0.781388, current_train_items 163680.\n",
            "I0314 03:03:56.859449 138313941204992 run.py:479] Algo floyd_warshall step 5115 current loss 0.024318, current_train_items 163712.\n",
            "I0314 03:03:56.919599 138313941204992 run.py:479] Algo floyd_warshall step 5116 current loss 0.092830, current_train_items 163744.\n",
            "I0314 03:03:57.084570 138313941204992 run.py:479] Algo floyd_warshall step 5117 current loss 0.228152, current_train_items 163776.\n",
            "I0314 03:03:57.359841 138313941204992 run.py:479] Algo floyd_warshall step 5118 current loss 0.510918, current_train_items 163808.\n",
            "I0314 03:03:57.863406 138313941204992 run.py:479] Algo floyd_warshall step 5119 current loss 0.843151, current_train_items 163840.\n",
            "I0314 03:03:57.887927 138313941204992 run.py:479] Algo floyd_warshall step 5120 current loss 0.008366, current_train_items 163872.\n",
            "I0314 03:03:57.934380 138313941204992 run.py:479] Algo floyd_warshall step 5121 current loss 0.173538, current_train_items 163904.\n",
            "I0314 03:03:58.067003 138313941204992 run.py:479] Algo floyd_warshall step 5122 current loss 0.431989, current_train_items 163936.\n",
            "I0314 03:03:58.291410 138313941204992 run.py:479] Algo floyd_warshall step 5123 current loss 0.547119, current_train_items 163968.\n",
            "I0314 03:03:58.720831 138313941204992 run.py:479] Algo floyd_warshall step 5124 current loss 0.824031, current_train_items 164000.\n",
            "I0314 03:03:58.744712 138313941204992 run.py:479] Algo floyd_warshall step 5125 current loss 0.021042, current_train_items 164032.\n",
            "I0314 03:03:58.791513 138313941204992 run.py:479] Algo floyd_warshall step 5126 current loss 0.084604, current_train_items 164064.\n",
            "I0314 03:03:58.922888 138313941204992 run.py:479] Algo floyd_warshall step 5127 current loss 0.421732, current_train_items 164096.\n",
            "I0314 03:03:59.141539 138313941204992 run.py:479] Algo floyd_warshall step 5128 current loss 0.579770, current_train_items 164128.\n",
            "I0314 03:03:59.542576 138313941204992 run.py:479] Algo floyd_warshall step 5129 current loss 0.743806, current_train_items 164160.\n",
            "I0314 03:03:59.567429 138313941204992 run.py:479] Algo floyd_warshall step 5130 current loss 0.039192, current_train_items 164192.\n",
            "I0314 03:03:59.614218 138313941204992 run.py:479] Algo floyd_warshall step 5131 current loss 0.139104, current_train_items 164224.\n",
            "I0314 03:03:59.746116 138313941204992 run.py:479] Algo floyd_warshall step 5132 current loss 0.318769, current_train_items 164256.\n",
            "I0314 03:03:59.973250 138313941204992 run.py:479] Algo floyd_warshall step 5133 current loss 0.446003, current_train_items 164288.\n",
            "I0314 03:04:00.407203 138313941204992 run.py:479] Algo floyd_warshall step 5134 current loss 0.845763, current_train_items 164320.\n",
            "I0314 03:04:00.432027 138313941204992 run.py:479] Algo floyd_warshall step 5135 current loss 0.046712, current_train_items 164352.\n",
            "I0314 03:04:00.478372 138313941204992 run.py:479] Algo floyd_warshall step 5136 current loss 0.112517, current_train_items 164384.\n",
            "I0314 03:04:00.611201 138313941204992 run.py:479] Algo floyd_warshall step 5137 current loss 0.284283, current_train_items 164416.\n",
            "I0314 03:04:00.837697 138313941204992 run.py:479] Algo floyd_warshall step 5138 current loss 0.474774, current_train_items 164448.\n",
            "I0314 03:04:01.258286 138313941204992 run.py:479] Algo floyd_warshall step 5139 current loss 0.851273, current_train_items 164480.\n",
            "I0314 03:04:01.281197 138313941204992 run.py:479] Algo floyd_warshall step 5140 current loss 0.041987, current_train_items 164512.\n",
            "I0314 03:04:01.326087 138313941204992 run.py:479] Algo floyd_warshall step 5141 current loss 0.078164, current_train_items 164544.\n",
            "I0314 03:04:01.455811 138313941204992 run.py:479] Algo floyd_warshall step 5142 current loss 0.257871, current_train_items 164576.\n",
            "I0314 03:04:01.671068 138313941204992 run.py:479] Algo floyd_warshall step 5143 current loss 0.463698, current_train_items 164608.\n",
            "I0314 03:04:02.080795 138313941204992 run.py:479] Algo floyd_warshall step 5144 current loss 0.696171, current_train_items 164640.\n",
            "I0314 03:04:02.106052 138313941204992 run.py:479] Algo floyd_warshall step 5145 current loss 0.041999, current_train_items 164672.\n",
            "I0314 03:04:02.152225 138313941204992 run.py:479] Algo floyd_warshall step 5146 current loss 0.090737, current_train_items 164704.\n",
            "I0314 03:04:02.283460 138313941204992 run.py:479] Algo floyd_warshall step 5147 current loss 0.437542, current_train_items 164736.\n",
            "I0314 03:04:02.516374 138313941204992 run.py:479] Algo floyd_warshall step 5148 current loss 0.521226, current_train_items 164768.\n",
            "I0314 03:04:02.953062 138313941204992 run.py:479] Algo floyd_warshall step 5149 current loss 0.760539, current_train_items 164800.\n",
            "I0314 03:04:02.977128 138313941204992 run.py:479] Algo floyd_warshall step 5150 current loss 0.026537, current_train_items 164832.\n",
            "I0314 03:04:03.072126 138313941204992 run.py:499] (val) algo floyd_warshall step 5150: {'Pi': 0.878662109375, 'score': 0.878662109375, 'examples_seen': 164832, 'step': 5150, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:04:03.072490 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.888, current avg val score is 0.879, val scores are: floyd_warshall: 0.879\n",
            "I0314 03:04:03.121774 138313941204992 run.py:479] Algo floyd_warshall step 5151 current loss 0.091346, current_train_items 164864.\n",
            "I0314 03:04:03.252376 138313941204992 run.py:479] Algo floyd_warshall step 5152 current loss 0.259487, current_train_items 164896.\n",
            "I0314 03:04:03.474962 138313941204992 run.py:479] Algo floyd_warshall step 5153 current loss 0.570282, current_train_items 164928.\n",
            "I0314 03:04:03.896441 138313941204992 run.py:479] Algo floyd_warshall step 5154 current loss 0.792044, current_train_items 164960.\n",
            "I0314 03:04:03.921851 138313941204992 run.py:479] Algo floyd_warshall step 5155 current loss 0.021677, current_train_items 164992.\n",
            "I0314 03:04:03.965551 138313941204992 run.py:479] Algo floyd_warshall step 5156 current loss 0.081347, current_train_items 165024.\n",
            "I0314 03:04:04.094603 138313941204992 run.py:479] Algo floyd_warshall step 5157 current loss 0.298257, current_train_items 165056.\n",
            "I0314 03:04:04.319496 138313941204992 run.py:479] Algo floyd_warshall step 5158 current loss 0.472852, current_train_items 165088.\n",
            "I0314 03:04:04.742748 138313941204992 run.py:479] Algo floyd_warshall step 5159 current loss 0.792163, current_train_items 165120.\n",
            "I0314 03:04:04.768334 138313941204992 run.py:479] Algo floyd_warshall step 5160 current loss 0.018986, current_train_items 165152.\n",
            "I0314 03:04:04.811897 138313941204992 run.py:479] Algo floyd_warshall step 5161 current loss 0.057585, current_train_items 165184.\n",
            "I0314 03:04:04.940970 138313941204992 run.py:479] Algo floyd_warshall step 5162 current loss 0.203580, current_train_items 165216.\n",
            "I0314 03:04:05.163131 138313941204992 run.py:479] Algo floyd_warshall step 5163 current loss 0.404576, current_train_items 165248.\n",
            "I0314 03:04:05.583086 138313941204992 run.py:479] Algo floyd_warshall step 5164 current loss 0.721608, current_train_items 165280.\n",
            "I0314 03:04:05.606012 138313941204992 run.py:479] Algo floyd_warshall step 5165 current loss 0.020346, current_train_items 165312.\n",
            "I0314 03:04:05.651225 138313941204992 run.py:479] Algo floyd_warshall step 5166 current loss 0.097552, current_train_items 165344.\n",
            "I0314 03:04:05.789969 138313941204992 run.py:479] Algo floyd_warshall step 5167 current loss 0.314702, current_train_items 165376.\n",
            "I0314 03:04:06.004482 138313941204992 run.py:479] Algo floyd_warshall step 5168 current loss 0.415752, current_train_items 165408.\n",
            "I0314 03:04:06.492235 138313941204992 run.py:479] Algo floyd_warshall step 5169 current loss 0.693080, current_train_items 165440.\n",
            "I0314 03:04:06.524920 138313941204992 run.py:479] Algo floyd_warshall step 5170 current loss 0.009872, current_train_items 165472.\n",
            "I0314 03:04:06.582662 138313941204992 run.py:479] Algo floyd_warshall step 5171 current loss 0.093835, current_train_items 165504.\n",
            "I0314 03:04:06.740318 138313941204992 run.py:479] Algo floyd_warshall step 5172 current loss 0.335657, current_train_items 165536.\n",
            "I0314 03:04:07.007019 138313941204992 run.py:479] Algo floyd_warshall step 5173 current loss 0.482907, current_train_items 165568.\n",
            "I0314 03:04:07.491552 138313941204992 run.py:479] Algo floyd_warshall step 5174 current loss 0.695139, current_train_items 165600.\n",
            "I0314 03:04:07.524741 138313941204992 run.py:479] Algo floyd_warshall step 5175 current loss 0.012288, current_train_items 165632.\n",
            "I0314 03:04:07.582155 138313941204992 run.py:479] Algo floyd_warshall step 5176 current loss 0.089597, current_train_items 165664.\n",
            "I0314 03:04:07.742287 138313941204992 run.py:479] Algo floyd_warshall step 5177 current loss 0.389429, current_train_items 165696.\n",
            "I0314 03:04:08.001729 138313941204992 run.py:479] Algo floyd_warshall step 5178 current loss 0.341119, current_train_items 165728.\n",
            "I0314 03:04:08.496654 138313941204992 run.py:479] Algo floyd_warshall step 5179 current loss 0.829221, current_train_items 165760.\n",
            "I0314 03:04:08.529257 138313941204992 run.py:479] Algo floyd_warshall step 5180 current loss 0.035809, current_train_items 165792.\n",
            "I0314 03:04:08.590641 138313941204992 run.py:479] Algo floyd_warshall step 5181 current loss 0.175878, current_train_items 165824.\n",
            "I0314 03:04:08.741849 138313941204992 run.py:479] Algo floyd_warshall step 5182 current loss 0.276812, current_train_items 165856.\n",
            "I0314 03:04:09.014684 138313941204992 run.py:479] Algo floyd_warshall step 5183 current loss 0.444726, current_train_items 165888.\n",
            "I0314 03:04:09.429842 138313941204992 run.py:479] Algo floyd_warshall step 5184 current loss 0.732348, current_train_items 165920.\n",
            "I0314 03:04:09.452630 138313941204992 run.py:479] Algo floyd_warshall step 5185 current loss 0.020741, current_train_items 165952.\n",
            "I0314 03:04:09.497359 138313941204992 run.py:479] Algo floyd_warshall step 5186 current loss 0.098255, current_train_items 165984.\n",
            "I0314 03:04:09.636132 138313941204992 run.py:479] Algo floyd_warshall step 5187 current loss 0.437712, current_train_items 166016.\n",
            "I0314 03:04:09.864399 138313941204992 run.py:479] Algo floyd_warshall step 5188 current loss 0.528083, current_train_items 166048.\n",
            "I0314 03:04:10.281892 138313941204992 run.py:479] Algo floyd_warshall step 5189 current loss 0.693519, current_train_items 166080.\n",
            "I0314 03:04:10.305531 138313941204992 run.py:479] Algo floyd_warshall step 5190 current loss 0.028281, current_train_items 166112.\n",
            "I0314 03:04:10.353480 138313941204992 run.py:479] Algo floyd_warshall step 5191 current loss 0.082123, current_train_items 166144.\n",
            "I0314 03:04:10.484557 138313941204992 run.py:479] Algo floyd_warshall step 5192 current loss 0.368403, current_train_items 166176.\n",
            "I0314 03:04:10.697283 138313941204992 run.py:479] Algo floyd_warshall step 5193 current loss 0.458838, current_train_items 166208.\n",
            "I0314 03:04:11.128258 138313941204992 run.py:479] Algo floyd_warshall step 5194 current loss 0.657556, current_train_items 166240.\n",
            "I0314 03:04:11.151700 138313941204992 run.py:479] Algo floyd_warshall step 5195 current loss 0.020229, current_train_items 166272.\n",
            "I0314 03:04:11.195300 138313941204992 run.py:479] Algo floyd_warshall step 5196 current loss 0.077012, current_train_items 166304.\n",
            "I0314 03:04:11.329300 138313941204992 run.py:479] Algo floyd_warshall step 5197 current loss 0.355930, current_train_items 166336.\n",
            "I0314 03:04:11.550902 138313941204992 run.py:479] Algo floyd_warshall step 5198 current loss 0.572832, current_train_items 166368.\n",
            "I0314 03:04:11.960082 138313941204992 run.py:479] Algo floyd_warshall step 5199 current loss 0.813744, current_train_items 166400.\n",
            "I0314 03:04:11.983057 138313941204992 run.py:479] Algo floyd_warshall step 5200 current loss 0.016739, current_train_items 166432.\n",
            "I0314 03:04:12.071173 138313941204992 run.py:499] (val) algo floyd_warshall step 5200: {'Pi': 0.87835693359375, 'score': 0.87835693359375, 'examples_seen': 166432, 'step': 5200, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:04:12.071412 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.888, current avg val score is 0.878, val scores are: floyd_warshall: 0.878\n",
            "I0314 03:04:12.119352 138313941204992 run.py:479] Algo floyd_warshall step 5201 current loss 0.055911, current_train_items 166464.\n",
            "I0314 03:04:12.250376 138313941204992 run.py:479] Algo floyd_warshall step 5202 current loss 0.345410, current_train_items 166496.\n",
            "I0314 03:04:12.468082 138313941204992 run.py:479] Algo floyd_warshall step 5203 current loss 0.458463, current_train_items 166528.\n",
            "I0314 03:04:12.890870 138313941204992 run.py:479] Algo floyd_warshall step 5204 current loss 0.755023, current_train_items 166560.\n",
            "I0314 03:04:12.915626 138313941204992 run.py:479] Algo floyd_warshall step 5205 current loss 0.023510, current_train_items 166592.\n",
            "I0314 03:04:12.965820 138313941204992 run.py:479] Algo floyd_warshall step 5206 current loss 0.159505, current_train_items 166624.\n",
            "I0314 03:04:13.095426 138313941204992 run.py:479] Algo floyd_warshall step 5207 current loss 0.287027, current_train_items 166656.\n",
            "I0314 03:04:13.310801 138313941204992 run.py:479] Algo floyd_warshall step 5208 current loss 0.465401, current_train_items 166688.\n",
            "I0314 03:04:13.708051 138313941204992 run.py:479] Algo floyd_warshall step 5209 current loss 0.551829, current_train_items 166720.\n",
            "I0314 03:04:13.731035 138313941204992 run.py:479] Algo floyd_warshall step 5210 current loss 0.026559, current_train_items 166752.\n",
            "I0314 03:04:13.775565 138313941204992 run.py:479] Algo floyd_warshall step 5211 current loss 0.065728, current_train_items 166784.\n",
            "I0314 03:04:13.905646 138313941204992 run.py:479] Algo floyd_warshall step 5212 current loss 0.241890, current_train_items 166816.\n",
            "I0314 03:04:14.128100 138313941204992 run.py:479] Algo floyd_warshall step 5213 current loss 0.392254, current_train_items 166848.\n",
            "I0314 03:04:14.553184 138313941204992 run.py:479] Algo floyd_warshall step 5214 current loss 0.909863, current_train_items 166880.\n",
            "I0314 03:04:14.577908 138313941204992 run.py:479] Algo floyd_warshall step 5215 current loss 0.021227, current_train_items 166912.\n",
            "I0314 03:04:14.623182 138313941204992 run.py:479] Algo floyd_warshall step 5216 current loss 0.106383, current_train_items 166944.\n",
            "I0314 03:04:14.754738 138313941204992 run.py:479] Algo floyd_warshall step 5217 current loss 0.293123, current_train_items 166976.\n",
            "I0314 03:04:14.982617 138313941204992 run.py:479] Algo floyd_warshall step 5218 current loss 0.448474, current_train_items 167008.\n",
            "I0314 03:04:15.417441 138313941204992 run.py:479] Algo floyd_warshall step 5219 current loss 0.842204, current_train_items 167040.\n",
            "I0314 03:04:15.441253 138313941204992 run.py:479] Algo floyd_warshall step 5220 current loss 0.028020, current_train_items 167072.\n",
            "I0314 03:04:15.486524 138313941204992 run.py:479] Algo floyd_warshall step 5221 current loss 0.083894, current_train_items 167104.\n",
            "I0314 03:04:15.620933 138313941204992 run.py:479] Algo floyd_warshall step 5222 current loss 0.365785, current_train_items 167136.\n",
            "I0314 03:04:15.837965 138313941204992 run.py:479] Algo floyd_warshall step 5223 current loss 0.441362, current_train_items 167168.\n",
            "I0314 03:04:16.245309 138313941204992 run.py:479] Algo floyd_warshall step 5224 current loss 0.700068, current_train_items 167200.\n",
            "I0314 03:04:16.268126 138313941204992 run.py:479] Algo floyd_warshall step 5225 current loss 0.011524, current_train_items 167232.\n",
            "I0314 03:04:16.312374 138313941204992 run.py:479] Algo floyd_warshall step 5226 current loss 0.143565, current_train_items 167264.\n",
            "I0314 03:04:16.439704 138313941204992 run.py:479] Algo floyd_warshall step 5227 current loss 0.241940, current_train_items 167296.\n",
            "I0314 03:04:16.655130 138313941204992 run.py:479] Algo floyd_warshall step 5228 current loss 0.510876, current_train_items 167328.\n",
            "I0314 03:04:17.069096 138313941204992 run.py:479] Algo floyd_warshall step 5229 current loss 0.811679, current_train_items 167360.\n",
            "I0314 03:04:17.093573 138313941204992 run.py:479] Algo floyd_warshall step 5230 current loss 0.030647, current_train_items 167392.\n",
            "I0314 03:04:17.140458 138313941204992 run.py:479] Algo floyd_warshall step 5231 current loss 0.103974, current_train_items 167424.\n",
            "I0314 03:04:17.277868 138313941204992 run.py:479] Algo floyd_warshall step 5232 current loss 0.311621, current_train_items 167456.\n",
            "I0314 03:04:17.505660 138313941204992 run.py:479] Algo floyd_warshall step 5233 current loss 0.484647, current_train_items 167488.\n",
            "I0314 03:04:17.916923 138313941204992 run.py:479] Algo floyd_warshall step 5234 current loss 0.738340, current_train_items 167520.\n",
            "I0314 03:04:17.940413 138313941204992 run.py:479] Algo floyd_warshall step 5235 current loss 0.023275, current_train_items 167552.\n",
            "I0314 03:04:17.987361 138313941204992 run.py:479] Algo floyd_warshall step 5236 current loss 0.054230, current_train_items 167584.\n",
            "I0314 03:04:18.117840 138313941204992 run.py:479] Algo floyd_warshall step 5237 current loss 0.216369, current_train_items 167616.\n",
            "I0314 03:04:18.332281 138313941204992 run.py:479] Algo floyd_warshall step 5238 current loss 0.412452, current_train_items 167648.\n",
            "I0314 03:04:18.758083 138313941204992 run.py:479] Algo floyd_warshall step 5239 current loss 0.780581, current_train_items 167680.\n",
            "I0314 03:04:18.781479 138313941204992 run.py:479] Algo floyd_warshall step 5240 current loss 0.038400, current_train_items 167712.\n",
            "I0314 03:04:18.826646 138313941204992 run.py:479] Algo floyd_warshall step 5241 current loss 0.053980, current_train_items 167744.\n",
            "I0314 03:04:18.957662 138313941204992 run.py:479] Algo floyd_warshall step 5242 current loss 0.294514, current_train_items 167776.\n",
            "I0314 03:04:19.173002 138313941204992 run.py:479] Algo floyd_warshall step 5243 current loss 0.354616, current_train_items 167808.\n",
            "I0314 03:04:19.647736 138313941204992 run.py:479] Algo floyd_warshall step 5244 current loss 0.625275, current_train_items 167840.\n",
            "I0314 03:04:19.683142 138313941204992 run.py:479] Algo floyd_warshall step 5245 current loss 0.015049, current_train_items 167872.\n",
            "I0314 03:04:19.738627 138313941204992 run.py:479] Algo floyd_warshall step 5246 current loss 0.130755, current_train_items 167904.\n",
            "I0314 03:04:19.898366 138313941204992 run.py:479] Algo floyd_warshall step 5247 current loss 0.296913, current_train_items 167936.\n",
            "I0314 03:04:20.161698 138313941204992 run.py:479] Algo floyd_warshall step 5248 current loss 0.368972, current_train_items 167968.\n",
            "I0314 03:04:20.668363 138313941204992 run.py:479] Algo floyd_warshall step 5249 current loss 0.719532, current_train_items 168000.\n",
            "I0314 03:04:20.703319 138313941204992 run.py:479] Algo floyd_warshall step 5250 current loss 0.053820, current_train_items 168032.\n",
            "I0314 03:04:20.811169 138313941204992 run.py:499] (val) algo floyd_warshall step 5250: {'Pi': 0.87384033203125, 'score': 0.87384033203125, 'examples_seen': 168032, 'step': 5250, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:04:20.811463 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.888, current avg val score is 0.874, val scores are: floyd_warshall: 0.874\n",
            "I0314 03:04:20.872237 138313941204992 run.py:479] Algo floyd_warshall step 5251 current loss 0.056605, current_train_items 168064.\n",
            "I0314 03:04:21.036406 138313941204992 run.py:479] Algo floyd_warshall step 5252 current loss 0.294939, current_train_items 168096.\n",
            "I0314 03:04:21.301087 138313941204992 run.py:479] Algo floyd_warshall step 5253 current loss 0.746200, current_train_items 168128.\n",
            "I0314 03:04:21.790541 138313941204992 run.py:479] Algo floyd_warshall step 5254 current loss 0.929004, current_train_items 168160.\n",
            "I0314 03:04:21.832907 138313941204992 run.py:479] Algo floyd_warshall step 5255 current loss 0.033435, current_train_items 168192.\n",
            "I0314 03:04:21.891763 138313941204992 run.py:479] Algo floyd_warshall step 5256 current loss 0.134104, current_train_items 168224.\n",
            "I0314 03:04:22.047703 138313941204992 run.py:479] Algo floyd_warshall step 5257 current loss 0.348645, current_train_items 168256.\n",
            "I0314 03:04:22.265871 138313941204992 run.py:479] Algo floyd_warshall step 5258 current loss 0.504163, current_train_items 168288.\n",
            "I0314 03:04:22.682456 138313941204992 run.py:479] Algo floyd_warshall step 5259 current loss 0.779535, current_train_items 168320.\n",
            "I0314 03:04:22.706851 138313941204992 run.py:479] Algo floyd_warshall step 5260 current loss 0.018609, current_train_items 168352.\n",
            "I0314 03:04:22.752072 138313941204992 run.py:479] Algo floyd_warshall step 5261 current loss 0.062707, current_train_items 168384.\n",
            "I0314 03:04:22.883000 138313941204992 run.py:479] Algo floyd_warshall step 5262 current loss 0.293652, current_train_items 168416.\n",
            "I0314 03:04:23.104275 138313941204992 run.py:479] Algo floyd_warshall step 5263 current loss 0.570768, current_train_items 168448.\n",
            "I0314 03:04:23.516422 138313941204992 run.py:479] Algo floyd_warshall step 5264 current loss 0.987145, current_train_items 168480.\n",
            "I0314 03:04:23.539882 138313941204992 run.py:479] Algo floyd_warshall step 5265 current loss 0.052111, current_train_items 168512.\n",
            "I0314 03:04:23.583983 138313941204992 run.py:479] Algo floyd_warshall step 5266 current loss 0.117753, current_train_items 168544.\n",
            "I0314 03:04:23.713882 138313941204992 run.py:479] Algo floyd_warshall step 5267 current loss 0.321717, current_train_items 168576.\n",
            "I0314 03:04:23.945676 138313941204992 run.py:479] Algo floyd_warshall step 5268 current loss 0.537136, current_train_items 168608.\n",
            "I0314 03:04:24.364390 138313941204992 run.py:479] Algo floyd_warshall step 5269 current loss 0.847188, current_train_items 168640.\n",
            "I0314 03:04:24.386775 138313941204992 run.py:479] Algo floyd_warshall step 5270 current loss 0.193394, current_train_items 168672.\n",
            "I0314 03:04:24.431728 138313941204992 run.py:479] Algo floyd_warshall step 5271 current loss 0.113497, current_train_items 168704.\n",
            "I0314 03:04:24.560620 138313941204992 run.py:479] Algo floyd_warshall step 5272 current loss 0.320389, current_train_items 168736.\n",
            "I0314 03:04:24.777020 138313941204992 run.py:479] Algo floyd_warshall step 5273 current loss 0.514322, current_train_items 168768.\n",
            "I0314 03:04:25.185310 138313941204992 run.py:479] Algo floyd_warshall step 5274 current loss 0.714321, current_train_items 168800.\n",
            "I0314 03:04:25.208851 138313941204992 run.py:479] Algo floyd_warshall step 5275 current loss 0.061872, current_train_items 168832.\n",
            "I0314 03:04:25.253403 138313941204992 run.py:479] Algo floyd_warshall step 5276 current loss 0.050804, current_train_items 168864.\n",
            "I0314 03:04:25.379817 138313941204992 run.py:479] Algo floyd_warshall step 5277 current loss 0.230127, current_train_items 168896.\n",
            "I0314 03:04:25.596005 138313941204992 run.py:479] Algo floyd_warshall step 5278 current loss 0.413802, current_train_items 168928.\n",
            "I0314 03:04:26.019792 138313941204992 run.py:479] Algo floyd_warshall step 5279 current loss 0.743780, current_train_items 168960.\n",
            "I0314 03:04:26.042481 138313941204992 run.py:479] Algo floyd_warshall step 5280 current loss 0.031407, current_train_items 168992.\n",
            "I0314 03:04:26.092440 138313941204992 run.py:479] Algo floyd_warshall step 5281 current loss 0.173021, current_train_items 169024.\n",
            "I0314 03:04:26.223606 138313941204992 run.py:479] Algo floyd_warshall step 5282 current loss 0.500047, current_train_items 169056.\n",
            "I0314 03:04:26.454467 138313941204992 run.py:479] Algo floyd_warshall step 5283 current loss 0.550234, current_train_items 169088.\n",
            "I0314 03:04:26.879518 138313941204992 run.py:479] Algo floyd_warshall step 5284 current loss 0.880536, current_train_items 169120.\n",
            "I0314 03:04:26.902654 138313941204992 run.py:479] Algo floyd_warshall step 5285 current loss 0.023377, current_train_items 169152.\n",
            "I0314 03:04:26.947718 138313941204992 run.py:479] Algo floyd_warshall step 5286 current loss 0.146323, current_train_items 169184.\n",
            "I0314 03:04:27.077703 138313941204992 run.py:479] Algo floyd_warshall step 5287 current loss 0.389075, current_train_items 169216.\n",
            "I0314 03:04:27.292968 138313941204992 run.py:479] Algo floyd_warshall step 5288 current loss 0.507122, current_train_items 169248.\n",
            "I0314 03:04:27.717324 138313941204992 run.py:479] Algo floyd_warshall step 5289 current loss 0.870151, current_train_items 169280.\n",
            "I0314 03:04:27.740862 138313941204992 run.py:479] Algo floyd_warshall step 5290 current loss 0.024890, current_train_items 169312.\n",
            "I0314 03:04:27.787306 138313941204992 run.py:479] Algo floyd_warshall step 5291 current loss 0.087130, current_train_items 169344.\n",
            "I0314 03:04:27.918711 138313941204992 run.py:479] Algo floyd_warshall step 5292 current loss 0.338393, current_train_items 169376.\n",
            "I0314 03:04:28.134614 138313941204992 run.py:479] Algo floyd_warshall step 5293 current loss 0.525059, current_train_items 169408.\n",
            "I0314 03:04:28.558748 138313941204992 run.py:479] Algo floyd_warshall step 5294 current loss 0.887788, current_train_items 169440.\n",
            "I0314 03:04:28.585339 138313941204992 run.py:479] Algo floyd_warshall step 5295 current loss 0.028985, current_train_items 169472.\n",
            "I0314 03:04:28.631919 138313941204992 run.py:479] Algo floyd_warshall step 5296 current loss 0.152202, current_train_items 169504.\n",
            "I0314 03:04:28.762651 138313941204992 run.py:479] Algo floyd_warshall step 5297 current loss 0.382233, current_train_items 169536.\n",
            "I0314 03:04:28.989548 138313941204992 run.py:479] Algo floyd_warshall step 5298 current loss 0.465209, current_train_items 169568.\n",
            "I0314 03:04:29.402729 138313941204992 run.py:479] Algo floyd_warshall step 5299 current loss 0.636499, current_train_items 169600.\n",
            "I0314 03:04:29.432695 138313941204992 run.py:479] Algo floyd_warshall step 5300 current loss 0.012450, current_train_items 169632.\n",
            "I0314 03:04:29.526885 138313941204992 run.py:499] (val) algo floyd_warshall step 5300: {'Pi': 0.86248779296875, 'score': 0.86248779296875, 'examples_seen': 169632, 'step': 5300, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:04:29.527162 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.888, current avg val score is 0.862, val scores are: floyd_warshall: 0.862\n",
            "I0314 03:04:29.574952 138313941204992 run.py:479] Algo floyd_warshall step 5301 current loss 0.186333, current_train_items 169664.\n",
            "I0314 03:04:29.707688 138313941204992 run.py:479] Algo floyd_warshall step 5302 current loss 0.337719, current_train_items 169696.\n",
            "I0314 03:04:29.930805 138313941204992 run.py:479] Algo floyd_warshall step 5303 current loss 0.434945, current_train_items 169728.\n",
            "I0314 03:04:30.359652 138313941204992 run.py:479] Algo floyd_warshall step 5304 current loss 0.797341, current_train_items 169760.\n",
            "I0314 03:04:30.385048 138313941204992 run.py:479] Algo floyd_warshall step 5305 current loss 0.059998, current_train_items 169792.\n",
            "I0314 03:04:30.431035 138313941204992 run.py:479] Algo floyd_warshall step 5306 current loss 0.094942, current_train_items 169824.\n",
            "I0314 03:04:30.572126 138313941204992 run.py:479] Algo floyd_warshall step 5307 current loss 0.220657, current_train_items 169856.\n",
            "I0314 03:04:30.797939 138313941204992 run.py:479] Algo floyd_warshall step 5308 current loss 0.352877, current_train_items 169888.\n",
            "I0314 03:04:31.223710 138313941204992 run.py:479] Algo floyd_warshall step 5309 current loss 0.684679, current_train_items 169920.\n",
            "I0314 03:04:31.247782 138313941204992 run.py:479] Algo floyd_warshall step 5310 current loss 0.012289, current_train_items 169952.\n",
            "I0314 03:04:31.295663 138313941204992 run.py:479] Algo floyd_warshall step 5311 current loss 0.084069, current_train_items 169984.\n",
            "I0314 03:04:31.423690 138313941204992 run.py:479] Algo floyd_warshall step 5312 current loss 0.292499, current_train_items 170016.\n",
            "I0314 03:04:31.647036 138313941204992 run.py:479] Algo floyd_warshall step 5313 current loss 0.456224, current_train_items 170048.\n",
            "I0314 03:04:32.064052 138313941204992 run.py:479] Algo floyd_warshall step 5314 current loss 0.821253, current_train_items 170080.\n",
            "I0314 03:04:32.102951 138313941204992 run.py:479] Algo floyd_warshall step 5315 current loss 0.025276, current_train_items 170112.\n",
            "I0314 03:04:32.164182 138313941204992 run.py:479] Algo floyd_warshall step 5316 current loss 0.205628, current_train_items 170144.\n",
            "I0314 03:04:32.322475 138313941204992 run.py:479] Algo floyd_warshall step 5317 current loss 0.268822, current_train_items 170176.\n",
            "I0314 03:04:32.585986 138313941204992 run.py:479] Algo floyd_warshall step 5318 current loss 0.466224, current_train_items 170208.\n",
            "I0314 03:04:33.107669 138313941204992 run.py:479] Algo floyd_warshall step 5319 current loss 0.869245, current_train_items 170240.\n",
            "I0314 03:04:33.150918 138313941204992 run.py:479] Algo floyd_warshall step 5320 current loss 0.036002, current_train_items 170272.\n",
            "I0314 03:04:33.207024 138313941204992 run.py:479] Algo floyd_warshall step 5321 current loss 0.089971, current_train_items 170304.\n",
            "I0314 03:04:33.363622 138313941204992 run.py:479] Algo floyd_warshall step 5322 current loss 0.433634, current_train_items 170336.\n",
            "I0314 03:04:33.630078 138313941204992 run.py:479] Algo floyd_warshall step 5323 current loss 0.473837, current_train_items 170368.\n",
            "I0314 03:04:34.130342 138313941204992 run.py:479] Algo floyd_warshall step 5324 current loss 0.740271, current_train_items 170400.\n",
            "I0314 03:04:34.161906 138313941204992 run.py:479] Algo floyd_warshall step 5325 current loss 0.056264, current_train_items 170432.\n",
            "I0314 03:04:34.223288 138313941204992 run.py:479] Algo floyd_warshall step 5326 current loss 0.094366, current_train_items 170464.\n",
            "I0314 03:04:34.379698 138313941204992 run.py:479] Algo floyd_warshall step 5327 current loss 0.372898, current_train_items 170496.\n",
            "I0314 03:04:34.655334 138313941204992 run.py:479] Algo floyd_warshall step 5328 current loss 0.545550, current_train_items 170528.\n",
            "I0314 03:04:35.173593 138313941204992 run.py:479] Algo floyd_warshall step 5329 current loss 0.969724, current_train_items 170560.\n",
            "I0314 03:04:35.197583 138313941204992 run.py:479] Algo floyd_warshall step 5330 current loss 0.018149, current_train_items 170592.\n",
            "I0314 03:04:35.246084 138313941204992 run.py:479] Algo floyd_warshall step 5331 current loss 0.061697, current_train_items 170624.\n",
            "I0314 03:04:35.375511 138313941204992 run.py:479] Algo floyd_warshall step 5332 current loss 0.354407, current_train_items 170656.\n",
            "I0314 03:04:35.604896 138313941204992 run.py:479] Algo floyd_warshall step 5333 current loss 0.456063, current_train_items 170688.\n",
            "I0314 03:04:36.017747 138313941204992 run.py:479] Algo floyd_warshall step 5334 current loss 0.720258, current_train_items 170720.\n",
            "I0314 03:04:36.042043 138313941204992 run.py:479] Algo floyd_warshall step 5335 current loss 0.029127, current_train_items 170752.\n",
            "I0314 03:04:36.089769 138313941204992 run.py:479] Algo floyd_warshall step 5336 current loss 0.127192, current_train_items 170784.\n",
            "I0314 03:04:36.224161 138313941204992 run.py:479] Algo floyd_warshall step 5337 current loss 0.331133, current_train_items 170816.\n",
            "I0314 03:04:36.449554 138313941204992 run.py:479] Algo floyd_warshall step 5338 current loss 0.400139, current_train_items 170848.\n",
            "I0314 03:04:36.857964 138313941204992 run.py:479] Algo floyd_warshall step 5339 current loss 0.653926, current_train_items 170880.\n",
            "I0314 03:04:36.881380 138313941204992 run.py:479] Algo floyd_warshall step 5340 current loss 0.014570, current_train_items 170912.\n",
            "I0314 03:04:36.925453 138313941204992 run.py:479] Algo floyd_warshall step 5341 current loss 0.055083, current_train_items 170944.\n",
            "I0314 03:04:37.056752 138313941204992 run.py:479] Algo floyd_warshall step 5342 current loss 0.347827, current_train_items 170976.\n",
            "I0314 03:04:37.273091 138313941204992 run.py:479] Algo floyd_warshall step 5343 current loss 0.478773, current_train_items 171008.\n",
            "I0314 03:04:37.684745 138313941204992 run.py:479] Algo floyd_warshall step 5344 current loss 0.782270, current_train_items 171040.\n",
            "I0314 03:04:37.710127 138313941204992 run.py:479] Algo floyd_warshall step 5345 current loss 0.040941, current_train_items 171072.\n",
            "I0314 03:04:37.755352 138313941204992 run.py:479] Algo floyd_warshall step 5346 current loss 0.158732, current_train_items 171104.\n",
            "I0314 03:04:37.896826 138313941204992 run.py:479] Algo floyd_warshall step 5347 current loss 0.295404, current_train_items 171136.\n",
            "I0314 03:04:38.119230 138313941204992 run.py:479] Algo floyd_warshall step 5348 current loss 0.426454, current_train_items 171168.\n",
            "I0314 03:04:38.550181 138313941204992 run.py:479] Algo floyd_warshall step 5349 current loss 0.968562, current_train_items 171200.\n",
            "I0314 03:04:38.574640 138313941204992 run.py:479] Algo floyd_warshall step 5350 current loss 0.009334, current_train_items 171232.\n",
            "I0314 03:04:38.663830 138313941204992 run.py:499] (val) algo floyd_warshall step 5350: {'Pi': 0.8717041015625, 'score': 0.8717041015625, 'examples_seen': 171232, 'step': 5350, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:04:38.664087 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.888, current avg val score is 0.872, val scores are: floyd_warshall: 0.872\n",
            "I0314 03:04:38.711566 138313941204992 run.py:479] Algo floyd_warshall step 5351 current loss 0.078679, current_train_items 171264.\n",
            "I0314 03:04:38.842609 138313941204992 run.py:479] Algo floyd_warshall step 5352 current loss 0.221254, current_train_items 171296.\n",
            "I0314 03:04:39.068780 138313941204992 run.py:479] Algo floyd_warshall step 5353 current loss 0.509599, current_train_items 171328.\n",
            "I0314 03:04:39.503548 138313941204992 run.py:479] Algo floyd_warshall step 5354 current loss 0.732619, current_train_items 171360.\n",
            "I0314 03:04:39.530581 138313941204992 run.py:479] Algo floyd_warshall step 5355 current loss 0.018991, current_train_items 171392.\n",
            "I0314 03:04:39.576086 138313941204992 run.py:479] Algo floyd_warshall step 5356 current loss 0.073086, current_train_items 171424.\n",
            "I0314 03:04:39.702931 138313941204992 run.py:479] Algo floyd_warshall step 5357 current loss 0.240423, current_train_items 171456.\n",
            "I0314 03:04:39.927110 138313941204992 run.py:479] Algo floyd_warshall step 5358 current loss 0.443034, current_train_items 171488.\n",
            "I0314 03:04:40.339201 138313941204992 run.py:479] Algo floyd_warshall step 5359 current loss 0.802043, current_train_items 171520.\n",
            "I0314 03:04:40.364307 138313941204992 run.py:479] Algo floyd_warshall step 5360 current loss 0.044268, current_train_items 171552.\n",
            "I0314 03:04:40.408980 138313941204992 run.py:479] Algo floyd_warshall step 5361 current loss 0.102596, current_train_items 171584.\n",
            "I0314 03:04:40.539551 138313941204992 run.py:479] Algo floyd_warshall step 5362 current loss 0.362119, current_train_items 171616.\n",
            "I0314 03:04:40.762522 138313941204992 run.py:479] Algo floyd_warshall step 5363 current loss 0.391138, current_train_items 171648.\n",
            "I0314 03:04:41.204792 138313941204992 run.py:479] Algo floyd_warshall step 5364 current loss 0.665810, current_train_items 171680.\n",
            "I0314 03:04:41.228467 138313941204992 run.py:479] Algo floyd_warshall step 5365 current loss 0.033878, current_train_items 171712.\n",
            "I0314 03:04:41.272097 138313941204992 run.py:479] Algo floyd_warshall step 5366 current loss 0.123211, current_train_items 171744.\n",
            "I0314 03:04:41.404128 138313941204992 run.py:479] Algo floyd_warshall step 5367 current loss 0.412289, current_train_items 171776.\n",
            "I0314 03:04:41.632324 138313941204992 run.py:479] Algo floyd_warshall step 5368 current loss 0.507866, current_train_items 171808.\n",
            "I0314 03:04:42.046910 138313941204992 run.py:479] Algo floyd_warshall step 5369 current loss 0.850770, current_train_items 171840.\n",
            "I0314 03:04:42.070770 138313941204992 run.py:479] Algo floyd_warshall step 5370 current loss 0.013634, current_train_items 171872.\n",
            "I0314 03:04:42.118728 138313941204992 run.py:479] Algo floyd_warshall step 5371 current loss 0.059003, current_train_items 171904.\n",
            "I0314 03:04:42.249727 138313941204992 run.py:479] Algo floyd_warshall step 5372 current loss 0.287189, current_train_items 171936.\n",
            "I0314 03:04:42.477508 138313941204992 run.py:479] Algo floyd_warshall step 5373 current loss 0.661429, current_train_items 171968.\n",
            "I0314 03:04:42.882321 138313941204992 run.py:479] Algo floyd_warshall step 5374 current loss 0.731135, current_train_items 172000.\n",
            "I0314 03:04:42.905843 138313941204992 run.py:479] Algo floyd_warshall step 5375 current loss 0.009543, current_train_items 172032.\n",
            "I0314 03:04:42.959565 138313941204992 run.py:479] Algo floyd_warshall step 5376 current loss 0.060967, current_train_items 172064.\n",
            "I0314 03:04:43.088818 138313941204992 run.py:479] Algo floyd_warshall step 5377 current loss 0.473769, current_train_items 172096.\n",
            "I0314 03:04:43.304254 138313941204992 run.py:479] Algo floyd_warshall step 5378 current loss 0.461421, current_train_items 172128.\n",
            "I0314 03:04:43.713498 138313941204992 run.py:479] Algo floyd_warshall step 5379 current loss 0.731855, current_train_items 172160.\n",
            "I0314 03:04:43.738011 138313941204992 run.py:479] Algo floyd_warshall step 5380 current loss 0.021817, current_train_items 172192.\n",
            "I0314 03:04:43.781876 138313941204992 run.py:479] Algo floyd_warshall step 5381 current loss 0.118305, current_train_items 172224.\n",
            "I0314 03:04:43.912380 138313941204992 run.py:479] Algo floyd_warshall step 5382 current loss 0.225865, current_train_items 172256.\n",
            "I0314 03:04:44.133600 138313941204992 run.py:479] Algo floyd_warshall step 5383 current loss 0.376543, current_train_items 172288.\n",
            "I0314 03:04:44.542553 138313941204992 run.py:479] Algo floyd_warshall step 5384 current loss 0.708259, current_train_items 172320.\n",
            "I0314 03:04:44.566955 138313941204992 run.py:479] Algo floyd_warshall step 5385 current loss 0.035766, current_train_items 172352.\n",
            "I0314 03:04:44.612592 138313941204992 run.py:479] Algo floyd_warshall step 5386 current loss 0.107498, current_train_items 172384.\n",
            "I0314 03:04:44.745310 138313941204992 run.py:479] Algo floyd_warshall step 5387 current loss 0.355334, current_train_items 172416.\n",
            "I0314 03:04:44.971327 138313941204992 run.py:479] Algo floyd_warshall step 5388 current loss 0.412984, current_train_items 172448.\n",
            "I0314 03:04:45.385416 138313941204992 run.py:479] Algo floyd_warshall step 5389 current loss 0.558419, current_train_items 172480.\n",
            "I0314 03:04:45.421112 138313941204992 run.py:479] Algo floyd_warshall step 5390 current loss 0.023778, current_train_items 172512.\n",
            "I0314 03:04:45.478136 138313941204992 run.py:479] Algo floyd_warshall step 5391 current loss 0.154124, current_train_items 172544.\n",
            "I0314 03:04:45.638672 138313941204992 run.py:479] Algo floyd_warshall step 5392 current loss 0.326391, current_train_items 172576.\n",
            "I0314 03:04:45.905707 138313941204992 run.py:479] Algo floyd_warshall step 5393 current loss 0.485699, current_train_items 172608.\n",
            "I0314 03:04:46.414666 138313941204992 run.py:479] Algo floyd_warshall step 5394 current loss 0.766381, current_train_items 172640.\n",
            "I0314 03:04:46.448154 138313941204992 run.py:479] Algo floyd_warshall step 5395 current loss 0.047394, current_train_items 172672.\n",
            "I0314 03:04:46.504962 138313941204992 run.py:479] Algo floyd_warshall step 5396 current loss 0.095967, current_train_items 172704.\n",
            "I0314 03:04:46.659100 138313941204992 run.py:479] Algo floyd_warshall step 5397 current loss 0.269353, current_train_items 172736.\n",
            "I0314 03:04:46.938866 138313941204992 run.py:479] Algo floyd_warshall step 5398 current loss 0.459227, current_train_items 172768.\n",
            "I0314 03:04:47.434775 138313941204992 run.py:479] Algo floyd_warshall step 5399 current loss 0.667490, current_train_items 172800.\n",
            "I0314 03:04:47.473304 138313941204992 run.py:479] Algo floyd_warshall step 5400 current loss 0.018479, current_train_items 172832.\n",
            "I0314 03:04:47.584843 138313941204992 run.py:499] (val) algo floyd_warshall step 5400: {'Pi': 0.879150390625, 'score': 0.879150390625, 'examples_seen': 172832, 'step': 5400, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:04:47.585202 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.888, current avg val score is 0.879, val scores are: floyd_warshall: 0.879\n",
            "I0314 03:04:47.646027 138313941204992 run.py:479] Algo floyd_warshall step 5401 current loss 0.083643, current_train_items 172864.\n",
            "I0314 03:04:47.824376 138313941204992 run.py:479] Algo floyd_warshall step 5402 current loss 0.274332, current_train_items 172896.\n",
            "I0314 03:04:48.084068 138313941204992 run.py:479] Algo floyd_warshall step 5403 current loss 0.404936, current_train_items 172928.\n",
            "I0314 03:04:48.529822 138313941204992 run.py:479] Algo floyd_warshall step 5404 current loss 0.720068, current_train_items 172960.\n",
            "I0314 03:04:48.556273 138313941204992 run.py:479] Algo floyd_warshall step 5405 current loss 0.016120, current_train_items 172992.\n",
            "I0314 03:04:48.602313 138313941204992 run.py:479] Algo floyd_warshall step 5406 current loss 0.096880, current_train_items 173024.\n",
            "I0314 03:04:48.734465 138313941204992 run.py:479] Algo floyd_warshall step 5407 current loss 0.190315, current_train_items 173056.\n",
            "I0314 03:04:48.950429 138313941204992 run.py:479] Algo floyd_warshall step 5408 current loss 0.390132, current_train_items 173088.\n",
            "I0314 03:04:49.377662 138313941204992 run.py:479] Algo floyd_warshall step 5409 current loss 0.627947, current_train_items 173120.\n",
            "I0314 03:04:49.401944 138313941204992 run.py:479] Algo floyd_warshall step 5410 current loss 0.021268, current_train_items 173152.\n",
            "I0314 03:04:49.449367 138313941204992 run.py:479] Algo floyd_warshall step 5411 current loss 0.072675, current_train_items 173184.\n",
            "I0314 03:04:49.579720 138313941204992 run.py:479] Algo floyd_warshall step 5412 current loss 0.398268, current_train_items 173216.\n",
            "I0314 03:04:49.805066 138313941204992 run.py:479] Algo floyd_warshall step 5413 current loss 0.324999, current_train_items 173248.\n",
            "I0314 03:04:50.230200 138313941204992 run.py:479] Algo floyd_warshall step 5414 current loss 0.729885, current_train_items 173280.\n",
            "I0314 03:04:50.257342 138313941204992 run.py:479] Algo floyd_warshall step 5415 current loss 0.047275, current_train_items 173312.\n",
            "I0314 03:04:50.301157 138313941204992 run.py:479] Algo floyd_warshall step 5416 current loss 0.159156, current_train_items 173344.\n",
            "I0314 03:04:50.429316 138313941204992 run.py:479] Algo floyd_warshall step 5417 current loss 0.241090, current_train_items 173376.\n",
            "I0314 03:04:50.644899 138313941204992 run.py:479] Algo floyd_warshall step 5418 current loss 0.432579, current_train_items 173408.\n",
            "I0314 03:04:51.053894 138313941204992 run.py:479] Algo floyd_warshall step 5419 current loss 0.688687, current_train_items 173440.\n",
            "I0314 03:04:51.078434 138313941204992 run.py:479] Algo floyd_warshall step 5420 current loss 0.015030, current_train_items 173472.\n",
            "I0314 03:04:51.123504 138313941204992 run.py:479] Algo floyd_warshall step 5421 current loss 0.068675, current_train_items 173504.\n",
            "I0314 03:04:51.255955 138313941204992 run.py:479] Algo floyd_warshall step 5422 current loss 0.264100, current_train_items 173536.\n",
            "I0314 03:04:51.469680 138313941204992 run.py:479] Algo floyd_warshall step 5423 current loss 0.376985, current_train_items 173568.\n",
            "I0314 03:04:51.887742 138313941204992 run.py:479] Algo floyd_warshall step 5424 current loss 0.765845, current_train_items 173600.\n",
            "I0314 03:04:51.909823 138313941204992 run.py:479] Algo floyd_warshall step 5425 current loss 0.021640, current_train_items 173632.\n",
            "I0314 03:04:51.954980 138313941204992 run.py:479] Algo floyd_warshall step 5426 current loss 0.075271, current_train_items 173664.\n",
            "I0314 03:04:52.084675 138313941204992 run.py:479] Algo floyd_warshall step 5427 current loss 0.270035, current_train_items 173696.\n",
            "I0314 03:04:52.320092 138313941204992 run.py:479] Algo floyd_warshall step 5428 current loss 0.557291, current_train_items 173728.\n",
            "I0314 03:04:52.742962 138313941204992 run.py:479] Algo floyd_warshall step 5429 current loss 0.683341, current_train_items 173760.\n",
            "I0314 03:04:52.767527 138313941204992 run.py:479] Algo floyd_warshall step 5430 current loss 0.033996, current_train_items 173792.\n",
            "I0314 03:04:52.812559 138313941204992 run.py:479] Algo floyd_warshall step 5431 current loss 0.105086, current_train_items 173824.\n",
            "I0314 03:04:52.941900 138313941204992 run.py:479] Algo floyd_warshall step 5432 current loss 0.311031, current_train_items 173856.\n",
            "I0314 03:04:53.153389 138313941204992 run.py:479] Algo floyd_warshall step 5433 current loss 0.372379, current_train_items 173888.\n",
            "I0314 03:04:53.569376 138313941204992 run.py:479] Algo floyd_warshall step 5434 current loss 0.570124, current_train_items 173920.\n",
            "I0314 03:04:53.592583 138313941204992 run.py:479] Algo floyd_warshall step 5435 current loss 0.027471, current_train_items 173952.\n",
            "I0314 03:04:53.636262 138313941204992 run.py:479] Algo floyd_warshall step 5436 current loss 0.066305, current_train_items 173984.\n",
            "I0314 03:04:53.765388 138313941204992 run.py:479] Algo floyd_warshall step 5437 current loss 0.325399, current_train_items 174016.\n",
            "I0314 03:04:53.978379 138313941204992 run.py:479] Algo floyd_warshall step 5438 current loss 0.409145, current_train_items 174048.\n",
            "I0314 03:04:54.387749 138313941204992 run.py:479] Algo floyd_warshall step 5439 current loss 0.819777, current_train_items 174080.\n",
            "I0314 03:04:54.412257 138313941204992 run.py:479] Algo floyd_warshall step 5440 current loss 0.024372, current_train_items 174112.\n",
            "I0314 03:04:54.457394 138313941204992 run.py:479] Algo floyd_warshall step 5441 current loss 0.060780, current_train_items 174144.\n",
            "I0314 03:04:54.586188 138313941204992 run.py:479] Algo floyd_warshall step 5442 current loss 0.302675, current_train_items 174176.\n",
            "I0314 03:04:54.811359 138313941204992 run.py:479] Algo floyd_warshall step 5443 current loss 0.378633, current_train_items 174208.\n",
            "I0314 03:04:55.223904 138313941204992 run.py:479] Algo floyd_warshall step 5444 current loss 0.574214, current_train_items 174240.\n",
            "I0314 03:04:55.248168 138313941204992 run.py:479] Algo floyd_warshall step 5445 current loss 0.032681, current_train_items 174272.\n",
            "I0314 03:04:55.292107 138313941204992 run.py:479] Algo floyd_warshall step 5446 current loss 0.070937, current_train_items 174304.\n",
            "I0314 03:04:55.428382 138313941204992 run.py:479] Algo floyd_warshall step 5447 current loss 0.235045, current_train_items 174336.\n",
            "I0314 03:04:55.653836 138313941204992 run.py:479] Algo floyd_warshall step 5448 current loss 0.383396, current_train_items 174368.\n",
            "I0314 03:04:56.066436 138313941204992 run.py:479] Algo floyd_warshall step 5449 current loss 0.655347, current_train_items 174400.\n",
            "I0314 03:04:56.090370 138313941204992 run.py:479] Algo floyd_warshall step 5450 current loss 0.032782, current_train_items 174432.\n",
            "I0314 03:04:56.178545 138313941204992 run.py:499] (val) algo floyd_warshall step 5450: {'Pi': 0.88262939453125, 'score': 0.88262939453125, 'examples_seen': 174432, 'step': 5450, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:04:56.178812 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.888, current avg val score is 0.883, val scores are: floyd_warshall: 0.883\n",
            "I0314 03:04:56.230662 138313941204992 run.py:479] Algo floyd_warshall step 5451 current loss 0.090458, current_train_items 174464.\n",
            "I0314 03:04:56.360627 138313941204992 run.py:479] Algo floyd_warshall step 5452 current loss 0.335173, current_train_items 174496.\n",
            "I0314 03:04:56.576576 138313941204992 run.py:479] Algo floyd_warshall step 5453 current loss 0.341629, current_train_items 174528.\n",
            "I0314 03:04:56.989484 138313941204992 run.py:479] Algo floyd_warshall step 5454 current loss 0.590871, current_train_items 174560.\n",
            "I0314 03:04:57.014443 138313941204992 run.py:479] Algo floyd_warshall step 5455 current loss 0.019081, current_train_items 174592.\n",
            "I0314 03:04:57.059181 138313941204992 run.py:479] Algo floyd_warshall step 5456 current loss 0.082072, current_train_items 174624.\n",
            "I0314 03:04:57.185955 138313941204992 run.py:479] Algo floyd_warshall step 5457 current loss 0.228417, current_train_items 174656.\n",
            "I0314 03:04:57.407537 138313941204992 run.py:479] Algo floyd_warshall step 5458 current loss 0.477160, current_train_items 174688.\n",
            "I0314 03:04:57.811237 138313941204992 run.py:479] Algo floyd_warshall step 5459 current loss 0.603526, current_train_items 174720.\n",
            "I0314 03:04:57.834326 138313941204992 run.py:479] Algo floyd_warshall step 5460 current loss 0.010108, current_train_items 174752.\n",
            "I0314 03:04:57.879029 138313941204992 run.py:479] Algo floyd_warshall step 5461 current loss 0.067029, current_train_items 174784.\n",
            "I0314 03:04:58.009736 138313941204992 run.py:479] Algo floyd_warshall step 5462 current loss 0.253667, current_train_items 174816.\n",
            "I0314 03:04:58.241352 138313941204992 run.py:479] Algo floyd_warshall step 5463 current loss 0.445013, current_train_items 174848.\n",
            "I0314 03:04:58.734164 138313941204992 run.py:479] Algo floyd_warshall step 5464 current loss 0.606135, current_train_items 174880.\n",
            "I0314 03:04:58.771036 138313941204992 run.py:479] Algo floyd_warshall step 5465 current loss 0.022883, current_train_items 174912.\n",
            "I0314 03:04:58.830415 138313941204992 run.py:479] Algo floyd_warshall step 5466 current loss 0.120155, current_train_items 174944.\n",
            "I0314 03:04:58.985513 138313941204992 run.py:479] Algo floyd_warshall step 5467 current loss 0.284903, current_train_items 174976.\n",
            "I0314 03:04:59.247499 138313941204992 run.py:479] Algo floyd_warshall step 5468 current loss 0.432559, current_train_items 175008.\n",
            "I0314 03:04:59.751078 138313941204992 run.py:479] Algo floyd_warshall step 5469 current loss 0.686285, current_train_items 175040.\n",
            "I0314 03:04:59.784602 138313941204992 run.py:479] Algo floyd_warshall step 5470 current loss 0.020178, current_train_items 175072.\n",
            "I0314 03:04:59.841447 138313941204992 run.py:479] Algo floyd_warshall step 5471 current loss 0.088319, current_train_items 175104.\n",
            "I0314 03:04:59.995321 138313941204992 run.py:479] Algo floyd_warshall step 5472 current loss 0.285489, current_train_items 175136.\n",
            "I0314 03:05:00.250901 138313941204992 run.py:479] Algo floyd_warshall step 5473 current loss 0.421852, current_train_items 175168.\n",
            "I0314 03:05:00.740748 138313941204992 run.py:479] Algo floyd_warshall step 5474 current loss 0.772526, current_train_items 175200.\n",
            "I0314 03:05:00.775080 138313941204992 run.py:479] Algo floyd_warshall step 5475 current loss 0.029536, current_train_items 175232.\n",
            "I0314 03:05:00.837422 138313941204992 run.py:479] Algo floyd_warshall step 5476 current loss 0.121016, current_train_items 175264.\n",
            "I0314 03:05:00.993847 138313941204992 run.py:479] Algo floyd_warshall step 5477 current loss 0.242652, current_train_items 175296.\n",
            "I0314 03:05:01.250818 138313941204992 run.py:479] Algo floyd_warshall step 5478 current loss 0.408184, current_train_items 175328.\n",
            "I0314 03:05:01.672296 138313941204992 run.py:479] Algo floyd_warshall step 5479 current loss 0.679971, current_train_items 175360.\n",
            "I0314 03:05:01.696061 138313941204992 run.py:479] Algo floyd_warshall step 5480 current loss 0.028518, current_train_items 175392.\n",
            "I0314 03:05:01.741405 138313941204992 run.py:479] Algo floyd_warshall step 5481 current loss 0.080944, current_train_items 175424.\n",
            "I0314 03:05:01.872037 138313941204992 run.py:479] Algo floyd_warshall step 5482 current loss 0.270021, current_train_items 175456.\n",
            "I0314 03:05:02.083219 138313941204992 run.py:479] Algo floyd_warshall step 5483 current loss 0.480306, current_train_items 175488.\n",
            "I0314 03:05:02.496102 138313941204992 run.py:479] Algo floyd_warshall step 5484 current loss 0.914896, current_train_items 175520.\n",
            "I0314 03:05:02.519614 138313941204992 run.py:479] Algo floyd_warshall step 5485 current loss 0.033798, current_train_items 175552.\n",
            "I0314 03:05:02.574941 138313941204992 run.py:479] Algo floyd_warshall step 5486 current loss 0.067697, current_train_items 175584.\n",
            "I0314 03:05:02.706330 138313941204992 run.py:479] Algo floyd_warshall step 5487 current loss 0.246761, current_train_items 175616.\n",
            "I0314 03:05:02.937683 138313941204992 run.py:479] Algo floyd_warshall step 5488 current loss 0.439763, current_train_items 175648.\n",
            "I0314 03:05:03.354073 138313941204992 run.py:479] Algo floyd_warshall step 5489 current loss 0.752871, current_train_items 175680.\n",
            "I0314 03:05:03.379815 138313941204992 run.py:479] Algo floyd_warshall step 5490 current loss 0.017973, current_train_items 175712.\n",
            "I0314 03:05:03.426889 138313941204992 run.py:479] Algo floyd_warshall step 5491 current loss 0.098727, current_train_items 175744.\n",
            "I0314 03:05:03.559169 138313941204992 run.py:479] Algo floyd_warshall step 5492 current loss 0.315684, current_train_items 175776.\n",
            "I0314 03:05:03.792310 138313941204992 run.py:479] Algo floyd_warshall step 5493 current loss 0.412822, current_train_items 175808.\n",
            "I0314 03:05:04.203142 138313941204992 run.py:479] Algo floyd_warshall step 5494 current loss 0.806332, current_train_items 175840.\n",
            "I0314 03:05:04.226574 138313941204992 run.py:479] Algo floyd_warshall step 5495 current loss 0.018327, current_train_items 175872.\n",
            "I0314 03:05:04.273274 138313941204992 run.py:479] Algo floyd_warshall step 5496 current loss 0.081128, current_train_items 175904.\n",
            "I0314 03:05:04.403075 138313941204992 run.py:479] Algo floyd_warshall step 5497 current loss 0.250403, current_train_items 175936.\n",
            "I0314 03:05:04.615833 138313941204992 run.py:479] Algo floyd_warshall step 5498 current loss 0.335981, current_train_items 175968.\n",
            "I0314 03:05:05.030490 138313941204992 run.py:479] Algo floyd_warshall step 5499 current loss 0.665208, current_train_items 176000.\n",
            "I0314 03:05:05.055863 138313941204992 run.py:479] Algo floyd_warshall step 5500 current loss 0.029426, current_train_items 176032.\n",
            "I0314 03:05:05.143644 138313941204992 run.py:499] (val) algo floyd_warshall step 5500: {'Pi': 0.87384033203125, 'score': 0.87384033203125, 'examples_seen': 176032, 'step': 5500, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:05:05.143914 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.888, current avg val score is 0.874, val scores are: floyd_warshall: 0.874\n",
            "I0314 03:05:05.193580 138313941204992 run.py:479] Algo floyd_warshall step 5501 current loss 0.124269, current_train_items 176064.\n",
            "I0314 03:05:05.324505 138313941204992 run.py:479] Algo floyd_warshall step 5502 current loss 0.301946, current_train_items 176096.\n",
            "I0314 03:05:05.541668 138313941204992 run.py:479] Algo floyd_warshall step 5503 current loss 0.496727, current_train_items 176128.\n",
            "I0314 03:05:05.978951 138313941204992 run.py:479] Algo floyd_warshall step 5504 current loss 0.938515, current_train_items 176160.\n",
            "I0314 03:05:06.004531 138313941204992 run.py:479] Algo floyd_warshall step 5505 current loss 0.061824, current_train_items 176192.\n",
            "I0314 03:05:06.049125 138313941204992 run.py:479] Algo floyd_warshall step 5506 current loss 0.050742, current_train_items 176224.\n",
            "I0314 03:05:06.182404 138313941204992 run.py:479] Algo floyd_warshall step 5507 current loss 0.242611, current_train_items 176256.\n",
            "I0314 03:05:06.407548 138313941204992 run.py:479] Algo floyd_warshall step 5508 current loss 0.436434, current_train_items 176288.\n",
            "I0314 03:05:06.817701 138313941204992 run.py:479] Algo floyd_warshall step 5509 current loss 0.765128, current_train_items 176320.\n",
            "I0314 03:05:06.840015 138313941204992 run.py:479] Algo floyd_warshall step 5510 current loss 0.016387, current_train_items 176352.\n",
            "I0314 03:05:06.884751 138313941204992 run.py:479] Algo floyd_warshall step 5511 current loss 0.099410, current_train_items 176384.\n",
            "I0314 03:05:07.014866 138313941204992 run.py:479] Algo floyd_warshall step 5512 current loss 0.280480, current_train_items 176416.\n",
            "I0314 03:05:07.229945 138313941204992 run.py:479] Algo floyd_warshall step 5513 current loss 0.356105, current_train_items 176448.\n",
            "I0314 03:05:07.644836 138313941204992 run.py:479] Algo floyd_warshall step 5514 current loss 0.736526, current_train_items 176480.\n",
            "I0314 03:05:07.668853 138313941204992 run.py:479] Algo floyd_warshall step 5515 current loss 0.031899, current_train_items 176512.\n",
            "I0314 03:05:07.724978 138313941204992 run.py:479] Algo floyd_warshall step 5516 current loss 0.070837, current_train_items 176544.\n",
            "I0314 03:05:07.858266 138313941204992 run.py:479] Algo floyd_warshall step 5517 current loss 0.274119, current_train_items 176576.\n",
            "I0314 03:05:08.086831 138313941204992 run.py:479] Algo floyd_warshall step 5518 current loss 0.512646, current_train_items 176608.\n",
            "I0314 03:05:08.496510 138313941204992 run.py:479] Algo floyd_warshall step 5519 current loss 0.750309, current_train_items 176640.\n",
            "I0314 03:05:08.520482 138313941204992 run.py:479] Algo floyd_warshall step 5520 current loss 0.028492, current_train_items 176672.\n",
            "I0314 03:05:08.564413 138313941204992 run.py:479] Algo floyd_warshall step 5521 current loss 0.109514, current_train_items 176704.\n",
            "I0314 03:05:08.696465 138313941204992 run.py:479] Algo floyd_warshall step 5522 current loss 0.359601, current_train_items 176736.\n",
            "I0314 03:05:08.930566 138313941204992 run.py:479] Algo floyd_warshall step 5523 current loss 0.402737, current_train_items 176768.\n",
            "I0314 03:05:09.340754 138313941204992 run.py:479] Algo floyd_warshall step 5524 current loss 0.817234, current_train_items 176800.\n",
            "I0314 03:05:09.365328 138313941204992 run.py:479] Algo floyd_warshall step 5525 current loss 0.012827, current_train_items 176832.\n",
            "I0314 03:05:09.410156 138313941204992 run.py:479] Algo floyd_warshall step 5526 current loss 0.063333, current_train_items 176864.\n",
            "I0314 03:05:09.544092 138313941204992 run.py:479] Algo floyd_warshall step 5527 current loss 0.409538, current_train_items 176896.\n",
            "I0314 03:05:09.760307 138313941204992 run.py:479] Algo floyd_warshall step 5528 current loss 0.574630, current_train_items 176928.\n",
            "I0314 03:05:10.190879 138313941204992 run.py:479] Algo floyd_warshall step 5529 current loss 0.822257, current_train_items 176960.\n",
            "I0314 03:05:10.216441 138313941204992 run.py:479] Algo floyd_warshall step 5530 current loss 0.028577, current_train_items 176992.\n",
            "I0314 03:05:10.260465 138313941204992 run.py:479] Algo floyd_warshall step 5531 current loss 0.103147, current_train_items 177024.\n",
            "I0314 03:05:10.394387 138313941204992 run.py:479] Algo floyd_warshall step 5532 current loss 0.300869, current_train_items 177056.\n",
            "I0314 03:05:10.621522 138313941204992 run.py:479] Algo floyd_warshall step 5533 current loss 0.518261, current_train_items 177088.\n",
            "I0314 03:05:11.030821 138313941204992 run.py:479] Algo floyd_warshall step 5534 current loss 0.725008, current_train_items 177120.\n",
            "I0314 03:05:11.054829 138313941204992 run.py:479] Algo floyd_warshall step 5535 current loss 0.026135, current_train_items 177152.\n",
            "I0314 03:05:11.099654 138313941204992 run.py:479] Algo floyd_warshall step 5536 current loss 0.126161, current_train_items 177184.\n",
            "I0314 03:05:11.229846 138313941204992 run.py:479] Algo floyd_warshall step 5537 current loss 0.335418, current_train_items 177216.\n",
            "I0314 03:05:11.467985 138313941204992 run.py:479] Algo floyd_warshall step 5538 current loss 0.463078, current_train_items 177248.\n",
            "I0314 03:05:11.939448 138313941204992 run.py:479] Algo floyd_warshall step 5539 current loss 0.577587, current_train_items 177280.\n",
            "I0314 03:05:11.970967 138313941204992 run.py:479] Algo floyd_warshall step 5540 current loss 0.029043, current_train_items 177312.\n",
            "I0314 03:05:12.027200 138313941204992 run.py:479] Algo floyd_warshall step 5541 current loss 0.062945, current_train_items 177344.\n",
            "I0314 03:05:12.180976 138313941204992 run.py:479] Algo floyd_warshall step 5542 current loss 0.247228, current_train_items 177376.\n",
            "I0314 03:05:12.456545 138313941204992 run.py:479] Algo floyd_warshall step 5543 current loss 0.379485, current_train_items 177408.\n",
            "I0314 03:05:12.941947 138313941204992 run.py:479] Algo floyd_warshall step 5544 current loss 0.704288, current_train_items 177440.\n",
            "I0314 03:05:12.978693 138313941204992 run.py:479] Algo floyd_warshall step 5545 current loss 0.013728, current_train_items 177472.\n",
            "I0314 03:05:13.037000 138313941204992 run.py:479] Algo floyd_warshall step 5546 current loss 0.129190, current_train_items 177504.\n",
            "I0314 03:05:13.203944 138313941204992 run.py:479] Algo floyd_warshall step 5547 current loss 0.364951, current_train_items 177536.\n",
            "I0314 03:05:13.466063 138313941204992 run.py:479] Algo floyd_warshall step 5548 current loss 0.472378, current_train_items 177568.\n",
            "I0314 03:05:13.955052 138313941204992 run.py:479] Algo floyd_warshall step 5549 current loss 0.727404, current_train_items 177600.\n",
            "I0314 03:05:13.990852 138313941204992 run.py:479] Algo floyd_warshall step 5550 current loss 0.014250, current_train_items 177632.\n",
            "I0314 03:05:14.115839 138313941204992 run.py:499] (val) algo floyd_warshall step 5550: {'Pi': 0.89306640625, 'score': 0.89306640625, 'examples_seen': 177632, 'step': 5550, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:05:14.116270 138313941204992 run.py:516] Checkpointing best model, best avg val score was 0.888, current avg val score is 0.893, val scores are: floyd_warshall: 0.893\n",
            "I0314 03:05:14.252573 138313941204992 run.py:479] Algo floyd_warshall step 5551 current loss 0.063138, current_train_items 177664.\n",
            "I0314 03:05:14.424834 138313941204992 run.py:479] Algo floyd_warshall step 5552 current loss 0.285604, current_train_items 177696.\n",
            "I0314 03:05:14.646659 138313941204992 run.py:479] Algo floyd_warshall step 5553 current loss 0.396034, current_train_items 177728.\n",
            "I0314 03:05:15.066310 138313941204992 run.py:479] Algo floyd_warshall step 5554 current loss 0.868161, current_train_items 177760.\n",
            "I0314 03:05:15.090839 138313941204992 run.py:479] Algo floyd_warshall step 5555 current loss 0.033846, current_train_items 177792.\n",
            "I0314 03:05:15.135086 138313941204992 run.py:479] Algo floyd_warshall step 5556 current loss 0.099022, current_train_items 177824.\n",
            "I0314 03:05:15.265831 138313941204992 run.py:479] Algo floyd_warshall step 5557 current loss 0.272762, current_train_items 177856.\n",
            "I0314 03:05:15.481101 138313941204992 run.py:479] Algo floyd_warshall step 5558 current loss 0.400676, current_train_items 177888.\n",
            "I0314 03:05:15.890235 138313941204992 run.py:479] Algo floyd_warshall step 5559 current loss 0.636752, current_train_items 177920.\n",
            "I0314 03:05:15.914591 138313941204992 run.py:479] Algo floyd_warshall step 5560 current loss 0.056576, current_train_items 177952.\n",
            "I0314 03:05:15.961606 138313941204992 run.py:479] Algo floyd_warshall step 5561 current loss 0.100883, current_train_items 177984.\n",
            "I0314 03:05:16.104335 138313941204992 run.py:479] Algo floyd_warshall step 5562 current loss 0.351727, current_train_items 178016.\n",
            "I0314 03:05:16.332924 138313941204992 run.py:479] Algo floyd_warshall step 5563 current loss 0.459266, current_train_items 178048.\n",
            "I0314 03:05:16.742965 138313941204992 run.py:479] Algo floyd_warshall step 5564 current loss 0.654506, current_train_items 178080.\n",
            "I0314 03:05:16.768573 138313941204992 run.py:479] Algo floyd_warshall step 5565 current loss 0.081096, current_train_items 178112.\n",
            "I0314 03:05:16.814585 138313941204992 run.py:479] Algo floyd_warshall step 5566 current loss 0.068856, current_train_items 178144.\n",
            "I0314 03:05:16.949377 138313941204992 run.py:479] Algo floyd_warshall step 5567 current loss 0.290996, current_train_items 178176.\n",
            "I0314 03:05:17.186526 138313941204992 run.py:479] Algo floyd_warshall step 5568 current loss 0.383542, current_train_items 178208.\n",
            "I0314 03:05:17.595451 138313941204992 run.py:479] Algo floyd_warshall step 5569 current loss 0.664615, current_train_items 178240.\n",
            "I0314 03:05:17.620041 138313941204992 run.py:479] Algo floyd_warshall step 5570 current loss 0.018440, current_train_items 178272.\n",
            "I0314 03:05:17.666190 138313941204992 run.py:479] Algo floyd_warshall step 5571 current loss 0.077917, current_train_items 178304.\n",
            "I0314 03:05:17.796979 138313941204992 run.py:479] Algo floyd_warshall step 5572 current loss 0.243369, current_train_items 178336.\n",
            "I0314 03:05:18.015244 138313941204992 run.py:479] Algo floyd_warshall step 5573 current loss 0.402167, current_train_items 178368.\n",
            "I0314 03:05:18.444722 138313941204992 run.py:479] Algo floyd_warshall step 5574 current loss 0.640950, current_train_items 178400.\n",
            "I0314 03:05:18.469260 138313941204992 run.py:479] Algo floyd_warshall step 5575 current loss 0.027966, current_train_items 178432.\n",
            "I0314 03:05:18.518210 138313941204992 run.py:479] Algo floyd_warshall step 5576 current loss 0.076851, current_train_items 178464.\n",
            "I0314 03:05:18.650068 138313941204992 run.py:479] Algo floyd_warshall step 5577 current loss 0.225737, current_train_items 178496.\n",
            "I0314 03:05:18.876989 138313941204992 run.py:479] Algo floyd_warshall step 5578 current loss 0.354306, current_train_items 178528.\n",
            "I0314 03:05:19.297661 138313941204992 run.py:479] Algo floyd_warshall step 5579 current loss 0.800137, current_train_items 178560.\n",
            "I0314 03:05:19.324176 138313941204992 run.py:479] Algo floyd_warshall step 5580 current loss 0.047830, current_train_items 178592.\n",
            "I0314 03:05:19.369844 138313941204992 run.py:479] Algo floyd_warshall step 5581 current loss 0.075895, current_train_items 178624.\n",
            "I0314 03:05:19.503412 138313941204992 run.py:479] Algo floyd_warshall step 5582 current loss 0.264958, current_train_items 178656.\n",
            "I0314 03:05:19.717222 138313941204992 run.py:479] Algo floyd_warshall step 5583 current loss 0.337798, current_train_items 178688.\n",
            "I0314 03:05:20.132014 138313941204992 run.py:479] Algo floyd_warshall step 5584 current loss 0.821934, current_train_items 178720.\n",
            "I0314 03:05:20.155034 138313941204992 run.py:479] Algo floyd_warshall step 5585 current loss 0.027170, current_train_items 178752.\n",
            "I0314 03:05:20.199743 138313941204992 run.py:479] Algo floyd_warshall step 5586 current loss 0.062903, current_train_items 178784.\n",
            "I0314 03:05:20.334244 138313941204992 run.py:479] Algo floyd_warshall step 5587 current loss 0.336203, current_train_items 178816.\n",
            "I0314 03:05:20.556346 138313941204992 run.py:479] Algo floyd_warshall step 5588 current loss 0.356244, current_train_items 178848.\n",
            "I0314 03:05:20.974455 138313941204992 run.py:479] Algo floyd_warshall step 5589 current loss 0.770441, current_train_items 178880.\n",
            "I0314 03:05:21.001988 138313941204992 run.py:479] Algo floyd_warshall step 5590 current loss 0.052022, current_train_items 178912.\n",
            "I0314 03:05:21.048373 138313941204992 run.py:479] Algo floyd_warshall step 5591 current loss 0.133564, current_train_items 178944.\n",
            "I0314 03:05:21.178987 138313941204992 run.py:479] Algo floyd_warshall step 5592 current loss 0.290337, current_train_items 178976.\n",
            "I0314 03:05:21.395664 138313941204992 run.py:479] Algo floyd_warshall step 5593 current loss 0.475629, current_train_items 179008.\n",
            "I0314 03:05:21.804257 138313941204992 run.py:479] Algo floyd_warshall step 5594 current loss 0.634012, current_train_items 179040.\n",
            "I0314 03:05:21.829225 138313941204992 run.py:479] Algo floyd_warshall step 5595 current loss 0.019280, current_train_items 179072.\n",
            "I0314 03:05:21.874933 138313941204992 run.py:479] Algo floyd_warshall step 5596 current loss 0.061870, current_train_items 179104.\n",
            "I0314 03:05:22.005209 138313941204992 run.py:479] Algo floyd_warshall step 5597 current loss 0.257744, current_train_items 179136.\n",
            "I0314 03:05:22.217838 138313941204992 run.py:479] Algo floyd_warshall step 5598 current loss 0.384745, current_train_items 179168.\n",
            "I0314 03:05:22.625107 138313941204992 run.py:479] Algo floyd_warshall step 5599 current loss 0.638933, current_train_items 179200.\n",
            "I0314 03:05:22.648247 138313941204992 run.py:479] Algo floyd_warshall step 5600 current loss 0.012305, current_train_items 179232.\n",
            "I0314 03:05:22.734213 138313941204992 run.py:499] (val) algo floyd_warshall step 5600: {'Pi': 0.8817138671875, 'score': 0.8817138671875, 'examples_seen': 179232, 'step': 5600, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:05:22.734437 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.893, current avg val score is 0.882, val scores are: floyd_warshall: 0.882\n",
            "I0314 03:05:22.782951 138313941204992 run.py:479] Algo floyd_warshall step 5601 current loss 0.082903, current_train_items 179264.\n",
            "I0314 03:05:22.915782 138313941204992 run.py:479] Algo floyd_warshall step 5602 current loss 0.238995, current_train_items 179296.\n",
            "I0314 03:05:23.133122 138313941204992 run.py:479] Algo floyd_warshall step 5603 current loss 0.429908, current_train_items 179328.\n",
            "I0314 03:05:23.561764 138313941204992 run.py:479] Algo floyd_warshall step 5604 current loss 0.697540, current_train_items 179360.\n",
            "I0314 03:05:23.586788 138313941204992 run.py:479] Algo floyd_warshall step 5605 current loss 0.027834, current_train_items 179392.\n",
            "I0314 03:05:23.633565 138313941204992 run.py:479] Algo floyd_warshall step 5606 current loss 0.088547, current_train_items 179424.\n",
            "I0314 03:05:23.764517 138313941204992 run.py:479] Algo floyd_warshall step 5607 current loss 0.299883, current_train_items 179456.\n",
            "I0314 03:05:23.991418 138313941204992 run.py:479] Algo floyd_warshall step 5608 current loss 0.428387, current_train_items 179488.\n",
            "I0314 03:05:24.402602 138313941204992 run.py:479] Algo floyd_warshall step 5609 current loss 0.645126, current_train_items 179520.\n",
            "I0314 03:05:24.438194 138313941204992 run.py:479] Algo floyd_warshall step 5610 current loss 0.033617, current_train_items 179552.\n",
            "I0314 03:05:24.498604 138313941204992 run.py:479] Algo floyd_warshall step 5611 current loss 0.105399, current_train_items 179584.\n",
            "I0314 03:05:24.661421 138313941204992 run.py:479] Algo floyd_warshall step 5612 current loss 0.355890, current_train_items 179616.\n",
            "I0314 03:05:24.933779 138313941204992 run.py:479] Algo floyd_warshall step 5613 current loss 0.512105, current_train_items 179648.\n",
            "I0314 03:05:25.422743 138313941204992 run.py:479] Algo floyd_warshall step 5614 current loss 0.694057, current_train_items 179680.\n",
            "I0314 03:05:25.462519 138313941204992 run.py:479] Algo floyd_warshall step 5615 current loss 0.025875, current_train_items 179712.\n",
            "I0314 03:05:25.524527 138313941204992 run.py:479] Algo floyd_warshall step 5616 current loss 0.062868, current_train_items 179744.\n",
            "I0314 03:05:25.683525 138313941204992 run.py:479] Algo floyd_warshall step 5617 current loss 0.345878, current_train_items 179776.\n",
            "I0314 03:05:25.947359 138313941204992 run.py:479] Algo floyd_warshall step 5618 current loss 0.414510, current_train_items 179808.\n",
            "I0314 03:05:26.457080 138313941204992 run.py:479] Algo floyd_warshall step 5619 current loss 0.744955, current_train_items 179840.\n",
            "I0314 03:05:26.492280 138313941204992 run.py:479] Algo floyd_warshall step 5620 current loss 0.035247, current_train_items 179872.\n",
            "I0314 03:05:26.551141 138313941204992 run.py:479] Algo floyd_warshall step 5621 current loss 0.091658, current_train_items 179904.\n",
            "I0314 03:05:26.709434 138313941204992 run.py:479] Algo floyd_warshall step 5622 current loss 0.292681, current_train_items 179936.\n",
            "I0314 03:05:26.987925 138313941204992 run.py:479] Algo floyd_warshall step 5623 current loss 0.551615, current_train_items 179968.\n",
            "I0314 03:05:27.513597 138313941204992 run.py:479] Algo floyd_warshall step 5624 current loss 0.798023, current_train_items 180000.\n",
            "I0314 03:05:27.539467 138313941204992 run.py:479] Algo floyd_warshall step 5625 current loss 0.016471, current_train_items 180032.\n",
            "I0314 03:05:27.587762 138313941204992 run.py:479] Algo floyd_warshall step 5626 current loss 0.059301, current_train_items 180064.\n",
            "I0314 03:05:27.721338 138313941204992 run.py:479] Algo floyd_warshall step 5627 current loss 0.254051, current_train_items 180096.\n",
            "I0314 03:05:27.939418 138313941204992 run.py:479] Algo floyd_warshall step 5628 current loss 0.439876, current_train_items 180128.\n",
            "I0314 03:05:28.350673 138313941204992 run.py:479] Algo floyd_warshall step 5629 current loss 0.620791, current_train_items 180160.\n",
            "I0314 03:05:28.380785 138313941204992 run.py:479] Algo floyd_warshall step 5630 current loss 0.026071, current_train_items 180192.\n",
            "I0314 03:05:28.433479 138313941204992 run.py:479] Algo floyd_warshall step 5631 current loss 0.100750, current_train_items 180224.\n",
            "I0314 03:05:28.570221 138313941204992 run.py:479] Algo floyd_warshall step 5632 current loss 0.332548, current_train_items 180256.\n",
            "I0314 03:05:28.799430 138313941204992 run.py:479] Algo floyd_warshall step 5633 current loss 0.488027, current_train_items 180288.\n",
            "I0314 03:05:29.213072 138313941204992 run.py:479] Algo floyd_warshall step 5634 current loss 0.596074, current_train_items 180320.\n",
            "I0314 03:05:29.238730 138313941204992 run.py:479] Algo floyd_warshall step 5635 current loss 0.023417, current_train_items 180352.\n",
            "I0314 03:05:29.283339 138313941204992 run.py:479] Algo floyd_warshall step 5636 current loss 0.056691, current_train_items 180384.\n",
            "I0314 03:05:29.416652 138313941204992 run.py:479] Algo floyd_warshall step 5637 current loss 0.278850, current_train_items 180416.\n",
            "I0314 03:05:29.646715 138313941204992 run.py:479] Algo floyd_warshall step 5638 current loss 0.393641, current_train_items 180448.\n",
            "I0314 03:05:30.056099 138313941204992 run.py:479] Algo floyd_warshall step 5639 current loss 0.628078, current_train_items 180480.\n",
            "I0314 03:05:30.078378 138313941204992 run.py:479] Algo floyd_warshall step 5640 current loss 0.026242, current_train_items 180512.\n",
            "I0314 03:05:30.123615 138313941204992 run.py:479] Algo floyd_warshall step 5641 current loss 0.219241, current_train_items 180544.\n",
            "I0314 03:05:30.255307 138313941204992 run.py:479] Algo floyd_warshall step 5642 current loss 0.362744, current_train_items 180576.\n",
            "I0314 03:05:30.468764 138313941204992 run.py:479] Algo floyd_warshall step 5643 current loss 0.314578, current_train_items 180608.\n",
            "I0314 03:05:30.878037 138313941204992 run.py:479] Algo floyd_warshall step 5644 current loss 0.536521, current_train_items 180640.\n",
            "I0314 03:05:30.901772 138313941204992 run.py:479] Algo floyd_warshall step 5645 current loss 0.027384, current_train_items 180672.\n",
            "I0314 03:05:30.946964 138313941204992 run.py:479] Algo floyd_warshall step 5646 current loss 0.105536, current_train_items 180704.\n",
            "I0314 03:05:31.080159 138313941204992 run.py:479] Algo floyd_warshall step 5647 current loss 0.327197, current_train_items 180736.\n",
            "I0314 03:05:31.300985 138313941204992 run.py:479] Algo floyd_warshall step 5648 current loss 0.408225, current_train_items 180768.\n",
            "I0314 03:05:31.711881 138313941204992 run.py:479] Algo floyd_warshall step 5649 current loss 1.050241, current_train_items 180800.\n",
            "I0314 03:05:31.736521 138313941204992 run.py:479] Algo floyd_warshall step 5650 current loss 0.020132, current_train_items 180832.\n",
            "I0314 03:05:31.825364 138313941204992 run.py:499] (val) algo floyd_warshall step 5650: {'Pi': 0.87139892578125, 'score': 0.87139892578125, 'examples_seen': 180832, 'step': 5650, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:05:31.825583 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.893, current avg val score is 0.871, val scores are: floyd_warshall: 0.871\n",
            "I0314 03:05:31.874377 138313941204992 run.py:479] Algo floyd_warshall step 5651 current loss 0.042396, current_train_items 180864.\n",
            "I0314 03:05:32.005394 138313941204992 run.py:479] Algo floyd_warshall step 5652 current loss 0.249191, current_train_items 180896.\n",
            "I0314 03:05:32.226586 138313941204992 run.py:479] Algo floyd_warshall step 5653 current loss 0.420090, current_train_items 180928.\n",
            "I0314 03:05:32.648209 138313941204992 run.py:479] Algo floyd_warshall step 5654 current loss 0.784495, current_train_items 180960.\n",
            "I0314 03:05:32.673437 138313941204992 run.py:479] Algo floyd_warshall step 5655 current loss 0.062492, current_train_items 180992.\n",
            "I0314 03:05:32.717960 138313941204992 run.py:479] Algo floyd_warshall step 5656 current loss 0.063464, current_train_items 181024.\n",
            "I0314 03:05:32.851942 138313941204992 run.py:479] Algo floyd_warshall step 5657 current loss 0.306026, current_train_items 181056.\n",
            "I0314 03:05:33.064408 138313941204992 run.py:479] Algo floyd_warshall step 5658 current loss 0.344471, current_train_items 181088.\n",
            "I0314 03:05:33.458371 138313941204992 run.py:479] Algo floyd_warshall step 5659 current loss 0.479706, current_train_items 181120.\n",
            "I0314 03:05:33.481680 138313941204992 run.py:479] Algo floyd_warshall step 5660 current loss 0.016976, current_train_items 181152.\n",
            "I0314 03:05:33.537268 138313941204992 run.py:479] Algo floyd_warshall step 5661 current loss 0.060908, current_train_items 181184.\n",
            "I0314 03:05:33.668727 138313941204992 run.py:479] Algo floyd_warshall step 5662 current loss 0.302128, current_train_items 181216.\n",
            "I0314 03:05:33.887232 138313941204992 run.py:479] Algo floyd_warshall step 5663 current loss 0.426505, current_train_items 181248.\n",
            "I0314 03:05:34.299882 138313941204992 run.py:479] Algo floyd_warshall step 5664 current loss 0.766107, current_train_items 181280.\n",
            "I0314 03:05:34.322908 138313941204992 run.py:479] Algo floyd_warshall step 5665 current loss 0.016003, current_train_items 181312.\n",
            "I0314 03:05:34.367027 138313941204992 run.py:479] Algo floyd_warshall step 5666 current loss 0.048130, current_train_items 181344.\n",
            "I0314 03:05:34.505044 138313941204992 run.py:479] Algo floyd_warshall step 5667 current loss 0.375997, current_train_items 181376.\n",
            "I0314 03:05:34.746287 138313941204992 run.py:479] Algo floyd_warshall step 5668 current loss 0.492196, current_train_items 181408.\n",
            "I0314 03:05:35.164831 138313941204992 run.py:479] Algo floyd_warshall step 5669 current loss 0.697188, current_train_items 181440.\n",
            "I0314 03:05:35.188452 138313941204992 run.py:479] Algo floyd_warshall step 5670 current loss 0.006148, current_train_items 181472.\n",
            "I0314 03:05:35.236586 138313941204992 run.py:479] Algo floyd_warshall step 5671 current loss 0.079398, current_train_items 181504.\n",
            "I0314 03:05:35.367205 138313941204992 run.py:479] Algo floyd_warshall step 5672 current loss 0.284086, current_train_items 181536.\n",
            "I0314 03:05:35.584043 138313941204992 run.py:479] Algo floyd_warshall step 5673 current loss 0.427839, current_train_items 181568.\n",
            "I0314 03:05:35.999041 138313941204992 run.py:479] Algo floyd_warshall step 5674 current loss 0.938607, current_train_items 181600.\n",
            "I0314 03:05:36.022881 138313941204992 run.py:479] Algo floyd_warshall step 5675 current loss 0.013487, current_train_items 181632.\n",
            "I0314 03:05:36.066740 138313941204992 run.py:479] Algo floyd_warshall step 5676 current loss 0.091914, current_train_items 181664.\n",
            "I0314 03:05:36.197830 138313941204992 run.py:479] Algo floyd_warshall step 5677 current loss 0.288026, current_train_items 181696.\n",
            "I0314 03:05:36.417276 138313941204992 run.py:479] Algo floyd_warshall step 5678 current loss 0.541450, current_train_items 181728.\n",
            "I0314 03:05:36.830412 138313941204992 run.py:479] Algo floyd_warshall step 5679 current loss 0.817977, current_train_items 181760.\n",
            "I0314 03:05:36.854843 138313941204992 run.py:479] Algo floyd_warshall step 5680 current loss 0.032298, current_train_items 181792.\n",
            "I0314 03:05:36.899196 138313941204992 run.py:479] Algo floyd_warshall step 5681 current loss 0.137400, current_train_items 181824.\n",
            "I0314 03:05:37.032462 138313941204992 run.py:479] Algo floyd_warshall step 5682 current loss 0.353216, current_train_items 181856.\n",
            "I0314 03:05:37.256367 138313941204992 run.py:479] Algo floyd_warshall step 5683 current loss 0.411896, current_train_items 181888.\n",
            "I0314 03:05:37.669960 138313941204992 run.py:479] Algo floyd_warshall step 5684 current loss 0.573470, current_train_items 181920.\n",
            "I0314 03:05:37.707124 138313941204992 run.py:479] Algo floyd_warshall step 5685 current loss 0.020408, current_train_items 181952.\n",
            "I0314 03:05:37.763937 138313941204992 run.py:479] Algo floyd_warshall step 5686 current loss 0.060566, current_train_items 181984.\n",
            "I0314 03:05:37.924878 138313941204992 run.py:479] Algo floyd_warshall step 5687 current loss 0.236067, current_train_items 182016.\n",
            "I0314 03:05:38.208587 138313941204992 run.py:479] Algo floyd_warshall step 5688 current loss 0.437477, current_train_items 182048.\n",
            "I0314 03:05:38.700005 138313941204992 run.py:479] Algo floyd_warshall step 5689 current loss 0.652130, current_train_items 182080.\n",
            "I0314 03:05:38.738505 138313941204992 run.py:479] Algo floyd_warshall step 5690 current loss 0.040262, current_train_items 182112.\n",
            "I0314 03:05:38.798979 138313941204992 run.py:479] Algo floyd_warshall step 5691 current loss 0.131394, current_train_items 182144.\n",
            "I0314 03:05:38.963823 138313941204992 run.py:479] Algo floyd_warshall step 5692 current loss 0.369739, current_train_items 182176.\n",
            "I0314 03:05:39.241214 138313941204992 run.py:479] Algo floyd_warshall step 5693 current loss 0.465393, current_train_items 182208.\n",
            "I0314 03:05:39.724167 138313941204992 run.py:479] Algo floyd_warshall step 5694 current loss 0.560800, current_train_items 182240.\n",
            "I0314 03:05:39.766801 138313941204992 run.py:479] Algo floyd_warshall step 5695 current loss 0.010955, current_train_items 182272.\n",
            "I0314 03:05:39.825874 138313941204992 run.py:479] Algo floyd_warshall step 5696 current loss 0.172643, current_train_items 182304.\n",
            "I0314 03:05:39.986843 138313941204992 run.py:479] Algo floyd_warshall step 5697 current loss 0.313141, current_train_items 182336.\n",
            "I0314 03:05:40.250002 138313941204992 run.py:479] Algo floyd_warshall step 5698 current loss 0.448769, current_train_items 182368.\n",
            "I0314 03:05:40.756645 138313941204992 run.py:479] Algo floyd_warshall step 5699 current loss 0.931871, current_train_items 182400.\n",
            "I0314 03:05:40.787584 138313941204992 run.py:479] Algo floyd_warshall step 5700 current loss 0.016753, current_train_items 182432.\n",
            "I0314 03:05:40.875482 138313941204992 run.py:499] (val) algo floyd_warshall step 5700: {'Pi': 0.88330078125, 'score': 0.88330078125, 'examples_seen': 182432, 'step': 5700, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:05:40.875718 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.893, current avg val score is 0.883, val scores are: floyd_warshall: 0.883\n",
            "I0314 03:05:40.922656 138313941204992 run.py:479] Algo floyd_warshall step 5701 current loss 0.085516, current_train_items 182464.\n",
            "I0314 03:05:41.052481 138313941204992 run.py:479] Algo floyd_warshall step 5702 current loss 0.252869, current_train_items 182496.\n",
            "I0314 03:05:41.287900 138313941204992 run.py:479] Algo floyd_warshall step 5703 current loss 0.408955, current_train_items 182528.\n",
            "I0314 03:05:41.683827 138313941204992 run.py:479] Algo floyd_warshall step 5704 current loss 0.484941, current_train_items 182560.\n",
            "I0314 03:05:41.709943 138313941204992 run.py:479] Algo floyd_warshall step 5705 current loss 0.104187, current_train_items 182592.\n",
            "I0314 03:05:41.755365 138313941204992 run.py:479] Algo floyd_warshall step 5706 current loss 0.145167, current_train_items 182624.\n",
            "I0314 03:05:41.900200 138313941204992 run.py:479] Algo floyd_warshall step 5707 current loss 0.298991, current_train_items 182656.\n",
            "I0314 03:05:42.116970 138313941204992 run.py:479] Algo floyd_warshall step 5708 current loss 0.522312, current_train_items 182688.\n",
            "I0314 03:05:42.542862 138313941204992 run.py:479] Algo floyd_warshall step 5709 current loss 0.723608, current_train_items 182720.\n",
            "I0314 03:05:42.566278 138313941204992 run.py:479] Algo floyd_warshall step 5710 current loss 0.036468, current_train_items 182752.\n",
            "I0314 03:05:42.611195 138313941204992 run.py:479] Algo floyd_warshall step 5711 current loss 0.108663, current_train_items 182784.\n",
            "I0314 03:05:42.739526 138313941204992 run.py:479] Algo floyd_warshall step 5712 current loss 0.287717, current_train_items 182816.\n",
            "I0314 03:05:42.965023 138313941204992 run.py:479] Algo floyd_warshall step 5713 current loss 0.449074, current_train_items 182848.\n",
            "I0314 03:05:43.370058 138313941204992 run.py:479] Algo floyd_warshall step 5714 current loss 0.671606, current_train_items 182880.\n",
            "I0314 03:05:43.394098 138313941204992 run.py:479] Algo floyd_warshall step 5715 current loss 0.017823, current_train_items 182912.\n",
            "I0314 03:05:43.439761 138313941204992 run.py:479] Algo floyd_warshall step 5716 current loss 0.082944, current_train_items 182944.\n",
            "I0314 03:05:43.568456 138313941204992 run.py:479] Algo floyd_warshall step 5717 current loss 0.239299, current_train_items 182976.\n",
            "I0314 03:05:43.793382 138313941204992 run.py:479] Algo floyd_warshall step 5718 current loss 0.384432, current_train_items 183008.\n",
            "I0314 03:05:44.220034 138313941204992 run.py:479] Algo floyd_warshall step 5719 current loss 0.528394, current_train_items 183040.\n",
            "I0314 03:05:44.245591 138313941204992 run.py:479] Algo floyd_warshall step 5720 current loss 0.017730, current_train_items 183072.\n",
            "I0314 03:05:44.293961 138313941204992 run.py:479] Algo floyd_warshall step 5721 current loss 0.059258, current_train_items 183104.\n",
            "I0314 03:05:44.429986 138313941204992 run.py:479] Algo floyd_warshall step 5722 current loss 0.308987, current_train_items 183136.\n",
            "I0314 03:05:44.650327 138313941204992 run.py:479] Algo floyd_warshall step 5723 current loss 0.367485, current_train_items 183168.\n",
            "I0314 03:05:45.081498 138313941204992 run.py:479] Algo floyd_warshall step 5724 current loss 0.838005, current_train_items 183200.\n",
            "I0314 03:05:45.105260 138313941204992 run.py:479] Algo floyd_warshall step 5725 current loss 0.011582, current_train_items 183232.\n",
            "I0314 03:05:45.150525 138313941204992 run.py:479] Algo floyd_warshall step 5726 current loss 0.085081, current_train_items 183264.\n",
            "I0314 03:05:45.284446 138313941204992 run.py:479] Algo floyd_warshall step 5727 current loss 0.264158, current_train_items 183296.\n",
            "I0314 03:05:45.513909 138313941204992 run.py:479] Algo floyd_warshall step 5728 current loss 0.351741, current_train_items 183328.\n",
            "I0314 03:05:45.929967 138313941204992 run.py:479] Algo floyd_warshall step 5729 current loss 0.701101, current_train_items 183360.\n",
            "I0314 03:05:45.954719 138313941204992 run.py:479] Algo floyd_warshall step 5730 current loss 0.029001, current_train_items 183392.\n",
            "I0314 03:05:46.000024 138313941204992 run.py:479] Algo floyd_warshall step 5731 current loss 0.061171, current_train_items 183424.\n",
            "I0314 03:05:46.135962 138313941204992 run.py:479] Algo floyd_warshall step 5732 current loss 0.298850, current_train_items 183456.\n",
            "I0314 03:05:46.349449 138313941204992 run.py:479] Algo floyd_warshall step 5733 current loss 0.392085, current_train_items 183488.\n",
            "I0314 03:05:46.758519 138313941204992 run.py:479] Algo floyd_warshall step 5734 current loss 0.704842, current_train_items 183520.\n",
            "I0314 03:05:46.783463 138313941204992 run.py:479] Algo floyd_warshall step 5735 current loss 0.031195, current_train_items 183552.\n",
            "I0314 03:05:46.829955 138313941204992 run.py:479] Algo floyd_warshall step 5736 current loss 0.062456, current_train_items 183584.\n",
            "I0314 03:05:46.965370 138313941204992 run.py:479] Algo floyd_warshall step 5737 current loss 0.204660, current_train_items 183616.\n",
            "I0314 03:05:47.185728 138313941204992 run.py:479] Algo floyd_warshall step 5738 current loss 0.422247, current_train_items 183648.\n",
            "I0314 03:05:47.600594 138313941204992 run.py:479] Algo floyd_warshall step 5739 current loss 0.744048, current_train_items 183680.\n",
            "I0314 03:05:47.625895 138313941204992 run.py:479] Algo floyd_warshall step 5740 current loss 0.021102, current_train_items 183712.\n",
            "I0314 03:05:47.672481 138313941204992 run.py:479] Algo floyd_warshall step 5741 current loss 0.070666, current_train_items 183744.\n",
            "I0314 03:05:47.808080 138313941204992 run.py:479] Algo floyd_warshall step 5742 current loss 0.316671, current_train_items 183776.\n",
            "I0314 03:05:48.036157 138313941204992 run.py:479] Algo floyd_warshall step 5743 current loss 0.391123, current_train_items 183808.\n",
            "I0314 03:05:48.459831 138313941204992 run.py:479] Algo floyd_warshall step 5744 current loss 0.717256, current_train_items 183840.\n",
            "I0314 03:05:48.486487 138313941204992 run.py:479] Algo floyd_warshall step 5745 current loss 0.018451, current_train_items 183872.\n",
            "I0314 03:05:48.532585 138313941204992 run.py:479] Algo floyd_warshall step 5746 current loss 0.112212, current_train_items 183904.\n",
            "I0314 03:05:48.664652 138313941204992 run.py:479] Algo floyd_warshall step 5747 current loss 0.212760, current_train_items 183936.\n",
            "I0314 03:05:48.884630 138313941204992 run.py:479] Algo floyd_warshall step 5748 current loss 0.410822, current_train_items 183968.\n",
            "I0314 03:05:49.315245 138313941204992 run.py:479] Algo floyd_warshall step 5749 current loss 0.606526, current_train_items 184000.\n",
            "I0314 03:05:49.340018 138313941204992 run.py:479] Algo floyd_warshall step 5750 current loss 0.072328, current_train_items 184032.\n",
            "I0314 03:05:49.429395 138313941204992 run.py:499] (val) algo floyd_warshall step 5750: {'Pi': 0.8829345703125, 'score': 0.8829345703125, 'examples_seen': 184032, 'step': 5750, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:05:49.429665 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.893, current avg val score is 0.883, val scores are: floyd_warshall: 0.883\n",
            "I0314 03:05:49.482838 138313941204992 run.py:479] Algo floyd_warshall step 5751 current loss 0.061533, current_train_items 184064.\n",
            "I0314 03:05:49.612804 138313941204992 run.py:479] Algo floyd_warshall step 5752 current loss 0.209291, current_train_items 184096.\n",
            "I0314 03:05:49.832333 138313941204992 run.py:479] Algo floyd_warshall step 5753 current loss 0.387204, current_train_items 184128.\n",
            "I0314 03:05:50.238996 138313941204992 run.py:479] Algo floyd_warshall step 5754 current loss 0.624040, current_train_items 184160.\n",
            "I0314 03:05:50.264926 138313941204992 run.py:479] Algo floyd_warshall step 5755 current loss 0.035872, current_train_items 184192.\n",
            "I0314 03:05:50.310234 138313941204992 run.py:479] Algo floyd_warshall step 5756 current loss 0.056522, current_train_items 184224.\n",
            "I0314 03:05:50.441437 138313941204992 run.py:479] Algo floyd_warshall step 5757 current loss 0.228828, current_train_items 184256.\n",
            "I0314 03:05:50.668530 138313941204992 run.py:479] Algo floyd_warshall step 5758 current loss 0.345198, current_train_items 184288.\n",
            "I0314 03:05:51.161212 138313941204992 run.py:479] Algo floyd_warshall step 5759 current loss 0.662645, current_train_items 184320.\n",
            "I0314 03:05:51.195052 138313941204992 run.py:479] Algo floyd_warshall step 5760 current loss 0.023944, current_train_items 184352.\n",
            "I0314 03:05:51.254683 138313941204992 run.py:479] Algo floyd_warshall step 5761 current loss 0.059186, current_train_items 184384.\n",
            "I0314 03:05:51.414450 138313941204992 run.py:479] Algo floyd_warshall step 5762 current loss 0.265930, current_train_items 184416.\n",
            "I0314 03:05:51.677087 138313941204992 run.py:479] Algo floyd_warshall step 5763 current loss 0.484459, current_train_items 184448.\n",
            "I0314 03:05:52.173207 138313941204992 run.py:479] Algo floyd_warshall step 5764 current loss 0.770161, current_train_items 184480.\n",
            "I0314 03:05:52.208727 138313941204992 run.py:479] Algo floyd_warshall step 5765 current loss 0.019460, current_train_items 184512.\n",
            "I0314 03:05:52.265311 138313941204992 run.py:479] Algo floyd_warshall step 5766 current loss 0.083256, current_train_items 184544.\n",
            "I0314 03:05:52.423182 138313941204992 run.py:479] Algo floyd_warshall step 5767 current loss 0.202962, current_train_items 184576.\n",
            "I0314 03:05:52.689863 138313941204992 run.py:479] Algo floyd_warshall step 5768 current loss 0.431188, current_train_items 184608.\n",
            "I0314 03:05:53.192031 138313941204992 run.py:479] Algo floyd_warshall step 5769 current loss 0.685148, current_train_items 184640.\n",
            "I0314 03:05:53.225202 138313941204992 run.py:479] Algo floyd_warshall step 5770 current loss 0.026596, current_train_items 184672.\n",
            "I0314 03:05:53.286065 138313941204992 run.py:479] Algo floyd_warshall step 5771 current loss 0.054764, current_train_items 184704.\n",
            "I0314 03:05:53.452553 138313941204992 run.py:479] Algo floyd_warshall step 5772 current loss 0.264477, current_train_items 184736.\n",
            "I0314 03:05:53.730673 138313941204992 run.py:479] Algo floyd_warshall step 5773 current loss 0.333421, current_train_items 184768.\n",
            "I0314 03:05:54.145087 138313941204992 run.py:479] Algo floyd_warshall step 5774 current loss 0.617926, current_train_items 184800.\n",
            "I0314 03:05:54.170144 138313941204992 run.py:479] Algo floyd_warshall step 5775 current loss 0.016975, current_train_items 184832.\n",
            "I0314 03:05:54.225733 138313941204992 run.py:479] Algo floyd_warshall step 5776 current loss 0.061679, current_train_items 184864.\n",
            "I0314 03:05:54.361301 138313941204992 run.py:479] Algo floyd_warshall step 5777 current loss 0.229062, current_train_items 184896.\n",
            "I0314 03:05:54.586659 138313941204992 run.py:479] Algo floyd_warshall step 5778 current loss 0.356064, current_train_items 184928.\n",
            "I0314 03:05:54.999982 138313941204992 run.py:479] Algo floyd_warshall step 5779 current loss 0.715859, current_train_items 184960.\n",
            "I0314 03:05:55.024007 138313941204992 run.py:479] Algo floyd_warshall step 5780 current loss 0.015737, current_train_items 184992.\n",
            "I0314 03:05:55.068545 138313941204992 run.py:479] Algo floyd_warshall step 5781 current loss 0.056654, current_train_items 185024.\n",
            "I0314 03:05:55.197769 138313941204992 run.py:479] Algo floyd_warshall step 5782 current loss 0.331066, current_train_items 185056.\n",
            "I0314 03:05:55.421882 138313941204992 run.py:479] Algo floyd_warshall step 5783 current loss 0.614488, current_train_items 185088.\n",
            "I0314 03:05:55.838351 138313941204992 run.py:479] Algo floyd_warshall step 5784 current loss 1.028797, current_train_items 185120.\n",
            "I0314 03:05:55.862793 138313941204992 run.py:479] Algo floyd_warshall step 5785 current loss 0.021350, current_train_items 185152.\n",
            "I0314 03:05:55.907884 138313941204992 run.py:479] Algo floyd_warshall step 5786 current loss 0.082088, current_train_items 185184.\n",
            "I0314 03:05:56.039583 138313941204992 run.py:479] Algo floyd_warshall step 5787 current loss 0.376957, current_train_items 185216.\n",
            "I0314 03:05:56.262503 138313941204992 run.py:479] Algo floyd_warshall step 5788 current loss 0.490858, current_train_items 185248.\n",
            "I0314 03:05:56.670505 138313941204992 run.py:479] Algo floyd_warshall step 5789 current loss 0.920730, current_train_items 185280.\n",
            "I0314 03:05:56.694705 138313941204992 run.py:479] Algo floyd_warshall step 5790 current loss 0.114510, current_train_items 185312.\n",
            "I0314 03:05:56.739912 138313941204992 run.py:479] Algo floyd_warshall step 5791 current loss 0.080983, current_train_items 185344.\n",
            "I0314 03:05:56.870415 138313941204992 run.py:479] Algo floyd_warshall step 5792 current loss 0.273304, current_train_items 185376.\n",
            "I0314 03:05:57.092224 138313941204992 run.py:479] Algo floyd_warshall step 5793 current loss 0.446890, current_train_items 185408.\n",
            "I0314 03:05:57.497584 138313941204992 run.py:479] Algo floyd_warshall step 5794 current loss 0.667298, current_train_items 185440.\n",
            "I0314 03:05:57.528602 138313941204992 run.py:479] Algo floyd_warshall step 5795 current loss 0.019325, current_train_items 185472.\n",
            "I0314 03:05:57.577699 138313941204992 run.py:479] Algo floyd_warshall step 5796 current loss 0.057994, current_train_items 185504.\n",
            "I0314 03:05:57.713182 138313941204992 run.py:479] Algo floyd_warshall step 5797 current loss 0.224326, current_train_items 185536.\n",
            "I0314 03:05:57.931937 138313941204992 run.py:479] Algo floyd_warshall step 5798 current loss 0.426786, current_train_items 185568.\n",
            "I0314 03:05:58.339241 138313941204992 run.py:479] Algo floyd_warshall step 5799 current loss 0.728856, current_train_items 185600.\n",
            "I0314 03:05:58.363086 138313941204992 run.py:479] Algo floyd_warshall step 5800 current loss 0.026388, current_train_items 185632.\n",
            "I0314 03:05:58.452194 138313941204992 run.py:499] (val) algo floyd_warshall step 5800: {'Pi': 0.88262939453125, 'score': 0.88262939453125, 'examples_seen': 185632, 'step': 5800, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:05:58.452492 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.893, current avg val score is 0.883, val scores are: floyd_warshall: 0.883\n",
            "I0314 03:05:58.501826 138313941204992 run.py:479] Algo floyd_warshall step 5801 current loss 0.047941, current_train_items 185664.\n",
            "I0314 03:05:58.635423 138313941204992 run.py:479] Algo floyd_warshall step 5802 current loss 0.196713, current_train_items 185696.\n",
            "I0314 03:05:58.860536 138313941204992 run.py:479] Algo floyd_warshall step 5803 current loss 0.411801, current_train_items 185728.\n",
            "I0314 03:05:59.291334 138313941204992 run.py:479] Algo floyd_warshall step 5804 current loss 0.732433, current_train_items 185760.\n",
            "I0314 03:05:59.328100 138313941204992 run.py:479] Algo floyd_warshall step 5805 current loss 0.040186, current_train_items 185792.\n",
            "I0314 03:05:59.372220 138313941204992 run.py:479] Algo floyd_warshall step 5806 current loss 0.055327, current_train_items 185824.\n",
            "I0314 03:05:59.511481 138313941204992 run.py:479] Algo floyd_warshall step 5807 current loss 0.362931, current_train_items 185856.\n",
            "I0314 03:05:59.733648 138313941204992 run.py:479] Algo floyd_warshall step 5808 current loss 0.445032, current_train_items 185888.\n",
            "I0314 03:06:00.141716 138313941204992 run.py:479] Algo floyd_warshall step 5809 current loss 0.771999, current_train_items 185920.\n",
            "I0314 03:06:00.164685 138313941204992 run.py:479] Algo floyd_warshall step 5810 current loss 0.019256, current_train_items 185952.\n",
            "I0314 03:06:00.209682 138313941204992 run.py:479] Algo floyd_warshall step 5811 current loss 0.075540, current_train_items 185984.\n",
            "I0314 03:06:00.341810 138313941204992 run.py:479] Algo floyd_warshall step 5812 current loss 0.417531, current_train_items 186016.\n",
            "I0314 03:06:00.564526 138313941204992 run.py:479] Algo floyd_warshall step 5813 current loss 0.546628, current_train_items 186048.\n",
            "I0314 03:06:00.972438 138313941204992 run.py:479] Algo floyd_warshall step 5814 current loss 0.664004, current_train_items 186080.\n",
            "I0314 03:06:00.997327 138313941204992 run.py:479] Algo floyd_warshall step 5815 current loss 0.032796, current_train_items 186112.\n",
            "I0314 03:06:01.043251 138313941204992 run.py:479] Algo floyd_warshall step 5816 current loss 0.071317, current_train_items 186144.\n",
            "I0314 03:06:01.177847 138313941204992 run.py:479] Algo floyd_warshall step 5817 current loss 0.214788, current_train_items 186176.\n",
            "I0314 03:06:01.405576 138313941204992 run.py:479] Algo floyd_warshall step 5818 current loss 0.556763, current_train_items 186208.\n",
            "I0314 03:06:01.820307 138313941204992 run.py:479] Algo floyd_warshall step 5819 current loss 0.854064, current_train_items 186240.\n",
            "I0314 03:06:01.845427 138313941204992 run.py:479] Algo floyd_warshall step 5820 current loss 0.033271, current_train_items 186272.\n",
            "I0314 03:06:01.890678 138313941204992 run.py:479] Algo floyd_warshall step 5821 current loss 0.093624, current_train_items 186304.\n",
            "I0314 03:06:02.021811 138313941204992 run.py:479] Algo floyd_warshall step 5822 current loss 0.313608, current_train_items 186336.\n",
            "I0314 03:06:02.239686 138313941204992 run.py:479] Algo floyd_warshall step 5823 current loss 0.587832, current_train_items 186368.\n",
            "I0314 03:06:02.656327 138313941204992 run.py:479] Algo floyd_warshall step 5824 current loss 0.803417, current_train_items 186400.\n",
            "I0314 03:06:02.680065 138313941204992 run.py:479] Algo floyd_warshall step 5825 current loss 0.019591, current_train_items 186432.\n",
            "I0314 03:06:02.725945 138313941204992 run.py:479] Algo floyd_warshall step 5826 current loss 0.093764, current_train_items 186464.\n",
            "I0314 03:06:02.858548 138313941204992 run.py:479] Algo floyd_warshall step 5827 current loss 0.329064, current_train_items 186496.\n",
            "I0314 03:06:03.082986 138313941204992 run.py:479] Algo floyd_warshall step 5828 current loss 0.505827, current_train_items 186528.\n",
            "I0314 03:06:03.505741 138313941204992 run.py:479] Algo floyd_warshall step 5829 current loss 0.994250, current_train_items 186560.\n",
            "I0314 03:06:03.530463 138313941204992 run.py:479] Algo floyd_warshall step 5830 current loss 0.022016, current_train_items 186592.\n",
            "I0314 03:06:03.574923 138313941204992 run.py:479] Algo floyd_warshall step 5831 current loss 0.085127, current_train_items 186624.\n",
            "I0314 03:06:03.709259 138313941204992 run.py:479] Algo floyd_warshall step 5832 current loss 0.370690, current_train_items 186656.\n",
            "I0314 03:06:03.979142 138313941204992 run.py:479] Algo floyd_warshall step 5833 current loss 0.543522, current_train_items 186688.\n",
            "I0314 03:06:04.461439 138313941204992 run.py:479] Algo floyd_warshall step 5834 current loss 0.729774, current_train_items 186720.\n",
            "I0314 03:06:04.497943 138313941204992 run.py:479] Algo floyd_warshall step 5835 current loss 0.044120, current_train_items 186752.\n",
            "I0314 03:06:04.557629 138313941204992 run.py:479] Algo floyd_warshall step 5836 current loss 0.104247, current_train_items 186784.\n",
            "I0314 03:06:04.724427 138313941204992 run.py:479] Algo floyd_warshall step 5837 current loss 0.345017, current_train_items 186816.\n",
            "I0314 03:06:04.995203 138313941204992 run.py:479] Algo floyd_warshall step 5838 current loss 0.486410, current_train_items 186848.\n",
            "I0314 03:06:05.480651 138313941204992 run.py:479] Algo floyd_warshall step 5839 current loss 0.735382, current_train_items 186880.\n",
            "I0314 03:06:05.521531 138313941204992 run.py:479] Algo floyd_warshall step 5840 current loss 0.031709, current_train_items 186912.\n",
            "I0314 03:06:05.582202 138313941204992 run.py:479] Algo floyd_warshall step 5841 current loss 0.060706, current_train_items 186944.\n",
            "I0314 03:06:05.739436 138313941204992 run.py:479] Algo floyd_warshall step 5842 current loss 0.255567, current_train_items 186976.\n",
            "I0314 03:06:06.005647 138313941204992 run.py:479] Algo floyd_warshall step 5843 current loss 0.476296, current_train_items 187008.\n",
            "I0314 03:06:06.498734 138313941204992 run.py:479] Algo floyd_warshall step 5844 current loss 0.728269, current_train_items 187040.\n",
            "I0314 03:06:06.538454 138313941204992 run.py:479] Algo floyd_warshall step 5845 current loss 0.020063, current_train_items 187072.\n",
            "I0314 03:06:06.606292 138313941204992 run.py:479] Algo floyd_warshall step 5846 current loss 0.109009, current_train_items 187104.\n",
            "I0314 03:06:06.767645 138313941204992 run.py:479] Algo floyd_warshall step 5847 current loss 0.282211, current_train_items 187136.\n",
            "I0314 03:06:06.988033 138313941204992 run.py:479] Algo floyd_warshall step 5848 current loss 0.492132, current_train_items 187168.\n",
            "I0314 03:06:07.418708 138313941204992 run.py:479] Algo floyd_warshall step 5849 current loss 0.791325, current_train_items 187200.\n",
            "I0314 03:06:07.443360 138313941204992 run.py:479] Algo floyd_warshall step 5850 current loss 0.011302, current_train_items 187232.\n",
            "I0314 03:06:07.533272 138313941204992 run.py:499] (val) algo floyd_warshall step 5850: {'Pi': 0.8897705078125, 'score': 0.8897705078125, 'examples_seen': 187232, 'step': 5850, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:06:07.533519 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.893, current avg val score is 0.890, val scores are: floyd_warshall: 0.890\n",
            "I0314 03:06:07.581898 138313941204992 run.py:479] Algo floyd_warshall step 5851 current loss 0.057035, current_train_items 187264.\n",
            "I0314 03:06:07.726175 138313941204992 run.py:479] Algo floyd_warshall step 5852 current loss 0.297217, current_train_items 187296.\n",
            "I0314 03:06:07.944379 138313941204992 run.py:479] Algo floyd_warshall step 5853 current loss 0.427163, current_train_items 187328.\n",
            "I0314 03:06:08.368136 138313941204992 run.py:479] Algo floyd_warshall step 5854 current loss 0.855843, current_train_items 187360.\n",
            "I0314 03:06:08.394927 138313941204992 run.py:479] Algo floyd_warshall step 5855 current loss 0.030041, current_train_items 187392.\n",
            "I0314 03:06:08.442127 138313941204992 run.py:479] Algo floyd_warshall step 5856 current loss 0.056948, current_train_items 187424.\n",
            "I0314 03:06:08.570800 138313941204992 run.py:479] Algo floyd_warshall step 5857 current loss 0.351988, current_train_items 187456.\n",
            "I0314 03:06:08.806187 138313941204992 run.py:479] Algo floyd_warshall step 5858 current loss 0.421663, current_train_items 187488.\n",
            "I0314 03:06:09.225398 138313941204992 run.py:479] Algo floyd_warshall step 5859 current loss 0.812917, current_train_items 187520.\n",
            "I0314 03:06:09.249104 138313941204992 run.py:479] Algo floyd_warshall step 5860 current loss 0.025473, current_train_items 187552.\n",
            "I0314 03:06:09.293673 138313941204992 run.py:479] Algo floyd_warshall step 5861 current loss 0.146735, current_train_items 187584.\n",
            "I0314 03:06:09.426698 138313941204992 run.py:479] Algo floyd_warshall step 5862 current loss 0.334770, current_train_items 187616.\n",
            "I0314 03:06:09.656675 138313941204992 run.py:479] Algo floyd_warshall step 5863 current loss 0.413839, current_train_items 187648.\n",
            "I0314 03:06:10.066121 138313941204992 run.py:479] Algo floyd_warshall step 5864 current loss 0.693806, current_train_items 187680.\n",
            "I0314 03:06:10.090959 138313941204992 run.py:479] Algo floyd_warshall step 5865 current loss 0.019862, current_train_items 187712.\n",
            "I0314 03:06:10.135519 138313941204992 run.py:479] Algo floyd_warshall step 5866 current loss 0.096074, current_train_items 187744.\n",
            "I0314 03:06:10.259383 138313941204992 run.py:479] Algo floyd_warshall step 5867 current loss 0.152381, current_train_items 187776.\n",
            "I0314 03:06:10.472177 138313941204992 run.py:479] Algo floyd_warshall step 5868 current loss 0.382954, current_train_items 187808.\n",
            "I0314 03:06:10.876729 138313941204992 run.py:479] Algo floyd_warshall step 5869 current loss 0.673933, current_train_items 187840.\n",
            "I0314 03:06:10.899752 138313941204992 run.py:479] Algo floyd_warshall step 5870 current loss 0.021685, current_train_items 187872.\n",
            "I0314 03:06:10.944685 138313941204992 run.py:479] Algo floyd_warshall step 5871 current loss 0.114140, current_train_items 187904.\n",
            "I0314 03:06:11.075561 138313941204992 run.py:479] Algo floyd_warshall step 5872 current loss 0.321457, current_train_items 187936.\n",
            "I0314 03:06:11.302305 138313941204992 run.py:479] Algo floyd_warshall step 5873 current loss 0.449124, current_train_items 187968.\n",
            "I0314 03:06:11.710272 138313941204992 run.py:479] Algo floyd_warshall step 5874 current loss 0.708721, current_train_items 188000.\n",
            "I0314 03:06:11.733908 138313941204992 run.py:479] Algo floyd_warshall step 5875 current loss 0.026139, current_train_items 188032.\n",
            "I0314 03:06:11.780693 138313941204992 run.py:479] Algo floyd_warshall step 5876 current loss 0.103889, current_train_items 188064.\n",
            "I0314 03:06:11.912893 138313941204992 run.py:479] Algo floyd_warshall step 5877 current loss 0.241602, current_train_items 188096.\n",
            "I0314 03:06:12.136381 138313941204992 run.py:479] Algo floyd_warshall step 5878 current loss 0.456631, current_train_items 188128.\n",
            "I0314 03:06:12.556721 138313941204992 run.py:479] Algo floyd_warshall step 5879 current loss 0.787904, current_train_items 188160.\n",
            "I0314 03:06:12.580369 138313941204992 run.py:479] Algo floyd_warshall step 5880 current loss 0.027671, current_train_items 188192.\n",
            "I0314 03:06:12.626446 138313941204992 run.py:479] Algo floyd_warshall step 5881 current loss 0.064494, current_train_items 188224.\n",
            "I0314 03:06:12.755251 138313941204992 run.py:479] Algo floyd_warshall step 5882 current loss 0.285548, current_train_items 188256.\n",
            "I0314 03:06:12.972388 138313941204992 run.py:479] Algo floyd_warshall step 5883 current loss 0.300523, current_train_items 188288.\n",
            "I0314 03:06:13.390016 138313941204992 run.py:479] Algo floyd_warshall step 5884 current loss 0.709935, current_train_items 188320.\n",
            "I0314 03:06:13.415204 138313941204992 run.py:479] Algo floyd_warshall step 5885 current loss 0.026606, current_train_items 188352.\n",
            "I0314 03:06:13.459369 138313941204992 run.py:479] Algo floyd_warshall step 5886 current loss 0.050232, current_train_items 188384.\n",
            "I0314 03:06:13.588407 138313941204992 run.py:479] Algo floyd_warshall step 5887 current loss 0.209471, current_train_items 188416.\n",
            "I0314 03:06:13.807861 138313941204992 run.py:479] Algo floyd_warshall step 5888 current loss 0.423940, current_train_items 188448.\n",
            "I0314 03:06:14.209593 138313941204992 run.py:479] Algo floyd_warshall step 5889 current loss 0.642305, current_train_items 188480.\n",
            "I0314 03:06:14.233829 138313941204992 run.py:479] Algo floyd_warshall step 5890 current loss 0.021250, current_train_items 188512.\n",
            "I0314 03:06:14.278734 138313941204992 run.py:479] Algo floyd_warshall step 5891 current loss 0.082642, current_train_items 188544.\n",
            "I0314 03:06:14.410226 138313941204992 run.py:479] Algo floyd_warshall step 5892 current loss 0.303406, current_train_items 188576.\n",
            "I0314 03:06:14.632825 138313941204992 run.py:479] Algo floyd_warshall step 5893 current loss 0.503919, current_train_items 188608.\n",
            "I0314 03:06:15.039412 138313941204992 run.py:479] Algo floyd_warshall step 5894 current loss 0.646752, current_train_items 188640.\n",
            "I0314 03:06:15.064056 138313941204992 run.py:479] Algo floyd_warshall step 5895 current loss 0.018647, current_train_items 188672.\n",
            "I0314 03:06:15.109039 138313941204992 run.py:479] Algo floyd_warshall step 5896 current loss 0.072675, current_train_items 188704.\n",
            "I0314 03:06:15.242054 138313941204992 run.py:479] Algo floyd_warshall step 5897 current loss 0.310051, current_train_items 188736.\n",
            "I0314 03:06:15.469697 138313941204992 run.py:479] Algo floyd_warshall step 5898 current loss 0.446066, current_train_items 188768.\n",
            "I0314 03:06:15.880374 138313941204992 run.py:479] Algo floyd_warshall step 5899 current loss 0.617139, current_train_items 188800.\n",
            "I0314 03:06:15.904189 138313941204992 run.py:479] Algo floyd_warshall step 5900 current loss 0.011657, current_train_items 188832.\n",
            "I0314 03:06:15.993130 138313941204992 run.py:499] (val) algo floyd_warshall step 5900: {'Pi': 0.8890380859375, 'score': 0.8890380859375, 'examples_seen': 188832, 'step': 5900, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:06:15.993429 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.893, current avg val score is 0.889, val scores are: floyd_warshall: 0.889\n",
            "I0314 03:06:16.042689 138313941204992 run.py:479] Algo floyd_warshall step 5901 current loss 0.076510, current_train_items 188864.\n",
            "I0314 03:06:16.174854 138313941204992 run.py:479] Algo floyd_warshall step 5902 current loss 0.211529, current_train_items 188896.\n",
            "I0314 03:06:16.402279 138313941204992 run.py:479] Algo floyd_warshall step 5903 current loss 0.483926, current_train_items 188928.\n",
            "I0314 03:06:16.814082 138313941204992 run.py:479] Algo floyd_warshall step 5904 current loss 0.698493, current_train_items 188960.\n",
            "I0314 03:06:16.857615 138313941204992 run.py:479] Algo floyd_warshall step 5905 current loss 0.015939, current_train_items 188992.\n",
            "I0314 03:06:16.919385 138313941204992 run.py:479] Algo floyd_warshall step 5906 current loss 0.054618, current_train_items 189024.\n",
            "I0314 03:06:17.086361 138313941204992 run.py:479] Algo floyd_warshall step 5907 current loss 0.384743, current_train_items 189056.\n",
            "I0314 03:06:17.352035 138313941204992 run.py:479] Algo floyd_warshall step 5908 current loss 0.583083, current_train_items 189088.\n",
            "I0314 03:06:17.861362 138313941204992 run.py:479] Algo floyd_warshall step 5909 current loss 0.783648, current_train_items 189120.\n",
            "I0314 03:06:17.908256 138313941204992 run.py:479] Algo floyd_warshall step 5910 current loss 0.029848, current_train_items 189152.\n",
            "I0314 03:06:17.968423 138313941204992 run.py:479] Algo floyd_warshall step 5911 current loss 0.074932, current_train_items 189184.\n",
            "I0314 03:06:18.132454 138313941204992 run.py:479] Algo floyd_warshall step 5912 current loss 0.242063, current_train_items 189216.\n",
            "I0314 03:06:18.387803 138313941204992 run.py:479] Algo floyd_warshall step 5913 current loss 0.383623, current_train_items 189248.\n",
            "I0314 03:06:18.899724 138313941204992 run.py:479] Algo floyd_warshall step 5914 current loss 0.627849, current_train_items 189280.\n",
            "I0314 03:06:18.941193 138313941204992 run.py:479] Algo floyd_warshall step 5915 current loss 0.017566, current_train_items 189312.\n",
            "I0314 03:06:18.999959 138313941204992 run.py:479] Algo floyd_warshall step 5916 current loss 0.112667, current_train_items 189344.\n",
            "I0314 03:06:19.156618 138313941204992 run.py:479] Algo floyd_warshall step 5917 current loss 0.313194, current_train_items 189376.\n",
            "I0314 03:06:19.427027 138313941204992 run.py:479] Algo floyd_warshall step 5918 current loss 0.441060, current_train_items 189408.\n",
            "I0314 03:06:19.920728 138313941204992 run.py:479] Algo floyd_warshall step 5919 current loss 0.752143, current_train_items 189440.\n",
            "I0314 03:06:19.944759 138313941204992 run.py:479] Algo floyd_warshall step 5920 current loss 0.058648, current_train_items 189472.\n",
            "I0314 03:06:19.996619 138313941204992 run.py:479] Algo floyd_warshall step 5921 current loss 0.053560, current_train_items 189504.\n",
            "I0314 03:06:20.130105 138313941204992 run.py:479] Algo floyd_warshall step 5922 current loss 0.307099, current_train_items 189536.\n",
            "I0314 03:06:20.342393 138313941204992 run.py:479] Algo floyd_warshall step 5923 current loss 0.404041, current_train_items 189568.\n",
            "I0314 03:06:20.755941 138313941204992 run.py:479] Algo floyd_warshall step 5924 current loss 0.754860, current_train_items 189600.\n",
            "I0314 03:06:20.779335 138313941204992 run.py:479] Algo floyd_warshall step 5925 current loss 0.030974, current_train_items 189632.\n",
            "I0314 03:06:20.824161 138313941204992 run.py:479] Algo floyd_warshall step 5926 current loss 0.193386, current_train_items 189664.\n",
            "I0314 03:06:20.954066 138313941204992 run.py:479] Algo floyd_warshall step 5927 current loss 0.255016, current_train_items 189696.\n",
            "I0314 03:06:21.186227 138313941204992 run.py:479] Algo floyd_warshall step 5928 current loss 0.352274, current_train_items 189728.\n",
            "I0314 03:06:21.595416 138313941204992 run.py:479] Algo floyd_warshall step 5929 current loss 0.573747, current_train_items 189760.\n",
            "I0314 03:06:21.620514 138313941204992 run.py:479] Algo floyd_warshall step 5930 current loss 0.025115, current_train_items 189792.\n",
            "I0314 03:06:21.665846 138313941204992 run.py:479] Algo floyd_warshall step 5931 current loss 0.081480, current_train_items 189824.\n",
            "I0314 03:06:21.798287 138313941204992 run.py:479] Algo floyd_warshall step 5932 current loss 0.439899, current_train_items 189856.\n",
            "I0314 03:06:22.020277 138313941204992 run.py:479] Algo floyd_warshall step 5933 current loss 0.366626, current_train_items 189888.\n",
            "I0314 03:06:22.431111 138313941204992 run.py:479] Algo floyd_warshall step 5934 current loss 0.552708, current_train_items 189920.\n",
            "I0314 03:06:22.455067 138313941204992 run.py:479] Algo floyd_warshall step 5935 current loss 0.026661, current_train_items 189952.\n",
            "I0314 03:06:22.499530 138313941204992 run.py:479] Algo floyd_warshall step 5936 current loss 0.086400, current_train_items 189984.\n",
            "I0314 03:06:22.627881 138313941204992 run.py:479] Algo floyd_warshall step 5937 current loss 0.274117, current_train_items 190016.\n",
            "I0314 03:06:22.840624 138313941204992 run.py:479] Algo floyd_warshall step 5938 current loss 0.375526, current_train_items 190048.\n",
            "I0314 03:06:23.251604 138313941204992 run.py:479] Algo floyd_warshall step 5939 current loss 0.713546, current_train_items 190080.\n",
            "I0314 03:06:23.274292 138313941204992 run.py:479] Algo floyd_warshall step 5940 current loss 0.011897, current_train_items 190112.\n",
            "I0314 03:06:23.318877 138313941204992 run.py:479] Algo floyd_warshall step 5941 current loss 0.130772, current_train_items 190144.\n",
            "I0314 03:06:23.447752 138313941204992 run.py:479] Algo floyd_warshall step 5942 current loss 0.271219, current_train_items 190176.\n",
            "I0314 03:06:23.670767 138313941204992 run.py:479] Algo floyd_warshall step 5943 current loss 0.524033, current_train_items 190208.\n",
            "I0314 03:06:24.081918 138313941204992 run.py:479] Algo floyd_warshall step 5944 current loss 0.669030, current_train_items 190240.\n",
            "I0314 03:06:24.108725 138313941204992 run.py:479] Algo floyd_warshall step 5945 current loss 0.029843, current_train_items 190272.\n",
            "I0314 03:06:24.153375 138313941204992 run.py:479] Algo floyd_warshall step 5946 current loss 0.082837, current_train_items 190304.\n",
            "I0314 03:06:24.283926 138313941204992 run.py:479] Algo floyd_warshall step 5947 current loss 0.292706, current_train_items 190336.\n",
            "I0314 03:06:24.502115 138313941204992 run.py:479] Algo floyd_warshall step 5948 current loss 0.361498, current_train_items 190368.\n",
            "I0314 03:06:24.920868 138313941204992 run.py:479] Algo floyd_warshall step 5949 current loss 0.723535, current_train_items 190400.\n",
            "I0314 03:06:24.945937 138313941204992 run.py:479] Algo floyd_warshall step 5950 current loss 0.016964, current_train_items 190432.\n",
            "I0314 03:06:25.031456 138313941204992 run.py:499] (val) algo floyd_warshall step 5950: {'Pi': 0.89691162109375, 'score': 0.89691162109375, 'examples_seen': 190432, 'step': 5950, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:06:25.031692 138313941204992 run.py:516] Checkpointing best model, best avg val score was 0.893, current avg val score is 0.897, val scores are: floyd_warshall: 0.897\n",
            "I0314 03:06:25.114621 138313941204992 run.py:479] Algo floyd_warshall step 5951 current loss 0.039583, current_train_items 190464.\n",
            "I0314 03:06:25.253819 138313941204992 run.py:479] Algo floyd_warshall step 5952 current loss 0.243796, current_train_items 190496.\n",
            "I0314 03:06:25.469171 138313941204992 run.py:479] Algo floyd_warshall step 5953 current loss 0.456427, current_train_items 190528.\n",
            "I0314 03:06:25.880510 138313941204992 run.py:479] Algo floyd_warshall step 5954 current loss 0.691830, current_train_items 190560.\n",
            "I0314 03:06:25.905435 138313941204992 run.py:479] Algo floyd_warshall step 5955 current loss 0.021026, current_train_items 190592.\n",
            "I0314 03:06:25.949798 138313941204992 run.py:479] Algo floyd_warshall step 5956 current loss 0.085118, current_train_items 190624.\n",
            "I0314 03:06:26.078819 138313941204992 run.py:479] Algo floyd_warshall step 5957 current loss 0.266370, current_train_items 190656.\n",
            "I0314 03:06:26.306036 138313941204992 run.py:479] Algo floyd_warshall step 5958 current loss 0.442685, current_train_items 190688.\n",
            "I0314 03:06:26.734158 138313941204992 run.py:479] Algo floyd_warshall step 5959 current loss 0.812002, current_train_items 190720.\n",
            "I0314 03:06:26.759661 138313941204992 run.py:479] Algo floyd_warshall step 5960 current loss 0.031002, current_train_items 190752.\n",
            "I0314 03:06:26.809811 138313941204992 run.py:479] Algo floyd_warshall step 5961 current loss 0.138521, current_train_items 190784.\n",
            "I0314 03:06:26.942454 138313941204992 run.py:479] Algo floyd_warshall step 5962 current loss 0.306630, current_train_items 190816.\n",
            "I0314 03:06:27.163224 138313941204992 run.py:479] Algo floyd_warshall step 5963 current loss 0.415997, current_train_items 190848.\n",
            "I0314 03:06:27.580106 138313941204992 run.py:479] Algo floyd_warshall step 5964 current loss 0.761488, current_train_items 190880.\n",
            "I0314 03:06:27.603614 138313941204992 run.py:479] Algo floyd_warshall step 5965 current loss 0.025311, current_train_items 190912.\n",
            "I0314 03:06:27.650161 138313941204992 run.py:479] Algo floyd_warshall step 5966 current loss 0.058880, current_train_items 190944.\n",
            "I0314 03:06:27.788099 138313941204992 run.py:479] Algo floyd_warshall step 5967 current loss 0.300161, current_train_items 190976.\n",
            "I0314 03:06:28.011986 138313941204992 run.py:479] Algo floyd_warshall step 5968 current loss 0.476321, current_train_items 191008.\n",
            "I0314 03:06:28.426288 138313941204992 run.py:479] Algo floyd_warshall step 5969 current loss 0.788608, current_train_items 191040.\n",
            "I0314 03:06:28.449646 138313941204992 run.py:479] Algo floyd_warshall step 5970 current loss 0.021269, current_train_items 191072.\n",
            "I0314 03:06:28.492642 138313941204992 run.py:479] Algo floyd_warshall step 5971 current loss 0.045779, current_train_items 191104.\n",
            "I0314 03:06:28.624628 138313941204992 run.py:479] Algo floyd_warshall step 5972 current loss 0.276074, current_train_items 191136.\n",
            "I0314 03:06:28.855304 138313941204992 run.py:479] Algo floyd_warshall step 5973 current loss 0.492214, current_train_items 191168.\n",
            "I0314 03:06:29.263863 138313941204992 run.py:479] Algo floyd_warshall step 5974 current loss 0.596811, current_train_items 191200.\n",
            "I0314 03:06:29.287487 138313941204992 run.py:479] Algo floyd_warshall step 5975 current loss 0.029303, current_train_items 191232.\n",
            "I0314 03:06:29.331384 138313941204992 run.py:479] Algo floyd_warshall step 5976 current loss 0.063552, current_train_items 191264.\n",
            "I0314 03:06:29.457942 138313941204992 run.py:479] Algo floyd_warshall step 5977 current loss 0.214247, current_train_items 191296.\n",
            "I0314 03:06:29.681611 138313941204992 run.py:479] Algo floyd_warshall step 5978 current loss 0.391249, current_train_items 191328.\n",
            "I0314 03:06:30.102605 138313941204992 run.py:479] Algo floyd_warshall step 5979 current loss 0.561657, current_train_items 191360.\n",
            "I0314 03:06:30.137953 138313941204992 run.py:479] Algo floyd_warshall step 5980 current loss 0.020872, current_train_items 191392.\n",
            "I0314 03:06:30.197093 138313941204992 run.py:479] Algo floyd_warshall step 5981 current loss 0.037991, current_train_items 191424.\n",
            "I0314 03:06:30.356459 138313941204992 run.py:479] Algo floyd_warshall step 5982 current loss 0.208968, current_train_items 191456.\n",
            "I0314 03:06:30.643618 138313941204992 run.py:479] Algo floyd_warshall step 5983 current loss 0.370687, current_train_items 191488.\n",
            "I0314 03:06:31.137212 138313941204992 run.py:479] Algo floyd_warshall step 5984 current loss 0.601882, current_train_items 191520.\n",
            "I0314 03:06:31.175002 138313941204992 run.py:479] Algo floyd_warshall step 5985 current loss 0.068574, current_train_items 191552.\n",
            "I0314 03:06:31.232070 138313941204992 run.py:479] Algo floyd_warshall step 5986 current loss 0.100401, current_train_items 191584.\n",
            "I0314 03:06:31.394577 138313941204992 run.py:479] Algo floyd_warshall step 5987 current loss 0.341357, current_train_items 191616.\n",
            "I0314 03:06:31.650992 138313941204992 run.py:479] Algo floyd_warshall step 5988 current loss 0.453711, current_train_items 191648.\n",
            "I0314 03:06:32.163682 138313941204992 run.py:479] Algo floyd_warshall step 5989 current loss 0.970771, current_train_items 191680.\n",
            "I0314 03:06:32.196508 138313941204992 run.py:479] Algo floyd_warshall step 5990 current loss 0.104767, current_train_items 191712.\n",
            "I0314 03:06:32.259348 138313941204992 run.py:479] Algo floyd_warshall step 5991 current loss 0.140145, current_train_items 191744.\n",
            "I0314 03:06:32.422830 138313941204992 run.py:479] Algo floyd_warshall step 5992 current loss 0.259051, current_train_items 191776.\n",
            "I0314 03:06:32.693231 138313941204992 run.py:479] Algo floyd_warshall step 5993 current loss 0.468272, current_train_items 191808.\n",
            "I0314 03:06:33.180348 138313941204992 run.py:479] Algo floyd_warshall step 5994 current loss 0.610835, current_train_items 191840.\n",
            "I0314 03:06:33.203280 138313941204992 run.py:479] Algo floyd_warshall step 5995 current loss 0.010389, current_train_items 191872.\n",
            "I0314 03:06:33.247470 138313941204992 run.py:479] Algo floyd_warshall step 5996 current loss 0.099416, current_train_items 191904.\n",
            "I0314 03:06:33.373921 138313941204992 run.py:479] Algo floyd_warshall step 5997 current loss 0.203736, current_train_items 191936.\n",
            "I0314 03:06:33.600778 138313941204992 run.py:479] Algo floyd_warshall step 5998 current loss 0.584176, current_train_items 191968.\n",
            "I0314 03:06:34.024083 138313941204992 run.py:479] Algo floyd_warshall step 5999 current loss 0.801941, current_train_items 192000.\n",
            "I0314 03:06:34.045665 138313941204992 run.py:479] Algo floyd_warshall step 6000 current loss 0.046332, current_train_items 192032.\n",
            "I0314 03:06:34.136913 138313941204992 run.py:499] (val) algo floyd_warshall step 6000: {'Pi': 0.8770751953125, 'score': 0.8770751953125, 'examples_seen': 192032, 'step': 6000, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:06:34.137157 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.897, current avg val score is 0.877, val scores are: floyd_warshall: 0.877\n",
            "I0314 03:06:34.184839 138313941204992 run.py:479] Algo floyd_warshall step 6001 current loss 0.115868, current_train_items 192064.\n",
            "I0314 03:06:34.315179 138313941204992 run.py:479] Algo floyd_warshall step 6002 current loss 0.319480, current_train_items 192096.\n",
            "I0314 03:06:34.541842 138313941204992 run.py:479] Algo floyd_warshall step 6003 current loss 0.466350, current_train_items 192128.\n",
            "I0314 03:06:34.962666 138313941204992 run.py:479] Algo floyd_warshall step 6004 current loss 0.686984, current_train_items 192160.\n",
            "I0314 03:06:34.986963 138313941204992 run.py:479] Algo floyd_warshall step 6005 current loss 0.019932, current_train_items 192192.\n",
            "I0314 03:06:35.030866 138313941204992 run.py:479] Algo floyd_warshall step 6006 current loss 0.075001, current_train_items 192224.\n",
            "I0314 03:06:35.164199 138313941204992 run.py:479] Algo floyd_warshall step 6007 current loss 0.199459, current_train_items 192256.\n",
            "I0314 03:06:35.387730 138313941204992 run.py:479] Algo floyd_warshall step 6008 current loss 0.437159, current_train_items 192288.\n",
            "I0314 03:06:35.817801 138313941204992 run.py:479] Algo floyd_warshall step 6009 current loss 0.757614, current_train_items 192320.\n",
            "I0314 03:06:35.841300 138313941204992 run.py:479] Algo floyd_warshall step 6010 current loss 0.037350, current_train_items 192352.\n",
            "I0314 03:06:35.887251 138313941204992 run.py:479] Algo floyd_warshall step 6011 current loss 0.090449, current_train_items 192384.\n",
            "I0314 03:06:36.019523 138313941204992 run.py:479] Algo floyd_warshall step 6012 current loss 0.290048, current_train_items 192416.\n",
            "I0314 03:06:36.235744 138313941204992 run.py:479] Algo floyd_warshall step 6013 current loss 0.399039, current_train_items 192448.\n",
            "I0314 03:06:36.636710 138313941204992 run.py:479] Algo floyd_warshall step 6014 current loss 0.708894, current_train_items 192480.\n",
            "I0314 03:06:36.660395 138313941204992 run.py:479] Algo floyd_warshall step 6015 current loss 0.013677, current_train_items 192512.\n",
            "I0314 03:06:36.704232 138313941204992 run.py:479] Algo floyd_warshall step 6016 current loss 0.122704, current_train_items 192544.\n",
            "I0314 03:06:36.835553 138313941204992 run.py:479] Algo floyd_warshall step 6017 current loss 0.237733, current_train_items 192576.\n",
            "I0314 03:06:37.046927 138313941204992 run.py:479] Algo floyd_warshall step 6018 current loss 0.372910, current_train_items 192608.\n",
            "I0314 03:06:37.473646 138313941204992 run.py:479] Algo floyd_warshall step 6019 current loss 0.856346, current_train_items 192640.\n",
            "I0314 03:06:37.498218 138313941204992 run.py:479] Algo floyd_warshall step 6020 current loss 0.021348, current_train_items 192672.\n",
            "I0314 03:06:37.543339 138313941204992 run.py:479] Algo floyd_warshall step 6021 current loss 0.096023, current_train_items 192704.\n",
            "I0314 03:06:37.671594 138313941204992 run.py:479] Algo floyd_warshall step 6022 current loss 0.296139, current_train_items 192736.\n",
            "I0314 03:06:37.896644 138313941204992 run.py:479] Algo floyd_warshall step 6023 current loss 0.345014, current_train_items 192768.\n",
            "I0314 03:06:38.302514 138313941204992 run.py:479] Algo floyd_warshall step 6024 current loss 0.557046, current_train_items 192800.\n",
            "I0314 03:06:38.327957 138313941204992 run.py:479] Algo floyd_warshall step 6025 current loss 0.045155, current_train_items 192832.\n",
            "I0314 03:06:38.372777 138313941204992 run.py:479] Algo floyd_warshall step 6026 current loss 0.094345, current_train_items 192864.\n",
            "I0314 03:06:38.502410 138313941204992 run.py:479] Algo floyd_warshall step 6027 current loss 0.255109, current_train_items 192896.\n",
            "I0314 03:06:38.728665 138313941204992 run.py:479] Algo floyd_warshall step 6028 current loss 0.399910, current_train_items 192928.\n",
            "I0314 03:06:39.150973 138313941204992 run.py:479] Algo floyd_warshall step 6029 current loss 0.809575, current_train_items 192960.\n",
            "I0314 03:06:39.174712 138313941204992 run.py:479] Algo floyd_warshall step 6030 current loss 0.020828, current_train_items 192992.\n",
            "I0314 03:06:39.218574 138313941204992 run.py:479] Algo floyd_warshall step 6031 current loss 0.076764, current_train_items 193024.\n",
            "I0314 03:06:39.348572 138313941204992 run.py:479] Algo floyd_warshall step 6032 current loss 0.216829, current_train_items 193056.\n",
            "I0314 03:06:39.565810 138313941204992 run.py:479] Algo floyd_warshall step 6033 current loss 0.473741, current_train_items 193088.\n",
            "I0314 03:06:39.975238 138313941204992 run.py:479] Algo floyd_warshall step 6034 current loss 0.784354, current_train_items 193120.\n",
            "I0314 03:06:39.998727 138313941204992 run.py:479] Algo floyd_warshall step 6035 current loss 0.013749, current_train_items 193152.\n",
            "I0314 03:06:40.044159 138313941204992 run.py:479] Algo floyd_warshall step 6036 current loss 0.074747, current_train_items 193184.\n",
            "I0314 03:06:40.177304 138313941204992 run.py:479] Algo floyd_warshall step 6037 current loss 0.330406, current_train_items 193216.\n",
            "I0314 03:06:40.400474 138313941204992 run.py:479] Algo floyd_warshall step 6038 current loss 0.468016, current_train_items 193248.\n",
            "I0314 03:06:40.808940 138313941204992 run.py:479] Algo floyd_warshall step 6039 current loss 0.622120, current_train_items 193280.\n",
            "I0314 03:06:40.832325 138313941204992 run.py:479] Algo floyd_warshall step 6040 current loss 0.023214, current_train_items 193312.\n",
            "I0314 03:06:40.878293 138313941204992 run.py:479] Algo floyd_warshall step 6041 current loss 0.097639, current_train_items 193344.\n",
            "I0314 03:06:41.007251 138313941204992 run.py:479] Algo floyd_warshall step 6042 current loss 0.327802, current_train_items 193376.\n",
            "I0314 03:06:41.236305 138313941204992 run.py:479] Algo floyd_warshall step 6043 current loss 0.445503, current_train_items 193408.\n",
            "I0314 03:06:41.671201 138313941204992 run.py:479] Algo floyd_warshall step 6044 current loss 0.663716, current_train_items 193440.\n",
            "I0314 03:06:41.695409 138313941204992 run.py:479] Algo floyd_warshall step 6045 current loss 0.014517, current_train_items 193472.\n",
            "I0314 03:06:41.740777 138313941204992 run.py:479] Algo floyd_warshall step 6046 current loss 0.054115, current_train_items 193504.\n",
            "I0314 03:06:41.874892 138313941204992 run.py:479] Algo floyd_warshall step 6047 current loss 0.226007, current_train_items 193536.\n",
            "I0314 03:06:42.096065 138313941204992 run.py:479] Algo floyd_warshall step 6048 current loss 0.360901, current_train_items 193568.\n",
            "I0314 03:06:42.512913 138313941204992 run.py:479] Algo floyd_warshall step 6049 current loss 0.617314, current_train_items 193600.\n",
            "I0314 03:06:42.536274 138313941204992 run.py:479] Algo floyd_warshall step 6050 current loss 0.015486, current_train_items 193632.\n",
            "I0314 03:06:42.623916 138313941204992 run.py:499] (val) algo floyd_warshall step 6050: {'Pi': 0.88623046875, 'score': 0.88623046875, 'examples_seen': 193632, 'step': 6050, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:06:42.624181 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.897, current avg val score is 0.886, val scores are: floyd_warshall: 0.886\n",
            "I0314 03:06:42.672259 138313941204992 run.py:479] Algo floyd_warshall step 6051 current loss 0.078576, current_train_items 193664.\n",
            "I0314 03:06:42.802863 138313941204992 run.py:479] Algo floyd_warshall step 6052 current loss 0.213754, current_train_items 193696.\n",
            "I0314 03:06:43.024987 138313941204992 run.py:479] Algo floyd_warshall step 6053 current loss 0.406499, current_train_items 193728.\n",
            "I0314 03:06:43.512132 138313941204992 run.py:479] Algo floyd_warshall step 6054 current loss 0.574853, current_train_items 193760.\n",
            "I0314 03:06:43.549659 138313941204992 run.py:479] Algo floyd_warshall step 6055 current loss 0.010984, current_train_items 193792.\n",
            "I0314 03:06:43.606590 138313941204992 run.py:479] Algo floyd_warshall step 6056 current loss 0.040852, current_train_items 193824.\n",
            "I0314 03:06:43.770379 138313941204992 run.py:479] Algo floyd_warshall step 6057 current loss 0.227165, current_train_items 193856.\n",
            "I0314 03:06:44.033100 138313941204992 run.py:479] Algo floyd_warshall step 6058 current loss 0.346701, current_train_items 193888.\n",
            "I0314 03:06:44.536715 138313941204992 run.py:479] Algo floyd_warshall step 6059 current loss 0.779078, current_train_items 193920.\n",
            "I0314 03:06:44.571956 138313941204992 run.py:479] Algo floyd_warshall step 6060 current loss 0.023652, current_train_items 193952.\n",
            "I0314 03:06:44.630682 138313941204992 run.py:479] Algo floyd_warshall step 6061 current loss 0.188262, current_train_items 193984.\n",
            "I0314 03:06:44.794392 138313941204992 run.py:479] Algo floyd_warshall step 6062 current loss 0.247363, current_train_items 194016.\n",
            "I0314 03:06:45.052492 138313941204992 run.py:479] Algo floyd_warshall step 6063 current loss 0.375614, current_train_items 194048.\n",
            "I0314 03:06:45.523195 138313941204992 run.py:479] Algo floyd_warshall step 6064 current loss 0.534751, current_train_items 194080.\n",
            "I0314 03:06:45.557689 138313941204992 run.py:479] Algo floyd_warshall step 6065 current loss 0.022706, current_train_items 194112.\n",
            "I0314 03:06:45.614295 138313941204992 run.py:479] Algo floyd_warshall step 6066 current loss 0.066390, current_train_items 194144.\n",
            "I0314 03:06:45.781306 138313941204992 run.py:479] Algo floyd_warshall step 6067 current loss 0.313821, current_train_items 194176.\n",
            "I0314 03:06:46.053755 138313941204992 run.py:479] Algo floyd_warshall step 6068 current loss 0.357172, current_train_items 194208.\n",
            "I0314 03:06:46.507755 138313941204992 run.py:479] Algo floyd_warshall step 6069 current loss 0.556551, current_train_items 194240.\n",
            "I0314 03:06:46.532848 138313941204992 run.py:479] Algo floyd_warshall step 6070 current loss 0.028329, current_train_items 194272.\n",
            "I0314 03:06:46.578207 138313941204992 run.py:479] Algo floyd_warshall step 6071 current loss 0.127219, current_train_items 194304.\n",
            "I0314 03:06:46.711676 138313941204992 run.py:479] Algo floyd_warshall step 6072 current loss 0.275442, current_train_items 194336.\n",
            "I0314 03:06:46.946607 138313941204992 run.py:479] Algo floyd_warshall step 6073 current loss 0.381973, current_train_items 194368.\n",
            "I0314 03:06:47.354261 138313941204992 run.py:479] Algo floyd_warshall step 6074 current loss 0.528583, current_train_items 194400.\n",
            "I0314 03:06:47.379323 138313941204992 run.py:479] Algo floyd_warshall step 6075 current loss 0.017316, current_train_items 194432.\n",
            "I0314 03:06:47.427349 138313941204992 run.py:479] Algo floyd_warshall step 6076 current loss 0.065824, current_train_items 194464.\n",
            "I0314 03:06:47.559646 138313941204992 run.py:479] Algo floyd_warshall step 6077 current loss 0.193011, current_train_items 194496.\n",
            "I0314 03:06:47.781675 138313941204992 run.py:479] Algo floyd_warshall step 6078 current loss 0.375173, current_train_items 194528.\n",
            "I0314 03:06:48.209359 138313941204992 run.py:479] Algo floyd_warshall step 6079 current loss 0.602130, current_train_items 194560.\n",
            "I0314 03:06:48.232930 138313941204992 run.py:479] Algo floyd_warshall step 6080 current loss 0.021162, current_train_items 194592.\n",
            "I0314 03:06:48.277278 138313941204992 run.py:479] Algo floyd_warshall step 6081 current loss 0.037621, current_train_items 194624.\n",
            "I0314 03:06:48.409229 138313941204992 run.py:479] Algo floyd_warshall step 6082 current loss 0.247062, current_train_items 194656.\n",
            "I0314 03:06:48.626150 138313941204992 run.py:479] Algo floyd_warshall step 6083 current loss 0.366581, current_train_items 194688.\n",
            "I0314 03:06:49.048686 138313941204992 run.py:479] Algo floyd_warshall step 6084 current loss 0.626384, current_train_items 194720.\n",
            "I0314 03:06:49.073125 138313941204992 run.py:479] Algo floyd_warshall step 6085 current loss 0.013302, current_train_items 194752.\n",
            "I0314 03:06:49.122613 138313941204992 run.py:479] Algo floyd_warshall step 6086 current loss 0.045835, current_train_items 194784.\n",
            "I0314 03:06:49.252127 138313941204992 run.py:479] Algo floyd_warshall step 6087 current loss 0.252527, current_train_items 194816.\n",
            "I0314 03:06:49.488085 138313941204992 run.py:479] Algo floyd_warshall step 6088 current loss 0.405458, current_train_items 194848.\n",
            "I0314 03:06:49.972394 138313941204992 run.py:479] Algo floyd_warshall step 6089 current loss 0.541449, current_train_items 194880.\n",
            "I0314 03:06:50.007196 138313941204992 run.py:479] Algo floyd_warshall step 6090 current loss 0.174463, current_train_items 194912.\n",
            "I0314 03:06:50.064932 138313941204992 run.py:479] Algo floyd_warshall step 6091 current loss 0.090643, current_train_items 194944.\n",
            "I0314 03:06:50.222768 138313941204992 run.py:479] Algo floyd_warshall step 6092 current loss 0.276970, current_train_items 194976.\n",
            "I0314 03:06:50.485796 138313941204992 run.py:479] Algo floyd_warshall step 6093 current loss 0.482351, current_train_items 195008.\n",
            "I0314 03:06:50.972764 138313941204992 run.py:479] Algo floyd_warshall step 6094 current loss 0.582439, current_train_items 195040.\n",
            "I0314 03:06:51.006248 138313941204992 run.py:479] Algo floyd_warshall step 6095 current loss 0.018332, current_train_items 195072.\n",
            "I0314 03:06:51.064451 138313941204992 run.py:479] Algo floyd_warshall step 6096 current loss 0.072054, current_train_items 195104.\n",
            "I0314 03:06:51.221302 138313941204992 run.py:479] Algo floyd_warshall step 6097 current loss 0.270110, current_train_items 195136.\n",
            "I0314 03:06:51.483587 138313941204992 run.py:479] Algo floyd_warshall step 6098 current loss 0.418249, current_train_items 195168.\n",
            "I0314 03:06:51.965788 138313941204992 run.py:479] Algo floyd_warshall step 6099 current loss 0.632376, current_train_items 195200.\n",
            "I0314 03:06:52.008542 138313941204992 run.py:479] Algo floyd_warshall step 6100 current loss 0.018845, current_train_items 195232.\n",
            "I0314 03:06:52.116580 138313941204992 run.py:499] (val) algo floyd_warshall step 6100: {'Pi': 0.88916015625, 'score': 0.88916015625, 'examples_seen': 195232, 'step': 6100, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:06:52.116971 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.897, current avg val score is 0.889, val scores are: floyd_warshall: 0.889\n",
            "I0314 03:06:52.179603 138313941204992 run.py:479] Algo floyd_warshall step 6101 current loss 0.052930, current_train_items 195264.\n",
            "I0314 03:06:52.336648 138313941204992 run.py:479] Algo floyd_warshall step 6102 current loss 0.241892, current_train_items 195296.\n",
            "I0314 03:06:52.601028 138313941204992 run.py:479] Algo floyd_warshall step 6103 current loss 0.423761, current_train_items 195328.\n",
            "I0314 03:06:53.025457 138313941204992 run.py:479] Algo floyd_warshall step 6104 current loss 0.764354, current_train_items 195360.\n",
            "I0314 03:06:53.051467 138313941204992 run.py:479] Algo floyd_warshall step 6105 current loss 0.017700, current_train_items 195392.\n",
            "I0314 03:06:53.096431 138313941204992 run.py:479] Algo floyd_warshall step 6106 current loss 0.054331, current_train_items 195424.\n",
            "I0314 03:06:53.226334 138313941204992 run.py:479] Algo floyd_warshall step 6107 current loss 0.265612, current_train_items 195456.\n",
            "I0314 03:06:53.438467 138313941204992 run.py:479] Algo floyd_warshall step 6108 current loss 0.301779, current_train_items 195488.\n",
            "I0314 03:06:53.842178 138313941204992 run.py:479] Algo floyd_warshall step 6109 current loss 0.569516, current_train_items 195520.\n",
            "I0314 03:06:53.867885 138313941204992 run.py:479] Algo floyd_warshall step 6110 current loss 0.023584, current_train_items 195552.\n",
            "I0314 03:06:53.911959 138313941204992 run.py:479] Algo floyd_warshall step 6111 current loss 0.035252, current_train_items 195584.\n",
            "I0314 03:06:54.041680 138313941204992 run.py:479] Algo floyd_warshall step 6112 current loss 0.258552, current_train_items 195616.\n",
            "I0314 03:06:54.260864 138313941204992 run.py:479] Algo floyd_warshall step 6113 current loss 0.363239, current_train_items 195648.\n",
            "I0314 03:06:54.677719 138313941204992 run.py:479] Algo floyd_warshall step 6114 current loss 0.639763, current_train_items 195680.\n",
            "I0314 03:06:54.702532 138313941204992 run.py:479] Algo floyd_warshall step 6115 current loss 0.019723, current_train_items 195712.\n",
            "I0314 03:06:54.748316 138313941204992 run.py:479] Algo floyd_warshall step 6116 current loss 0.104151, current_train_items 195744.\n",
            "I0314 03:06:54.882070 138313941204992 run.py:479] Algo floyd_warshall step 6117 current loss 0.280405, current_train_items 195776.\n",
            "I0314 03:06:55.110417 138313941204992 run.py:479] Algo floyd_warshall step 6118 current loss 0.457875, current_train_items 195808.\n",
            "I0314 03:06:55.524386 138313941204992 run.py:479] Algo floyd_warshall step 6119 current loss 0.714774, current_train_items 195840.\n",
            "I0314 03:06:55.549222 138313941204992 run.py:479] Algo floyd_warshall step 6120 current loss 0.045587, current_train_items 195872.\n",
            "I0314 03:06:55.594439 138313941204992 run.py:479] Algo floyd_warshall step 6121 current loss 0.080769, current_train_items 195904.\n",
            "I0314 03:06:55.728840 138313941204992 run.py:479] Algo floyd_warshall step 6122 current loss 0.226204, current_train_items 195936.\n",
            "I0314 03:06:55.947014 138313941204992 run.py:479] Algo floyd_warshall step 6123 current loss 0.429172, current_train_items 195968.\n",
            "I0314 03:06:56.353202 138313941204992 run.py:479] Algo floyd_warshall step 6124 current loss 0.600253, current_train_items 196000.\n",
            "I0314 03:06:56.386646 138313941204992 run.py:479] Algo floyd_warshall step 6125 current loss 0.025249, current_train_items 196032.\n",
            "I0314 03:06:56.449307 138313941204992 run.py:479] Algo floyd_warshall step 6126 current loss 0.036302, current_train_items 196064.\n",
            "I0314 03:06:56.600272 138313941204992 run.py:479] Algo floyd_warshall step 6127 current loss 0.175598, current_train_items 196096.\n",
            "I0314 03:06:56.863060 138313941204992 run.py:479] Algo floyd_warshall step 6128 current loss 0.365477, current_train_items 196128.\n",
            "I0314 03:06:57.367568 138313941204992 run.py:479] Algo floyd_warshall step 6129 current loss 0.711356, current_train_items 196160.\n",
            "I0314 03:06:57.405207 138313941204992 run.py:479] Algo floyd_warshall step 6130 current loss 0.026841, current_train_items 196192.\n",
            "I0314 03:06:57.465083 138313941204992 run.py:479] Algo floyd_warshall step 6131 current loss 0.039169, current_train_items 196224.\n",
            "I0314 03:06:57.626356 138313941204992 run.py:479] Algo floyd_warshall step 6132 current loss 0.298109, current_train_items 196256.\n",
            "I0314 03:06:57.898129 138313941204992 run.py:479] Algo floyd_warshall step 6133 current loss 0.447483, current_train_items 196288.\n",
            "I0314 03:06:58.395969 138313941204992 run.py:479] Algo floyd_warshall step 6134 current loss 0.736638, current_train_items 196320.\n",
            "I0314 03:06:58.431432 138313941204992 run.py:479] Algo floyd_warshall step 6135 current loss 0.033748, current_train_items 196352.\n",
            "I0314 03:06:58.487629 138313941204992 run.py:479] Algo floyd_warshall step 6136 current loss 0.083651, current_train_items 196384.\n",
            "I0314 03:06:58.644808 138313941204992 run.py:479] Algo floyd_warshall step 6137 current loss 0.271796, current_train_items 196416.\n",
            "I0314 03:06:58.910924 138313941204992 run.py:479] Algo floyd_warshall step 6138 current loss 0.450567, current_train_items 196448.\n",
            "I0314 03:06:59.422551 138313941204992 run.py:479] Algo floyd_warshall step 6139 current loss 0.800978, current_train_items 196480.\n",
            "I0314 03:06:59.445568 138313941204992 run.py:479] Algo floyd_warshall step 6140 current loss 0.033835, current_train_items 196512.\n",
            "I0314 03:06:59.489565 138313941204992 run.py:479] Algo floyd_warshall step 6141 current loss 0.110106, current_train_items 196544.\n",
            "I0314 03:06:59.620190 138313941204992 run.py:479] Algo floyd_warshall step 6142 current loss 0.321484, current_train_items 196576.\n",
            "I0314 03:06:59.833648 138313941204992 run.py:479] Algo floyd_warshall step 6143 current loss 0.370754, current_train_items 196608.\n",
            "I0314 03:07:00.248777 138313941204992 run.py:479] Algo floyd_warshall step 6144 current loss 0.767030, current_train_items 196640.\n",
            "I0314 03:07:00.272689 138313941204992 run.py:479] Algo floyd_warshall step 6145 current loss 0.192648, current_train_items 196672.\n",
            "I0314 03:07:00.324649 138313941204992 run.py:479] Algo floyd_warshall step 6146 current loss 0.090347, current_train_items 196704.\n",
            "I0314 03:07:00.457420 138313941204992 run.py:479] Algo floyd_warshall step 6147 current loss 0.399730, current_train_items 196736.\n",
            "I0314 03:07:00.672625 138313941204992 run.py:479] Algo floyd_warshall step 6148 current loss 0.402694, current_train_items 196768.\n",
            "I0314 03:07:01.090531 138313941204992 run.py:479] Algo floyd_warshall step 6149 current loss 0.830088, current_train_items 196800.\n",
            "I0314 03:07:01.113542 138313941204992 run.py:479] Algo floyd_warshall step 6150 current loss 0.057666, current_train_items 196832.\n",
            "I0314 03:07:01.201900 138313941204992 run.py:499] (val) algo floyd_warshall step 6150: {'Pi': 0.861572265625, 'score': 0.861572265625, 'examples_seen': 196832, 'step': 6150, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:07:01.202127 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.897, current avg val score is 0.862, val scores are: floyd_warshall: 0.862\n",
            "I0314 03:07:01.248916 138313941204992 run.py:479] Algo floyd_warshall step 6151 current loss 0.111881, current_train_items 196864.\n",
            "I0314 03:07:01.379245 138313941204992 run.py:479] Algo floyd_warshall step 6152 current loss 0.344345, current_train_items 196896.\n",
            "I0314 03:07:01.599047 138313941204992 run.py:479] Algo floyd_warshall step 6153 current loss 0.437954, current_train_items 196928.\n",
            "I0314 03:07:02.012894 138313941204992 run.py:479] Algo floyd_warshall step 6154 current loss 0.740246, current_train_items 196960.\n",
            "I0314 03:07:02.037894 138313941204992 run.py:479] Algo floyd_warshall step 6155 current loss 0.041653, current_train_items 196992.\n",
            "I0314 03:07:02.083984 138313941204992 run.py:479] Algo floyd_warshall step 6156 current loss 0.067236, current_train_items 197024.\n",
            "I0314 03:07:02.214469 138313941204992 run.py:479] Algo floyd_warshall step 6157 current loss 0.270109, current_train_items 197056.\n",
            "I0314 03:07:02.440641 138313941204992 run.py:479] Algo floyd_warshall step 6158 current loss 0.367910, current_train_items 197088.\n",
            "I0314 03:07:02.859010 138313941204992 run.py:479] Algo floyd_warshall step 6159 current loss 0.652470, current_train_items 197120.\n",
            "I0314 03:07:02.883004 138313941204992 run.py:479] Algo floyd_warshall step 6160 current loss 0.031757, current_train_items 197152.\n",
            "I0314 03:07:02.929734 138313941204992 run.py:479] Algo floyd_warshall step 6161 current loss 0.081372, current_train_items 197184.\n",
            "I0314 03:07:03.055640 138313941204992 run.py:479] Algo floyd_warshall step 6162 current loss 0.341337, current_train_items 197216.\n",
            "I0314 03:07:03.276834 138313941204992 run.py:479] Algo floyd_warshall step 6163 current loss 0.432640, current_train_items 197248.\n",
            "I0314 03:07:03.694556 138313941204992 run.py:479] Algo floyd_warshall step 6164 current loss 0.688655, current_train_items 197280.\n",
            "I0314 03:07:03.718378 138313941204992 run.py:479] Algo floyd_warshall step 6165 current loss 0.011772, current_train_items 197312.\n",
            "I0314 03:07:03.763314 138313941204992 run.py:479] Algo floyd_warshall step 6166 current loss 0.111794, current_train_items 197344.\n",
            "I0314 03:07:03.891458 138313941204992 run.py:479] Algo floyd_warshall step 6167 current loss 0.215013, current_train_items 197376.\n",
            "I0314 03:07:04.114679 138313941204992 run.py:479] Algo floyd_warshall step 6168 current loss 0.396552, current_train_items 197408.\n",
            "I0314 03:07:04.521580 138313941204992 run.py:479] Algo floyd_warshall step 6169 current loss 0.681290, current_train_items 197440.\n",
            "I0314 03:07:04.545041 138313941204992 run.py:479] Algo floyd_warshall step 6170 current loss 0.025394, current_train_items 197472.\n",
            "I0314 03:07:04.589965 138313941204992 run.py:479] Algo floyd_warshall step 6171 current loss 0.085285, current_train_items 197504.\n",
            "I0314 03:07:04.721054 138313941204992 run.py:479] Algo floyd_warshall step 6172 current loss 0.219269, current_train_items 197536.\n",
            "I0314 03:07:04.941962 138313941204992 run.py:479] Algo floyd_warshall step 6173 current loss 0.332071, current_train_items 197568.\n",
            "I0314 03:07:05.350610 138313941204992 run.py:479] Algo floyd_warshall step 6174 current loss 0.585263, current_train_items 197600.\n",
            "I0314 03:07:05.373301 138313941204992 run.py:479] Algo floyd_warshall step 6175 current loss 0.043717, current_train_items 197632.\n",
            "I0314 03:07:05.420317 138313941204992 run.py:479] Algo floyd_warshall step 6176 current loss 0.075601, current_train_items 197664.\n",
            "I0314 03:07:05.554403 138313941204992 run.py:479] Algo floyd_warshall step 6177 current loss 0.282830, current_train_items 197696.\n",
            "I0314 03:07:05.769081 138313941204992 run.py:479] Algo floyd_warshall step 6178 current loss 0.374804, current_train_items 197728.\n",
            "I0314 03:07:06.184954 138313941204992 run.py:479] Algo floyd_warshall step 6179 current loss 0.741270, current_train_items 197760.\n",
            "I0314 03:07:06.208010 138313941204992 run.py:479] Algo floyd_warshall step 6180 current loss 0.029095, current_train_items 197792.\n",
            "I0314 03:07:06.251230 138313941204992 run.py:479] Algo floyd_warshall step 6181 current loss 0.045025, current_train_items 197824.\n",
            "I0314 03:07:06.379615 138313941204992 run.py:479] Algo floyd_warshall step 6182 current loss 0.247730, current_train_items 197856.\n",
            "I0314 03:07:06.597845 138313941204992 run.py:479] Algo floyd_warshall step 6183 current loss 0.437301, current_train_items 197888.\n",
            "I0314 03:07:07.005137 138313941204992 run.py:479] Algo floyd_warshall step 6184 current loss 0.581881, current_train_items 197920.\n",
            "I0314 03:07:07.028511 138313941204992 run.py:479] Algo floyd_warshall step 6185 current loss 0.009934, current_train_items 197952.\n",
            "I0314 03:07:07.074427 138313941204992 run.py:479] Algo floyd_warshall step 6186 current loss 0.062434, current_train_items 197984.\n",
            "I0314 03:07:07.206270 138313941204992 run.py:479] Algo floyd_warshall step 6187 current loss 0.279723, current_train_items 198016.\n",
            "I0314 03:07:07.425861 138313941204992 run.py:479] Algo floyd_warshall step 6188 current loss 0.438408, current_train_items 198048.\n",
            "I0314 03:07:07.849856 138313941204992 run.py:479] Algo floyd_warshall step 6189 current loss 0.787665, current_train_items 198080.\n",
            "I0314 03:07:07.873631 138313941204992 run.py:479] Algo floyd_warshall step 6190 current loss 0.064461, current_train_items 198112.\n",
            "I0314 03:07:07.918388 138313941204992 run.py:479] Algo floyd_warshall step 6191 current loss 0.089546, current_train_items 198144.\n",
            "I0314 03:07:08.048070 138313941204992 run.py:479] Algo floyd_warshall step 6192 current loss 0.237698, current_train_items 198176.\n",
            "I0314 03:07:08.271630 138313941204992 run.py:479] Algo floyd_warshall step 6193 current loss 0.456275, current_train_items 198208.\n",
            "I0314 03:07:08.691123 138313941204992 run.py:479] Algo floyd_warshall step 6194 current loss 0.732062, current_train_items 198240.\n",
            "I0314 03:07:08.714451 138313941204992 run.py:479] Algo floyd_warshall step 6195 current loss 0.011066, current_train_items 198272.\n",
            "I0314 03:07:08.758064 138313941204992 run.py:479] Algo floyd_warshall step 6196 current loss 0.042303, current_train_items 198304.\n",
            "I0314 03:07:08.885876 138313941204992 run.py:479] Algo floyd_warshall step 6197 current loss 0.260377, current_train_items 198336.\n",
            "I0314 03:07:09.106729 138313941204992 run.py:479] Algo floyd_warshall step 6198 current loss 0.466558, current_train_items 198368.\n",
            "I0314 03:07:09.523450 138313941204992 run.py:479] Algo floyd_warshall step 6199 current loss 0.596592, current_train_items 198400.\n",
            "I0314 03:07:09.565880 138313941204992 run.py:479] Algo floyd_warshall step 6200 current loss 0.030685, current_train_items 198432.\n",
            "I0314 03:07:09.667055 138313941204992 run.py:499] (val) algo floyd_warshall step 6200: {'Pi': 0.88922119140625, 'score': 0.88922119140625, 'examples_seen': 198432, 'step': 6200, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:07:09.667389 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.897, current avg val score is 0.889, val scores are: floyd_warshall: 0.889\n",
            "I0314 03:07:09.726597 138313941204992 run.py:479] Algo floyd_warshall step 6201 current loss 0.064167, current_train_items 198464.\n",
            "I0314 03:07:09.889792 138313941204992 run.py:479] Algo floyd_warshall step 6202 current loss 0.228060, current_train_items 198496.\n",
            "I0314 03:07:10.153471 138313941204992 run.py:479] Algo floyd_warshall step 6203 current loss 0.443056, current_train_items 198528.\n",
            "I0314 03:07:10.642006 138313941204992 run.py:479] Algo floyd_warshall step 6204 current loss 0.595633, current_train_items 198560.\n",
            "I0314 03:07:10.682682 138313941204992 run.py:479] Algo floyd_warshall step 6205 current loss 0.029536, current_train_items 198592.\n",
            "I0314 03:07:10.739697 138313941204992 run.py:479] Algo floyd_warshall step 6206 current loss 0.116383, current_train_items 198624.\n",
            "I0314 03:07:10.902037 138313941204992 run.py:479] Algo floyd_warshall step 6207 current loss 0.266810, current_train_items 198656.\n",
            "I0314 03:07:11.166537 138313941204992 run.py:479] Algo floyd_warshall step 6208 current loss 0.416973, current_train_items 198688.\n",
            "I0314 03:07:11.660189 138313941204992 run.py:479] Algo floyd_warshall step 6209 current loss 0.548691, current_train_items 198720.\n",
            "I0314 03:07:11.695391 138313941204992 run.py:479] Algo floyd_warshall step 6210 current loss 0.012037, current_train_items 198752.\n",
            "I0314 03:07:11.753314 138313941204992 run.py:479] Algo floyd_warshall step 6211 current loss 0.063888, current_train_items 198784.\n",
            "I0314 03:07:11.913477 138313941204992 run.py:479] Algo floyd_warshall step 6212 current loss 0.221240, current_train_items 198816.\n",
            "I0314 03:07:12.185381 138313941204992 run.py:479] Algo floyd_warshall step 6213 current loss 0.369410, current_train_items 198848.\n",
            "I0314 03:07:12.704310 138313941204992 run.py:479] Algo floyd_warshall step 6214 current loss 0.768818, current_train_items 198880.\n",
            "I0314 03:07:12.728954 138313941204992 run.py:479] Algo floyd_warshall step 6215 current loss 0.018244, current_train_items 198912.\n",
            "I0314 03:07:12.773894 138313941204992 run.py:479] Algo floyd_warshall step 6216 current loss 0.147207, current_train_items 198944.\n",
            "I0314 03:07:12.907297 138313941204992 run.py:479] Algo floyd_warshall step 6217 current loss 0.376692, current_train_items 198976.\n",
            "I0314 03:07:13.125373 138313941204992 run.py:479] Algo floyd_warshall step 6218 current loss 0.368486, current_train_items 199008.\n",
            "I0314 03:07:13.535844 138313941204992 run.py:479] Algo floyd_warshall step 6219 current loss 0.698246, current_train_items 199040.\n",
            "I0314 03:07:13.559223 138313941204992 run.py:479] Algo floyd_warshall step 6220 current loss 0.030168, current_train_items 199072.\n",
            "I0314 03:07:13.602995 138313941204992 run.py:479] Algo floyd_warshall step 6221 current loss 0.044050, current_train_items 199104.\n",
            "I0314 03:07:13.730183 138313941204992 run.py:479] Algo floyd_warshall step 6222 current loss 0.208561, current_train_items 199136.\n",
            "I0314 03:07:13.955448 138313941204992 run.py:479] Algo floyd_warshall step 6223 current loss 0.540658, current_train_items 199168.\n",
            "I0314 03:07:14.377502 138313941204992 run.py:479] Algo floyd_warshall step 6224 current loss 0.761038, current_train_items 199200.\n",
            "I0314 03:07:14.402642 138313941204992 run.py:479] Algo floyd_warshall step 6225 current loss 0.017836, current_train_items 199232.\n",
            "I0314 03:07:14.449163 138313941204992 run.py:479] Algo floyd_warshall step 6226 current loss 0.069377, current_train_items 199264.\n",
            "I0314 03:07:14.578661 138313941204992 run.py:479] Algo floyd_warshall step 6227 current loss 0.252850, current_train_items 199296.\n",
            "I0314 03:07:14.807093 138313941204992 run.py:479] Algo floyd_warshall step 6228 current loss 0.400217, current_train_items 199328.\n",
            "I0314 03:07:15.232714 138313941204992 run.py:479] Algo floyd_warshall step 6229 current loss 0.802601, current_train_items 199360.\n",
            "I0314 03:07:15.256539 138313941204992 run.py:479] Algo floyd_warshall step 6230 current loss 0.019261, current_train_items 199392.\n",
            "I0314 03:07:15.301231 138313941204992 run.py:479] Algo floyd_warshall step 6231 current loss 0.070072, current_train_items 199424.\n",
            "I0314 03:07:15.431110 138313941204992 run.py:479] Algo floyd_warshall step 6232 current loss 0.269151, current_train_items 199456.\n",
            "I0314 03:07:15.645627 138313941204992 run.py:479] Algo floyd_warshall step 6233 current loss 0.409861, current_train_items 199488.\n",
            "I0314 03:07:16.064527 138313941204992 run.py:479] Algo floyd_warshall step 6234 current loss 0.650646, current_train_items 199520.\n",
            "I0314 03:07:16.088994 138313941204992 run.py:479] Algo floyd_warshall step 6235 current loss 0.032192, current_train_items 199552.\n",
            "I0314 03:07:16.135139 138313941204992 run.py:479] Algo floyd_warshall step 6236 current loss 0.062430, current_train_items 199584.\n",
            "I0314 03:07:16.262304 138313941204992 run.py:479] Algo floyd_warshall step 6237 current loss 0.198595, current_train_items 199616.\n",
            "I0314 03:07:16.486694 138313941204992 run.py:479] Algo floyd_warshall step 6238 current loss 0.389770, current_train_items 199648.\n",
            "I0314 03:07:16.899662 138313941204992 run.py:479] Algo floyd_warshall step 6239 current loss 0.646526, current_train_items 199680.\n",
            "I0314 03:07:16.923853 138313941204992 run.py:479] Algo floyd_warshall step 6240 current loss 0.016286, current_train_items 199712.\n",
            "I0314 03:07:16.970416 138313941204992 run.py:479] Algo floyd_warshall step 6241 current loss 0.142615, current_train_items 199744.\n",
            "I0314 03:07:17.099773 138313941204992 run.py:479] Algo floyd_warshall step 6242 current loss 0.180429, current_train_items 199776.\n",
            "I0314 03:07:17.317388 138313941204992 run.py:479] Algo floyd_warshall step 6243 current loss 0.344081, current_train_items 199808.\n",
            "I0314 03:07:17.731063 138313941204992 run.py:479] Algo floyd_warshall step 6244 current loss 0.584879, current_train_items 199840.\n",
            "I0314 03:07:17.755371 138313941204992 run.py:479] Algo floyd_warshall step 6245 current loss 0.019165, current_train_items 199872.\n",
            "I0314 03:07:17.805003 138313941204992 run.py:479] Algo floyd_warshall step 6246 current loss 0.049374, current_train_items 199904.\n",
            "I0314 03:07:17.932999 138313941204992 run.py:479] Algo floyd_warshall step 6247 current loss 0.176750, current_train_items 199936.\n",
            "I0314 03:07:18.149437 138313941204992 run.py:479] Algo floyd_warshall step 6248 current loss 0.380968, current_train_items 199968.\n",
            "I0314 03:07:18.577007 138313941204992 run.py:479] Algo floyd_warshall step 6249 current loss 0.648816, current_train_items 200000.\n",
            "I0314 03:07:18.601499 138313941204992 run.py:479] Algo floyd_warshall step 6250 current loss 0.015617, current_train_items 200032.\n",
            "I0314 03:07:18.688999 138313941204992 run.py:499] (val) algo floyd_warshall step 6250: {'Pi': 0.89508056640625, 'score': 0.89508056640625, 'examples_seen': 200032, 'step': 6250, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:07:18.689250 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.897, current avg val score is 0.895, val scores are: floyd_warshall: 0.895\n",
            "I0314 03:07:18.736899 138313941204992 run.py:479] Algo floyd_warshall step 6251 current loss 0.049166, current_train_items 200064.\n",
            "I0314 03:07:18.869812 138313941204992 run.py:479] Algo floyd_warshall step 6252 current loss 0.180994, current_train_items 200096.\n",
            "I0314 03:07:19.088450 138313941204992 run.py:479] Algo floyd_warshall step 6253 current loss 0.365977, current_train_items 200128.\n",
            "I0314 03:07:19.494382 138313941204992 run.py:479] Algo floyd_warshall step 6254 current loss 0.522450, current_train_items 200160.\n",
            "I0314 03:07:19.518965 138313941204992 run.py:479] Algo floyd_warshall step 6255 current loss 0.036720, current_train_items 200192.\n",
            "I0314 03:07:19.567008 138313941204992 run.py:479] Algo floyd_warshall step 6256 current loss 0.081853, current_train_items 200224.\n",
            "I0314 03:07:19.698139 138313941204992 run.py:479] Algo floyd_warshall step 6257 current loss 0.285749, current_train_items 200256.\n",
            "I0314 03:07:19.922111 138313941204992 run.py:479] Algo floyd_warshall step 6258 current loss 0.420115, current_train_items 200288.\n",
            "I0314 03:07:20.341856 138313941204992 run.py:479] Algo floyd_warshall step 6259 current loss 0.588855, current_train_items 200320.\n",
            "I0314 03:07:20.365256 138313941204992 run.py:479] Algo floyd_warshall step 6260 current loss 0.022488, current_train_items 200352.\n",
            "I0314 03:07:20.410201 138313941204992 run.py:479] Algo floyd_warshall step 6261 current loss 0.048432, current_train_items 200384.\n",
            "I0314 03:07:20.541033 138313941204992 run.py:479] Algo floyd_warshall step 6262 current loss 0.302691, current_train_items 200416.\n",
            "I0314 03:07:20.754926 138313941204992 run.py:479] Algo floyd_warshall step 6263 current loss 0.422939, current_train_items 200448.\n",
            "I0314 03:07:21.165536 138313941204992 run.py:479] Algo floyd_warshall step 6264 current loss 0.846038, current_train_items 200480.\n",
            "I0314 03:07:21.188897 138313941204992 run.py:479] Algo floyd_warshall step 6265 current loss 0.021022, current_train_items 200512.\n",
            "I0314 03:07:21.234409 138313941204992 run.py:479] Algo floyd_warshall step 6266 current loss 0.074587, current_train_items 200544.\n",
            "I0314 03:07:21.362787 138313941204992 run.py:479] Algo floyd_warshall step 6267 current loss 0.298806, current_train_items 200576.\n",
            "I0314 03:07:21.582224 138313941204992 run.py:479] Algo floyd_warshall step 6268 current loss 0.424977, current_train_items 200608.\n",
            "I0314 03:07:21.991389 138313941204992 run.py:479] Algo floyd_warshall step 6269 current loss 0.660376, current_train_items 200640.\n",
            "I0314 03:07:22.015031 138313941204992 run.py:479] Algo floyd_warshall step 6270 current loss 0.016290, current_train_items 200672.\n",
            "I0314 03:07:22.059536 138313941204992 run.py:479] Algo floyd_warshall step 6271 current loss 0.155327, current_train_items 200704.\n",
            "I0314 03:07:22.190212 138313941204992 run.py:479] Algo floyd_warshall step 6272 current loss 0.278825, current_train_items 200736.\n",
            "I0314 03:07:22.416272 138313941204992 run.py:479] Algo floyd_warshall step 6273 current loss 0.442200, current_train_items 200768.\n",
            "I0314 03:07:22.902629 138313941204992 run.py:479] Algo floyd_warshall step 6274 current loss 0.681465, current_train_items 200800.\n",
            "I0314 03:07:22.952427 138313941204992 run.py:479] Algo floyd_warshall step 6275 current loss 0.011768, current_train_items 200832.\n",
            "I0314 03:07:23.027476 138313941204992 run.py:479] Algo floyd_warshall step 6276 current loss 0.043503, current_train_items 200864.\n",
            "I0314 03:07:23.189296 138313941204992 run.py:479] Algo floyd_warshall step 6277 current loss 0.267475, current_train_items 200896.\n",
            "I0314 03:07:23.444808 138313941204992 run.py:479] Algo floyd_warshall step 6278 current loss 0.338695, current_train_items 200928.\n",
            "I0314 03:07:23.941928 138313941204992 run.py:479] Algo floyd_warshall step 6279 current loss 0.742623, current_train_items 200960.\n",
            "I0314 03:07:23.975368 138313941204992 run.py:479] Algo floyd_warshall step 6280 current loss 0.018722, current_train_items 200992.\n",
            "I0314 03:07:24.034503 138313941204992 run.py:479] Algo floyd_warshall step 6281 current loss 0.063201, current_train_items 201024.\n",
            "I0314 03:07:24.198904 138313941204992 run.py:479] Algo floyd_warshall step 6282 current loss 0.212303, current_train_items 201056.\n",
            "I0314 03:07:24.454608 138313941204992 run.py:479] Algo floyd_warshall step 6283 current loss 0.299939, current_train_items 201088.\n",
            "I0314 03:07:24.949170 138313941204992 run.py:479] Algo floyd_warshall step 6284 current loss 0.643634, current_train_items 201120.\n",
            "I0314 03:07:24.982457 138313941204992 run.py:479] Algo floyd_warshall step 6285 current loss 0.042596, current_train_items 201152.\n",
            "I0314 03:07:25.040781 138313941204992 run.py:479] Algo floyd_warshall step 6286 current loss 0.064902, current_train_items 201184.\n",
            "I0314 03:07:25.214167 138313941204992 run.py:479] Algo floyd_warshall step 6287 current loss 0.225680, current_train_items 201216.\n",
            "I0314 03:07:25.484906 138313941204992 run.py:479] Algo floyd_warshall step 6288 current loss 0.441291, current_train_items 201248.\n",
            "I0314 03:07:25.918431 138313941204992 run.py:479] Algo floyd_warshall step 6289 current loss 0.672039, current_train_items 201280.\n",
            "I0314 03:07:25.941930 138313941204992 run.py:479] Algo floyd_warshall step 6290 current loss 0.044245, current_train_items 201312.\n",
            "I0314 03:07:25.987178 138313941204992 run.py:479] Algo floyd_warshall step 6291 current loss 0.092628, current_train_items 201344.\n",
            "I0314 03:07:26.122446 138313941204992 run.py:479] Algo floyd_warshall step 6292 current loss 0.276853, current_train_items 201376.\n",
            "I0314 03:07:26.355056 138313941204992 run.py:479] Algo floyd_warshall step 6293 current loss 0.340484, current_train_items 201408.\n",
            "I0314 03:07:26.765890 138313941204992 run.py:479] Algo floyd_warshall step 6294 current loss 0.564880, current_train_items 201440.\n",
            "I0314 03:07:26.792482 138313941204992 run.py:479] Algo floyd_warshall step 6295 current loss 0.030957, current_train_items 201472.\n",
            "I0314 03:07:26.837517 138313941204992 run.py:479] Algo floyd_warshall step 6296 current loss 0.061122, current_train_items 201504.\n",
            "I0314 03:07:26.967304 138313941204992 run.py:479] Algo floyd_warshall step 6297 current loss 0.171917, current_train_items 201536.\n",
            "I0314 03:07:27.184853 138313941204992 run.py:479] Algo floyd_warshall step 6298 current loss 0.291658, current_train_items 201568.\n",
            "I0314 03:07:27.595489 138313941204992 run.py:479] Algo floyd_warshall step 6299 current loss 0.571800, current_train_items 201600.\n",
            "I0314 03:07:27.618912 138313941204992 run.py:479] Algo floyd_warshall step 6300 current loss 0.024832, current_train_items 201632.\n",
            "I0314 03:07:27.707231 138313941204992 run.py:499] (val) algo floyd_warshall step 6300: {'Pi': 0.9080810546875, 'score': 0.9080810546875, 'examples_seen': 201632, 'step': 6300, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:07:27.707495 138313941204992 run.py:516] Checkpointing best model, best avg val score was 0.897, current avg val score is 0.908, val scores are: floyd_warshall: 0.908\n",
            "I0314 03:07:27.790338 138313941204992 run.py:479] Algo floyd_warshall step 6301 current loss 0.062221, current_train_items 201664.\n",
            "I0314 03:07:27.930509 138313941204992 run.py:479] Algo floyd_warshall step 6302 current loss 0.211409, current_train_items 201696.\n",
            "I0314 03:07:28.149283 138313941204992 run.py:479] Algo floyd_warshall step 6303 current loss 0.423013, current_train_items 201728.\n",
            "I0314 03:07:28.591612 138313941204992 run.py:479] Algo floyd_warshall step 6304 current loss 0.768124, current_train_items 201760.\n",
            "I0314 03:07:28.618212 138313941204992 run.py:479] Algo floyd_warshall step 6305 current loss 0.017901, current_train_items 201792.\n",
            "I0314 03:07:28.664622 138313941204992 run.py:479] Algo floyd_warshall step 6306 current loss 0.091433, current_train_items 201824.\n",
            "I0314 03:07:28.798647 138313941204992 run.py:479] Algo floyd_warshall step 6307 current loss 0.217715, current_train_items 201856.\n",
            "I0314 03:07:29.017289 138313941204992 run.py:479] Algo floyd_warshall step 6308 current loss 0.320662, current_train_items 201888.\n",
            "I0314 03:07:29.436549 138313941204992 run.py:479] Algo floyd_warshall step 6309 current loss 0.581847, current_train_items 201920.\n",
            "I0314 03:07:29.460330 138313941204992 run.py:479] Algo floyd_warshall step 6310 current loss 0.023311, current_train_items 201952.\n",
            "I0314 03:07:29.505903 138313941204992 run.py:479] Algo floyd_warshall step 6311 current loss 0.068837, current_train_items 201984.\n",
            "I0314 03:07:29.637002 138313941204992 run.py:479] Algo floyd_warshall step 6312 current loss 0.287834, current_train_items 202016.\n",
            "I0314 03:07:29.864973 138313941204992 run.py:479] Algo floyd_warshall step 6313 current loss 0.331052, current_train_items 202048.\n",
            "I0314 03:07:30.291805 138313941204992 run.py:479] Algo floyd_warshall step 6314 current loss 0.721739, current_train_items 202080.\n",
            "I0314 03:07:30.316390 138313941204992 run.py:479] Algo floyd_warshall step 6315 current loss 0.022991, current_train_items 202112.\n",
            "I0314 03:07:30.360111 138313941204992 run.py:479] Algo floyd_warshall step 6316 current loss 0.076842, current_train_items 202144.\n",
            "I0314 03:07:30.490039 138313941204992 run.py:479] Algo floyd_warshall step 6317 current loss 0.219252, current_train_items 202176.\n",
            "I0314 03:07:30.713834 138313941204992 run.py:479] Algo floyd_warshall step 6318 current loss 0.470744, current_train_items 202208.\n",
            "I0314 03:07:31.123662 138313941204992 run.py:479] Algo floyd_warshall step 6319 current loss 0.549195, current_train_items 202240.\n",
            "I0314 03:07:31.149130 138313941204992 run.py:479] Algo floyd_warshall step 6320 current loss 0.031134, current_train_items 202272.\n",
            "I0314 03:07:31.194133 138313941204992 run.py:479] Algo floyd_warshall step 6321 current loss 0.130557, current_train_items 202304.\n",
            "I0314 03:07:31.326679 138313941204992 run.py:479] Algo floyd_warshall step 6322 current loss 0.247638, current_train_items 202336.\n",
            "I0314 03:07:31.551281 138313941204992 run.py:479] Algo floyd_warshall step 6323 current loss 0.381638, current_train_items 202368.\n",
            "I0314 03:07:31.973748 138313941204992 run.py:479] Algo floyd_warshall step 6324 current loss 0.641641, current_train_items 202400.\n",
            "I0314 03:07:31.996738 138313941204992 run.py:479] Algo floyd_warshall step 6325 current loss 0.014512, current_train_items 202432.\n",
            "I0314 03:07:32.042520 138313941204992 run.py:479] Algo floyd_warshall step 6326 current loss 0.075464, current_train_items 202464.\n",
            "I0314 03:07:32.175623 138313941204992 run.py:479] Algo floyd_warshall step 6327 current loss 0.258979, current_train_items 202496.\n",
            "I0314 03:07:32.404077 138313941204992 run.py:479] Algo floyd_warshall step 6328 current loss 0.356783, current_train_items 202528.\n",
            "I0314 03:07:32.823365 138313941204992 run.py:479] Algo floyd_warshall step 6329 current loss 0.823594, current_train_items 202560.\n",
            "I0314 03:07:32.849249 138313941204992 run.py:479] Algo floyd_warshall step 6330 current loss 0.024178, current_train_items 202592.\n",
            "I0314 03:07:32.895740 138313941204992 run.py:479] Algo floyd_warshall step 6331 current loss 0.086671, current_train_items 202624.\n",
            "I0314 03:07:33.027359 138313941204992 run.py:479] Algo floyd_warshall step 6332 current loss 0.259439, current_train_items 202656.\n",
            "I0314 03:07:33.252260 138313941204992 run.py:479] Algo floyd_warshall step 6333 current loss 0.424646, current_train_items 202688.\n",
            "I0314 03:07:33.673403 138313941204992 run.py:479] Algo floyd_warshall step 6334 current loss 0.579421, current_train_items 202720.\n",
            "I0314 03:07:33.698043 138313941204992 run.py:479] Algo floyd_warshall step 6335 current loss 0.036565, current_train_items 202752.\n",
            "I0314 03:07:33.744503 138313941204992 run.py:479] Algo floyd_warshall step 6336 current loss 0.073377, current_train_items 202784.\n",
            "I0314 03:07:33.879501 138313941204992 run.py:479] Algo floyd_warshall step 6337 current loss 0.223485, current_train_items 202816.\n",
            "I0314 03:07:34.108253 138313941204992 run.py:479] Algo floyd_warshall step 6338 current loss 0.417096, current_train_items 202848.\n",
            "I0314 03:07:34.532453 138313941204992 run.py:479] Algo floyd_warshall step 6339 current loss 0.669760, current_train_items 202880.\n",
            "I0314 03:07:34.555612 138313941204992 run.py:479] Algo floyd_warshall step 6340 current loss 0.036713, current_train_items 202912.\n",
            "I0314 03:07:34.602939 138313941204992 run.py:479] Algo floyd_warshall step 6341 current loss 0.036651, current_train_items 202944.\n",
            "I0314 03:07:34.732879 138313941204992 run.py:479] Algo floyd_warshall step 6342 current loss 0.148499, current_train_items 202976.\n",
            "I0314 03:07:34.949592 138313941204992 run.py:479] Algo floyd_warshall step 6343 current loss 0.491845, current_train_items 203008.\n",
            "I0314 03:07:35.375975 138313941204992 run.py:479] Algo floyd_warshall step 6344 current loss 0.843334, current_train_items 203040.\n",
            "I0314 03:07:35.401983 138313941204992 run.py:479] Algo floyd_warshall step 6345 current loss 0.026296, current_train_items 203072.\n",
            "I0314 03:07:35.449174 138313941204992 run.py:479] Algo floyd_warshall step 6346 current loss 0.101909, current_train_items 203104.\n",
            "I0314 03:07:35.585631 138313941204992 run.py:479] Algo floyd_warshall step 6347 current loss 0.211719, current_train_items 203136.\n",
            "I0314 03:07:35.851556 138313941204992 run.py:479] Algo floyd_warshall step 6348 current loss 0.346994, current_train_items 203168.\n",
            "I0314 03:07:36.335709 138313941204992 run.py:479] Algo floyd_warshall step 6349 current loss 0.593164, current_train_items 203200.\n",
            "I0314 03:07:36.371923 138313941204992 run.py:479] Algo floyd_warshall step 6350 current loss 0.018335, current_train_items 203232.\n",
            "I0314 03:07:36.502780 138313941204992 run.py:499] (val) algo floyd_warshall step 6350: {'Pi': 0.86773681640625, 'score': 0.86773681640625, 'examples_seen': 203232, 'step': 6350, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:07:36.503107 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.908, current avg val score is 0.868, val scores are: floyd_warshall: 0.868\n",
            "I0314 03:07:36.565826 138313941204992 run.py:479] Algo floyd_warshall step 6351 current loss 0.089035, current_train_items 203264.\n",
            "I0314 03:07:36.733541 138313941204992 run.py:479] Algo floyd_warshall step 6352 current loss 0.203084, current_train_items 203296.\n",
            "I0314 03:07:37.001342 138313941204992 run.py:479] Algo floyd_warshall step 6353 current loss 0.404699, current_train_items 203328.\n",
            "I0314 03:07:37.500029 138313941204992 run.py:479] Algo floyd_warshall step 6354 current loss 0.476492, current_train_items 203360.\n",
            "I0314 03:07:37.538691 138313941204992 run.py:479] Algo floyd_warshall step 6355 current loss 0.022635, current_train_items 203392.\n",
            "I0314 03:07:37.599284 138313941204992 run.py:479] Algo floyd_warshall step 6356 current loss 0.072349, current_train_items 203424.\n",
            "I0314 03:07:37.760968 138313941204992 run.py:479] Algo floyd_warshall step 6357 current loss 0.247029, current_train_items 203456.\n",
            "I0314 03:07:38.017370 138313941204992 run.py:479] Algo floyd_warshall step 6358 current loss 0.261086, current_train_items 203488.\n",
            "I0314 03:07:38.516542 138313941204992 run.py:479] Algo floyd_warshall step 6359 current loss 0.637002, current_train_items 203520.\n",
            "I0314 03:07:38.563083 138313941204992 run.py:479] Algo floyd_warshall step 6360 current loss 0.009116, current_train_items 203552.\n",
            "I0314 03:07:38.625584 138313941204992 run.py:479] Algo floyd_warshall step 6361 current loss 0.099059, current_train_items 203584.\n",
            "I0314 03:07:38.783511 138313941204992 run.py:479] Algo floyd_warshall step 6362 current loss 0.180794, current_train_items 203616.\n",
            "I0314 03:07:39.003110 138313941204992 run.py:479] Algo floyd_warshall step 6363 current loss 0.407808, current_train_items 203648.\n",
            "I0314 03:07:39.430050 138313941204992 run.py:479] Algo floyd_warshall step 6364 current loss 0.653898, current_train_items 203680.\n",
            "I0314 03:07:39.453806 138313941204992 run.py:479] Algo floyd_warshall step 6365 current loss 0.010280, current_train_items 203712.\n",
            "I0314 03:07:39.498324 138313941204992 run.py:479] Algo floyd_warshall step 6366 current loss 0.127136, current_train_items 203744.\n",
            "I0314 03:07:39.629093 138313941204992 run.py:479] Algo floyd_warshall step 6367 current loss 0.252601, current_train_items 203776.\n",
            "I0314 03:07:39.859936 138313941204992 run.py:479] Algo floyd_warshall step 6368 current loss 0.438233, current_train_items 203808.\n",
            "I0314 03:07:40.269258 138313941204992 run.py:479] Algo floyd_warshall step 6369 current loss 0.602690, current_train_items 203840.\n",
            "I0314 03:07:40.293796 138313941204992 run.py:479] Algo floyd_warshall step 6370 current loss 0.015187, current_train_items 203872.\n",
            "I0314 03:07:40.340247 138313941204992 run.py:479] Algo floyd_warshall step 6371 current loss 0.042938, current_train_items 203904.\n",
            "I0314 03:07:40.472448 138313941204992 run.py:479] Algo floyd_warshall step 6372 current loss 0.305514, current_train_items 203936.\n",
            "I0314 03:07:40.685111 138313941204992 run.py:479] Algo floyd_warshall step 6373 current loss 0.392149, current_train_items 203968.\n",
            "I0314 03:07:41.088721 138313941204992 run.py:479] Algo floyd_warshall step 6374 current loss 0.522039, current_train_items 204000.\n",
            "I0314 03:07:41.112955 138313941204992 run.py:479] Algo floyd_warshall step 6375 current loss 0.023617, current_train_items 204032.\n",
            "I0314 03:07:41.159709 138313941204992 run.py:479] Algo floyd_warshall step 6376 current loss 0.053023, current_train_items 204064.\n",
            "I0314 03:07:41.288769 138313941204992 run.py:479] Algo floyd_warshall step 6377 current loss 0.227868, current_train_items 204096.\n",
            "I0314 03:07:41.500671 138313941204992 run.py:479] Algo floyd_warshall step 6378 current loss 0.421404, current_train_items 204128.\n",
            "I0314 03:07:41.922201 138313941204992 run.py:479] Algo floyd_warshall step 6379 current loss 0.671810, current_train_items 204160.\n",
            "I0314 03:07:41.945212 138313941204992 run.py:479] Algo floyd_warshall step 6380 current loss 0.021315, current_train_items 204192.\n",
            "I0314 03:07:41.990082 138313941204992 run.py:479] Algo floyd_warshall step 6381 current loss 0.067467, current_train_items 204224.\n",
            "I0314 03:07:42.118449 138313941204992 run.py:479] Algo floyd_warshall step 6382 current loss 0.276258, current_train_items 204256.\n",
            "I0314 03:07:42.345569 138313941204992 run.py:479] Algo floyd_warshall step 6383 current loss 0.368754, current_train_items 204288.\n",
            "I0314 03:07:42.743984 138313941204992 run.py:479] Algo floyd_warshall step 6384 current loss 0.496336, current_train_items 204320.\n",
            "I0314 03:07:42.768703 138313941204992 run.py:479] Algo floyd_warshall step 6385 current loss 0.031944, current_train_items 204352.\n",
            "I0314 03:07:42.813206 138313941204992 run.py:479] Algo floyd_warshall step 6386 current loss 0.077554, current_train_items 204384.\n",
            "I0314 03:07:42.943193 138313941204992 run.py:479] Algo floyd_warshall step 6387 current loss 0.214398, current_train_items 204416.\n",
            "I0314 03:07:43.163175 138313941204992 run.py:479] Algo floyd_warshall step 6388 current loss 0.305682, current_train_items 204448.\n",
            "I0314 03:07:43.576006 138313941204992 run.py:479] Algo floyd_warshall step 6389 current loss 0.680550, current_train_items 204480.\n",
            "I0314 03:07:43.599296 138313941204992 run.py:479] Algo floyd_warshall step 6390 current loss 0.016036, current_train_items 204512.\n",
            "I0314 03:07:43.643123 138313941204992 run.py:479] Algo floyd_warshall step 6391 current loss 0.092806, current_train_items 204544.\n",
            "I0314 03:07:43.782810 138313941204992 run.py:479] Algo floyd_warshall step 6392 current loss 0.263591, current_train_items 204576.\n",
            "I0314 03:07:44.006568 138313941204992 run.py:479] Algo floyd_warshall step 6393 current loss 0.516455, current_train_items 204608.\n",
            "I0314 03:07:44.418962 138313941204992 run.py:479] Algo floyd_warshall step 6394 current loss 0.709100, current_train_items 204640.\n",
            "I0314 03:07:44.446191 138313941204992 run.py:479] Algo floyd_warshall step 6395 current loss 0.016356, current_train_items 204672.\n",
            "I0314 03:07:44.490654 138313941204992 run.py:479] Algo floyd_warshall step 6396 current loss 0.065832, current_train_items 204704.\n",
            "I0314 03:07:44.617059 138313941204992 run.py:479] Algo floyd_warshall step 6397 current loss 0.227302, current_train_items 204736.\n",
            "I0314 03:07:44.846595 138313941204992 run.py:479] Algo floyd_warshall step 6398 current loss 0.373796, current_train_items 204768.\n",
            "I0314 03:07:45.269921 138313941204992 run.py:479] Algo floyd_warshall step 6399 current loss 0.669438, current_train_items 204800.\n",
            "I0314 03:07:45.293740 138313941204992 run.py:479] Algo floyd_warshall step 6400 current loss 0.138594, current_train_items 204832.\n",
            "I0314 03:07:45.383431 138313941204992 run.py:499] (val) algo floyd_warshall step 6400: {'Pi': 0.891845703125, 'score': 0.891845703125, 'examples_seen': 204832, 'step': 6400, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:07:45.383704 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.908, current avg val score is 0.892, val scores are: floyd_warshall: 0.892\n",
            "I0314 03:07:45.431937 138313941204992 run.py:479] Algo floyd_warshall step 6401 current loss 0.055674, current_train_items 204864.\n",
            "I0314 03:07:45.565154 138313941204992 run.py:479] Algo floyd_warshall step 6402 current loss 0.191425, current_train_items 204896.\n",
            "I0314 03:07:45.787423 138313941204992 run.py:479] Algo floyd_warshall step 6403 current loss 0.345523, current_train_items 204928.\n",
            "I0314 03:07:46.207107 138313941204992 run.py:479] Algo floyd_warshall step 6404 current loss 0.628974, current_train_items 204960.\n",
            "I0314 03:07:46.233392 138313941204992 run.py:479] Algo floyd_warshall step 6405 current loss 0.023775, current_train_items 204992.\n",
            "I0314 03:07:46.277791 138313941204992 run.py:479] Algo floyd_warshall step 6406 current loss 0.049394, current_train_items 205024.\n",
            "I0314 03:07:46.405426 138313941204992 run.py:479] Algo floyd_warshall step 6407 current loss 0.173830, current_train_items 205056.\n",
            "I0314 03:07:46.619930 138313941204992 run.py:479] Algo floyd_warshall step 6408 current loss 0.380555, current_train_items 205088.\n",
            "I0314 03:07:47.022492 138313941204992 run.py:479] Algo floyd_warshall step 6409 current loss 0.433806, current_train_items 205120.\n",
            "I0314 03:07:47.047123 138313941204992 run.py:479] Algo floyd_warshall step 6410 current loss 0.031540, current_train_items 205152.\n",
            "I0314 03:07:47.093345 138313941204992 run.py:479] Algo floyd_warshall step 6411 current loss 0.080158, current_train_items 205184.\n",
            "I0314 03:07:47.223341 138313941204992 run.py:479] Algo floyd_warshall step 6412 current loss 0.225137, current_train_items 205216.\n",
            "I0314 03:07:47.445036 138313941204992 run.py:479] Algo floyd_warshall step 6413 current loss 0.373631, current_train_items 205248.\n",
            "I0314 03:07:47.856483 138313941204992 run.py:479] Algo floyd_warshall step 6414 current loss 0.670470, current_train_items 205280.\n",
            "I0314 03:07:47.882195 138313941204992 run.py:479] Algo floyd_warshall step 6415 current loss 0.013667, current_train_items 205312.\n",
            "I0314 03:07:47.927008 138313941204992 run.py:479] Algo floyd_warshall step 6416 current loss 0.110140, current_train_items 205344.\n",
            "I0314 03:07:48.057895 138313941204992 run.py:479] Algo floyd_warshall step 6417 current loss 0.270709, current_train_items 205376.\n",
            "I0314 03:07:48.287141 138313941204992 run.py:479] Algo floyd_warshall step 6418 current loss 0.418790, current_train_items 205408.\n",
            "I0314 03:07:48.709840 138313941204992 run.py:479] Algo floyd_warshall step 6419 current loss 0.682314, current_train_items 205440.\n",
            "I0314 03:07:48.750595 138313941204992 run.py:479] Algo floyd_warshall step 6420 current loss 0.013284, current_train_items 205472.\n",
            "I0314 03:07:48.815189 138313941204992 run.py:479] Algo floyd_warshall step 6421 current loss 0.061467, current_train_items 205504.\n",
            "I0314 03:07:48.977472 138313941204992 run.py:479] Algo floyd_warshall step 6422 current loss 0.150981, current_train_items 205536.\n",
            "I0314 03:07:49.235008 138313941204992 run.py:479] Algo floyd_warshall step 6423 current loss 0.356975, current_train_items 205568.\n",
            "I0314 03:07:49.732474 138313941204992 run.py:479] Algo floyd_warshall step 6424 current loss 0.645288, current_train_items 205600.\n",
            "I0314 03:07:49.765549 138313941204992 run.py:479] Algo floyd_warshall step 6425 current loss 0.028111, current_train_items 205632.\n",
            "I0314 03:07:49.827119 138313941204992 run.py:479] Algo floyd_warshall step 6426 current loss 0.055133, current_train_items 205664.\n",
            "I0314 03:07:49.989386 138313941204992 run.py:479] Algo floyd_warshall step 6427 current loss 0.162133, current_train_items 205696.\n",
            "I0314 03:07:50.275948 138313941204992 run.py:479] Algo floyd_warshall step 6428 current loss 0.407917, current_train_items 205728.\n",
            "I0314 03:07:50.778724 138313941204992 run.py:479] Algo floyd_warshall step 6429 current loss 0.670636, current_train_items 205760.\n",
            "I0314 03:07:50.815607 138313941204992 run.py:479] Algo floyd_warshall step 6430 current loss 0.018975, current_train_items 205792.\n",
            "I0314 03:07:50.876054 138313941204992 run.py:479] Algo floyd_warshall step 6431 current loss 0.071402, current_train_items 205824.\n",
            "I0314 03:07:51.034403 138313941204992 run.py:479] Algo floyd_warshall step 6432 current loss 0.225014, current_train_items 205856.\n",
            "I0314 03:07:51.295134 138313941204992 run.py:479] Algo floyd_warshall step 6433 current loss 0.365214, current_train_items 205888.\n",
            "I0314 03:07:51.802379 138313941204992 run.py:479] Algo floyd_warshall step 6434 current loss 0.557602, current_train_items 205920.\n",
            "I0314 03:07:51.827377 138313941204992 run.py:479] Algo floyd_warshall step 6435 current loss 0.032783, current_train_items 205952.\n",
            "I0314 03:07:51.875370 138313941204992 run.py:479] Algo floyd_warshall step 6436 current loss 0.064222, current_train_items 205984.\n",
            "I0314 03:07:52.005591 138313941204992 run.py:479] Algo floyd_warshall step 6437 current loss 0.178628, current_train_items 206016.\n",
            "I0314 03:07:52.234980 138313941204992 run.py:479] Algo floyd_warshall step 6438 current loss 0.479123, current_train_items 206048.\n",
            "I0314 03:07:52.646693 138313941204992 run.py:479] Algo floyd_warshall step 6439 current loss 0.663134, current_train_items 206080.\n",
            "I0314 03:07:52.670867 138313941204992 run.py:479] Algo floyd_warshall step 6440 current loss 0.014536, current_train_items 206112.\n",
            "I0314 03:07:52.717247 138313941204992 run.py:479] Algo floyd_warshall step 6441 current loss 0.043561, current_train_items 206144.\n",
            "I0314 03:07:52.852030 138313941204992 run.py:479] Algo floyd_warshall step 6442 current loss 0.363048, current_train_items 206176.\n",
            "I0314 03:07:53.064974 138313941204992 run.py:479] Algo floyd_warshall step 6443 current loss 0.410410, current_train_items 206208.\n",
            "I0314 03:07:53.483970 138313941204992 run.py:479] Algo floyd_warshall step 6444 current loss 0.618583, current_train_items 206240.\n",
            "I0314 03:07:53.508992 138313941204992 run.py:479] Algo floyd_warshall step 6445 current loss 0.016740, current_train_items 206272.\n",
            "I0314 03:07:53.554810 138313941204992 run.py:479] Algo floyd_warshall step 6446 current loss 0.052017, current_train_items 206304.\n",
            "I0314 03:07:53.688660 138313941204992 run.py:479] Algo floyd_warshall step 6447 current loss 0.300172, current_train_items 206336.\n",
            "I0314 03:07:53.919571 138313941204992 run.py:479] Algo floyd_warshall step 6448 current loss 0.284621, current_train_items 206368.\n",
            "I0314 03:07:54.358434 138313941204992 run.py:479] Algo floyd_warshall step 6449 current loss 0.680609, current_train_items 206400.\n",
            "I0314 03:07:54.382164 138313941204992 run.py:479] Algo floyd_warshall step 6450 current loss 0.018954, current_train_items 206432.\n",
            "I0314 03:07:54.473116 138313941204992 run.py:499] (val) algo floyd_warshall step 6450: {'Pi': 0.88922119140625, 'score': 0.88922119140625, 'examples_seen': 206432, 'step': 6450, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:07:54.473448 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.908, current avg val score is 0.889, val scores are: floyd_warshall: 0.889\n",
            "I0314 03:07:54.522604 138313941204992 run.py:479] Algo floyd_warshall step 6451 current loss 0.065792, current_train_items 206464.\n",
            "I0314 03:07:54.656787 138313941204992 run.py:479] Algo floyd_warshall step 6452 current loss 0.233411, current_train_items 206496.\n",
            "I0314 03:07:54.873591 138313941204992 run.py:479] Algo floyd_warshall step 6453 current loss 0.410907, current_train_items 206528.\n",
            "I0314 03:07:55.299076 138313941204992 run.py:479] Algo floyd_warshall step 6454 current loss 0.701850, current_train_items 206560.\n",
            "I0314 03:07:55.324640 138313941204992 run.py:479] Algo floyd_warshall step 6455 current loss 0.021907, current_train_items 206592.\n",
            "I0314 03:07:55.369636 138313941204992 run.py:479] Algo floyd_warshall step 6456 current loss 0.088167, current_train_items 206624.\n",
            "I0314 03:07:55.500150 138313941204992 run.py:479] Algo floyd_warshall step 6457 current loss 0.257497, current_train_items 206656.\n",
            "I0314 03:07:55.724073 138313941204992 run.py:479] Algo floyd_warshall step 6458 current loss 0.343570, current_train_items 206688.\n",
            "I0314 03:07:56.155073 138313941204992 run.py:479] Algo floyd_warshall step 6459 current loss 0.741775, current_train_items 206720.\n",
            "I0314 03:07:56.179466 138313941204992 run.py:479] Algo floyd_warshall step 6460 current loss 0.013853, current_train_items 206752.\n",
            "I0314 03:07:56.226904 138313941204992 run.py:479] Algo floyd_warshall step 6461 current loss 0.062458, current_train_items 206784.\n",
            "I0314 03:07:56.355843 138313941204992 run.py:479] Algo floyd_warshall step 6462 current loss 0.191415, current_train_items 206816.\n",
            "I0314 03:07:56.573996 138313941204992 run.py:479] Algo floyd_warshall step 6463 current loss 0.358130, current_train_items 206848.\n",
            "I0314 03:07:56.980711 138313941204992 run.py:479] Algo floyd_warshall step 6464 current loss 0.594569, current_train_items 206880.\n",
            "I0314 03:07:57.004881 138313941204992 run.py:479] Algo floyd_warshall step 6465 current loss 0.025796, current_train_items 206912.\n",
            "I0314 03:07:57.052121 138313941204992 run.py:479] Algo floyd_warshall step 6466 current loss 0.084736, current_train_items 206944.\n",
            "I0314 03:07:57.190936 138313941204992 run.py:479] Algo floyd_warshall step 6467 current loss 0.268691, current_train_items 206976.\n",
            "I0314 03:07:57.406339 138313941204992 run.py:479] Algo floyd_warshall step 6468 current loss 0.302352, current_train_items 207008.\n",
            "I0314 03:07:57.812111 138313941204992 run.py:479] Algo floyd_warshall step 6469 current loss 0.631066, current_train_items 207040.\n",
            "I0314 03:07:57.836387 138313941204992 run.py:479] Algo floyd_warshall step 6470 current loss 0.038965, current_train_items 207072.\n",
            "I0314 03:07:57.883620 138313941204992 run.py:479] Algo floyd_warshall step 6471 current loss 0.058731, current_train_items 207104.\n",
            "I0314 03:07:58.016820 138313941204992 run.py:479] Algo floyd_warshall step 6472 current loss 0.228563, current_train_items 207136.\n",
            "I0314 03:07:58.242138 138313941204992 run.py:479] Algo floyd_warshall step 6473 current loss 0.249647, current_train_items 207168.\n",
            "I0314 03:07:58.652549 138313941204992 run.py:479] Algo floyd_warshall step 6474 current loss 0.611406, current_train_items 207200.\n",
            "I0314 03:07:58.676872 138313941204992 run.py:479] Algo floyd_warshall step 6475 current loss 0.020156, current_train_items 207232.\n",
            "I0314 03:07:58.720738 138313941204992 run.py:479] Algo floyd_warshall step 6476 current loss 0.054326, current_train_items 207264.\n",
            "I0314 03:07:58.852346 138313941204992 run.py:479] Algo floyd_warshall step 6477 current loss 0.248923, current_train_items 207296.\n",
            "I0314 03:07:59.089779 138313941204992 run.py:479] Algo floyd_warshall step 6478 current loss 0.482689, current_train_items 207328.\n",
            "I0314 03:07:59.526833 138313941204992 run.py:479] Algo floyd_warshall step 6479 current loss 0.765452, current_train_items 207360.\n",
            "I0314 03:07:59.550975 138313941204992 run.py:479] Algo floyd_warshall step 6480 current loss 0.032638, current_train_items 207392.\n",
            "I0314 03:07:59.596194 138313941204992 run.py:479] Algo floyd_warshall step 6481 current loss 0.061065, current_train_items 207424.\n",
            "I0314 03:07:59.727774 138313941204992 run.py:479] Algo floyd_warshall step 6482 current loss 0.269840, current_train_items 207456.\n",
            "I0314 03:07:59.952620 138313941204992 run.py:479] Algo floyd_warshall step 6483 current loss 0.356832, current_train_items 207488.\n",
            "I0314 03:08:00.372134 138313941204992 run.py:479] Algo floyd_warshall step 6484 current loss 0.687225, current_train_items 207520.\n",
            "I0314 03:08:00.394628 138313941204992 run.py:479] Algo floyd_warshall step 6485 current loss 0.025158, current_train_items 207552.\n",
            "I0314 03:08:00.441826 138313941204992 run.py:479] Algo floyd_warshall step 6486 current loss 0.080466, current_train_items 207584.\n",
            "I0314 03:08:00.570570 138313941204992 run.py:479] Algo floyd_warshall step 6487 current loss 0.178028, current_train_items 207616.\n",
            "I0314 03:08:00.782501 138313941204992 run.py:479] Algo floyd_warshall step 6488 current loss 0.313024, current_train_items 207648.\n",
            "I0314 03:08:01.197677 138313941204992 run.py:479] Algo floyd_warshall step 6489 current loss 0.627569, current_train_items 207680.\n",
            "I0314 03:08:01.222096 138313941204992 run.py:479] Algo floyd_warshall step 6490 current loss 0.024765, current_train_items 207712.\n",
            "I0314 03:08:01.265944 138313941204992 run.py:479] Algo floyd_warshall step 6491 current loss 0.063571, current_train_items 207744.\n",
            "I0314 03:08:01.393906 138313941204992 run.py:479] Algo floyd_warshall step 6492 current loss 0.185055, current_train_items 207776.\n",
            "I0314 03:08:01.609667 138313941204992 run.py:479] Algo floyd_warshall step 6493 current loss 0.392613, current_train_items 207808.\n",
            "I0314 03:08:02.010663 138313941204992 run.py:479] Algo floyd_warshall step 6494 current loss 0.532933, current_train_items 207840.\n",
            "I0314 03:08:02.046723 138313941204992 run.py:479] Algo floyd_warshall step 6495 current loss 0.027692, current_train_items 207872.\n",
            "I0314 03:08:02.103817 138313941204992 run.py:479] Algo floyd_warshall step 6496 current loss 0.055024, current_train_items 207904.\n",
            "I0314 03:08:02.268075 138313941204992 run.py:479] Algo floyd_warshall step 6497 current loss 0.302911, current_train_items 207936.\n",
            "I0314 03:08:02.522504 138313941204992 run.py:479] Algo floyd_warshall step 6498 current loss 0.314065, current_train_items 207968.\n",
            "I0314 03:08:03.037167 138313941204992 run.py:479] Algo floyd_warshall step 6499 current loss 0.861120, current_train_items 208000.\n",
            "I0314 03:08:03.075324 138313941204992 run.py:479] Algo floyd_warshall step 6500 current loss 0.019712, current_train_items 208032.\n",
            "I0314 03:08:03.185138 138313941204992 run.py:499] (val) algo floyd_warshall step 6500: {'Pi': 0.850830078125, 'score': 0.850830078125, 'examples_seen': 208032, 'step': 6500, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:08:03.185485 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.908, current avg val score is 0.851, val scores are: floyd_warshall: 0.851\n",
            "I0314 03:08:03.246661 138313941204992 run.py:479] Algo floyd_warshall step 6501 current loss 0.076065, current_train_items 208064.\n",
            "I0314 03:08:03.409735 138313941204992 run.py:479] Algo floyd_warshall step 6502 current loss 0.280623, current_train_items 208096.\n",
            "I0314 03:08:03.663378 138313941204992 run.py:479] Algo floyd_warshall step 6503 current loss 0.303943, current_train_items 208128.\n",
            "I0314 03:08:04.175006 138313941204992 run.py:479] Algo floyd_warshall step 6504 current loss 0.713598, current_train_items 208160.\n",
            "I0314 03:08:04.219375 138313941204992 run.py:479] Algo floyd_warshall step 6505 current loss 0.033382, current_train_items 208192.\n",
            "I0314 03:08:04.281079 138313941204992 run.py:479] Algo floyd_warshall step 6506 current loss 0.050096, current_train_items 208224.\n",
            "I0314 03:08:04.448433 138313941204992 run.py:479] Algo floyd_warshall step 6507 current loss 0.220836, current_train_items 208256.\n",
            "I0314 03:08:04.714280 138313941204992 run.py:479] Algo floyd_warshall step 6508 current loss 0.427658, current_train_items 208288.\n",
            "I0314 03:08:05.199163 138313941204992 run.py:479] Algo floyd_warshall step 6509 current loss 0.506403, current_train_items 208320.\n",
            "I0314 03:08:05.222711 138313941204992 run.py:479] Algo floyd_warshall step 6510 current loss 0.015822, current_train_items 208352.\n",
            "I0314 03:08:05.269964 138313941204992 run.py:479] Algo floyd_warshall step 6511 current loss 0.070241, current_train_items 208384.\n",
            "I0314 03:08:05.405844 138313941204992 run.py:479] Algo floyd_warshall step 6512 current loss 0.240631, current_train_items 208416.\n",
            "I0314 03:08:05.625229 138313941204992 run.py:479] Algo floyd_warshall step 6513 current loss 0.389747, current_train_items 208448.\n",
            "I0314 03:08:06.043405 138313941204992 run.py:479] Algo floyd_warshall step 6514 current loss 0.699933, current_train_items 208480.\n",
            "I0314 03:08:06.068242 138313941204992 run.py:479] Algo floyd_warshall step 6515 current loss 0.031806, current_train_items 208512.\n",
            "I0314 03:08:06.113250 138313941204992 run.py:479] Algo floyd_warshall step 6516 current loss 0.067056, current_train_items 208544.\n",
            "I0314 03:08:06.246353 138313941204992 run.py:479] Algo floyd_warshall step 6517 current loss 0.339128, current_train_items 208576.\n",
            "I0314 03:08:06.467517 138313941204992 run.py:479] Algo floyd_warshall step 6518 current loss 0.383939, current_train_items 208608.\n",
            "I0314 03:08:06.899132 138313941204992 run.py:479] Algo floyd_warshall step 6519 current loss 0.750222, current_train_items 208640.\n",
            "I0314 03:08:06.923703 138313941204992 run.py:479] Algo floyd_warshall step 6520 current loss 0.014695, current_train_items 208672.\n",
            "I0314 03:08:06.968955 138313941204992 run.py:479] Algo floyd_warshall step 6521 current loss 0.056549, current_train_items 208704.\n",
            "I0314 03:08:07.102339 138313941204992 run.py:479] Algo floyd_warshall step 6522 current loss 0.281150, current_train_items 208736.\n",
            "I0314 03:08:07.323634 138313941204992 run.py:479] Algo floyd_warshall step 6523 current loss 0.219424, current_train_items 208768.\n",
            "I0314 03:08:07.749605 138313941204992 run.py:479] Algo floyd_warshall step 6524 current loss 0.760715, current_train_items 208800.\n",
            "I0314 03:08:07.772905 138313941204992 run.py:479] Algo floyd_warshall step 6525 current loss 0.020688, current_train_items 208832.\n",
            "I0314 03:08:07.817611 138313941204992 run.py:479] Algo floyd_warshall step 6526 current loss 0.053750, current_train_items 208864.\n",
            "I0314 03:08:07.946449 138313941204992 run.py:479] Algo floyd_warshall step 6527 current loss 0.160739, current_train_items 208896.\n",
            "I0314 03:08:08.168848 138313941204992 run.py:479] Algo floyd_warshall step 6528 current loss 0.385972, current_train_items 208928.\n",
            "I0314 03:08:08.580731 138313941204992 run.py:479] Algo floyd_warshall step 6529 current loss 0.696573, current_train_items 208960.\n",
            "I0314 03:08:08.604458 138313941204992 run.py:479] Algo floyd_warshall step 6530 current loss 0.011663, current_train_items 208992.\n",
            "I0314 03:08:08.651085 138313941204992 run.py:479] Algo floyd_warshall step 6531 current loss 0.079518, current_train_items 209024.\n",
            "I0314 03:08:08.781936 138313941204992 run.py:479] Algo floyd_warshall step 6532 current loss 0.239845, current_train_items 209056.\n",
            "I0314 03:08:09.009642 138313941204992 run.py:479] Algo floyd_warshall step 6533 current loss 0.342822, current_train_items 209088.\n",
            "I0314 03:08:09.428715 138313941204992 run.py:479] Algo floyd_warshall step 6534 current loss 0.599727, current_train_items 209120.\n",
            "I0314 03:08:09.454649 138313941204992 run.py:479] Algo floyd_warshall step 6535 current loss 0.007748, current_train_items 209152.\n",
            "I0314 03:08:09.504448 138313941204992 run.py:479] Algo floyd_warshall step 6536 current loss 0.086770, current_train_items 209184.\n",
            "I0314 03:08:09.637893 138313941204992 run.py:479] Algo floyd_warshall step 6537 current loss 0.232171, current_train_items 209216.\n",
            "I0314 03:08:09.855253 138313941204992 run.py:479] Algo floyd_warshall step 6538 current loss 0.326412, current_train_items 209248.\n",
            "I0314 03:08:10.265604 138313941204992 run.py:479] Algo floyd_warshall step 6539 current loss 0.660695, current_train_items 209280.\n",
            "I0314 03:08:10.290164 138313941204992 run.py:479] Algo floyd_warshall step 6540 current loss 0.017611, current_train_items 209312.\n",
            "I0314 03:08:10.334788 138313941204992 run.py:479] Algo floyd_warshall step 6541 current loss 0.038250, current_train_items 209344.\n",
            "I0314 03:08:10.463889 138313941204992 run.py:479] Algo floyd_warshall step 6542 current loss 0.219945, current_train_items 209376.\n",
            "I0314 03:08:10.682520 138313941204992 run.py:479] Algo floyd_warshall step 6543 current loss 0.391530, current_train_items 209408.\n",
            "I0314 03:08:11.109222 138313941204992 run.py:479] Algo floyd_warshall step 6544 current loss 0.620402, current_train_items 209440.\n",
            "I0314 03:08:11.134980 138313941204992 run.py:479] Algo floyd_warshall step 6545 current loss 0.018091, current_train_items 209472.\n",
            "I0314 03:08:11.181525 138313941204992 run.py:479] Algo floyd_warshall step 6546 current loss 0.059383, current_train_items 209504.\n",
            "I0314 03:08:11.312469 138313941204992 run.py:479] Algo floyd_warshall step 6547 current loss 0.155908, current_train_items 209536.\n",
            "I0314 03:08:11.541690 138313941204992 run.py:479] Algo floyd_warshall step 6548 current loss 0.374572, current_train_items 209568.\n",
            "I0314 03:08:11.978754 138313941204992 run.py:479] Algo floyd_warshall step 6549 current loss 0.566623, current_train_items 209600.\n",
            "I0314 03:08:12.003941 138313941204992 run.py:479] Algo floyd_warshall step 6550 current loss 0.011782, current_train_items 209632.\n",
            "I0314 03:08:12.093815 138313941204992 run.py:499] (val) algo floyd_warshall step 6550: {'Pi': 0.89227294921875, 'score': 0.89227294921875, 'examples_seen': 209632, 'step': 6550, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:08:12.094089 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.908, current avg val score is 0.892, val scores are: floyd_warshall: 0.892\n",
            "I0314 03:08:12.142913 138313941204992 run.py:479] Algo floyd_warshall step 6551 current loss 0.105778, current_train_items 209664.\n",
            "I0314 03:08:12.275403 138313941204992 run.py:479] Algo floyd_warshall step 6552 current loss 0.280431, current_train_items 209696.\n",
            "I0314 03:08:12.495661 138313941204992 run.py:479] Algo floyd_warshall step 6553 current loss 0.397484, current_train_items 209728.\n",
            "I0314 03:08:12.925231 138313941204992 run.py:479] Algo floyd_warshall step 6554 current loss 0.762631, current_train_items 209760.\n",
            "I0314 03:08:12.950811 138313941204992 run.py:479] Algo floyd_warshall step 6555 current loss 0.021433, current_train_items 209792.\n",
            "I0314 03:08:12.997714 138313941204992 run.py:479] Algo floyd_warshall step 6556 current loss 0.092929, current_train_items 209824.\n",
            "I0314 03:08:13.125819 138313941204992 run.py:479] Algo floyd_warshall step 6557 current loss 0.151711, current_train_items 209856.\n",
            "I0314 03:08:13.347553 138313941204992 run.py:479] Algo floyd_warshall step 6558 current loss 0.242064, current_train_items 209888.\n",
            "I0314 03:08:13.775659 138313941204992 run.py:479] Algo floyd_warshall step 6559 current loss 0.685745, current_train_items 209920.\n",
            "I0314 03:08:13.799540 138313941204992 run.py:479] Algo floyd_warshall step 6560 current loss 0.015910, current_train_items 209952.\n",
            "I0314 03:08:13.844196 138313941204992 run.py:479] Algo floyd_warshall step 6561 current loss 0.037883, current_train_items 209984.\n",
            "I0314 03:08:13.975619 138313941204992 run.py:479] Algo floyd_warshall step 6562 current loss 0.199410, current_train_items 210016.\n",
            "I0314 03:08:14.192661 138313941204992 run.py:479] Algo floyd_warshall step 6563 current loss 0.397582, current_train_items 210048.\n",
            "I0314 03:08:14.606119 138313941204992 run.py:479] Algo floyd_warshall step 6564 current loss 0.570685, current_train_items 210080.\n",
            "I0314 03:08:14.630659 138313941204992 run.py:479] Algo floyd_warshall step 6565 current loss 0.009272, current_train_items 210112.\n",
            "I0314 03:08:14.675818 138313941204992 run.py:479] Algo floyd_warshall step 6566 current loss 0.073978, current_train_items 210144.\n",
            "I0314 03:08:14.806432 138313941204992 run.py:479] Algo floyd_warshall step 6567 current loss 0.206773, current_train_items 210176.\n",
            "I0314 03:08:15.026595 138313941204992 run.py:479] Algo floyd_warshall step 6568 current loss 0.472870, current_train_items 210208.\n",
            "I0314 03:08:15.517708 138313941204992 run.py:479] Algo floyd_warshall step 6569 current loss 0.761795, current_train_items 210240.\n",
            "I0314 03:08:15.551187 138313941204992 run.py:479] Algo floyd_warshall step 6570 current loss 0.019353, current_train_items 210272.\n",
            "I0314 03:08:15.610979 138313941204992 run.py:479] Algo floyd_warshall step 6571 current loss 0.046519, current_train_items 210304.\n",
            "I0314 03:08:15.769889 138313941204992 run.py:479] Algo floyd_warshall step 6572 current loss 0.250341, current_train_items 210336.\n",
            "I0314 03:08:16.056626 138313941204992 run.py:479] Algo floyd_warshall step 6573 current loss 0.432251, current_train_items 210368.\n",
            "I0314 03:08:16.543786 138313941204992 run.py:479] Algo floyd_warshall step 6574 current loss 0.593099, current_train_items 210400.\n",
            "I0314 03:08:16.578994 138313941204992 run.py:479] Algo floyd_warshall step 6575 current loss 0.031836, current_train_items 210432.\n",
            "I0314 03:08:16.641350 138313941204992 run.py:479] Algo floyd_warshall step 6576 current loss 0.096751, current_train_items 210464.\n",
            "I0314 03:08:16.802340 138313941204992 run.py:479] Algo floyd_warshall step 6577 current loss 0.359098, current_train_items 210496.\n",
            "I0314 03:08:17.059129 138313941204992 run.py:479] Algo floyd_warshall step 6578 current loss 0.431897, current_train_items 210528.\n",
            "I0314 03:08:17.564129 138313941204992 run.py:479] Algo floyd_warshall step 6579 current loss 0.727500, current_train_items 210560.\n",
            "I0314 03:08:17.598367 138313941204992 run.py:479] Algo floyd_warshall step 6580 current loss 0.026055, current_train_items 210592.\n",
            "I0314 03:08:17.658751 138313941204992 run.py:479] Algo floyd_warshall step 6581 current loss 0.104725, current_train_items 210624.\n",
            "I0314 03:08:17.832643 138313941204992 run.py:479] Algo floyd_warshall step 6582 current loss 0.291903, current_train_items 210656.\n",
            "I0314 03:08:18.093085 138313941204992 run.py:479] Algo floyd_warshall step 6583 current loss 0.475464, current_train_items 210688.\n",
            "I0314 03:08:18.497023 138313941204992 run.py:479] Algo floyd_warshall step 6584 current loss 0.549752, current_train_items 210720.\n",
            "I0314 03:08:18.523131 138313941204992 run.py:479] Algo floyd_warshall step 6585 current loss 0.022504, current_train_items 210752.\n",
            "I0314 03:08:18.568156 138313941204992 run.py:479] Algo floyd_warshall step 6586 current loss 0.050262, current_train_items 210784.\n",
            "I0314 03:08:18.697539 138313941204992 run.py:479] Algo floyd_warshall step 6587 current loss 0.216448, current_train_items 210816.\n",
            "I0314 03:08:18.923776 138313941204992 run.py:479] Algo floyd_warshall step 6588 current loss 0.276286, current_train_items 210848.\n",
            "I0314 03:08:19.332833 138313941204992 run.py:479] Algo floyd_warshall step 6589 current loss 0.587620, current_train_items 210880.\n",
            "I0314 03:08:19.356807 138313941204992 run.py:479] Algo floyd_warshall step 6590 current loss 0.010894, current_train_items 210912.\n",
            "I0314 03:08:19.400895 138313941204992 run.py:479] Algo floyd_warshall step 6591 current loss 0.050297, current_train_items 210944.\n",
            "I0314 03:08:19.535048 138313941204992 run.py:479] Algo floyd_warshall step 6592 current loss 0.218625, current_train_items 210976.\n",
            "I0314 03:08:19.750622 138313941204992 run.py:479] Algo floyd_warshall step 6593 current loss 0.470943, current_train_items 211008.\n",
            "I0314 03:08:20.174623 138313941204992 run.py:479] Algo floyd_warshall step 6594 current loss 0.800048, current_train_items 211040.\n",
            "I0314 03:08:20.197702 138313941204992 run.py:479] Algo floyd_warshall step 6595 current loss 0.013490, current_train_items 211072.\n",
            "I0314 03:08:20.242376 138313941204992 run.py:479] Algo floyd_warshall step 6596 current loss 0.035430, current_train_items 211104.\n",
            "I0314 03:08:20.375115 138313941204992 run.py:479] Algo floyd_warshall step 6597 current loss 0.242472, current_train_items 211136.\n",
            "I0314 03:08:20.602014 138313941204992 run.py:479] Algo floyd_warshall step 6598 current loss 0.438088, current_train_items 211168.\n",
            "I0314 03:08:21.014007 138313941204992 run.py:479] Algo floyd_warshall step 6599 current loss 0.616653, current_train_items 211200.\n",
            "I0314 03:08:21.038235 138313941204992 run.py:479] Algo floyd_warshall step 6600 current loss 0.016805, current_train_items 211232.\n",
            "I0314 03:08:21.124851 138313941204992 run.py:499] (val) algo floyd_warshall step 6600: {'Pi': 0.89453125, 'score': 0.89453125, 'examples_seen': 211232, 'step': 6600, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:08:21.125194 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.908, current avg val score is 0.895, val scores are: floyd_warshall: 0.895\n",
            "I0314 03:08:21.174849 138313941204992 run.py:479] Algo floyd_warshall step 6601 current loss 0.044241, current_train_items 211264.\n",
            "I0314 03:08:21.312525 138313941204992 run.py:479] Algo floyd_warshall step 6602 current loss 0.256859, current_train_items 211296.\n",
            "I0314 03:08:21.537690 138313941204992 run.py:479] Algo floyd_warshall step 6603 current loss 0.475497, current_train_items 211328.\n",
            "I0314 03:08:21.947363 138313941204992 run.py:479] Algo floyd_warshall step 6604 current loss 0.631430, current_train_items 211360.\n",
            "I0314 03:08:21.974086 138313941204992 run.py:479] Algo floyd_warshall step 6605 current loss 0.034192, current_train_items 211392.\n",
            "I0314 03:08:22.018586 138313941204992 run.py:479] Algo floyd_warshall step 6606 current loss 0.043240, current_train_items 211424.\n",
            "I0314 03:08:22.150252 138313941204992 run.py:479] Algo floyd_warshall step 6607 current loss 0.203375, current_train_items 211456.\n",
            "I0314 03:08:22.371901 138313941204992 run.py:479] Algo floyd_warshall step 6608 current loss 0.369765, current_train_items 211488.\n",
            "I0314 03:08:22.797971 138313941204992 run.py:479] Algo floyd_warshall step 6609 current loss 0.714053, current_train_items 211520.\n",
            "I0314 03:08:22.821499 138313941204992 run.py:479] Algo floyd_warshall step 6610 current loss 0.020986, current_train_items 211552.\n",
            "I0314 03:08:22.877895 138313941204992 run.py:479] Algo floyd_warshall step 6611 current loss 0.081861, current_train_items 211584.\n",
            "I0314 03:08:23.007331 138313941204992 run.py:479] Algo floyd_warshall step 6612 current loss 0.199331, current_train_items 211616.\n",
            "I0314 03:08:23.230850 138313941204992 run.py:479] Algo floyd_warshall step 6613 current loss 0.244767, current_train_items 211648.\n",
            "I0314 03:08:23.646212 138313941204992 run.py:479] Algo floyd_warshall step 6614 current loss 0.599210, current_train_items 211680.\n",
            "I0314 03:08:23.670172 138313941204992 run.py:479] Algo floyd_warshall step 6615 current loss 0.010792, current_train_items 211712.\n",
            "I0314 03:08:23.714705 138313941204992 run.py:479] Algo floyd_warshall step 6616 current loss 0.068076, current_train_items 211744.\n",
            "I0314 03:08:23.845896 138313941204992 run.py:479] Algo floyd_warshall step 6617 current loss 0.201368, current_train_items 211776.\n",
            "I0314 03:08:24.073685 138313941204992 run.py:479] Algo floyd_warshall step 6618 current loss 0.295591, current_train_items 211808.\n",
            "I0314 03:08:24.482618 138313941204992 run.py:479] Algo floyd_warshall step 6619 current loss 0.498018, current_train_items 211840.\n",
            "I0314 03:08:24.506592 138313941204992 run.py:479] Algo floyd_warshall step 6620 current loss 0.012150, current_train_items 211872.\n",
            "I0314 03:08:24.549767 138313941204992 run.py:479] Algo floyd_warshall step 6621 current loss 0.053495, current_train_items 211904.\n",
            "I0314 03:08:24.677448 138313941204992 run.py:479] Algo floyd_warshall step 6622 current loss 0.156000, current_train_items 211936.\n",
            "I0314 03:08:24.897829 138313941204992 run.py:479] Algo floyd_warshall step 6623 current loss 0.396147, current_train_items 211968.\n",
            "I0314 03:08:25.329768 138313941204992 run.py:479] Algo floyd_warshall step 6624 current loss 0.796616, current_train_items 212000.\n",
            "I0314 03:08:25.352730 138313941204992 run.py:479] Algo floyd_warshall step 6625 current loss 0.008536, current_train_items 212032.\n",
            "I0314 03:08:25.397421 138313941204992 run.py:479] Algo floyd_warshall step 6626 current loss 0.070822, current_train_items 212064.\n",
            "I0314 03:08:25.530406 138313941204992 run.py:479] Algo floyd_warshall step 6627 current loss 0.291276, current_train_items 212096.\n",
            "I0314 03:08:25.755462 138313941204992 run.py:479] Algo floyd_warshall step 6628 current loss 0.310099, current_train_items 212128.\n",
            "I0314 03:08:26.160118 138313941204992 run.py:479] Algo floyd_warshall step 6629 current loss 0.492186, current_train_items 212160.\n",
            "I0314 03:08:26.185566 138313941204992 run.py:479] Algo floyd_warshall step 6630 current loss 0.010418, current_train_items 212192.\n",
            "I0314 03:08:26.230002 138313941204992 run.py:479] Algo floyd_warshall step 6631 current loss 0.053770, current_train_items 212224.\n",
            "I0314 03:08:26.360964 138313941204992 run.py:479] Algo floyd_warshall step 6632 current loss 0.251538, current_train_items 212256.\n",
            "I0314 03:08:26.579199 138313941204992 run.py:479] Algo floyd_warshall step 6633 current loss 0.400341, current_train_items 212288.\n",
            "I0314 03:08:26.985432 138313941204992 run.py:479] Algo floyd_warshall step 6634 current loss 0.619424, current_train_items 212320.\n",
            "I0314 03:08:27.009459 138313941204992 run.py:479] Algo floyd_warshall step 6635 current loss 0.179537, current_train_items 212352.\n",
            "I0314 03:08:27.053670 138313941204992 run.py:479] Algo floyd_warshall step 6636 current loss 0.039982, current_train_items 212384.\n",
            "I0314 03:08:27.185246 138313941204992 run.py:479] Algo floyd_warshall step 6637 current loss 0.320358, current_train_items 212416.\n",
            "I0314 03:08:27.396977 138313941204992 run.py:479] Algo floyd_warshall step 6638 current loss 0.390960, current_train_items 212448.\n",
            "I0314 03:08:27.816758 138313941204992 run.py:479] Algo floyd_warshall step 6639 current loss 0.712005, current_train_items 212480.\n",
            "I0314 03:08:27.841030 138313941204992 run.py:479] Algo floyd_warshall step 6640 current loss 0.006712, current_train_items 212512.\n",
            "I0314 03:08:27.889528 138313941204992 run.py:479] Algo floyd_warshall step 6641 current loss 0.044907, current_train_items 212544.\n",
            "I0314 03:08:28.029095 138313941204992 run.py:479] Algo floyd_warshall step 6642 current loss 0.220169, current_train_items 212576.\n",
            "I0314 03:08:28.305995 138313941204992 run.py:479] Algo floyd_warshall step 6643 current loss 0.410976, current_train_items 212608.\n",
            "I0314 03:08:28.818388 138313941204992 run.py:479] Algo floyd_warshall step 6644 current loss 0.668734, current_train_items 212640.\n",
            "I0314 03:08:28.854530 138313941204992 run.py:479] Algo floyd_warshall step 6645 current loss 0.023553, current_train_items 212672.\n",
            "I0314 03:08:28.911524 138313941204992 run.py:479] Algo floyd_warshall step 6646 current loss 0.062942, current_train_items 212704.\n",
            "I0314 03:08:29.087415 138313941204992 run.py:479] Algo floyd_warshall step 6647 current loss 0.261099, current_train_items 212736.\n",
            "I0314 03:08:29.371451 138313941204992 run.py:479] Algo floyd_warshall step 6648 current loss 0.347930, current_train_items 212768.\n",
            "I0314 03:08:29.873049 138313941204992 run.py:479] Algo floyd_warshall step 6649 current loss 0.524200, current_train_items 212800.\n",
            "I0314 03:08:29.908056 138313941204992 run.py:479] Algo floyd_warshall step 6650 current loss 0.013587, current_train_items 212832.\n",
            "I0314 03:08:30.013892 138313941204992 run.py:499] (val) algo floyd_warshall step 6650: {'Pi': 0.89739990234375, 'score': 0.89739990234375, 'examples_seen': 212832, 'step': 6650, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:08:30.014188 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.908, current avg val score is 0.897, val scores are: floyd_warshall: 0.897\n",
            "I0314 03:08:30.080722 138313941204992 run.py:479] Algo floyd_warshall step 6651 current loss 0.041718, current_train_items 212864.\n",
            "I0314 03:08:30.239054 138313941204992 run.py:479] Algo floyd_warshall step 6652 current loss 0.255294, current_train_items 212896.\n",
            "I0314 03:08:30.502347 138313941204992 run.py:479] Algo floyd_warshall step 6653 current loss 0.346019, current_train_items 212928.\n",
            "I0314 03:08:30.995953 138313941204992 run.py:479] Algo floyd_warshall step 6654 current loss 0.583667, current_train_items 212960.\n",
            "I0314 03:08:31.037730 138313941204992 run.py:479] Algo floyd_warshall step 6655 current loss 0.013683, current_train_items 212992.\n",
            "I0314 03:08:31.099579 138313941204992 run.py:479] Algo floyd_warshall step 6656 current loss 0.046330, current_train_items 213024.\n",
            "I0314 03:08:31.242401 138313941204992 run.py:479] Algo floyd_warshall step 6657 current loss 0.272229, current_train_items 213056.\n",
            "I0314 03:08:31.464163 138313941204992 run.py:479] Algo floyd_warshall step 6658 current loss 0.293791, current_train_items 213088.\n",
            "I0314 03:08:31.870240 138313941204992 run.py:479] Algo floyd_warshall step 6659 current loss 0.436544, current_train_items 213120.\n",
            "I0314 03:08:31.895586 138313941204992 run.py:479] Algo floyd_warshall step 6660 current loss 0.039772, current_train_items 213152.\n",
            "I0314 03:08:31.940552 138313941204992 run.py:479] Algo floyd_warshall step 6661 current loss 0.066390, current_train_items 213184.\n",
            "I0314 03:08:32.068821 138313941204992 run.py:479] Algo floyd_warshall step 6662 current loss 0.200092, current_train_items 213216.\n",
            "I0314 03:08:32.312497 138313941204992 run.py:479] Algo floyd_warshall step 6663 current loss 0.402266, current_train_items 213248.\n",
            "I0314 03:08:32.722244 138313941204992 run.py:479] Algo floyd_warshall step 6664 current loss 0.522713, current_train_items 213280.\n",
            "I0314 03:08:32.747699 138313941204992 run.py:479] Algo floyd_warshall step 6665 current loss 0.011006, current_train_items 213312.\n",
            "I0314 03:08:32.792284 138313941204992 run.py:479] Algo floyd_warshall step 6666 current loss 0.096429, current_train_items 213344.\n",
            "I0314 03:08:32.923483 138313941204992 run.py:479] Algo floyd_warshall step 6667 current loss 0.213755, current_train_items 213376.\n",
            "I0314 03:08:33.139089 138313941204992 run.py:479] Algo floyd_warshall step 6668 current loss 0.318956, current_train_items 213408.\n",
            "I0314 03:08:33.565923 138313941204992 run.py:479] Algo floyd_warshall step 6669 current loss 0.682337, current_train_items 213440.\n",
            "I0314 03:08:33.589175 138313941204992 run.py:479] Algo floyd_warshall step 6670 current loss 0.008356, current_train_items 213472.\n",
            "I0314 03:08:33.634928 138313941204992 run.py:479] Algo floyd_warshall step 6671 current loss 0.063340, current_train_items 213504.\n",
            "I0314 03:08:33.763360 138313941204992 run.py:479] Algo floyd_warshall step 6672 current loss 0.161248, current_train_items 213536.\n",
            "I0314 03:08:33.992837 138313941204992 run.py:479] Algo floyd_warshall step 6673 current loss 0.386806, current_train_items 213568.\n",
            "I0314 03:08:34.413894 138313941204992 run.py:479] Algo floyd_warshall step 6674 current loss 0.645644, current_train_items 213600.\n",
            "I0314 03:08:34.438786 138313941204992 run.py:479] Algo floyd_warshall step 6675 current loss 0.032721, current_train_items 213632.\n",
            "I0314 03:08:34.484974 138313941204992 run.py:479] Algo floyd_warshall step 6676 current loss 0.057485, current_train_items 213664.\n",
            "I0314 03:08:34.614507 138313941204992 run.py:479] Algo floyd_warshall step 6677 current loss 0.186889, current_train_items 213696.\n",
            "I0314 03:08:34.835403 138313941204992 run.py:479] Algo floyd_warshall step 6678 current loss 0.313994, current_train_items 213728.\n",
            "I0314 03:08:35.240085 138313941204992 run.py:479] Algo floyd_warshall step 6679 current loss 0.523754, current_train_items 213760.\n",
            "I0314 03:08:35.262644 138313941204992 run.py:479] Algo floyd_warshall step 6680 current loss 0.156727, current_train_items 213792.\n",
            "I0314 03:08:35.305743 138313941204992 run.py:479] Algo floyd_warshall step 6681 current loss 0.091510, current_train_items 213824.\n",
            "I0314 03:08:35.433300 138313941204992 run.py:479] Algo floyd_warshall step 6682 current loss 0.221075, current_train_items 213856.\n",
            "I0314 03:08:35.648619 138313941204992 run.py:479] Algo floyd_warshall step 6683 current loss 0.396869, current_train_items 213888.\n",
            "I0314 03:08:36.063307 138313941204992 run.py:479] Algo floyd_warshall step 6684 current loss 0.653411, current_train_items 213920.\n",
            "I0314 03:08:36.086503 138313941204992 run.py:479] Algo floyd_warshall step 6685 current loss 0.010209, current_train_items 213952.\n",
            "I0314 03:08:36.134516 138313941204992 run.py:479] Algo floyd_warshall step 6686 current loss 0.031460, current_train_items 213984.\n",
            "I0314 03:08:36.264305 138313941204992 run.py:479] Algo floyd_warshall step 6687 current loss 0.222304, current_train_items 214016.\n",
            "I0314 03:08:36.487749 138313941204992 run.py:479] Algo floyd_warshall step 6688 current loss 0.391116, current_train_items 214048.\n",
            "I0314 03:08:36.891926 138313941204992 run.py:479] Algo floyd_warshall step 6689 current loss 0.531484, current_train_items 214080.\n",
            "I0314 03:08:36.914456 138313941204992 run.py:479] Algo floyd_warshall step 6690 current loss 0.005791, current_train_items 214112.\n",
            "I0314 03:08:36.959667 138313941204992 run.py:479] Algo floyd_warshall step 6691 current loss 0.071279, current_train_items 214144.\n",
            "I0314 03:08:37.092635 138313941204992 run.py:479] Algo floyd_warshall step 6692 current loss 0.264739, current_train_items 214176.\n",
            "I0314 03:08:37.320385 138313941204992 run.py:479] Algo floyd_warshall step 6693 current loss 0.383593, current_train_items 214208.\n",
            "I0314 03:08:37.727450 138313941204992 run.py:479] Algo floyd_warshall step 6694 current loss 0.447248, current_train_items 214240.\n",
            "I0314 03:08:37.752786 138313941204992 run.py:479] Algo floyd_warshall step 6695 current loss 0.020347, current_train_items 214272.\n",
            "I0314 03:08:37.798846 138313941204992 run.py:479] Algo floyd_warshall step 6696 current loss 0.039111, current_train_items 214304.\n",
            "I0314 03:08:37.928328 138313941204992 run.py:479] Algo floyd_warshall step 6697 current loss 0.179852, current_train_items 214336.\n",
            "I0314 03:08:38.152474 138313941204992 run.py:479] Algo floyd_warshall step 6698 current loss 0.312286, current_train_items 214368.\n",
            "I0314 03:08:38.558024 138313941204992 run.py:479] Algo floyd_warshall step 6699 current loss 0.554670, current_train_items 214400.\n",
            "I0314 03:08:38.580987 138313941204992 run.py:479] Algo floyd_warshall step 6700 current loss 0.023237, current_train_items 214432.\n",
            "I0314 03:08:38.668271 138313941204992 run.py:499] (val) algo floyd_warshall step 6700: {'Pi': 0.88946533203125, 'score': 0.88946533203125, 'examples_seen': 214432, 'step': 6700, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:08:38.668495 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.908, current avg val score is 0.889, val scores are: floyd_warshall: 0.889\n",
            "I0314 03:08:38.718510 138313941204992 run.py:479] Algo floyd_warshall step 6701 current loss 0.080745, current_train_items 214464.\n",
            "I0314 03:08:38.849962 138313941204992 run.py:479] Algo floyd_warshall step 6702 current loss 0.152589, current_train_items 214496.\n",
            "I0314 03:08:39.062648 138313941204992 run.py:479] Algo floyd_warshall step 6703 current loss 0.287610, current_train_items 214528.\n",
            "I0314 03:08:39.484925 138313941204992 run.py:479] Algo floyd_warshall step 6704 current loss 0.627469, current_train_items 214560.\n",
            "I0314 03:08:39.509591 138313941204992 run.py:479] Algo floyd_warshall step 6705 current loss 0.029902, current_train_items 214592.\n",
            "I0314 03:08:39.553873 138313941204992 run.py:479] Algo floyd_warshall step 6706 current loss 0.061026, current_train_items 214624.\n",
            "I0314 03:08:39.687210 138313941204992 run.py:479] Algo floyd_warshall step 6707 current loss 0.429248, current_train_items 214656.\n",
            "I0314 03:08:39.910024 138313941204992 run.py:479] Algo floyd_warshall step 6708 current loss 0.438326, current_train_items 214688.\n",
            "I0314 03:08:40.315886 138313941204992 run.py:479] Algo floyd_warshall step 6709 current loss 0.542362, current_train_items 214720.\n",
            "I0314 03:08:40.347061 138313941204992 run.py:479] Algo floyd_warshall step 6710 current loss 0.020150, current_train_items 214752.\n",
            "I0314 03:08:40.391817 138313941204992 run.py:479] Algo floyd_warshall step 6711 current loss 0.121179, current_train_items 214784.\n",
            "I0314 03:08:40.524087 138313941204992 run.py:479] Algo floyd_warshall step 6712 current loss 0.266983, current_train_items 214816.\n",
            "I0314 03:08:40.746331 138313941204992 run.py:479] Algo floyd_warshall step 6713 current loss 0.327165, current_train_items 214848.\n",
            "I0314 03:08:41.163003 138313941204992 run.py:479] Algo floyd_warshall step 6714 current loss 0.589671, current_train_items 214880.\n",
            "I0314 03:08:41.202808 138313941204992 run.py:479] Algo floyd_warshall step 6715 current loss 0.019581, current_train_items 214912.\n",
            "I0314 03:08:41.261817 138313941204992 run.py:479] Algo floyd_warshall step 6716 current loss 0.061663, current_train_items 214944.\n",
            "I0314 03:08:41.421521 138313941204992 run.py:479] Algo floyd_warshall step 6717 current loss 0.183021, current_train_items 214976.\n",
            "I0314 03:08:41.692949 138313941204992 run.py:479] Algo floyd_warshall step 6718 current loss 0.521112, current_train_items 215008.\n",
            "I0314 03:08:42.192134 138313941204992 run.py:479] Algo floyd_warshall step 6719 current loss 0.704367, current_train_items 215040.\n",
            "I0314 03:08:42.233258 138313941204992 run.py:479] Algo floyd_warshall step 6720 current loss 0.032228, current_train_items 215072.\n",
            "I0314 03:08:42.291139 138313941204992 run.py:479] Algo floyd_warshall step 6721 current loss 0.073671, current_train_items 215104.\n",
            "I0314 03:08:42.444000 138313941204992 run.py:479] Algo floyd_warshall step 6722 current loss 0.189341, current_train_items 215136.\n",
            "I0314 03:08:42.695682 138313941204992 run.py:479] Algo floyd_warshall step 6723 current loss 0.380895, current_train_items 215168.\n",
            "I0314 03:08:43.195090 138313941204992 run.py:479] Algo floyd_warshall step 6724 current loss 0.659137, current_train_items 215200.\n",
            "I0314 03:08:43.231117 138313941204992 run.py:479] Algo floyd_warshall step 6725 current loss 0.012986, current_train_items 215232.\n",
            "I0314 03:08:43.287791 138313941204992 run.py:479] Algo floyd_warshall step 6726 current loss 0.053674, current_train_items 215264.\n",
            "I0314 03:08:43.442836 138313941204992 run.py:479] Algo floyd_warshall step 6727 current loss 0.228429, current_train_items 215296.\n",
            "I0314 03:08:43.711248 138313941204992 run.py:479] Algo floyd_warshall step 6728 current loss 0.341052, current_train_items 215328.\n",
            "I0314 03:08:44.191307 138313941204992 run.py:479] Algo floyd_warshall step 6729 current loss 0.531960, current_train_items 215360.\n",
            "I0314 03:08:44.214761 138313941204992 run.py:479] Algo floyd_warshall step 6730 current loss 0.022037, current_train_items 215392.\n",
            "I0314 03:08:44.259881 138313941204992 run.py:479] Algo floyd_warshall step 6731 current loss 0.123600, current_train_items 215424.\n",
            "I0314 03:08:44.386383 138313941204992 run.py:479] Algo floyd_warshall step 6732 current loss 0.138804, current_train_items 215456.\n",
            "I0314 03:08:44.605129 138313941204992 run.py:479] Algo floyd_warshall step 6733 current loss 0.398981, current_train_items 215488.\n",
            "I0314 03:08:45.022287 138313941204992 run.py:479] Algo floyd_warshall step 6734 current loss 0.614188, current_train_items 215520.\n",
            "I0314 03:08:45.046192 138313941204992 run.py:479] Algo floyd_warshall step 6735 current loss 0.009753, current_train_items 215552.\n",
            "I0314 03:08:45.091287 138313941204992 run.py:479] Algo floyd_warshall step 6736 current loss 0.103178, current_train_items 215584.\n",
            "I0314 03:08:45.221452 138313941204992 run.py:479] Algo floyd_warshall step 6737 current loss 0.259346, current_train_items 215616.\n",
            "I0314 03:08:45.448119 138313941204992 run.py:479] Algo floyd_warshall step 6738 current loss 0.464281, current_train_items 215648.\n",
            "I0314 03:08:45.870423 138313941204992 run.py:479] Algo floyd_warshall step 6739 current loss 0.628122, current_train_items 215680.\n",
            "I0314 03:08:45.893323 138313941204992 run.py:479] Algo floyd_warshall step 6740 current loss 0.015205, current_train_items 215712.\n",
            "I0314 03:08:45.941457 138313941204992 run.py:479] Algo floyd_warshall step 6741 current loss 0.060693, current_train_items 215744.\n",
            "I0314 03:08:46.072016 138313941204992 run.py:479] Algo floyd_warshall step 6742 current loss 0.218443, current_train_items 215776.\n",
            "I0314 03:08:46.285396 138313941204992 run.py:479] Algo floyd_warshall step 6743 current loss 0.343073, current_train_items 215808.\n",
            "I0314 03:08:46.690343 138313941204992 run.py:479] Algo floyd_warshall step 6744 current loss 0.587876, current_train_items 215840.\n",
            "I0314 03:08:46.714461 138313941204992 run.py:479] Algo floyd_warshall step 6745 current loss 0.011140, current_train_items 215872.\n",
            "I0314 03:08:46.759702 138313941204992 run.py:479] Algo floyd_warshall step 6746 current loss 0.061452, current_train_items 215904.\n",
            "I0314 03:08:46.894259 138313941204992 run.py:479] Algo floyd_warshall step 6747 current loss 0.237033, current_train_items 215936.\n",
            "I0314 03:08:47.106660 138313941204992 run.py:479] Algo floyd_warshall step 6748 current loss 0.275367, current_train_items 215968.\n",
            "I0314 03:08:47.526493 138313941204992 run.py:479] Algo floyd_warshall step 6749 current loss 0.615195, current_train_items 216000.\n",
            "I0314 03:08:47.550188 138313941204992 run.py:479] Algo floyd_warshall step 6750 current loss 0.016541, current_train_items 216032.\n",
            "I0314 03:08:47.655768 138313941204992 run.py:499] (val) algo floyd_warshall step 6750: {'Pi': 0.9007568359375, 'score': 0.9007568359375, 'examples_seen': 216032, 'step': 6750, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:08:47.656018 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.908, current avg val score is 0.901, val scores are: floyd_warshall: 0.901\n",
            "I0314 03:08:47.703983 138313941204992 run.py:479] Algo floyd_warshall step 6751 current loss 0.069492, current_train_items 216064.\n",
            "I0314 03:08:47.833387 138313941204992 run.py:479] Algo floyd_warshall step 6752 current loss 0.226846, current_train_items 216096.\n",
            "I0314 03:08:48.050129 138313941204992 run.py:479] Algo floyd_warshall step 6753 current loss 0.383590, current_train_items 216128.\n",
            "I0314 03:08:48.474314 138313941204992 run.py:479] Algo floyd_warshall step 6754 current loss 0.646959, current_train_items 216160.\n",
            "I0314 03:08:48.500250 138313941204992 run.py:479] Algo floyd_warshall step 6755 current loss 0.012590, current_train_items 216192.\n",
            "I0314 03:08:48.547659 138313941204992 run.py:479] Algo floyd_warshall step 6756 current loss 0.046968, current_train_items 216224.\n",
            "I0314 03:08:48.690172 138313941204992 run.py:479] Algo floyd_warshall step 6757 current loss 0.292761, current_train_items 216256.\n",
            "I0314 03:08:48.899615 138313941204992 run.py:479] Algo floyd_warshall step 6758 current loss 0.262607, current_train_items 216288.\n",
            "I0314 03:08:49.306506 138313941204992 run.py:479] Algo floyd_warshall step 6759 current loss 0.552720, current_train_items 216320.\n",
            "I0314 03:08:49.329934 138313941204992 run.py:479] Algo floyd_warshall step 6760 current loss 0.017415, current_train_items 216352.\n",
            "I0314 03:08:49.374595 138313941204992 run.py:479] Algo floyd_warshall step 6761 current loss 0.062396, current_train_items 216384.\n",
            "I0314 03:08:49.507292 138313941204992 run.py:479] Algo floyd_warshall step 6762 current loss 0.281280, current_train_items 216416.\n",
            "I0314 03:08:49.720995 138313941204992 run.py:479] Algo floyd_warshall step 6763 current loss 0.308123, current_train_items 216448.\n",
            "I0314 03:08:50.127055 138313941204992 run.py:479] Algo floyd_warshall step 6764 current loss 0.581733, current_train_items 216480.\n",
            "I0314 03:08:50.150083 138313941204992 run.py:479] Algo floyd_warshall step 6765 current loss 0.010857, current_train_items 216512.\n",
            "I0314 03:08:50.194279 138313941204992 run.py:479] Algo floyd_warshall step 6766 current loss 0.046140, current_train_items 216544.\n",
            "I0314 03:08:50.325202 138313941204992 run.py:479] Algo floyd_warshall step 6767 current loss 0.230062, current_train_items 216576.\n",
            "I0314 03:08:50.539725 138313941204992 run.py:479] Algo floyd_warshall step 6768 current loss 0.302537, current_train_items 216608.\n",
            "I0314 03:08:50.965770 138313941204992 run.py:479] Algo floyd_warshall step 6769 current loss 0.628019, current_train_items 216640.\n",
            "I0314 03:08:50.989869 138313941204992 run.py:479] Algo floyd_warshall step 6770 current loss 0.009418, current_train_items 216672.\n",
            "I0314 03:08:51.036478 138313941204992 run.py:479] Algo floyd_warshall step 6771 current loss 0.044831, current_train_items 216704.\n",
            "I0314 03:08:51.169910 138313941204992 run.py:479] Algo floyd_warshall step 6772 current loss 0.271236, current_train_items 216736.\n",
            "I0314 03:08:51.396079 138313941204992 run.py:479] Algo floyd_warshall step 6773 current loss 0.318563, current_train_items 216768.\n",
            "I0314 03:08:51.812834 138313941204992 run.py:479] Algo floyd_warshall step 6774 current loss 0.632051, current_train_items 216800.\n",
            "I0314 03:08:51.836016 138313941204992 run.py:479] Algo floyd_warshall step 6775 current loss 0.012848, current_train_items 216832.\n",
            "I0314 03:08:51.881347 138313941204992 run.py:479] Algo floyd_warshall step 6776 current loss 0.095816, current_train_items 216864.\n",
            "I0314 03:08:52.008438 138313941204992 run.py:479] Algo floyd_warshall step 6777 current loss 0.232259, current_train_items 216896.\n",
            "I0314 03:08:52.228122 138313941204992 run.py:479] Algo floyd_warshall step 6778 current loss 0.372823, current_train_items 216928.\n",
            "I0314 03:08:52.640669 138313941204992 run.py:479] Algo floyd_warshall step 6779 current loss 0.609316, current_train_items 216960.\n",
            "I0314 03:08:52.664385 138313941204992 run.py:479] Algo floyd_warshall step 6780 current loss 0.018702, current_train_items 216992.\n",
            "I0314 03:08:52.720479 138313941204992 run.py:479] Algo floyd_warshall step 6781 current loss 0.048631, current_train_items 217024.\n",
            "I0314 03:08:52.849473 138313941204992 run.py:479] Algo floyd_warshall step 6782 current loss 0.245082, current_train_items 217056.\n",
            "I0314 03:08:53.076078 138313941204992 run.py:479] Algo floyd_warshall step 6783 current loss 0.417697, current_train_items 217088.\n",
            "I0314 03:08:53.485687 138313941204992 run.py:479] Algo floyd_warshall step 6784 current loss 0.488995, current_train_items 217120.\n",
            "I0314 03:08:53.508174 138313941204992 run.py:479] Algo floyd_warshall step 6785 current loss 0.013029, current_train_items 217152.\n",
            "I0314 03:08:53.551985 138313941204992 run.py:479] Algo floyd_warshall step 6786 current loss 0.090539, current_train_items 217184.\n",
            "I0314 03:08:53.680321 138313941204992 run.py:479] Algo floyd_warshall step 6787 current loss 0.209652, current_train_items 217216.\n",
            "I0314 03:08:53.923021 138313941204992 run.py:479] Algo floyd_warshall step 6788 current loss 0.364989, current_train_items 217248.\n",
            "I0314 03:08:54.341429 138313941204992 run.py:479] Algo floyd_warshall step 6789 current loss 0.617620, current_train_items 217280.\n",
            "I0314 03:08:54.377810 138313941204992 run.py:479] Algo floyd_warshall step 6790 current loss 0.021240, current_train_items 217312.\n",
            "I0314 03:08:54.434272 138313941204992 run.py:479] Algo floyd_warshall step 6791 current loss 0.069042, current_train_items 217344.\n",
            "I0314 03:08:54.589731 138313941204992 run.py:479] Algo floyd_warshall step 6792 current loss 0.203845, current_train_items 217376.\n",
            "I0314 03:08:54.846993 138313941204992 run.py:479] Algo floyd_warshall step 6793 current loss 0.348254, current_train_items 217408.\n",
            "I0314 03:08:55.339548 138313941204992 run.py:479] Algo floyd_warshall step 6794 current loss 0.656783, current_train_items 217440.\n",
            "I0314 03:08:55.376680 138313941204992 run.py:479] Algo floyd_warshall step 6795 current loss 0.022674, current_train_items 217472.\n",
            "I0314 03:08:55.434834 138313941204992 run.py:479] Algo floyd_warshall step 6796 current loss 0.072181, current_train_items 217504.\n",
            "I0314 03:08:55.590447 138313941204992 run.py:479] Algo floyd_warshall step 6797 current loss 0.256059, current_train_items 217536.\n",
            "I0314 03:08:55.849714 138313941204992 run.py:479] Algo floyd_warshall step 6798 current loss 0.372215, current_train_items 217568.\n",
            "I0314 03:08:56.350333 138313941204992 run.py:479] Algo floyd_warshall step 6799 current loss 0.628537, current_train_items 217600.\n",
            "I0314 03:08:56.382333 138313941204992 run.py:479] Algo floyd_warshall step 6800 current loss 0.037887, current_train_items 217632.\n",
            "I0314 03:08:56.497757 138313941204992 run.py:499] (val) algo floyd_warshall step 6800: {'Pi': 0.9173583984375, 'score': 0.9173583984375, 'examples_seen': 217632, 'step': 6800, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:08:56.498087 138313941204992 run.py:516] Checkpointing best model, best avg val score was 0.908, current avg val score is 0.917, val scores are: floyd_warshall: 0.917\n",
            "I0314 03:08:56.610208 138313941204992 run.py:479] Algo floyd_warshall step 6801 current loss 0.076701, current_train_items 217664.\n",
            "I0314 03:08:56.774471 138313941204992 run.py:479] Algo floyd_warshall step 6802 current loss 0.168021, current_train_items 217696.\n",
            "I0314 03:08:57.041278 138313941204992 run.py:479] Algo floyd_warshall step 6803 current loss 0.361192, current_train_items 217728.\n",
            "I0314 03:08:57.535374 138313941204992 run.py:479] Algo floyd_warshall step 6804 current loss 0.690328, current_train_items 217760.\n",
            "I0314 03:08:57.559839 138313941204992 run.py:479] Algo floyd_warshall step 6805 current loss 0.015800, current_train_items 217792.\n",
            "I0314 03:08:57.604804 138313941204992 run.py:479] Algo floyd_warshall step 6806 current loss 0.072130, current_train_items 217824.\n",
            "I0314 03:08:57.738589 138313941204992 run.py:479] Algo floyd_warshall step 6807 current loss 0.262328, current_train_items 217856.\n",
            "I0314 03:08:57.956387 138313941204992 run.py:479] Algo floyd_warshall step 6808 current loss 0.355329, current_train_items 217888.\n",
            "I0314 03:08:58.358446 138313941204992 run.py:479] Algo floyd_warshall step 6809 current loss 0.517034, current_train_items 217920.\n",
            "I0314 03:08:58.383134 138313941204992 run.py:479] Algo floyd_warshall step 6810 current loss 0.014664, current_train_items 217952.\n",
            "I0314 03:08:58.428971 138313941204992 run.py:479] Algo floyd_warshall step 6811 current loss 0.065438, current_train_items 217984.\n",
            "I0314 03:08:58.559663 138313941204992 run.py:479] Algo floyd_warshall step 6812 current loss 0.226637, current_train_items 218016.\n",
            "I0314 03:08:58.776398 138313941204992 run.py:479] Algo floyd_warshall step 6813 current loss 0.279111, current_train_items 218048.\n",
            "I0314 03:08:59.197489 138313941204992 run.py:479] Algo floyd_warshall step 6814 current loss 0.617300, current_train_items 218080.\n",
            "I0314 03:08:59.222570 138313941204992 run.py:479] Algo floyd_warshall step 6815 current loss 0.011496, current_train_items 218112.\n",
            "I0314 03:08:59.268316 138313941204992 run.py:479] Algo floyd_warshall step 6816 current loss 0.091735, current_train_items 218144.\n",
            "I0314 03:08:59.400284 138313941204992 run.py:479] Algo floyd_warshall step 6817 current loss 0.202840, current_train_items 218176.\n",
            "I0314 03:08:59.626136 138313941204992 run.py:479] Algo floyd_warshall step 6818 current loss 0.303176, current_train_items 218208.\n",
            "I0314 03:09:00.058707 138313941204992 run.py:479] Algo floyd_warshall step 6819 current loss 0.628847, current_train_items 218240.\n",
            "I0314 03:09:00.084379 138313941204992 run.py:479] Algo floyd_warshall step 6820 current loss 0.011476, current_train_items 218272.\n",
            "I0314 03:09:00.132586 138313941204992 run.py:479] Algo floyd_warshall step 6821 current loss 0.049887, current_train_items 218304.\n",
            "I0314 03:09:00.264177 138313941204992 run.py:479] Algo floyd_warshall step 6822 current loss 0.218678, current_train_items 218336.\n",
            "I0314 03:09:00.483770 138313941204992 run.py:479] Algo floyd_warshall step 6823 current loss 0.404752, current_train_items 218368.\n",
            "I0314 03:09:00.914175 138313941204992 run.py:479] Algo floyd_warshall step 6824 current loss 0.723469, current_train_items 218400.\n",
            "I0314 03:09:00.938464 138313941204992 run.py:479] Algo floyd_warshall step 6825 current loss 0.016673, current_train_items 218432.\n",
            "I0314 03:09:00.986391 138313941204992 run.py:479] Algo floyd_warshall step 6826 current loss 0.077807, current_train_items 218464.\n",
            "I0314 03:09:01.124699 138313941204992 run.py:479] Algo floyd_warshall step 6827 current loss 0.279234, current_train_items 218496.\n",
            "I0314 03:09:01.350805 138313941204992 run.py:479] Algo floyd_warshall step 6828 current loss 0.344191, current_train_items 218528.\n",
            "I0314 03:09:01.790860 138313941204992 run.py:479] Algo floyd_warshall step 6829 current loss 0.712582, current_train_items 218560.\n",
            "I0314 03:09:01.815570 138313941204992 run.py:479] Algo floyd_warshall step 6830 current loss 0.021394, current_train_items 218592.\n",
            "I0314 03:09:01.862723 138313941204992 run.py:479] Algo floyd_warshall step 6831 current loss 0.046190, current_train_items 218624.\n",
            "I0314 03:09:01.994103 138313941204992 run.py:479] Algo floyd_warshall step 6832 current loss 0.169985, current_train_items 218656.\n",
            "I0314 03:09:02.227633 138313941204992 run.py:479] Algo floyd_warshall step 6833 current loss 0.349174, current_train_items 218688.\n",
            "I0314 03:09:02.629753 138313941204992 run.py:479] Algo floyd_warshall step 6834 current loss 0.420472, current_train_items 218720.\n",
            "I0314 03:09:02.653860 138313941204992 run.py:479] Algo floyd_warshall step 6835 current loss 0.021219, current_train_items 218752.\n",
            "I0314 03:09:02.698907 138313941204992 run.py:479] Algo floyd_warshall step 6836 current loss 0.137590, current_train_items 218784.\n",
            "I0314 03:09:02.832820 138313941204992 run.py:479] Algo floyd_warshall step 6837 current loss 0.242619, current_train_items 218816.\n",
            "I0314 03:09:03.057562 138313941204992 run.py:479] Algo floyd_warshall step 6838 current loss 0.265927, current_train_items 218848.\n",
            "I0314 03:09:03.491774 138313941204992 run.py:479] Algo floyd_warshall step 6839 current loss 0.676104, current_train_items 218880.\n",
            "I0314 03:09:03.514975 138313941204992 run.py:479] Algo floyd_warshall step 6840 current loss 0.029986, current_train_items 218912.\n",
            "I0314 03:09:03.561450 138313941204992 run.py:479] Algo floyd_warshall step 6841 current loss 0.051546, current_train_items 218944.\n",
            "I0314 03:09:03.693797 138313941204992 run.py:479] Algo floyd_warshall step 6842 current loss 0.181639, current_train_items 218976.\n",
            "I0314 03:09:03.911772 138313941204992 run.py:479] Algo floyd_warshall step 6843 current loss 0.310616, current_train_items 219008.\n",
            "I0314 03:09:04.315383 138313941204992 run.py:479] Algo floyd_warshall step 6844 current loss 0.461473, current_train_items 219040.\n",
            "I0314 03:09:04.340306 138313941204992 run.py:479] Algo floyd_warshall step 6845 current loss 0.015914, current_train_items 219072.\n",
            "I0314 03:09:04.385631 138313941204992 run.py:479] Algo floyd_warshall step 6846 current loss 0.070604, current_train_items 219104.\n",
            "I0314 03:09:04.517951 138313941204992 run.py:479] Algo floyd_warshall step 6847 current loss 0.218406, current_train_items 219136.\n",
            "I0314 03:09:04.740246 138313941204992 run.py:479] Algo floyd_warshall step 6848 current loss 0.482405, current_train_items 219168.\n",
            "I0314 03:09:05.169671 138313941204992 run.py:479] Algo floyd_warshall step 6849 current loss 0.568123, current_train_items 219200.\n",
            "I0314 03:09:05.194675 138313941204992 run.py:479] Algo floyd_warshall step 6850 current loss 0.012251, current_train_items 219232.\n",
            "I0314 03:09:05.283374 138313941204992 run.py:499] (val) algo floyd_warshall step 6850: {'Pi': 0.896728515625, 'score': 0.896728515625, 'examples_seen': 219232, 'step': 6850, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:09:05.283621 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.917, current avg val score is 0.897, val scores are: floyd_warshall: 0.897\n",
            "I0314 03:09:05.333327 138313941204992 run.py:479] Algo floyd_warshall step 6851 current loss 0.052169, current_train_items 219264.\n",
            "I0314 03:09:05.465471 138313941204992 run.py:479] Algo floyd_warshall step 6852 current loss 0.206390, current_train_items 219296.\n",
            "I0314 03:09:05.681402 138313941204992 run.py:479] Algo floyd_warshall step 6853 current loss 0.262372, current_train_items 219328.\n",
            "I0314 03:09:06.100120 138313941204992 run.py:479] Algo floyd_warshall step 6854 current loss 0.514297, current_train_items 219360.\n",
            "I0314 03:09:06.140209 138313941204992 run.py:479] Algo floyd_warshall step 6855 current loss 0.012003, current_train_items 219392.\n",
            "I0314 03:09:06.184772 138313941204992 run.py:479] Algo floyd_warshall step 6856 current loss 0.045856, current_train_items 219424.\n",
            "I0314 03:09:06.315184 138313941204992 run.py:479] Algo floyd_warshall step 6857 current loss 0.190025, current_train_items 219456.\n",
            "I0314 03:09:06.524637 138313941204992 run.py:479] Algo floyd_warshall step 6858 current loss 0.264770, current_train_items 219488.\n",
            "I0314 03:09:06.942263 138313941204992 run.py:479] Algo floyd_warshall step 6859 current loss 0.542658, current_train_items 219520.\n",
            "I0314 03:09:06.965842 138313941204992 run.py:479] Algo floyd_warshall step 6860 current loss 0.029812, current_train_items 219552.\n",
            "I0314 03:09:07.009948 138313941204992 run.py:479] Algo floyd_warshall step 6861 current loss 0.055327, current_train_items 219584.\n",
            "I0314 03:09:07.137471 138313941204992 run.py:479] Algo floyd_warshall step 6862 current loss 0.202956, current_train_items 219616.\n",
            "I0314 03:09:07.382867 138313941204992 run.py:479] Algo floyd_warshall step 6863 current loss 0.347438, current_train_items 219648.\n",
            "I0314 03:09:07.854866 138313941204992 run.py:479] Algo floyd_warshall step 6864 current loss 0.506748, current_train_items 219680.\n",
            "I0314 03:09:07.890493 138313941204992 run.py:479] Algo floyd_warshall step 6865 current loss 0.011958, current_train_items 219712.\n",
            "I0314 03:09:07.949259 138313941204992 run.py:479] Algo floyd_warshall step 6866 current loss 0.147829, current_train_items 219744.\n",
            "I0314 03:09:08.106866 138313941204992 run.py:479] Algo floyd_warshall step 6867 current loss 0.195497, current_train_items 219776.\n",
            "I0314 03:09:08.379489 138313941204992 run.py:479] Algo floyd_warshall step 6868 current loss 0.320759, current_train_items 219808.\n",
            "I0314 03:09:08.869451 138313941204992 run.py:479] Algo floyd_warshall step 6869 current loss 0.547403, current_train_items 219840.\n",
            "I0314 03:09:08.903699 138313941204992 run.py:479] Algo floyd_warshall step 6870 current loss 0.013413, current_train_items 219872.\n",
            "I0314 03:09:08.960588 138313941204992 run.py:479] Algo floyd_warshall step 6871 current loss 0.051073, current_train_items 219904.\n",
            "I0314 03:09:09.117526 138313941204992 run.py:479] Algo floyd_warshall step 6872 current loss 0.202908, current_train_items 219936.\n",
            "I0314 03:09:09.377999 138313941204992 run.py:479] Algo floyd_warshall step 6873 current loss 0.376481, current_train_items 219968.\n",
            "I0314 03:09:09.874546 138313941204992 run.py:479] Algo floyd_warshall step 6874 current loss 0.565154, current_train_items 220000.\n",
            "I0314 03:09:09.910995 138313941204992 run.py:479] Algo floyd_warshall step 6875 current loss 0.014793, current_train_items 220032.\n",
            "I0314 03:09:09.969007 138313941204992 run.py:479] Algo floyd_warshall step 6876 current loss 0.109441, current_train_items 220064.\n",
            "I0314 03:09:10.125736 138313941204992 run.py:479] Algo floyd_warshall step 6877 current loss 0.213062, current_train_items 220096.\n",
            "I0314 03:09:10.382101 138313941204992 run.py:479] Algo floyd_warshall step 6878 current loss 0.314886, current_train_items 220128.\n",
            "I0314 03:09:10.802175 138313941204992 run.py:479] Algo floyd_warshall step 6879 current loss 0.566397, current_train_items 220160.\n",
            "I0314 03:09:10.827538 138313941204992 run.py:479] Algo floyd_warshall step 6880 current loss 0.019427, current_train_items 220192.\n",
            "I0314 03:09:10.874981 138313941204992 run.py:479] Algo floyd_warshall step 6881 current loss 0.076672, current_train_items 220224.\n",
            "I0314 03:09:11.003337 138313941204992 run.py:479] Algo floyd_warshall step 6882 current loss 0.199422, current_train_items 220256.\n",
            "I0314 03:09:11.229125 138313941204992 run.py:479] Algo floyd_warshall step 6883 current loss 0.457320, current_train_items 220288.\n",
            "I0314 03:09:11.645755 138313941204992 run.py:479] Algo floyd_warshall step 6884 current loss 0.586864, current_train_items 220320.\n",
            "I0314 03:09:11.668483 138313941204992 run.py:479] Algo floyd_warshall step 6885 current loss 0.022157, current_train_items 220352.\n",
            "I0314 03:09:11.711774 138313941204992 run.py:479] Algo floyd_warshall step 6886 current loss 0.107643, current_train_items 220384.\n",
            "I0314 03:09:11.842838 138313941204992 run.py:479] Algo floyd_warshall step 6887 current loss 0.183154, current_train_items 220416.\n",
            "I0314 03:09:12.062750 138313941204992 run.py:479] Algo floyd_warshall step 6888 current loss 0.372295, current_train_items 220448.\n",
            "I0314 03:09:12.474794 138313941204992 run.py:479] Algo floyd_warshall step 6889 current loss 0.566292, current_train_items 220480.\n",
            "I0314 03:09:12.496908 138313941204992 run.py:479] Algo floyd_warshall step 6890 current loss 0.011888, current_train_items 220512.\n",
            "I0314 03:09:12.541074 138313941204992 run.py:479] Algo floyd_warshall step 6891 current loss 0.065901, current_train_items 220544.\n",
            "I0314 03:09:12.667876 138313941204992 run.py:479] Algo floyd_warshall step 6892 current loss 0.164867, current_train_items 220576.\n",
            "I0314 03:09:12.886583 138313941204992 run.py:479] Algo floyd_warshall step 6893 current loss 0.333797, current_train_items 220608.\n",
            "I0314 03:09:13.299963 138313941204992 run.py:479] Algo floyd_warshall step 6894 current loss 0.499187, current_train_items 220640.\n",
            "I0314 03:09:13.322653 138313941204992 run.py:479] Algo floyd_warshall step 6895 current loss 0.010033, current_train_items 220672.\n",
            "I0314 03:09:13.368123 138313941204992 run.py:479] Algo floyd_warshall step 6896 current loss 0.047439, current_train_items 220704.\n",
            "I0314 03:09:13.498035 138313941204992 run.py:479] Algo floyd_warshall step 6897 current loss 0.187954, current_train_items 220736.\n",
            "I0314 03:09:13.719624 138313941204992 run.py:479] Algo floyd_warshall step 6898 current loss 0.342240, current_train_items 220768.\n",
            "I0314 03:09:14.128291 138313941204992 run.py:479] Algo floyd_warshall step 6899 current loss 0.509165, current_train_items 220800.\n",
            "I0314 03:09:14.152434 138313941204992 run.py:479] Algo floyd_warshall step 6900 current loss 0.051556, current_train_items 220832.\n",
            "I0314 03:09:14.237661 138313941204992 run.py:499] (val) algo floyd_warshall step 6900: {'Pi': 0.891357421875, 'score': 0.891357421875, 'examples_seen': 220832, 'step': 6900, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:09:14.237927 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.917, current avg val score is 0.891, val scores are: floyd_warshall: 0.891\n",
            "I0314 03:09:14.287588 138313941204992 run.py:479] Algo floyd_warshall step 6901 current loss 0.043629, current_train_items 220864.\n",
            "I0314 03:09:14.421087 138313941204992 run.py:479] Algo floyd_warshall step 6902 current loss 0.165661, current_train_items 220896.\n",
            "I0314 03:09:14.641792 138313941204992 run.py:479] Algo floyd_warshall step 6903 current loss 0.366891, current_train_items 220928.\n",
            "I0314 03:09:15.068228 138313941204992 run.py:479] Algo floyd_warshall step 6904 current loss 0.607082, current_train_items 220960.\n",
            "I0314 03:09:15.093609 138313941204992 run.py:479] Algo floyd_warshall step 6905 current loss 0.031044, current_train_items 220992.\n",
            "I0314 03:09:15.138979 138313941204992 run.py:479] Algo floyd_warshall step 6906 current loss 0.044538, current_train_items 221024.\n",
            "I0314 03:09:15.269285 138313941204992 run.py:479] Algo floyd_warshall step 6907 current loss 0.129777, current_train_items 221056.\n",
            "I0314 03:09:15.482990 138313941204992 run.py:479] Algo floyd_warshall step 6908 current loss 0.324702, current_train_items 221088.\n",
            "I0314 03:09:15.894146 138313941204992 run.py:479] Algo floyd_warshall step 6909 current loss 0.607230, current_train_items 221120.\n",
            "I0314 03:09:15.917191 138313941204992 run.py:479] Algo floyd_warshall step 6910 current loss 0.011050, current_train_items 221152.\n",
            "I0314 03:09:15.961676 138313941204992 run.py:479] Algo floyd_warshall step 6911 current loss 0.061668, current_train_items 221184.\n",
            "I0314 03:09:16.088345 138313941204992 run.py:479] Algo floyd_warshall step 6912 current loss 0.210447, current_train_items 221216.\n",
            "I0314 03:09:16.302037 138313941204992 run.py:479] Algo floyd_warshall step 6913 current loss 0.301404, current_train_items 221248.\n",
            "I0314 03:09:16.712059 138313941204992 run.py:479] Algo floyd_warshall step 6914 current loss 0.628760, current_train_items 221280.\n",
            "I0314 03:09:16.738942 138313941204992 run.py:479] Algo floyd_warshall step 6915 current loss 0.018400, current_train_items 221312.\n",
            "I0314 03:09:16.786519 138313941204992 run.py:479] Algo floyd_warshall step 6916 current loss 0.037604, current_train_items 221344.\n",
            "I0314 03:09:16.920895 138313941204992 run.py:479] Algo floyd_warshall step 6917 current loss 0.171940, current_train_items 221376.\n",
            "I0314 03:09:17.143371 138313941204992 run.py:479] Algo floyd_warshall step 6918 current loss 0.336433, current_train_items 221408.\n",
            "I0314 03:09:17.558510 138313941204992 run.py:479] Algo floyd_warshall step 6919 current loss 0.615223, current_train_items 221440.\n",
            "I0314 03:09:17.582855 138313941204992 run.py:479] Algo floyd_warshall step 6920 current loss 0.012682, current_train_items 221472.\n",
            "I0314 03:09:17.628512 138313941204992 run.py:479] Algo floyd_warshall step 6921 current loss 0.072652, current_train_items 221504.\n",
            "I0314 03:09:17.759315 138313941204992 run.py:479] Algo floyd_warshall step 6922 current loss 0.242391, current_train_items 221536.\n",
            "I0314 03:09:17.976850 138313941204992 run.py:479] Algo floyd_warshall step 6923 current loss 0.367542, current_train_items 221568.\n",
            "I0314 03:09:18.380247 138313941204992 run.py:479] Algo floyd_warshall step 6924 current loss 0.599703, current_train_items 221600.\n",
            "I0314 03:09:18.402812 138313941204992 run.py:479] Algo floyd_warshall step 6925 current loss 0.008117, current_train_items 221632.\n",
            "I0314 03:09:18.447958 138313941204992 run.py:479] Algo floyd_warshall step 6926 current loss 0.063328, current_train_items 221664.\n",
            "I0314 03:09:18.597776 138313941204992 run.py:479] Algo floyd_warshall step 6927 current loss 0.259491, current_train_items 221696.\n",
            "I0314 03:09:18.820504 138313941204992 run.py:479] Algo floyd_warshall step 6928 current loss 0.429723, current_train_items 221728.\n",
            "I0314 03:09:19.237270 138313941204992 run.py:479] Algo floyd_warshall step 6929 current loss 0.610177, current_train_items 221760.\n",
            "I0314 03:09:19.261220 138313941204992 run.py:479] Algo floyd_warshall step 6930 current loss 0.016670, current_train_items 221792.\n",
            "I0314 03:09:19.305672 138313941204992 run.py:479] Algo floyd_warshall step 6931 current loss 0.054086, current_train_items 221824.\n",
            "I0314 03:09:19.437470 138313941204992 run.py:479] Algo floyd_warshall step 6932 current loss 0.262309, current_train_items 221856.\n",
            "I0314 03:09:19.666168 138313941204992 run.py:479] Algo floyd_warshall step 6933 current loss 0.350007, current_train_items 221888.\n",
            "I0314 03:09:20.090903 138313941204992 run.py:479] Algo floyd_warshall step 6934 current loss 0.632554, current_train_items 221920.\n",
            "I0314 03:09:20.114941 138313941204992 run.py:479] Algo floyd_warshall step 6935 current loss 0.018118, current_train_items 221952.\n",
            "I0314 03:09:20.159509 138313941204992 run.py:479] Algo floyd_warshall step 6936 current loss 0.045113, current_train_items 221984.\n",
            "I0314 03:09:20.288917 138313941204992 run.py:479] Algo floyd_warshall step 6937 current loss 0.203906, current_train_items 222016.\n",
            "I0314 03:09:20.552690 138313941204992 run.py:479] Algo floyd_warshall step 6938 current loss 0.304427, current_train_items 222048.\n",
            "I0314 03:09:21.052558 138313941204992 run.py:479] Algo floyd_warshall step 6939 current loss 0.613973, current_train_items 222080.\n",
            "I0314 03:09:21.084548 138313941204992 run.py:479] Algo floyd_warshall step 6940 current loss 0.027883, current_train_items 222112.\n",
            "I0314 03:09:21.139751 138313941204992 run.py:479] Algo floyd_warshall step 6941 current loss 0.057328, current_train_items 222144.\n",
            "I0314 03:09:21.297697 138313941204992 run.py:479] Algo floyd_warshall step 6942 current loss 0.208816, current_train_items 222176.\n",
            "I0314 03:09:21.566525 138313941204992 run.py:479] Algo floyd_warshall step 6943 current loss 0.360731, current_train_items 222208.\n",
            "I0314 03:09:22.081954 138313941204992 run.py:479] Algo floyd_warshall step 6944 current loss 0.612892, current_train_items 222240.\n",
            "I0314 03:09:22.116241 138313941204992 run.py:479] Algo floyd_warshall step 6945 current loss 0.009457, current_train_items 222272.\n",
            "I0314 03:09:22.172947 138313941204992 run.py:479] Algo floyd_warshall step 6946 current loss 0.043017, current_train_items 222304.\n",
            "I0314 03:09:22.325546 138313941204992 run.py:479] Algo floyd_warshall step 6947 current loss 0.270192, current_train_items 222336.\n",
            "I0314 03:09:22.588861 138313941204992 run.py:479] Algo floyd_warshall step 6948 current loss 0.348075, current_train_items 222368.\n",
            "I0314 03:09:23.095919 138313941204992 run.py:479] Algo floyd_warshall step 6949 current loss 0.775134, current_train_items 222400.\n",
            "I0314 03:09:23.135281 138313941204992 run.py:479] Algo floyd_warshall step 6950 current loss 0.022566, current_train_items 222432.\n",
            "I0314 03:09:23.250650 138313941204992 run.py:499] (val) algo floyd_warshall step 6950: {'Pi': 0.90338134765625, 'score': 0.90338134765625, 'examples_seen': 222432, 'step': 6950, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:09:23.250918 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.917, current avg val score is 0.903, val scores are: floyd_warshall: 0.903\n",
            "I0314 03:09:23.299277 138313941204992 run.py:479] Algo floyd_warshall step 6951 current loss 0.057642, current_train_items 222464.\n",
            "I0314 03:09:23.427999 138313941204992 run.py:479] Algo floyd_warshall step 6952 current loss 0.255055, current_train_items 222496.\n",
            "I0314 03:09:23.638798 138313941204992 run.py:479] Algo floyd_warshall step 6953 current loss 0.317993, current_train_items 222528.\n",
            "I0314 03:09:24.064136 138313941204992 run.py:479] Algo floyd_warshall step 6954 current loss 0.734112, current_train_items 222560.\n",
            "I0314 03:09:24.089027 138313941204992 run.py:479] Algo floyd_warshall step 6955 current loss 0.025475, current_train_items 222592.\n",
            "I0314 03:09:24.133088 138313941204992 run.py:479] Algo floyd_warshall step 6956 current loss 0.054223, current_train_items 222624.\n",
            "I0314 03:09:24.261405 138313941204992 run.py:479] Algo floyd_warshall step 6957 current loss 0.210291, current_train_items 222656.\n",
            "I0314 03:09:24.484983 138313941204992 run.py:479] Algo floyd_warshall step 6958 current loss 0.341240, current_train_items 222688.\n",
            "I0314 03:09:24.894116 138313941204992 run.py:479] Algo floyd_warshall step 6959 current loss 0.618870, current_train_items 222720.\n",
            "I0314 03:09:24.917159 138313941204992 run.py:479] Algo floyd_warshall step 6960 current loss 0.031471, current_train_items 222752.\n",
            "I0314 03:09:24.961277 138313941204992 run.py:479] Algo floyd_warshall step 6961 current loss 0.075472, current_train_items 222784.\n",
            "I0314 03:09:25.089515 138313941204992 run.py:479] Algo floyd_warshall step 6962 current loss 0.239039, current_train_items 222816.\n",
            "I0314 03:09:25.303400 138313941204992 run.py:479] Algo floyd_warshall step 6963 current loss 0.322354, current_train_items 222848.\n",
            "I0314 03:09:25.698366 138313941204992 run.py:479] Algo floyd_warshall step 6964 current loss 0.514097, current_train_items 222880.\n",
            "I0314 03:09:25.721256 138313941204992 run.py:479] Algo floyd_warshall step 6965 current loss 0.011606, current_train_items 222912.\n",
            "I0314 03:09:25.764769 138313941204992 run.py:479] Algo floyd_warshall step 6966 current loss 0.081642, current_train_items 222944.\n",
            "I0314 03:09:25.896849 138313941204992 run.py:479] Algo floyd_warshall step 6967 current loss 0.226635, current_train_items 222976.\n",
            "I0314 03:09:26.115855 138313941204992 run.py:479] Algo floyd_warshall step 6968 current loss 0.452474, current_train_items 223008.\n",
            "I0314 03:09:26.525472 138313941204992 run.py:479] Algo floyd_warshall step 6969 current loss 0.666175, current_train_items 223040.\n",
            "I0314 03:09:26.548306 138313941204992 run.py:479] Algo floyd_warshall step 6970 current loss 0.021359, current_train_items 223072.\n",
            "I0314 03:09:26.592711 138313941204992 run.py:479] Algo floyd_warshall step 6971 current loss 0.135960, current_train_items 223104.\n",
            "I0314 03:09:26.719854 138313941204992 run.py:479] Algo floyd_warshall step 6972 current loss 0.189565, current_train_items 223136.\n",
            "I0314 03:09:26.939643 138313941204992 run.py:479] Algo floyd_warshall step 6973 current loss 0.353530, current_train_items 223168.\n",
            "I0314 03:09:27.341133 138313941204992 run.py:479] Algo floyd_warshall step 6974 current loss 0.519855, current_train_items 223200.\n",
            "I0314 03:09:27.363885 138313941204992 run.py:479] Algo floyd_warshall step 6975 current loss 0.027409, current_train_items 223232.\n",
            "I0314 03:09:27.407789 138313941204992 run.py:479] Algo floyd_warshall step 6976 current loss 0.106742, current_train_items 223264.\n",
            "I0314 03:09:27.534300 138313941204992 run.py:479] Algo floyd_warshall step 6977 current loss 0.265601, current_train_items 223296.\n",
            "I0314 03:09:27.745377 138313941204992 run.py:479] Algo floyd_warshall step 6978 current loss 0.406253, current_train_items 223328.\n",
            "I0314 03:09:28.178671 138313941204992 run.py:479] Algo floyd_warshall step 6979 current loss 0.803827, current_train_items 223360.\n",
            "I0314 03:09:28.202190 138313941204992 run.py:479] Algo floyd_warshall step 6980 current loss 0.025373, current_train_items 223392.\n",
            "I0314 03:09:28.246795 138313941204992 run.py:479] Algo floyd_warshall step 6981 current loss 0.055516, current_train_items 223424.\n",
            "I0314 03:09:28.374391 138313941204992 run.py:479] Algo floyd_warshall step 6982 current loss 0.209390, current_train_items 223456.\n",
            "I0314 03:09:28.596324 138313941204992 run.py:479] Algo floyd_warshall step 6983 current loss 0.299216, current_train_items 223488.\n",
            "I0314 03:09:29.010420 138313941204992 run.py:479] Algo floyd_warshall step 6984 current loss 0.497770, current_train_items 223520.\n",
            "I0314 03:09:29.033222 138313941204992 run.py:479] Algo floyd_warshall step 6985 current loss 0.017001, current_train_items 223552.\n",
            "I0314 03:09:29.078192 138313941204992 run.py:479] Algo floyd_warshall step 6986 current loss 0.064258, current_train_items 223584.\n",
            "I0314 03:09:29.205728 138313941204992 run.py:479] Algo floyd_warshall step 6987 current loss 0.216824, current_train_items 223616.\n",
            "I0314 03:09:29.420641 138313941204992 run.py:479] Algo floyd_warshall step 6988 current loss 0.425271, current_train_items 223648.\n",
            "I0314 03:09:29.825218 138313941204992 run.py:479] Algo floyd_warshall step 6989 current loss 0.581935, current_train_items 223680.\n",
            "I0314 03:09:29.852346 138313941204992 run.py:479] Algo floyd_warshall step 6990 current loss 0.014781, current_train_items 223712.\n",
            "I0314 03:09:29.910201 138313941204992 run.py:479] Algo floyd_warshall step 6991 current loss 0.037545, current_train_items 223744.\n",
            "I0314 03:09:30.044492 138313941204992 run.py:479] Algo floyd_warshall step 6992 current loss 0.201426, current_train_items 223776.\n",
            "I0314 03:09:30.265851 138313941204992 run.py:479] Algo floyd_warshall step 6993 current loss 0.403668, current_train_items 223808.\n",
            "I0314 03:09:30.679650 138313941204992 run.py:479] Algo floyd_warshall step 6994 current loss 0.549416, current_train_items 223840.\n",
            "I0314 03:09:30.703293 138313941204992 run.py:479] Algo floyd_warshall step 6995 current loss 0.014446, current_train_items 223872.\n",
            "I0314 03:09:30.748381 138313941204992 run.py:479] Algo floyd_warshall step 6996 current loss 0.055917, current_train_items 223904.\n",
            "I0314 03:09:30.877880 138313941204992 run.py:479] Algo floyd_warshall step 6997 current loss 0.191315, current_train_items 223936.\n",
            "I0314 03:09:31.115652 138313941204992 run.py:479] Algo floyd_warshall step 6998 current loss 0.448100, current_train_items 223968.\n",
            "I0314 03:09:31.535133 138313941204992 run.py:479] Algo floyd_warshall step 6999 current loss 0.679925, current_train_items 224000.\n",
            "I0314 03:09:31.558450 138313941204992 run.py:479] Algo floyd_warshall step 7000 current loss 0.016073, current_train_items 224032.\n",
            "I0314 03:09:31.646309 138313941204992 run.py:499] (val) algo floyd_warshall step 7000: {'Pi': 0.8912353515625, 'score': 0.8912353515625, 'examples_seen': 224032, 'step': 7000, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:09:31.646542 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.917, current avg val score is 0.891, val scores are: floyd_warshall: 0.891\n",
            "I0314 03:09:31.693740 138313941204992 run.py:479] Algo floyd_warshall step 7001 current loss 0.062356, current_train_items 224064.\n",
            "I0314 03:09:31.823423 138313941204992 run.py:479] Algo floyd_warshall step 7002 current loss 0.159811, current_train_items 224096.\n",
            "I0314 03:09:32.041556 138313941204992 run.py:479] Algo floyd_warshall step 7003 current loss 0.300301, current_train_items 224128.\n",
            "I0314 03:09:32.466040 138313941204992 run.py:479] Algo floyd_warshall step 7004 current loss 0.730089, current_train_items 224160.\n",
            "I0314 03:09:32.492202 138313941204992 run.py:479] Algo floyd_warshall step 7005 current loss 0.042059, current_train_items 224192.\n",
            "I0314 03:09:32.536683 138313941204992 run.py:479] Algo floyd_warshall step 7006 current loss 0.068095, current_train_items 224224.\n",
            "I0314 03:09:32.666152 138313941204992 run.py:479] Algo floyd_warshall step 7007 current loss 0.260443, current_train_items 224256.\n",
            "I0314 03:09:32.889288 138313941204992 run.py:479] Algo floyd_warshall step 7008 current loss 0.316102, current_train_items 224288.\n",
            "I0314 03:09:33.319449 138313941204992 run.py:479] Algo floyd_warshall step 7009 current loss 0.621367, current_train_items 224320.\n",
            "I0314 03:09:33.355849 138313941204992 run.py:479] Algo floyd_warshall step 7010 current loss 0.012839, current_train_items 224352.\n",
            "I0314 03:09:33.415920 138313941204992 run.py:479] Algo floyd_warshall step 7011 current loss 0.050158, current_train_items 224384.\n",
            "I0314 03:09:33.577453 138313941204992 run.py:479] Algo floyd_warshall step 7012 current loss 0.221995, current_train_items 224416.\n",
            "I0314 03:09:33.854679 138313941204992 run.py:479] Algo floyd_warshall step 7013 current loss 0.311201, current_train_items 224448.\n",
            "I0314 03:09:34.356082 138313941204992 run.py:479] Algo floyd_warshall step 7014 current loss 0.565214, current_train_items 224480.\n",
            "I0314 03:09:34.395386 138313941204992 run.py:479] Algo floyd_warshall step 7015 current loss 0.025360, current_train_items 224512.\n",
            "I0314 03:09:34.453842 138313941204992 run.py:479] Algo floyd_warshall step 7016 current loss 0.057926, current_train_items 224544.\n",
            "I0314 03:09:34.612642 138313941204992 run.py:479] Algo floyd_warshall step 7017 current loss 0.321619, current_train_items 224576.\n",
            "I0314 03:09:34.871454 138313941204992 run.py:479] Algo floyd_warshall step 7018 current loss 0.399756, current_train_items 224608.\n",
            "I0314 03:09:35.376610 138313941204992 run.py:479] Algo floyd_warshall step 7019 current loss 0.671091, current_train_items 224640.\n",
            "I0314 03:09:35.415012 138313941204992 run.py:479] Algo floyd_warshall step 7020 current loss 0.014700, current_train_items 224672.\n",
            "I0314 03:09:35.472051 138313941204992 run.py:479] Algo floyd_warshall step 7021 current loss 0.062760, current_train_items 224704.\n",
            "I0314 03:09:35.631026 138313941204992 run.py:479] Algo floyd_warshall step 7022 current loss 0.182824, current_train_items 224736.\n",
            "I0314 03:09:35.907270 138313941204992 run.py:479] Algo floyd_warshall step 7023 current loss 0.355132, current_train_items 224768.\n",
            "I0314 03:09:36.411242 138313941204992 run.py:479] Algo floyd_warshall step 7024 current loss 0.620232, current_train_items 224800.\n",
            "I0314 03:09:36.434420 138313941204992 run.py:479] Algo floyd_warshall step 7025 current loss 0.023395, current_train_items 224832.\n",
            "I0314 03:09:36.479572 138313941204992 run.py:479] Algo floyd_warshall step 7026 current loss 0.065255, current_train_items 224864.\n",
            "I0314 03:09:36.610957 138313941204992 run.py:479] Algo floyd_warshall step 7027 current loss 0.342130, current_train_items 224896.\n",
            "I0314 03:09:36.845072 138313941204992 run.py:479] Algo floyd_warshall step 7028 current loss 0.513854, current_train_items 224928.\n",
            "I0314 03:09:37.274025 138313941204992 run.py:479] Algo floyd_warshall step 7029 current loss 0.799462, current_train_items 224960.\n",
            "I0314 03:09:37.298199 138313941204992 run.py:479] Algo floyd_warshall step 7030 current loss 0.014510, current_train_items 224992.\n",
            "I0314 03:09:37.343810 138313941204992 run.py:479] Algo floyd_warshall step 7031 current loss 0.041873, current_train_items 225024.\n",
            "I0314 03:09:37.473880 138313941204992 run.py:479] Algo floyd_warshall step 7032 current loss 0.196102, current_train_items 225056.\n",
            "I0314 03:09:37.687488 138313941204992 run.py:479] Algo floyd_warshall step 7033 current loss 0.310105, current_train_items 225088.\n",
            "I0314 03:09:38.114027 138313941204992 run.py:479] Algo floyd_warshall step 7034 current loss 0.714798, current_train_items 225120.\n",
            "I0314 03:09:38.139379 138313941204992 run.py:479] Algo floyd_warshall step 7035 current loss 0.019891, current_train_items 225152.\n",
            "I0314 03:09:38.190703 138313941204992 run.py:479] Algo floyd_warshall step 7036 current loss 0.047454, current_train_items 225184.\n",
            "I0314 03:09:38.326603 138313941204992 run.py:479] Algo floyd_warshall step 7037 current loss 0.187130, current_train_items 225216.\n",
            "I0314 03:09:38.553508 138313941204992 run.py:479] Algo floyd_warshall step 7038 current loss 0.330812, current_train_items 225248.\n",
            "I0314 03:09:38.979737 138313941204992 run.py:479] Algo floyd_warshall step 7039 current loss 0.740329, current_train_items 225280.\n",
            "I0314 03:09:39.003616 138313941204992 run.py:479] Algo floyd_warshall step 7040 current loss 0.033562, current_train_items 225312.\n",
            "I0314 03:09:39.050804 138313941204992 run.py:479] Algo floyd_warshall step 7041 current loss 0.074870, current_train_items 225344.\n",
            "I0314 03:09:39.181246 138313941204992 run.py:479] Algo floyd_warshall step 7042 current loss 0.187540, current_train_items 225376.\n",
            "I0314 03:09:39.411322 138313941204992 run.py:479] Algo floyd_warshall step 7043 current loss 0.347320, current_train_items 225408.\n",
            "I0314 03:09:39.830982 138313941204992 run.py:479] Algo floyd_warshall step 7044 current loss 0.565658, current_train_items 225440.\n",
            "I0314 03:09:39.858121 138313941204992 run.py:479] Algo floyd_warshall step 7045 current loss 0.017238, current_train_items 225472.\n",
            "I0314 03:09:39.905275 138313941204992 run.py:479] Algo floyd_warshall step 7046 current loss 0.073259, current_train_items 225504.\n",
            "I0314 03:09:40.043020 138313941204992 run.py:479] Algo floyd_warshall step 7047 current loss 0.303770, current_train_items 225536.\n",
            "I0314 03:09:40.262840 138313941204992 run.py:479] Algo floyd_warshall step 7048 current loss 0.277774, current_train_items 225568.\n",
            "I0314 03:09:40.677104 138313941204992 run.py:479] Algo floyd_warshall step 7049 current loss 0.575579, current_train_items 225600.\n",
            "I0314 03:09:40.702403 138313941204992 run.py:479] Algo floyd_warshall step 7050 current loss 0.025196, current_train_items 225632.\n",
            "I0314 03:09:40.792253 138313941204992 run.py:499] (val) algo floyd_warshall step 7050: {'Pi': 0.88201904296875, 'score': 0.88201904296875, 'examples_seen': 225632, 'step': 7050, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:09:40.792567 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.917, current avg val score is 0.882, val scores are: floyd_warshall: 0.882\n",
            "I0314 03:09:40.842600 138313941204992 run.py:479] Algo floyd_warshall step 7051 current loss 0.049849, current_train_items 225664.\n",
            "I0314 03:09:40.979183 138313941204992 run.py:479] Algo floyd_warshall step 7052 current loss 0.234855, current_train_items 225696.\n",
            "I0314 03:09:41.199015 138313941204992 run.py:479] Algo floyd_warshall step 7053 current loss 0.278250, current_train_items 225728.\n",
            "I0314 03:09:41.624673 138313941204992 run.py:479] Algo floyd_warshall step 7054 current loss 0.523274, current_train_items 225760.\n",
            "I0314 03:09:41.652920 138313941204992 run.py:479] Algo floyd_warshall step 7055 current loss 0.012291, current_train_items 225792.\n",
            "I0314 03:09:41.699073 138313941204992 run.py:479] Algo floyd_warshall step 7056 current loss 0.044604, current_train_items 225824.\n",
            "I0314 03:09:41.833893 138313941204992 run.py:479] Algo floyd_warshall step 7057 current loss 0.213416, current_train_items 225856.\n",
            "I0314 03:09:42.079483 138313941204992 run.py:479] Algo floyd_warshall step 7058 current loss 0.348680, current_train_items 225888.\n",
            "I0314 03:09:42.502217 138313941204992 run.py:479] Algo floyd_warshall step 7059 current loss 0.688683, current_train_items 225920.\n",
            "I0314 03:09:42.527158 138313941204992 run.py:479] Algo floyd_warshall step 7060 current loss 0.022160, current_train_items 225952.\n",
            "I0314 03:09:42.572800 138313941204992 run.py:479] Algo floyd_warshall step 7061 current loss 0.054154, current_train_items 225984.\n",
            "I0314 03:09:42.705380 138313941204992 run.py:479] Algo floyd_warshall step 7062 current loss 0.275562, current_train_items 226016.\n",
            "I0314 03:09:42.926064 138313941204992 run.py:479] Algo floyd_warshall step 7063 current loss 0.279989, current_train_items 226048.\n",
            "I0314 03:09:43.399169 138313941204992 run.py:479] Algo floyd_warshall step 7064 current loss 0.506099, current_train_items 226080.\n",
            "I0314 03:09:43.434986 138313941204992 run.py:479] Algo floyd_warshall step 7065 current loss 0.014898, current_train_items 226112.\n",
            "I0314 03:09:43.491377 138313941204992 run.py:479] Algo floyd_warshall step 7066 current loss 0.044752, current_train_items 226144.\n",
            "I0314 03:09:43.649431 138313941204992 run.py:479] Algo floyd_warshall step 7067 current loss 0.214649, current_train_items 226176.\n",
            "I0314 03:09:43.917919 138313941204992 run.py:479] Algo floyd_warshall step 7068 current loss 0.355443, current_train_items 226208.\n",
            "I0314 03:09:44.431628 138313941204992 run.py:479] Algo floyd_warshall step 7069 current loss 0.659592, current_train_items 226240.\n",
            "I0314 03:09:44.469202 138313941204992 run.py:479] Algo floyd_warshall step 7070 current loss 0.039606, current_train_items 226272.\n",
            "I0314 03:09:44.528208 138313941204992 run.py:479] Algo floyd_warshall step 7071 current loss 0.074649, current_train_items 226304.\n",
            "I0314 03:09:44.689224 138313941204992 run.py:479] Algo floyd_warshall step 7072 current loss 0.228386, current_train_items 226336.\n",
            "I0314 03:09:44.958489 138313941204992 run.py:479] Algo floyd_warshall step 7073 current loss 0.373963, current_train_items 226368.\n",
            "I0314 03:09:45.468895 138313941204992 run.py:479] Algo floyd_warshall step 7074 current loss 0.561734, current_train_items 226400.\n",
            "I0314 03:09:45.504714 138313941204992 run.py:479] Algo floyd_warshall step 7075 current loss 0.027030, current_train_items 226432.\n",
            "I0314 03:09:45.560045 138313941204992 run.py:479] Algo floyd_warshall step 7076 current loss 0.034524, current_train_items 226464.\n",
            "I0314 03:09:45.720717 138313941204992 run.py:479] Algo floyd_warshall step 7077 current loss 0.206017, current_train_items 226496.\n",
            "I0314 03:09:45.978530 138313941204992 run.py:479] Algo floyd_warshall step 7078 current loss 0.336974, current_train_items 226528.\n",
            "I0314 03:09:46.432781 138313941204992 run.py:479] Algo floyd_warshall step 7079 current loss 0.554283, current_train_items 226560.\n",
            "I0314 03:09:46.473063 138313941204992 run.py:479] Algo floyd_warshall step 7080 current loss 0.019332, current_train_items 226592.\n",
            "I0314 03:09:46.529652 138313941204992 run.py:479] Algo floyd_warshall step 7081 current loss 0.053808, current_train_items 226624.\n",
            "I0314 03:09:46.683681 138313941204992 run.py:479] Algo floyd_warshall step 7082 current loss 0.169600, current_train_items 226656.\n",
            "I0314 03:09:46.949805 138313941204992 run.py:479] Algo floyd_warshall step 7083 current loss 0.302393, current_train_items 226688.\n",
            "I0314 03:09:47.411483 138313941204992 run.py:479] Algo floyd_warshall step 7084 current loss 0.416621, current_train_items 226720.\n",
            "I0314 03:09:47.449550 138313941204992 run.py:479] Algo floyd_warshall step 7085 current loss 0.016042, current_train_items 226752.\n",
            "I0314 03:09:47.509214 138313941204992 run.py:479] Algo floyd_warshall step 7086 current loss 0.057780, current_train_items 226784.\n",
            "I0314 03:09:47.661391 138313941204992 run.py:479] Algo floyd_warshall step 7087 current loss 0.209804, current_train_items 226816.\n",
            "I0314 03:09:47.938312 138313941204992 run.py:479] Algo floyd_warshall step 7088 current loss 0.360247, current_train_items 226848.\n",
            "I0314 03:09:48.422356 138313941204992 run.py:479] Algo floyd_warshall step 7089 current loss 0.543226, current_train_items 226880.\n",
            "I0314 03:09:48.457709 138313941204992 run.py:479] Algo floyd_warshall step 7090 current loss 0.050548, current_train_items 226912.\n",
            "I0314 03:09:48.515262 138313941204992 run.py:479] Algo floyd_warshall step 7091 current loss 0.057434, current_train_items 226944.\n",
            "I0314 03:09:48.690233 138313941204992 run.py:479] Algo floyd_warshall step 7092 current loss 0.281668, current_train_items 226976.\n",
            "I0314 03:09:48.952265 138313941204992 run.py:479] Algo floyd_warshall step 7093 current loss 0.330373, current_train_items 227008.\n",
            "I0314 03:09:49.465558 138313941204992 run.py:479] Algo floyd_warshall step 7094 current loss 0.603573, current_train_items 227040.\n",
            "I0314 03:09:49.493925 138313941204992 run.py:479] Algo floyd_warshall step 7095 current loss 0.016843, current_train_items 227072.\n",
            "I0314 03:09:49.540922 138313941204992 run.py:479] Algo floyd_warshall step 7096 current loss 0.069463, current_train_items 227104.\n",
            "I0314 03:09:49.672328 138313941204992 run.py:479] Algo floyd_warshall step 7097 current loss 0.268305, current_train_items 227136.\n",
            "I0314 03:09:49.896716 138313941204992 run.py:479] Algo floyd_warshall step 7098 current loss 0.464154, current_train_items 227168.\n",
            "I0314 03:09:50.319357 138313941204992 run.py:479] Algo floyd_warshall step 7099 current loss 0.628000, current_train_items 227200.\n",
            "I0314 03:09:50.342852 138313941204992 run.py:479] Algo floyd_warshall step 7100 current loss 0.036344, current_train_items 227232.\n",
            "I0314 03:09:50.431293 138313941204992 run.py:499] (val) algo floyd_warshall step 7100: {'Pi': 0.907470703125, 'score': 0.907470703125, 'examples_seen': 227232, 'step': 7100, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:09:50.431526 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.917, current avg val score is 0.907, val scores are: floyd_warshall: 0.907\n",
            "I0314 03:09:50.479758 138313941204992 run.py:479] Algo floyd_warshall step 7101 current loss 0.105870, current_train_items 227264.\n",
            "I0314 03:09:50.608520 138313941204992 run.py:479] Algo floyd_warshall step 7102 current loss 0.275380, current_train_items 227296.\n",
            "I0314 03:09:50.849905 138313941204992 run.py:479] Algo floyd_warshall step 7103 current loss 0.382634, current_train_items 227328.\n",
            "I0314 03:09:51.270998 138313941204992 run.py:479] Algo floyd_warshall step 7104 current loss 0.567518, current_train_items 227360.\n",
            "I0314 03:09:51.295621 138313941204992 run.py:479] Algo floyd_warshall step 7105 current loss 0.039876, current_train_items 227392.\n",
            "I0314 03:09:51.341112 138313941204992 run.py:479] Algo floyd_warshall step 7106 current loss 0.042536, current_train_items 227424.\n",
            "I0314 03:09:51.473035 138313941204992 run.py:479] Algo floyd_warshall step 7107 current loss 0.237977, current_train_items 227456.\n",
            "I0314 03:09:51.693984 138313941204992 run.py:479] Algo floyd_warshall step 7108 current loss 0.346693, current_train_items 227488.\n",
            "I0314 03:09:52.119323 138313941204992 run.py:479] Algo floyd_warshall step 7109 current loss 0.684505, current_train_items 227520.\n",
            "I0314 03:09:52.143111 138313941204992 run.py:479] Algo floyd_warshall step 7110 current loss 0.024294, current_train_items 227552.\n",
            "I0314 03:09:52.189157 138313941204992 run.py:479] Algo floyd_warshall step 7111 current loss 0.132131, current_train_items 227584.\n",
            "I0314 03:09:52.320965 138313941204992 run.py:479] Algo floyd_warshall step 7112 current loss 0.213361, current_train_items 227616.\n",
            "I0314 03:09:52.539014 138313941204992 run.py:479] Algo floyd_warshall step 7113 current loss 0.400963, current_train_items 227648.\n",
            "I0314 03:09:52.945643 138313941204992 run.py:479] Algo floyd_warshall step 7114 current loss 0.535396, current_train_items 227680.\n",
            "I0314 03:09:52.970640 138313941204992 run.py:479] Algo floyd_warshall step 7115 current loss 0.016965, current_train_items 227712.\n",
            "I0314 03:09:53.015200 138313941204992 run.py:479] Algo floyd_warshall step 7116 current loss 0.068754, current_train_items 227744.\n",
            "I0314 03:09:53.146239 138313941204992 run.py:479] Algo floyd_warshall step 7117 current loss 0.230130, current_train_items 227776.\n",
            "I0314 03:09:53.360949 138313941204992 run.py:479] Algo floyd_warshall step 7118 current loss 0.263346, current_train_items 227808.\n",
            "I0314 03:09:53.778832 138313941204992 run.py:479] Algo floyd_warshall step 7119 current loss 0.514180, current_train_items 227840.\n",
            "I0314 03:09:53.805067 138313941204992 run.py:479] Algo floyd_warshall step 7120 current loss 0.015380, current_train_items 227872.\n",
            "I0314 03:09:53.855175 138313941204992 run.py:479] Algo floyd_warshall step 7121 current loss 0.052463, current_train_items 227904.\n",
            "I0314 03:09:53.991734 138313941204992 run.py:479] Algo floyd_warshall step 7122 current loss 0.306516, current_train_items 227936.\n",
            "I0314 03:09:54.218304 138313941204992 run.py:479] Algo floyd_warshall step 7123 current loss 0.284995, current_train_items 227968.\n",
            "I0314 03:09:54.633729 138313941204992 run.py:479] Algo floyd_warshall step 7124 current loss 0.593463, current_train_items 228000.\n",
            "I0314 03:09:54.656791 138313941204992 run.py:479] Algo floyd_warshall step 7125 current loss 0.034456, current_train_items 228032.\n",
            "I0314 03:09:54.701218 138313941204992 run.py:479] Algo floyd_warshall step 7126 current loss 0.061177, current_train_items 228064.\n",
            "I0314 03:09:54.843459 138313941204992 run.py:479] Algo floyd_warshall step 7127 current loss 0.221453, current_train_items 228096.\n",
            "I0314 03:09:55.062579 138313941204992 run.py:479] Algo floyd_warshall step 7128 current loss 0.277109, current_train_items 228128.\n",
            "I0314 03:09:55.467348 138313941204992 run.py:479] Algo floyd_warshall step 7129 current loss 0.453255, current_train_items 228160.\n",
            "I0314 03:09:55.491586 138313941204992 run.py:479] Algo floyd_warshall step 7130 current loss 0.091713, current_train_items 228192.\n",
            "I0314 03:09:55.537062 138313941204992 run.py:479] Algo floyd_warshall step 7131 current loss 0.054313, current_train_items 228224.\n",
            "I0314 03:09:55.666939 138313941204992 run.py:479] Algo floyd_warshall step 7132 current loss 0.218033, current_train_items 228256.\n",
            "I0314 03:09:55.881692 138313941204992 run.py:479] Algo floyd_warshall step 7133 current loss 0.313473, current_train_items 228288.\n",
            "I0314 03:09:56.292844 138313941204992 run.py:479] Algo floyd_warshall step 7134 current loss 0.508063, current_train_items 228320.\n",
            "I0314 03:09:56.318130 138313941204992 run.py:479] Algo floyd_warshall step 7135 current loss 0.012163, current_train_items 228352.\n",
            "I0314 03:09:56.363367 138313941204992 run.py:479] Algo floyd_warshall step 7136 current loss 0.095429, current_train_items 228384.\n",
            "I0314 03:09:56.496963 138313941204992 run.py:479] Algo floyd_warshall step 7137 current loss 0.184596, current_train_items 228416.\n",
            "I0314 03:09:56.725663 138313941204992 run.py:479] Algo floyd_warshall step 7138 current loss 0.347865, current_train_items 228448.\n",
            "I0314 03:09:57.157080 138313941204992 run.py:479] Algo floyd_warshall step 7139 current loss 0.482648, current_train_items 228480.\n",
            "I0314 03:09:57.180258 138313941204992 run.py:479] Algo floyd_warshall step 7140 current loss 0.018873, current_train_items 228512.\n",
            "I0314 03:09:57.227654 138313941204992 run.py:479] Algo floyd_warshall step 7141 current loss 0.073959, current_train_items 228544.\n",
            "I0314 03:09:57.358306 138313941204992 run.py:479] Algo floyd_warshall step 7142 current loss 0.181395, current_train_items 228576.\n",
            "I0314 03:09:57.574915 138313941204992 run.py:479] Algo floyd_warshall step 7143 current loss 0.309244, current_train_items 228608.\n",
            "I0314 03:09:57.990079 138313941204992 run.py:479] Algo floyd_warshall step 7144 current loss 0.569570, current_train_items 228640.\n",
            "I0314 03:09:58.014720 138313941204992 run.py:479] Algo floyd_warshall step 7145 current loss 0.020340, current_train_items 228672.\n",
            "I0314 03:09:58.060123 138313941204992 run.py:479] Algo floyd_warshall step 7146 current loss 0.137728, current_train_items 228704.\n",
            "I0314 03:09:58.190659 138313941204992 run.py:479] Algo floyd_warshall step 7147 current loss 0.215713, current_train_items 228736.\n",
            "I0314 03:09:58.411548 138313941204992 run.py:479] Algo floyd_warshall step 7148 current loss 0.329008, current_train_items 228768.\n",
            "I0314 03:09:58.829589 138313941204992 run.py:479] Algo floyd_warshall step 7149 current loss 0.639660, current_train_items 228800.\n",
            "I0314 03:09:58.865556 138313941204992 run.py:479] Algo floyd_warshall step 7150 current loss 0.027852, current_train_items 228832.\n",
            "I0314 03:09:58.953490 138313941204992 run.py:499] (val) algo floyd_warshall step 7150: {'Pi': 0.8865966796875, 'score': 0.8865966796875, 'examples_seen': 228832, 'step': 7150, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:09:58.953725 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.917, current avg val score is 0.887, val scores are: floyd_warshall: 0.887\n",
            "I0314 03:09:59.003399 138313941204992 run.py:479] Algo floyd_warshall step 7151 current loss 0.063023, current_train_items 228864.\n",
            "I0314 03:09:59.135761 138313941204992 run.py:479] Algo floyd_warshall step 7152 current loss 0.249080, current_train_items 228896.\n",
            "I0314 03:09:59.362022 138313941204992 run.py:479] Algo floyd_warshall step 7153 current loss 0.447293, current_train_items 228928.\n",
            "I0314 03:09:59.777365 138313941204992 run.py:479] Algo floyd_warshall step 7154 current loss 0.625986, current_train_items 228960.\n",
            "I0314 03:09:59.813967 138313941204992 run.py:479] Algo floyd_warshall step 7155 current loss 0.021931, current_train_items 228992.\n",
            "I0314 03:09:59.870448 138313941204992 run.py:479] Algo floyd_warshall step 7156 current loss 0.036238, current_train_items 229024.\n",
            "I0314 03:10:00.029485 138313941204992 run.py:479] Algo floyd_warshall step 7157 current loss 0.181090, current_train_items 229056.\n",
            "I0314 03:10:00.285965 138313941204992 run.py:479] Algo floyd_warshall step 7158 current loss 0.387488, current_train_items 229088.\n",
            "I0314 03:10:00.801018 138313941204992 run.py:479] Algo floyd_warshall step 7159 current loss 0.603568, current_train_items 229120.\n",
            "I0314 03:10:00.836744 138313941204992 run.py:479] Algo floyd_warshall step 7160 current loss 0.029359, current_train_items 229152.\n",
            "I0314 03:10:00.895606 138313941204992 run.py:479] Algo floyd_warshall step 7161 current loss 0.120447, current_train_items 229184.\n",
            "I0314 03:10:01.059203 138313941204992 run.py:479] Algo floyd_warshall step 7162 current loss 0.156422, current_train_items 229216.\n",
            "I0314 03:10:01.332006 138313941204992 run.py:479] Algo floyd_warshall step 7163 current loss 0.375083, current_train_items 229248.\n",
            "I0314 03:10:01.837922 138313941204992 run.py:479] Algo floyd_warshall step 7164 current loss 0.564685, current_train_items 229280.\n",
            "I0314 03:10:01.878490 138313941204992 run.py:479] Algo floyd_warshall step 7165 current loss 0.023710, current_train_items 229312.\n",
            "I0314 03:10:01.943516 138313941204992 run.py:479] Algo floyd_warshall step 7166 current loss 0.046946, current_train_items 229344.\n",
            "I0314 03:10:02.113775 138313941204992 run.py:479] Algo floyd_warshall step 7167 current loss 0.210586, current_train_items 229376.\n",
            "I0314 03:10:02.387287 138313941204992 run.py:479] Algo floyd_warshall step 7168 current loss 0.336165, current_train_items 229408.\n",
            "I0314 03:10:02.875487 138313941204992 run.py:479] Algo floyd_warshall step 7169 current loss 0.728475, current_train_items 229440.\n",
            "I0314 03:10:02.899972 138313941204992 run.py:479] Algo floyd_warshall step 7170 current loss 0.016216, current_train_items 229472.\n",
            "I0314 03:10:02.945609 138313941204992 run.py:479] Algo floyd_warshall step 7171 current loss 0.055794, current_train_items 229504.\n",
            "I0314 03:10:03.076011 138313941204992 run.py:479] Algo floyd_warshall step 7172 current loss 0.156304, current_train_items 229536.\n",
            "I0314 03:10:03.288444 138313941204992 run.py:479] Algo floyd_warshall step 7173 current loss 0.287843, current_train_items 229568.\n",
            "I0314 03:10:03.704115 138313941204992 run.py:479] Algo floyd_warshall step 7174 current loss 0.585782, current_train_items 229600.\n",
            "I0314 03:10:03.728270 138313941204992 run.py:479] Algo floyd_warshall step 7175 current loss 0.012553, current_train_items 229632.\n",
            "I0314 03:10:03.772535 138313941204992 run.py:479] Algo floyd_warshall step 7176 current loss 0.055265, current_train_items 229664.\n",
            "I0314 03:10:03.904294 138313941204992 run.py:479] Algo floyd_warshall step 7177 current loss 0.186214, current_train_items 229696.\n",
            "I0314 03:10:04.122889 138313941204992 run.py:479] Algo floyd_warshall step 7178 current loss 0.326154, current_train_items 229728.\n",
            "I0314 03:10:04.540583 138313941204992 run.py:479] Algo floyd_warshall step 7179 current loss 0.521908, current_train_items 229760.\n",
            "I0314 03:10:04.563851 138313941204992 run.py:479] Algo floyd_warshall step 7180 current loss 0.012455, current_train_items 229792.\n",
            "I0314 03:10:04.615820 138313941204992 run.py:479] Algo floyd_warshall step 7181 current loss 0.037074, current_train_items 229824.\n",
            "I0314 03:10:04.745852 138313941204992 run.py:479] Algo floyd_warshall step 7182 current loss 0.184814, current_train_items 229856.\n",
            "I0314 03:10:04.971535 138313941204992 run.py:479] Algo floyd_warshall step 7183 current loss 0.303163, current_train_items 229888.\n",
            "I0314 03:10:05.396518 138313941204992 run.py:479] Algo floyd_warshall step 7184 current loss 0.592831, current_train_items 229920.\n",
            "I0314 03:10:05.421168 138313941204992 run.py:479] Algo floyd_warshall step 7185 current loss 0.017314, current_train_items 229952.\n",
            "I0314 03:10:05.468299 138313941204992 run.py:479] Algo floyd_warshall step 7186 current loss 0.056839, current_train_items 229984.\n",
            "I0314 03:10:05.598006 138313941204992 run.py:479] Algo floyd_warshall step 7187 current loss 0.148431, current_train_items 230016.\n",
            "I0314 03:10:05.815750 138313941204992 run.py:479] Algo floyd_warshall step 7188 current loss 0.336299, current_train_items 230048.\n",
            "I0314 03:10:06.235483 138313941204992 run.py:479] Algo floyd_warshall step 7189 current loss 0.582062, current_train_items 230080.\n",
            "I0314 03:10:06.259430 138313941204992 run.py:479] Algo floyd_warshall step 7190 current loss 0.009097, current_train_items 230112.\n",
            "I0314 03:10:06.303541 138313941204992 run.py:479] Algo floyd_warshall step 7191 current loss 0.060603, current_train_items 230144.\n",
            "I0314 03:10:06.431801 138313941204992 run.py:479] Algo floyd_warshall step 7192 current loss 0.236238, current_train_items 230176.\n",
            "I0314 03:10:06.655247 138313941204992 run.py:479] Algo floyd_warshall step 7193 current loss 0.395023, current_train_items 230208.\n",
            "I0314 03:10:07.079250 138313941204992 run.py:479] Algo floyd_warshall step 7194 current loss 0.591172, current_train_items 230240.\n",
            "I0314 03:10:07.103243 138313941204992 run.py:479] Algo floyd_warshall step 7195 current loss 0.097995, current_train_items 230272.\n",
            "I0314 03:10:07.153864 138313941204992 run.py:479] Algo floyd_warshall step 7196 current loss 0.080773, current_train_items 230304.\n",
            "I0314 03:10:07.290397 138313941204992 run.py:479] Algo floyd_warshall step 7197 current loss 0.174056, current_train_items 230336.\n",
            "I0314 03:10:07.515492 138313941204992 run.py:479] Algo floyd_warshall step 7198 current loss 0.351666, current_train_items 230368.\n",
            "I0314 03:10:07.935822 138313941204992 run.py:479] Algo floyd_warshall step 7199 current loss 0.673180, current_train_items 230400.\n",
            "I0314 03:10:07.959486 138313941204992 run.py:479] Algo floyd_warshall step 7200 current loss 0.014308, current_train_items 230432.\n",
            "I0314 03:10:08.046316 138313941204992 run.py:499] (val) algo floyd_warshall step 7200: {'Pi': 0.8861083984375, 'score': 0.8861083984375, 'examples_seen': 230432, 'step': 7200, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:10:08.046610 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.917, current avg val score is 0.886, val scores are: floyd_warshall: 0.886\n",
            "I0314 03:10:08.095722 138313941204992 run.py:479] Algo floyd_warshall step 7201 current loss 0.048522, current_train_items 230464.\n",
            "I0314 03:10:08.229882 138313941204992 run.py:479] Algo floyd_warshall step 7202 current loss 0.234897, current_train_items 230496.\n",
            "I0314 03:10:08.448861 138313941204992 run.py:479] Algo floyd_warshall step 7203 current loss 0.353046, current_train_items 230528.\n",
            "I0314 03:10:08.879284 138313941204992 run.py:479] Algo floyd_warshall step 7204 current loss 0.652477, current_train_items 230560.\n",
            "I0314 03:10:08.905280 138313941204992 run.py:479] Algo floyd_warshall step 7205 current loss 0.018289, current_train_items 230592.\n",
            "I0314 03:10:08.953522 138313941204992 run.py:479] Algo floyd_warshall step 7206 current loss 0.052731, current_train_items 230624.\n",
            "I0314 03:10:09.086320 138313941204992 run.py:479] Algo floyd_warshall step 7207 current loss 0.223651, current_train_items 230656.\n",
            "I0314 03:10:09.307284 138313941204992 run.py:479] Algo floyd_warshall step 7208 current loss 0.342366, current_train_items 230688.\n",
            "I0314 03:10:09.738791 138313941204992 run.py:479] Algo floyd_warshall step 7209 current loss 0.586338, current_train_items 230720.\n",
            "I0314 03:10:09.761745 138313941204992 run.py:479] Algo floyd_warshall step 7210 current loss 0.009283, current_train_items 230752.\n",
            "I0314 03:10:09.806473 138313941204992 run.py:479] Algo floyd_warshall step 7211 current loss 0.064842, current_train_items 230784.\n",
            "I0314 03:10:09.937920 138313941204992 run.py:479] Algo floyd_warshall step 7212 current loss 0.233193, current_train_items 230816.\n",
            "I0314 03:10:10.153424 138313941204992 run.py:479] Algo floyd_warshall step 7213 current loss 0.340927, current_train_items 230848.\n",
            "I0314 03:10:10.579589 138313941204992 run.py:479] Algo floyd_warshall step 7214 current loss 0.654400, current_train_items 230880.\n",
            "I0314 03:10:10.603843 138313941204992 run.py:479] Algo floyd_warshall step 7215 current loss 0.019661, current_train_items 230912.\n",
            "I0314 03:10:10.648250 138313941204992 run.py:479] Algo floyd_warshall step 7216 current loss 0.066103, current_train_items 230944.\n",
            "I0314 03:10:10.778333 138313941204992 run.py:479] Algo floyd_warshall step 7217 current loss 0.217346, current_train_items 230976.\n",
            "I0314 03:10:11.003854 138313941204992 run.py:479] Algo floyd_warshall step 7218 current loss 0.314804, current_train_items 231008.\n",
            "I0314 03:10:11.413282 138313941204992 run.py:479] Algo floyd_warshall step 7219 current loss 0.575052, current_train_items 231040.\n",
            "I0314 03:10:11.438139 138313941204992 run.py:479] Algo floyd_warshall step 7220 current loss 0.023701, current_train_items 231072.\n",
            "I0314 03:10:11.484474 138313941204992 run.py:479] Algo floyd_warshall step 7221 current loss 0.074576, current_train_items 231104.\n",
            "I0314 03:10:11.618860 138313941204992 run.py:479] Algo floyd_warshall step 7222 current loss 0.208344, current_train_items 231136.\n",
            "I0314 03:10:11.848079 138313941204992 run.py:479] Algo floyd_warshall step 7223 current loss 0.354272, current_train_items 231168.\n",
            "I0314 03:10:12.268345 138313941204992 run.py:479] Algo floyd_warshall step 7224 current loss 0.599554, current_train_items 231200.\n",
            "I0314 03:10:12.299696 138313941204992 run.py:479] Algo floyd_warshall step 7225 current loss 0.070266, current_train_items 231232.\n",
            "I0314 03:10:12.344918 138313941204992 run.py:479] Algo floyd_warshall step 7226 current loss 0.107563, current_train_items 231264.\n",
            "I0314 03:10:12.478113 138313941204992 run.py:479] Algo floyd_warshall step 7227 current loss 0.258304, current_train_items 231296.\n",
            "I0314 03:10:12.699795 138313941204992 run.py:479] Algo floyd_warshall step 7228 current loss 0.274819, current_train_items 231328.\n",
            "I0314 03:10:13.203414 138313941204992 run.py:479] Algo floyd_warshall step 7229 current loss 0.576276, current_train_items 231360.\n",
            "I0314 03:10:13.240676 138313941204992 run.py:479] Algo floyd_warshall step 7230 current loss 0.006415, current_train_items 231392.\n",
            "I0314 03:10:13.300937 138313941204992 run.py:479] Algo floyd_warshall step 7231 current loss 0.058168, current_train_items 231424.\n",
            "I0314 03:10:13.465506 138313941204992 run.py:479] Algo floyd_warshall step 7232 current loss 0.173362, current_train_items 231456.\n",
            "I0314 03:10:13.724997 138313941204992 run.py:479] Algo floyd_warshall step 7233 current loss 0.334700, current_train_items 231488.\n",
            "I0314 03:10:14.205359 138313941204992 run.py:479] Algo floyd_warshall step 7234 current loss 0.534143, current_train_items 231520.\n",
            "I0314 03:10:14.243063 138313941204992 run.py:479] Algo floyd_warshall step 7235 current loss 0.014676, current_train_items 231552.\n",
            "I0314 03:10:14.302806 138313941204992 run.py:479] Algo floyd_warshall step 7236 current loss 0.073146, current_train_items 231584.\n",
            "I0314 03:10:14.471692 138313941204992 run.py:479] Algo floyd_warshall step 7237 current loss 0.210567, current_train_items 231616.\n",
            "I0314 03:10:14.730862 138313941204992 run.py:479] Algo floyd_warshall step 7238 current loss 0.288992, current_train_items 231648.\n",
            "I0314 03:10:15.230683 138313941204992 run.py:479] Algo floyd_warshall step 7239 current loss 0.525596, current_train_items 231680.\n",
            "I0314 03:10:15.267585 138313941204992 run.py:479] Algo floyd_warshall step 7240 current loss 0.014770, current_train_items 231712.\n",
            "I0314 03:10:15.325721 138313941204992 run.py:479] Algo floyd_warshall step 7241 current loss 0.034943, current_train_items 231744.\n",
            "I0314 03:10:15.482584 138313941204992 run.py:479] Algo floyd_warshall step 7242 current loss 0.153905, current_train_items 231776.\n",
            "I0314 03:10:15.751969 138313941204992 run.py:479] Algo floyd_warshall step 7243 current loss 0.294374, current_train_items 231808.\n",
            "I0314 03:10:16.169945 138313941204992 run.py:479] Algo floyd_warshall step 7244 current loss 0.521885, current_train_items 231840.\n",
            "I0314 03:10:16.194284 138313941204992 run.py:479] Algo floyd_warshall step 7245 current loss 0.031135, current_train_items 231872.\n",
            "I0314 03:10:16.238352 138313941204992 run.py:479] Algo floyd_warshall step 7246 current loss 0.040448, current_train_items 231904.\n",
            "I0314 03:10:16.369883 138313941204992 run.py:479] Algo floyd_warshall step 7247 current loss 0.271500, current_train_items 231936.\n",
            "I0314 03:10:16.591727 138313941204992 run.py:479] Algo floyd_warshall step 7248 current loss 0.392000, current_train_items 231968.\n",
            "I0314 03:10:17.003272 138313941204992 run.py:479] Algo floyd_warshall step 7249 current loss 0.541331, current_train_items 232000.\n",
            "I0314 03:10:17.026835 138313941204992 run.py:479] Algo floyd_warshall step 7250 current loss 0.037905, current_train_items 232032.\n",
            "I0314 03:10:17.117673 138313941204992 run.py:499] (val) algo floyd_warshall step 7250: {'Pi': 0.889404296875, 'score': 0.889404296875, 'examples_seen': 232032, 'step': 7250, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:10:17.117960 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.917, current avg val score is 0.889, val scores are: floyd_warshall: 0.889\n",
            "I0314 03:10:17.167712 138313941204992 run.py:479] Algo floyd_warshall step 7251 current loss 0.089004, current_train_items 232064.\n",
            "I0314 03:10:17.298937 138313941204992 run.py:479] Algo floyd_warshall step 7252 current loss 0.174594, current_train_items 232096.\n",
            "I0314 03:10:17.516268 138313941204992 run.py:479] Algo floyd_warshall step 7253 current loss 0.319373, current_train_items 232128.\n",
            "I0314 03:10:17.943465 138313941204992 run.py:479] Algo floyd_warshall step 7254 current loss 0.547830, current_train_items 232160.\n",
            "I0314 03:10:17.971886 138313941204992 run.py:479] Algo floyd_warshall step 7255 current loss 0.007348, current_train_items 232192.\n",
            "I0314 03:10:18.016556 138313941204992 run.py:479] Algo floyd_warshall step 7256 current loss 0.064291, current_train_items 232224.\n",
            "I0314 03:10:18.148508 138313941204992 run.py:479] Algo floyd_warshall step 7257 current loss 0.144989, current_train_items 232256.\n",
            "I0314 03:10:18.373051 138313941204992 run.py:479] Algo floyd_warshall step 7258 current loss 0.285679, current_train_items 232288.\n",
            "I0314 03:10:18.800070 138313941204992 run.py:479] Algo floyd_warshall step 7259 current loss 0.628899, current_train_items 232320.\n",
            "I0314 03:10:18.825095 138313941204992 run.py:479] Algo floyd_warshall step 7260 current loss 0.012820, current_train_items 232352.\n",
            "I0314 03:10:18.871564 138313941204992 run.py:479] Algo floyd_warshall step 7261 current loss 0.060844, current_train_items 232384.\n",
            "I0314 03:10:19.000634 138313941204992 run.py:479] Algo floyd_warshall step 7262 current loss 0.177517, current_train_items 232416.\n",
            "I0314 03:10:19.225437 138313941204992 run.py:479] Algo floyd_warshall step 7263 current loss 0.285809, current_train_items 232448.\n",
            "I0314 03:10:19.640869 138313941204992 run.py:479] Algo floyd_warshall step 7264 current loss 0.580299, current_train_items 232480.\n",
            "I0314 03:10:19.665290 138313941204992 run.py:479] Algo floyd_warshall step 7265 current loss 0.018602, current_train_items 232512.\n",
            "I0314 03:10:19.711682 138313941204992 run.py:479] Algo floyd_warshall step 7266 current loss 0.079666, current_train_items 232544.\n",
            "I0314 03:10:19.841644 138313941204992 run.py:479] Algo floyd_warshall step 7267 current loss 0.166218, current_train_items 232576.\n",
            "I0314 03:10:20.067539 138313941204992 run.py:479] Algo floyd_warshall step 7268 current loss 0.393175, current_train_items 232608.\n",
            "I0314 03:10:20.498886 138313941204992 run.py:479] Algo floyd_warshall step 7269 current loss 0.653465, current_train_items 232640.\n",
            "I0314 03:10:20.522263 138313941204992 run.py:479] Algo floyd_warshall step 7270 current loss 0.044154, current_train_items 232672.\n",
            "I0314 03:10:20.567531 138313941204992 run.py:479] Algo floyd_warshall step 7271 current loss 0.063568, current_train_items 232704.\n",
            "I0314 03:10:20.704981 138313941204992 run.py:479] Algo floyd_warshall step 7272 current loss 0.178230, current_train_items 232736.\n",
            "I0314 03:10:20.924559 138313941204992 run.py:479] Algo floyd_warshall step 7273 current loss 0.400064, current_train_items 232768.\n",
            "I0314 03:10:21.329876 138313941204992 run.py:479] Algo floyd_warshall step 7274 current loss 0.652164, current_train_items 232800.\n",
            "I0314 03:10:21.352752 138313941204992 run.py:479] Algo floyd_warshall step 7275 current loss 0.013381, current_train_items 232832.\n",
            "I0314 03:10:21.395839 138313941204992 run.py:479] Algo floyd_warshall step 7276 current loss 0.089024, current_train_items 232864.\n",
            "I0314 03:10:21.526839 138313941204992 run.py:479] Algo floyd_warshall step 7277 current loss 0.239341, current_train_items 232896.\n",
            "I0314 03:10:21.741893 138313941204992 run.py:479] Algo floyd_warshall step 7278 current loss 0.313786, current_train_items 232928.\n",
            "I0314 03:10:22.154957 138313941204992 run.py:479] Algo floyd_warshall step 7279 current loss 0.667080, current_train_items 232960.\n",
            "I0314 03:10:22.178715 138313941204992 run.py:479] Algo floyd_warshall step 7280 current loss 0.009186, current_train_items 232992.\n",
            "I0314 03:10:22.223341 138313941204992 run.py:479] Algo floyd_warshall step 7281 current loss 0.065520, current_train_items 233024.\n",
            "I0314 03:10:22.356458 138313941204992 run.py:479] Algo floyd_warshall step 7282 current loss 0.248020, current_train_items 233056.\n",
            "I0314 03:10:22.584064 138313941204992 run.py:479] Algo floyd_warshall step 7283 current loss 0.401479, current_train_items 233088.\n",
            "I0314 03:10:23.012224 138313941204992 run.py:479] Algo floyd_warshall step 7284 current loss 0.572213, current_train_items 233120.\n",
            "I0314 03:10:23.037490 138313941204992 run.py:479] Algo floyd_warshall step 7285 current loss 0.025864, current_train_items 233152.\n",
            "I0314 03:10:23.082362 138313941204992 run.py:479] Algo floyd_warshall step 7286 current loss 0.033320, current_train_items 233184.\n",
            "I0314 03:10:23.210824 138313941204992 run.py:479] Algo floyd_warshall step 7287 current loss 0.315755, current_train_items 233216.\n",
            "I0314 03:10:23.427717 138313941204992 run.py:479] Algo floyd_warshall step 7288 current loss 0.416572, current_train_items 233248.\n",
            "I0314 03:10:23.837823 138313941204992 run.py:479] Algo floyd_warshall step 7289 current loss 0.595297, current_train_items 233280.\n",
            "I0314 03:10:23.862785 138313941204992 run.py:479] Algo floyd_warshall step 7290 current loss 0.025427, current_train_items 233312.\n",
            "I0314 03:10:23.908298 138313941204992 run.py:479] Algo floyd_warshall step 7291 current loss 0.054698, current_train_items 233344.\n",
            "I0314 03:10:24.040826 138313941204992 run.py:479] Algo floyd_warshall step 7292 current loss 0.290261, current_train_items 233376.\n",
            "I0314 03:10:24.266394 138313941204992 run.py:479] Algo floyd_warshall step 7293 current loss 0.366572, current_train_items 233408.\n",
            "I0314 03:10:24.671360 138313941204992 run.py:479] Algo floyd_warshall step 7294 current loss 0.600279, current_train_items 233440.\n",
            "I0314 03:10:24.705186 138313941204992 run.py:479] Algo floyd_warshall step 7295 current loss 0.021476, current_train_items 233472.\n",
            "I0314 03:10:24.751241 138313941204992 run.py:479] Algo floyd_warshall step 7296 current loss 0.072248, current_train_items 233504.\n",
            "I0314 03:10:24.885570 138313941204992 run.py:479] Algo floyd_warshall step 7297 current loss 0.232385, current_train_items 233536.\n",
            "I0314 03:10:25.117201 138313941204992 run.py:479] Algo floyd_warshall step 7298 current loss 0.354757, current_train_items 233568.\n",
            "I0314 03:10:25.535263 138313941204992 run.py:479] Algo floyd_warshall step 7299 current loss 0.590461, current_train_items 233600.\n",
            "I0314 03:10:25.558810 138313941204992 run.py:479] Algo floyd_warshall step 7300 current loss 0.063723, current_train_items 233632.\n",
            "I0314 03:10:25.646350 138313941204992 run.py:499] (val) algo floyd_warshall step 7300: {'Pi': 0.8935546875, 'score': 0.8935546875, 'examples_seen': 233632, 'step': 7300, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:10:25.646653 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.917, current avg val score is 0.894, val scores are: floyd_warshall: 0.894\n",
            "I0314 03:10:25.710637 138313941204992 run.py:479] Algo floyd_warshall step 7301 current loss 0.063737, current_train_items 233664.\n",
            "I0314 03:10:25.877409 138313941204992 run.py:479] Algo floyd_warshall step 7302 current loss 0.260371, current_train_items 233696.\n",
            "I0314 03:10:26.139796 138313941204992 run.py:479] Algo floyd_warshall step 7303 current loss 0.381024, current_train_items 233728.\n",
            "I0314 03:10:26.648062 138313941204992 run.py:479] Algo floyd_warshall step 7304 current loss 0.640078, current_train_items 233760.\n",
            "I0314 03:10:26.687462 138313941204992 run.py:479] Algo floyd_warshall step 7305 current loss 0.014703, current_train_items 233792.\n",
            "I0314 03:10:26.749528 138313941204992 run.py:479] Algo floyd_warshall step 7306 current loss 0.078943, current_train_items 233824.\n",
            "I0314 03:10:26.913550 138313941204992 run.py:479] Algo floyd_warshall step 7307 current loss 0.206709, current_train_items 233856.\n",
            "I0314 03:10:27.179177 138313941204992 run.py:479] Algo floyd_warshall step 7308 current loss 0.385812, current_train_items 233888.\n",
            "I0314 03:10:27.696615 138313941204992 run.py:479] Algo floyd_warshall step 7309 current loss 0.583839, current_train_items 233920.\n",
            "I0314 03:10:27.730043 138313941204992 run.py:479] Algo floyd_warshall step 7310 current loss 0.017373, current_train_items 233952.\n",
            "I0314 03:10:27.786952 138313941204992 run.py:479] Algo floyd_warshall step 7311 current loss 0.049972, current_train_items 233984.\n",
            "I0314 03:10:27.951488 138313941204992 run.py:479] Algo floyd_warshall step 7312 current loss 0.221877, current_train_items 234016.\n",
            "I0314 03:10:28.227395 138313941204992 run.py:479] Algo floyd_warshall step 7313 current loss 0.276102, current_train_items 234048.\n",
            "I0314 03:10:28.734844 138313941204992 run.py:479] Algo floyd_warshall step 7314 current loss 0.562816, current_train_items 234080.\n",
            "I0314 03:10:28.759950 138313941204992 run.py:479] Algo floyd_warshall step 7315 current loss 0.027714, current_train_items 234112.\n",
            "I0314 03:10:28.806213 138313941204992 run.py:479] Algo floyd_warshall step 7316 current loss 0.132014, current_train_items 234144.\n",
            "I0314 03:10:28.947511 138313941204992 run.py:479] Algo floyd_warshall step 7317 current loss 0.168214, current_train_items 234176.\n",
            "I0314 03:10:29.165021 138313941204992 run.py:479] Algo floyd_warshall step 7318 current loss 0.378106, current_train_items 234208.\n",
            "I0314 03:10:29.566568 138313941204992 run.py:479] Algo floyd_warshall step 7319 current loss 0.441131, current_train_items 234240.\n",
            "I0314 03:10:29.590641 138313941204992 run.py:479] Algo floyd_warshall step 7320 current loss 0.011562, current_train_items 234272.\n",
            "I0314 03:10:29.635524 138313941204992 run.py:479] Algo floyd_warshall step 7321 current loss 0.066526, current_train_items 234304.\n",
            "I0314 03:10:29.763431 138313941204992 run.py:479] Algo floyd_warshall step 7322 current loss 0.233011, current_train_items 234336.\n",
            "I0314 03:10:29.984582 138313941204992 run.py:479] Algo floyd_warshall step 7323 current loss 0.352750, current_train_items 234368.\n",
            "I0314 03:10:30.404278 138313941204992 run.py:479] Algo floyd_warshall step 7324 current loss 0.598260, current_train_items 234400.\n",
            "I0314 03:10:30.428658 138313941204992 run.py:479] Algo floyd_warshall step 7325 current loss 0.019372, current_train_items 234432.\n",
            "I0314 03:10:30.474688 138313941204992 run.py:479] Algo floyd_warshall step 7326 current loss 0.105041, current_train_items 234464.\n",
            "I0314 03:10:30.611332 138313941204992 run.py:479] Algo floyd_warshall step 7327 current loss 0.222587, current_train_items 234496.\n",
            "I0314 03:10:30.846585 138313941204992 run.py:479] Algo floyd_warshall step 7328 current loss 0.313930, current_train_items 234528.\n",
            "I0314 03:10:31.279898 138313941204992 run.py:479] Algo floyd_warshall step 7329 current loss 0.544978, current_train_items 234560.\n",
            "I0314 03:10:31.303598 138313941204992 run.py:479] Algo floyd_warshall step 7330 current loss 0.009668, current_train_items 234592.\n",
            "I0314 03:10:31.349283 138313941204992 run.py:479] Algo floyd_warshall step 7331 current loss 0.081610, current_train_items 234624.\n",
            "I0314 03:10:31.481631 138313941204992 run.py:479] Algo floyd_warshall step 7332 current loss 0.206462, current_train_items 234656.\n",
            "I0314 03:10:31.705028 138313941204992 run.py:479] Algo floyd_warshall step 7333 current loss 0.236342, current_train_items 234688.\n",
            "I0314 03:10:32.126999 138313941204992 run.py:479] Algo floyd_warshall step 7334 current loss 0.568778, current_train_items 234720.\n",
            "I0314 03:10:32.151620 138313941204992 run.py:479] Algo floyd_warshall step 7335 current loss 0.020854, current_train_items 234752.\n",
            "I0314 03:10:32.196892 138313941204992 run.py:479] Algo floyd_warshall step 7336 current loss 0.056368, current_train_items 234784.\n",
            "I0314 03:10:32.332686 138313941204992 run.py:479] Algo floyd_warshall step 7337 current loss 0.174561, current_train_items 234816.\n",
            "I0314 03:10:32.553884 138313941204992 run.py:479] Algo floyd_warshall step 7338 current loss 0.365194, current_train_items 234848.\n",
            "I0314 03:10:32.969582 138313941204992 run.py:479] Algo floyd_warshall step 7339 current loss 0.503847, current_train_items 234880.\n",
            "I0314 03:10:33.001035 138313941204992 run.py:479] Algo floyd_warshall step 7340 current loss 0.022672, current_train_items 234912.\n",
            "I0314 03:10:33.045983 138313941204992 run.py:479] Algo floyd_warshall step 7341 current loss 0.046773, current_train_items 234944.\n",
            "I0314 03:10:33.180288 138313941204992 run.py:479] Algo floyd_warshall step 7342 current loss 0.117767, current_train_items 234976.\n",
            "I0314 03:10:33.405349 138313941204992 run.py:479] Algo floyd_warshall step 7343 current loss 0.413017, current_train_items 235008.\n",
            "I0314 03:10:33.827342 138313941204992 run.py:479] Algo floyd_warshall step 7344 current loss 0.475911, current_train_items 235040.\n",
            "I0314 03:10:33.852346 138313941204992 run.py:479] Algo floyd_warshall step 7345 current loss 0.012826, current_train_items 235072.\n",
            "I0314 03:10:33.896683 138313941204992 run.py:479] Algo floyd_warshall step 7346 current loss 0.026214, current_train_items 235104.\n",
            "I0314 03:10:34.027819 138313941204992 run.py:479] Algo floyd_warshall step 7347 current loss 0.216299, current_train_items 235136.\n",
            "I0314 03:10:34.259619 138313941204992 run.py:479] Algo floyd_warshall step 7348 current loss 0.450213, current_train_items 235168.\n",
            "I0314 03:10:34.678645 138313941204992 run.py:479] Algo floyd_warshall step 7349 current loss 0.637329, current_train_items 235200.\n",
            "I0314 03:10:34.703259 138313941204992 run.py:479] Algo floyd_warshall step 7350 current loss 0.023906, current_train_items 235232.\n",
            "I0314 03:10:34.794409 138313941204992 run.py:499] (val) algo floyd_warshall step 7350: {'Pi': 0.9051513671875, 'score': 0.9051513671875, 'examples_seen': 235232, 'step': 7350, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:10:34.794686 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.917, current avg val score is 0.905, val scores are: floyd_warshall: 0.905\n",
            "I0314 03:10:34.844816 138313941204992 run.py:479] Algo floyd_warshall step 7351 current loss 0.046988, current_train_items 235264.\n",
            "I0314 03:10:34.975624 138313941204992 run.py:479] Algo floyd_warshall step 7352 current loss 0.174659, current_train_items 235296.\n",
            "I0314 03:10:35.205742 138313941204992 run.py:479] Algo floyd_warshall step 7353 current loss 0.374040, current_train_items 235328.\n",
            "I0314 03:10:35.627722 138313941204992 run.py:479] Algo floyd_warshall step 7354 current loss 0.517625, current_train_items 235360.\n",
            "I0314 03:10:35.656134 138313941204992 run.py:479] Algo floyd_warshall step 7355 current loss 0.024791, current_train_items 235392.\n",
            "I0314 03:10:35.708844 138313941204992 run.py:479] Algo floyd_warshall step 7356 current loss 0.125482, current_train_items 235424.\n",
            "I0314 03:10:35.846067 138313941204992 run.py:479] Algo floyd_warshall step 7357 current loss 0.278459, current_train_items 235456.\n",
            "I0314 03:10:36.071072 138313941204992 run.py:479] Algo floyd_warshall step 7358 current loss 0.320106, current_train_items 235488.\n",
            "I0314 03:10:36.498618 138313941204992 run.py:479] Algo floyd_warshall step 7359 current loss 0.676101, current_train_items 235520.\n",
            "I0314 03:10:36.522071 138313941204992 run.py:479] Algo floyd_warshall step 7360 current loss 0.018732, current_train_items 235552.\n",
            "I0314 03:10:36.566469 138313941204992 run.py:479] Algo floyd_warshall step 7361 current loss 0.054921, current_train_items 235584.\n",
            "I0314 03:10:36.698008 138313941204992 run.py:479] Algo floyd_warshall step 7362 current loss 0.168746, current_train_items 235616.\n",
            "I0314 03:10:36.917310 138313941204992 run.py:479] Algo floyd_warshall step 7363 current loss 0.414829, current_train_items 235648.\n",
            "I0314 03:10:37.334030 138313941204992 run.py:479] Algo floyd_warshall step 7364 current loss 0.724357, current_train_items 235680.\n",
            "I0314 03:10:37.358562 138313941204992 run.py:479] Algo floyd_warshall step 7365 current loss 0.009762, current_train_items 235712.\n",
            "I0314 03:10:37.404418 138313941204992 run.py:479] Algo floyd_warshall step 7366 current loss 0.118410, current_train_items 235744.\n",
            "I0314 03:10:37.534638 138313941204992 run.py:479] Algo floyd_warshall step 7367 current loss 0.180670, current_train_items 235776.\n",
            "I0314 03:10:37.772953 138313941204992 run.py:479] Algo floyd_warshall step 7368 current loss 0.503524, current_train_items 235808.\n",
            "I0314 03:10:38.186262 138313941204992 run.py:479] Algo floyd_warshall step 7369 current loss 0.697870, current_train_items 235840.\n",
            "I0314 03:10:38.210453 138313941204992 run.py:479] Algo floyd_warshall step 7370 current loss 0.017086, current_train_items 235872.\n",
            "I0314 03:10:38.255709 138313941204992 run.py:479] Algo floyd_warshall step 7371 current loss 0.066213, current_train_items 235904.\n",
            "I0314 03:10:38.389514 138313941204992 run.py:479] Algo floyd_warshall step 7372 current loss 0.249305, current_train_items 235936.\n",
            "I0314 03:10:38.611005 138313941204992 run.py:479] Algo floyd_warshall step 7373 current loss 0.416490, current_train_items 235968.\n",
            "I0314 03:10:39.068489 138313941204992 run.py:479] Algo floyd_warshall step 7374 current loss 0.774324, current_train_items 236000.\n",
            "I0314 03:10:39.104887 138313941204992 run.py:479] Algo floyd_warshall step 7375 current loss 0.027778, current_train_items 236032.\n",
            "I0314 03:10:39.171422 138313941204992 run.py:479] Algo floyd_warshall step 7376 current loss 0.056368, current_train_items 236064.\n",
            "I0314 03:10:39.338888 138313941204992 run.py:479] Algo floyd_warshall step 7377 current loss 0.195724, current_train_items 236096.\n",
            "I0314 03:10:39.601437 138313941204992 run.py:479] Algo floyd_warshall step 7378 current loss 0.387014, current_train_items 236128.\n",
            "I0314 03:10:40.080822 138313941204992 run.py:479] Algo floyd_warshall step 7379 current loss 0.564415, current_train_items 236160.\n",
            "I0314 03:10:40.118680 138313941204992 run.py:479] Algo floyd_warshall step 7380 current loss 0.016590, current_train_items 236192.\n",
            "I0314 03:10:40.180034 138313941204992 run.py:479] Algo floyd_warshall step 7381 current loss 0.097759, current_train_items 236224.\n",
            "I0314 03:10:40.344186 138313941204992 run.py:479] Algo floyd_warshall step 7382 current loss 0.196488, current_train_items 236256.\n",
            "I0314 03:10:40.602474 138313941204992 run.py:479] Algo floyd_warshall step 7383 current loss 0.341503, current_train_items 236288.\n",
            "I0314 03:10:41.068462 138313941204992 run.py:479] Algo floyd_warshall step 7384 current loss 0.384213, current_train_items 236320.\n",
            "I0314 03:10:41.109580 138313941204992 run.py:479] Algo floyd_warshall step 7385 current loss 0.014736, current_train_items 236352.\n",
            "I0314 03:10:41.173918 138313941204992 run.py:479] Algo floyd_warshall step 7386 current loss 0.092551, current_train_items 236384.\n",
            "I0314 03:10:41.337892 138313941204992 run.py:479] Algo floyd_warshall step 7387 current loss 0.253605, current_train_items 236416.\n",
            "I0314 03:10:41.604407 138313941204992 run.py:479] Algo floyd_warshall step 7388 current loss 0.316941, current_train_items 236448.\n",
            "I0314 03:10:42.105175 138313941204992 run.py:479] Algo floyd_warshall step 7389 current loss 0.636237, current_train_items 236480.\n",
            "I0314 03:10:42.141279 138313941204992 run.py:479] Algo floyd_warshall step 7390 current loss 0.023363, current_train_items 236512.\n",
            "I0314 03:10:42.194866 138313941204992 run.py:479] Algo floyd_warshall step 7391 current loss 0.072359, current_train_items 236544.\n",
            "I0314 03:10:42.326602 138313941204992 run.py:479] Algo floyd_warshall step 7392 current loss 0.234214, current_train_items 236576.\n",
            "I0314 03:10:42.549825 138313941204992 run.py:479] Algo floyd_warshall step 7393 current loss 0.349363, current_train_items 236608.\n",
            "I0314 03:10:42.954738 138313941204992 run.py:479] Algo floyd_warshall step 7394 current loss 0.484778, current_train_items 236640.\n",
            "I0314 03:10:42.979658 138313941204992 run.py:479] Algo floyd_warshall step 7395 current loss 0.010826, current_train_items 236672.\n",
            "I0314 03:10:43.025734 138313941204992 run.py:479] Algo floyd_warshall step 7396 current loss 0.069467, current_train_items 236704.\n",
            "I0314 03:10:43.158110 138313941204992 run.py:479] Algo floyd_warshall step 7397 current loss 0.218773, current_train_items 236736.\n",
            "I0314 03:10:43.388722 138313941204992 run.py:479] Algo floyd_warshall step 7398 current loss 0.346515, current_train_items 236768.\n",
            "I0314 03:10:43.813439 138313941204992 run.py:479] Algo floyd_warshall step 7399 current loss 0.623380, current_train_items 236800.\n",
            "I0314 03:10:43.839474 138313941204992 run.py:479] Algo floyd_warshall step 7400 current loss 0.011108, current_train_items 236832.\n",
            "I0314 03:10:43.927147 138313941204992 run.py:499] (val) algo floyd_warshall step 7400: {'Pi': 0.894287109375, 'score': 0.894287109375, 'examples_seen': 236832, 'step': 7400, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:10:43.927532 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.917, current avg val score is 0.894, val scores are: floyd_warshall: 0.894\n",
            "I0314 03:10:43.975718 138313941204992 run.py:479] Algo floyd_warshall step 7401 current loss 0.033943, current_train_items 236864.\n",
            "I0314 03:10:44.109694 138313941204992 run.py:479] Algo floyd_warshall step 7402 current loss 0.280782, current_train_items 236896.\n",
            "I0314 03:10:44.331844 138313941204992 run.py:479] Algo floyd_warshall step 7403 current loss 0.364845, current_train_items 236928.\n",
            "I0314 03:10:44.769470 138313941204992 run.py:479] Algo floyd_warshall step 7404 current loss 0.572510, current_train_items 236960.\n",
            "I0314 03:10:44.796531 138313941204992 run.py:479] Algo floyd_warshall step 7405 current loss 0.017096, current_train_items 236992.\n",
            "I0314 03:10:44.843270 138313941204992 run.py:479] Algo floyd_warshall step 7406 current loss 0.053992, current_train_items 237024.\n",
            "I0314 03:10:44.972533 138313941204992 run.py:479] Algo floyd_warshall step 7407 current loss 0.193384, current_train_items 237056.\n",
            "I0314 03:10:45.193124 138313941204992 run.py:479] Algo floyd_warshall step 7408 current loss 0.236681, current_train_items 237088.\n",
            "I0314 03:10:45.616142 138313941204992 run.py:479] Algo floyd_warshall step 7409 current loss 0.616280, current_train_items 237120.\n",
            "I0314 03:10:45.640221 138313941204992 run.py:479] Algo floyd_warshall step 7410 current loss 0.024005, current_train_items 237152.\n",
            "I0314 03:10:45.686694 138313941204992 run.py:479] Algo floyd_warshall step 7411 current loss 0.085629, current_train_items 237184.\n",
            "I0314 03:10:45.816952 138313941204992 run.py:479] Algo floyd_warshall step 7412 current loss 0.195408, current_train_items 237216.\n",
            "I0314 03:10:46.039103 138313941204992 run.py:479] Algo floyd_warshall step 7413 current loss 0.319967, current_train_items 237248.\n",
            "I0314 03:10:46.450101 138313941204992 run.py:479] Algo floyd_warshall step 7414 current loss 0.532582, current_train_items 237280.\n",
            "I0314 03:10:46.475107 138313941204992 run.py:479] Algo floyd_warshall step 7415 current loss 0.038644, current_train_items 237312.\n",
            "I0314 03:10:46.520980 138313941204992 run.py:479] Algo floyd_warshall step 7416 current loss 0.053675, current_train_items 237344.\n",
            "I0314 03:10:46.652541 138313941204992 run.py:479] Algo floyd_warshall step 7417 current loss 0.190558, current_train_items 237376.\n",
            "I0314 03:10:46.866967 138313941204992 run.py:479] Algo floyd_warshall step 7418 current loss 0.240779, current_train_items 237408.\n",
            "I0314 03:10:47.284013 138313941204992 run.py:479] Algo floyd_warshall step 7419 current loss 0.533558, current_train_items 237440.\n",
            "I0314 03:10:47.308654 138313941204992 run.py:479] Algo floyd_warshall step 7420 current loss 0.002312, current_train_items 237472.\n",
            "I0314 03:10:47.354526 138313941204992 run.py:479] Algo floyd_warshall step 7421 current loss 0.053698, current_train_items 237504.\n",
            "I0314 03:10:47.485095 138313941204992 run.py:479] Algo floyd_warshall step 7422 current loss 0.239037, current_train_items 237536.\n",
            "I0314 03:10:47.711866 138313941204992 run.py:479] Algo floyd_warshall step 7423 current loss 0.319588, current_train_items 237568.\n",
            "I0314 03:10:48.144343 138313941204992 run.py:479] Algo floyd_warshall step 7424 current loss 0.617088, current_train_items 237600.\n",
            "I0314 03:10:48.168430 138313941204992 run.py:479] Algo floyd_warshall step 7425 current loss 0.015018, current_train_items 237632.\n",
            "I0314 03:10:48.214223 138313941204992 run.py:479] Algo floyd_warshall step 7426 current loss 0.058737, current_train_items 237664.\n",
            "I0314 03:10:48.345669 138313941204992 run.py:479] Algo floyd_warshall step 7427 current loss 0.180704, current_train_items 237696.\n",
            "I0314 03:10:48.564857 138313941204992 run.py:479] Algo floyd_warshall step 7428 current loss 0.247633, current_train_items 237728.\n",
            "I0314 03:10:48.977347 138313941204992 run.py:479] Algo floyd_warshall step 7429 current loss 0.495194, current_train_items 237760.\n",
            "I0314 03:10:49.001611 138313941204992 run.py:479] Algo floyd_warshall step 7430 current loss 0.020139, current_train_items 237792.\n",
            "I0314 03:10:49.045744 138313941204992 run.py:479] Algo floyd_warshall step 7431 current loss 0.044514, current_train_items 237824.\n",
            "I0314 03:10:49.177940 138313941204992 run.py:479] Algo floyd_warshall step 7432 current loss 0.360805, current_train_items 237856.\n",
            "I0314 03:10:49.395466 138313941204992 run.py:479] Algo floyd_warshall step 7433 current loss 0.354815, current_train_items 237888.\n",
            "I0314 03:10:49.830327 138313941204992 run.py:479] Algo floyd_warshall step 7434 current loss 0.575793, current_train_items 237920.\n",
            "I0314 03:10:49.856658 138313941204992 run.py:479] Algo floyd_warshall step 7435 current loss 0.013243, current_train_items 237952.\n",
            "I0314 03:10:49.901128 138313941204992 run.py:479] Algo floyd_warshall step 7436 current loss 0.040509, current_train_items 237984.\n",
            "I0314 03:10:50.031791 138313941204992 run.py:479] Algo floyd_warshall step 7437 current loss 0.174978, current_train_items 238016.\n",
            "I0314 03:10:50.264889 138313941204992 run.py:479] Algo floyd_warshall step 7438 current loss 0.431143, current_train_items 238048.\n",
            "I0314 03:10:50.680998 138313941204992 run.py:479] Algo floyd_warshall step 7439 current loss 0.545401, current_train_items 238080.\n",
            "I0314 03:10:50.705532 138313941204992 run.py:479] Algo floyd_warshall step 7440 current loss 0.020261, current_train_items 238112.\n",
            "I0314 03:10:50.751733 138313941204992 run.py:479] Algo floyd_warshall step 7441 current loss 0.065471, current_train_items 238144.\n",
            "I0314 03:10:50.885976 138313941204992 run.py:479] Algo floyd_warshall step 7442 current loss 0.158315, current_train_items 238176.\n",
            "I0314 03:10:51.110581 138313941204992 run.py:479] Algo floyd_warshall step 7443 current loss 0.364017, current_train_items 238208.\n",
            "I0314 03:10:51.537817 138313941204992 run.py:479] Algo floyd_warshall step 7444 current loss 0.566237, current_train_items 238240.\n",
            "I0314 03:10:51.572833 138313941204992 run.py:479] Algo floyd_warshall step 7445 current loss 0.030393, current_train_items 238272.\n",
            "I0314 03:10:51.620651 138313941204992 run.py:479] Algo floyd_warshall step 7446 current loss 0.059123, current_train_items 238304.\n",
            "I0314 03:10:51.753883 138313941204992 run.py:479] Algo floyd_warshall step 7447 current loss 0.310401, current_train_items 238336.\n",
            "I0314 03:10:51.977488 138313941204992 run.py:479] Algo floyd_warshall step 7448 current loss 0.249124, current_train_items 238368.\n",
            "I0314 03:10:52.470471 138313941204992 run.py:479] Algo floyd_warshall step 7449 current loss 0.536850, current_train_items 238400.\n",
            "I0314 03:10:52.505060 138313941204992 run.py:479] Algo floyd_warshall step 7450 current loss 0.017551, current_train_items 238432.\n",
            "I0314 03:10:52.612855 138313941204992 run.py:499] (val) algo floyd_warshall step 7450: {'Pi': 0.92071533203125, 'score': 0.92071533203125, 'examples_seen': 238432, 'step': 7450, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:10:52.613236 138313941204992 run.py:516] Checkpointing best model, best avg val score was 0.917, current avg val score is 0.921, val scores are: floyd_warshall: 0.921\n",
            "I0314 03:10:52.794008 138313941204992 run.py:479] Algo floyd_warshall step 7451 current loss 0.097165, current_train_items 238464.\n",
            "I0314 03:10:52.958323 138313941204992 run.py:479] Algo floyd_warshall step 7452 current loss 0.226614, current_train_items 238496.\n",
            "I0314 03:10:53.230185 138313941204992 run.py:479] Algo floyd_warshall step 7453 current loss 0.378552, current_train_items 238528.\n",
            "I0314 03:10:53.741544 138313941204992 run.py:479] Algo floyd_warshall step 7454 current loss 0.596891, current_train_items 238560.\n",
            "I0314 03:10:53.777589 138313941204992 run.py:479] Algo floyd_warshall step 7455 current loss 0.121049, current_train_items 238592.\n",
            "I0314 03:10:53.834895 138313941204992 run.py:479] Algo floyd_warshall step 7456 current loss 0.048930, current_train_items 238624.\n",
            "I0314 03:10:53.989434 138313941204992 run.py:479] Algo floyd_warshall step 7457 current loss 0.164939, current_train_items 238656.\n",
            "I0314 03:10:54.249141 138313941204992 run.py:479] Algo floyd_warshall step 7458 current loss 0.340551, current_train_items 238688.\n",
            "I0314 03:10:54.755219 138313941204992 run.py:479] Algo floyd_warshall step 7459 current loss 0.572666, current_train_items 238720.\n",
            "I0314 03:10:54.794357 138313941204992 run.py:479] Algo floyd_warshall step 7460 current loss 0.007935, current_train_items 238752.\n",
            "I0314 03:10:54.853551 138313941204992 run.py:479] Algo floyd_warshall step 7461 current loss 0.037473, current_train_items 238784.\n",
            "I0314 03:10:55.000662 138313941204992 run.py:479] Algo floyd_warshall step 7462 current loss 0.218181, current_train_items 238816.\n",
            "I0314 03:10:55.216626 138313941204992 run.py:479] Algo floyd_warshall step 7463 current loss 0.312023, current_train_items 238848.\n",
            "I0314 03:10:55.649832 138313941204992 run.py:479] Algo floyd_warshall step 7464 current loss 0.605145, current_train_items 238880.\n",
            "I0314 03:10:55.673961 138313941204992 run.py:479] Algo floyd_warshall step 7465 current loss 0.023332, current_train_items 238912.\n",
            "I0314 03:10:55.717982 138313941204992 run.py:479] Algo floyd_warshall step 7466 current loss 0.045324, current_train_items 238944.\n",
            "I0314 03:10:55.853174 138313941204992 run.py:479] Algo floyd_warshall step 7467 current loss 0.214691, current_train_items 238976.\n",
            "I0314 03:10:56.073482 138313941204992 run.py:479] Algo floyd_warshall step 7468 current loss 0.241285, current_train_items 239008.\n",
            "I0314 03:10:56.483264 138313941204992 run.py:479] Algo floyd_warshall step 7469 current loss 0.457959, current_train_items 239040.\n",
            "I0314 03:10:56.506922 138313941204992 run.py:479] Algo floyd_warshall step 7470 current loss 0.054005, current_train_items 239072.\n",
            "I0314 03:10:56.551318 138313941204992 run.py:479] Algo floyd_warshall step 7471 current loss 0.030764, current_train_items 239104.\n",
            "I0314 03:10:56.679998 138313941204992 run.py:479] Algo floyd_warshall step 7472 current loss 0.226866, current_train_items 239136.\n",
            "I0314 03:10:56.893743 138313941204992 run.py:479] Algo floyd_warshall step 7473 current loss 0.290549, current_train_items 239168.\n",
            "I0314 03:10:57.305685 138313941204992 run.py:479] Algo floyd_warshall step 7474 current loss 0.523244, current_train_items 239200.\n",
            "I0314 03:10:57.330110 138313941204992 run.py:479] Algo floyd_warshall step 7475 current loss 0.013181, current_train_items 239232.\n",
            "I0314 03:10:57.374870 138313941204992 run.py:479] Algo floyd_warshall step 7476 current loss 0.058227, current_train_items 239264.\n",
            "I0314 03:10:57.506445 138313941204992 run.py:479] Algo floyd_warshall step 7477 current loss 0.200007, current_train_items 239296.\n",
            "I0314 03:10:57.721019 138313941204992 run.py:479] Algo floyd_warshall step 7478 current loss 0.372644, current_train_items 239328.\n",
            "I0314 03:10:58.144302 138313941204992 run.py:479] Algo floyd_warshall step 7479 current loss 0.674296, current_train_items 239360.\n",
            "I0314 03:10:58.168530 138313941204992 run.py:479] Algo floyd_warshall step 7480 current loss 0.025812, current_train_items 239392.\n",
            "I0314 03:10:58.211938 138313941204992 run.py:479] Algo floyd_warshall step 7481 current loss 0.055366, current_train_items 239424.\n",
            "I0314 03:10:58.340817 138313941204992 run.py:479] Algo floyd_warshall step 7482 current loss 0.186054, current_train_items 239456.\n",
            "I0314 03:10:58.573997 138313941204992 run.py:479] Algo floyd_warshall step 7483 current loss 0.429184, current_train_items 239488.\n",
            "I0314 03:10:58.976708 138313941204992 run.py:479] Algo floyd_warshall step 7484 current loss 0.529850, current_train_items 239520.\n",
            "I0314 03:10:59.000142 138313941204992 run.py:479] Algo floyd_warshall step 7485 current loss 0.026546, current_train_items 239552.\n",
            "I0314 03:10:59.044208 138313941204992 run.py:479] Algo floyd_warshall step 7486 current loss 0.178348, current_train_items 239584.\n",
            "I0314 03:10:59.173505 138313941204992 run.py:479] Algo floyd_warshall step 7487 current loss 0.243133, current_train_items 239616.\n",
            "I0314 03:10:59.402216 138313941204992 run.py:479] Algo floyd_warshall step 7488 current loss 0.377352, current_train_items 239648.\n",
            "I0314 03:10:59.816330 138313941204992 run.py:479] Algo floyd_warshall step 7489 current loss 0.632440, current_train_items 239680.\n",
            "I0314 03:10:59.840494 138313941204992 run.py:479] Algo floyd_warshall step 7490 current loss 0.011302, current_train_items 239712.\n",
            "I0314 03:10:59.890553 138313941204992 run.py:479] Algo floyd_warshall step 7491 current loss 0.068110, current_train_items 239744.\n",
            "I0314 03:11:00.019476 138313941204992 run.py:479] Algo floyd_warshall step 7492 current loss 0.232846, current_train_items 239776.\n",
            "I0314 03:11:00.235661 138313941204992 run.py:479] Algo floyd_warshall step 7493 current loss 0.407092, current_train_items 239808.\n",
            "I0314 03:11:00.646510 138313941204992 run.py:479] Algo floyd_warshall step 7494 current loss 0.614091, current_train_items 239840.\n",
            "I0314 03:11:00.669512 138313941204992 run.py:479] Algo floyd_warshall step 7495 current loss 0.026966, current_train_items 239872.\n",
            "I0314 03:11:00.712817 138313941204992 run.py:479] Algo floyd_warshall step 7496 current loss 0.041040, current_train_items 239904.\n",
            "I0314 03:11:00.844334 138313941204992 run.py:479] Algo floyd_warshall step 7497 current loss 0.269888, current_train_items 239936.\n",
            "I0314 03:11:01.085252 138313941204992 run.py:479] Algo floyd_warshall step 7498 current loss 0.342242, current_train_items 239968.\n",
            "I0314 03:11:01.493259 138313941204992 run.py:479] Algo floyd_warshall step 7499 current loss 0.471455, current_train_items 240000.\n",
            "I0314 03:11:01.518183 138313941204992 run.py:479] Algo floyd_warshall step 7500 current loss 0.034147, current_train_items 240032.\n",
            "I0314 03:11:01.606170 138313941204992 run.py:499] (val) algo floyd_warshall step 7500: {'Pi': 0.90765380859375, 'score': 0.90765380859375, 'examples_seen': 240032, 'step': 7500, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:11:01.606411 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.921, current avg val score is 0.908, val scores are: floyd_warshall: 0.908\n",
            "I0314 03:11:01.655985 138313941204992 run.py:479] Algo floyd_warshall step 7501 current loss 0.080990, current_train_items 240064.\n",
            "I0314 03:11:01.784808 138313941204992 run.py:479] Algo floyd_warshall step 7502 current loss 0.176938, current_train_items 240096.\n",
            "I0314 03:11:01.995991 138313941204992 run.py:479] Algo floyd_warshall step 7503 current loss 0.194800, current_train_items 240128.\n",
            "I0314 03:11:02.421513 138313941204992 run.py:479] Algo floyd_warshall step 7504 current loss 0.530713, current_train_items 240160.\n",
            "I0314 03:11:02.446347 138313941204992 run.py:479] Algo floyd_warshall step 7505 current loss 0.029709, current_train_items 240192.\n",
            "I0314 03:11:02.490919 138313941204992 run.py:479] Algo floyd_warshall step 7506 current loss 0.059943, current_train_items 240224.\n",
            "I0314 03:11:02.618176 138313941204992 run.py:479] Algo floyd_warshall step 7507 current loss 0.158673, current_train_items 240256.\n",
            "I0314 03:11:02.829629 138313941204992 run.py:479] Algo floyd_warshall step 7508 current loss 0.221736, current_train_items 240288.\n",
            "I0314 03:11:03.249563 138313941204992 run.py:479] Algo floyd_warshall step 7509 current loss 0.598137, current_train_items 240320.\n",
            "I0314 03:11:03.272323 138313941204992 run.py:479] Algo floyd_warshall step 7510 current loss 0.016826, current_train_items 240352.\n",
            "I0314 03:11:03.316374 138313941204992 run.py:479] Algo floyd_warshall step 7511 current loss 0.048019, current_train_items 240384.\n",
            "I0314 03:11:03.444983 138313941204992 run.py:479] Algo floyd_warshall step 7512 current loss 0.189776, current_train_items 240416.\n",
            "I0314 03:11:03.662431 138313941204992 run.py:479] Algo floyd_warshall step 7513 current loss 0.396342, current_train_items 240448.\n",
            "I0314 03:11:04.072339 138313941204992 run.py:479] Algo floyd_warshall step 7514 current loss 0.500879, current_train_items 240480.\n",
            "I0314 03:11:04.097657 138313941204992 run.py:479] Algo floyd_warshall step 7515 current loss 0.027433, current_train_items 240512.\n",
            "I0314 03:11:04.143519 138313941204992 run.py:479] Algo floyd_warshall step 7516 current loss 0.116803, current_train_items 240544.\n",
            "I0314 03:11:04.277822 138313941204992 run.py:479] Algo floyd_warshall step 7517 current loss 0.167385, current_train_items 240576.\n",
            "I0314 03:11:04.503047 138313941204992 run.py:479] Algo floyd_warshall step 7518 current loss 0.221501, current_train_items 240608.\n",
            "I0314 03:11:04.913980 138313941204992 run.py:479] Algo floyd_warshall step 7519 current loss 0.412097, current_train_items 240640.\n",
            "I0314 03:11:04.953986 138313941204992 run.py:479] Algo floyd_warshall step 7520 current loss 0.029642, current_train_items 240672.\n",
            "I0314 03:11:05.018220 138313941204992 run.py:479] Algo floyd_warshall step 7521 current loss 0.037081, current_train_items 240704.\n",
            "I0314 03:11:05.181549 138313941204992 run.py:479] Algo floyd_warshall step 7522 current loss 0.195118, current_train_items 240736.\n",
            "I0314 03:11:05.444944 138313941204992 run.py:479] Algo floyd_warshall step 7523 current loss 0.342583, current_train_items 240768.\n",
            "I0314 03:11:05.941474 138313941204992 run.py:479] Algo floyd_warshall step 7524 current loss 0.597405, current_train_items 240800.\n",
            "I0314 03:11:05.973987 138313941204992 run.py:479] Algo floyd_warshall step 7525 current loss 0.017780, current_train_items 240832.\n",
            "I0314 03:11:06.032224 138313941204992 run.py:479] Algo floyd_warshall step 7526 current loss 0.051777, current_train_items 240864.\n",
            "I0314 03:11:06.200929 138313941204992 run.py:479] Algo floyd_warshall step 7527 current loss 0.193426, current_train_items 240896.\n",
            "I0314 03:11:06.479360 138313941204992 run.py:479] Algo floyd_warshall step 7528 current loss 0.403876, current_train_items 240928.\n",
            "I0314 03:11:06.979069 138313941204992 run.py:479] Algo floyd_warshall step 7529 current loss 0.621602, current_train_items 240960.\n",
            "I0314 03:11:07.013810 138313941204992 run.py:479] Algo floyd_warshall step 7530 current loss 0.025035, current_train_items 240992.\n",
            "I0314 03:11:07.070760 138313941204992 run.py:479] Algo floyd_warshall step 7531 current loss 0.068323, current_train_items 241024.\n",
            "I0314 03:11:07.242494 138313941204992 run.py:479] Algo floyd_warshall step 7532 current loss 0.233884, current_train_items 241056.\n",
            "I0314 03:11:07.505819 138313941204992 run.py:479] Algo floyd_warshall step 7533 current loss 0.271946, current_train_items 241088.\n",
            "I0314 03:11:08.004681 138313941204992 run.py:479] Algo floyd_warshall step 7534 current loss 0.544704, current_train_items 241120.\n",
            "I0314 03:11:08.035715 138313941204992 run.py:479] Algo floyd_warshall step 7535 current loss 0.016617, current_train_items 241152.\n",
            "I0314 03:11:08.082725 138313941204992 run.py:479] Algo floyd_warshall step 7536 current loss 0.046690, current_train_items 241184.\n",
            "I0314 03:11:08.215706 138313941204992 run.py:479] Algo floyd_warshall step 7537 current loss 0.207584, current_train_items 241216.\n",
            "I0314 03:11:08.437910 138313941204992 run.py:479] Algo floyd_warshall step 7538 current loss 0.263661, current_train_items 241248.\n",
            "I0314 03:11:08.858013 138313941204992 run.py:479] Algo floyd_warshall step 7539 current loss 0.538541, current_train_items 241280.\n",
            "I0314 03:11:08.881571 138313941204992 run.py:479] Algo floyd_warshall step 7540 current loss 0.015084, current_train_items 241312.\n",
            "I0314 03:11:08.928331 138313941204992 run.py:479] Algo floyd_warshall step 7541 current loss 0.058363, current_train_items 241344.\n",
            "I0314 03:11:09.060261 138313941204992 run.py:479] Algo floyd_warshall step 7542 current loss 0.205078, current_train_items 241376.\n",
            "I0314 03:11:09.280037 138313941204992 run.py:479] Algo floyd_warshall step 7543 current loss 0.284978, current_train_items 241408.\n",
            "I0314 03:11:09.699842 138313941204992 run.py:479] Algo floyd_warshall step 7544 current loss 0.568242, current_train_items 241440.\n",
            "I0314 03:11:09.723829 138313941204992 run.py:479] Algo floyd_warshall step 7545 current loss 0.009938, current_train_items 241472.\n",
            "I0314 03:11:09.767811 138313941204992 run.py:479] Algo floyd_warshall step 7546 current loss 0.039779, current_train_items 241504.\n",
            "I0314 03:11:09.898391 138313941204992 run.py:479] Algo floyd_warshall step 7547 current loss 0.206225, current_train_items 241536.\n",
            "I0314 03:11:10.128847 138313941204992 run.py:479] Algo floyd_warshall step 7548 current loss 0.304719, current_train_items 241568.\n",
            "I0314 03:11:10.565082 138313941204992 run.py:479] Algo floyd_warshall step 7549 current loss 0.634391, current_train_items 241600.\n",
            "I0314 03:11:10.590032 138313941204992 run.py:479] Algo floyd_warshall step 7550 current loss 0.019890, current_train_items 241632.\n",
            "I0314 03:11:10.677749 138313941204992 run.py:499] (val) algo floyd_warshall step 7550: {'Pi': 0.9112548828125, 'score': 0.9112548828125, 'examples_seen': 241632, 'step': 7550, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:11:10.678021 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.921, current avg val score is 0.911, val scores are: floyd_warshall: 0.911\n",
            "I0314 03:11:10.728276 138313941204992 run.py:479] Algo floyd_warshall step 7551 current loss 0.046160, current_train_items 241664.\n",
            "I0314 03:11:10.861973 138313941204992 run.py:479] Algo floyd_warshall step 7552 current loss 0.228593, current_train_items 241696.\n",
            "I0314 03:11:11.088417 138313941204992 run.py:479] Algo floyd_warshall step 7553 current loss 0.377751, current_train_items 241728.\n",
            "I0314 03:11:11.506726 138313941204992 run.py:479] Algo floyd_warshall step 7554 current loss 0.552790, current_train_items 241760.\n",
            "I0314 03:11:11.534524 138313941204992 run.py:479] Algo floyd_warshall step 7555 current loss 0.024522, current_train_items 241792.\n",
            "I0314 03:11:11.578711 138313941204992 run.py:479] Algo floyd_warshall step 7556 current loss 0.067739, current_train_items 241824.\n",
            "I0314 03:11:11.712141 138313941204992 run.py:479] Algo floyd_warshall step 7557 current loss 0.206554, current_train_items 241856.\n",
            "I0314 03:11:11.941267 138313941204992 run.py:479] Algo floyd_warshall step 7558 current loss 0.370482, current_train_items 241888.\n",
            "I0314 03:11:12.359812 138313941204992 run.py:479] Algo floyd_warshall step 7559 current loss 0.686726, current_train_items 241920.\n",
            "I0314 03:11:12.384056 138313941204992 run.py:479] Algo floyd_warshall step 7560 current loss 0.014650, current_train_items 241952.\n",
            "I0314 03:11:12.430942 138313941204992 run.py:479] Algo floyd_warshall step 7561 current loss 0.041751, current_train_items 241984.\n",
            "I0314 03:11:12.561662 138313941204992 run.py:479] Algo floyd_warshall step 7562 current loss 0.233808, current_train_items 242016.\n",
            "I0314 03:11:12.772183 138313941204992 run.py:479] Algo floyd_warshall step 7563 current loss 0.285692, current_train_items 242048.\n",
            "I0314 03:11:13.190311 138313941204992 run.py:479] Algo floyd_warshall step 7564 current loss 0.657840, current_train_items 242080.\n",
            "I0314 03:11:13.214814 138313941204992 run.py:479] Algo floyd_warshall step 7565 current loss 0.028333, current_train_items 242112.\n",
            "I0314 03:11:13.259417 138313941204992 run.py:479] Algo floyd_warshall step 7566 current loss 0.060498, current_train_items 242144.\n",
            "I0314 03:11:13.398451 138313941204992 run.py:479] Algo floyd_warshall step 7567 current loss 0.211443, current_train_items 242176.\n",
            "I0314 03:11:13.611657 138313941204992 run.py:479] Algo floyd_warshall step 7568 current loss 0.328234, current_train_items 242208.\n",
            "I0314 03:11:14.032124 138313941204992 run.py:479] Algo floyd_warshall step 7569 current loss 0.489362, current_train_items 242240.\n",
            "I0314 03:11:14.056004 138313941204992 run.py:479] Algo floyd_warshall step 7570 current loss 0.025992, current_train_items 242272.\n",
            "I0314 03:11:14.102344 138313941204992 run.py:479] Algo floyd_warshall step 7571 current loss 0.047889, current_train_items 242304.\n",
            "I0314 03:11:14.230657 138313941204992 run.py:479] Algo floyd_warshall step 7572 current loss 0.203222, current_train_items 242336.\n",
            "I0314 03:11:14.457096 138313941204992 run.py:479] Algo floyd_warshall step 7573 current loss 0.425449, current_train_items 242368.\n",
            "I0314 03:11:14.874302 138313941204992 run.py:479] Algo floyd_warshall step 7574 current loss 0.602382, current_train_items 242400.\n",
            "I0314 03:11:14.897198 138313941204992 run.py:479] Algo floyd_warshall step 7575 current loss 0.061148, current_train_items 242432.\n",
            "I0314 03:11:14.943194 138313941204992 run.py:479] Algo floyd_warshall step 7576 current loss 0.094379, current_train_items 242464.\n",
            "I0314 03:11:15.074048 138313941204992 run.py:479] Algo floyd_warshall step 7577 current loss 0.230954, current_train_items 242496.\n",
            "I0314 03:11:15.288120 138313941204992 run.py:479] Algo floyd_warshall step 7578 current loss 0.309169, current_train_items 242528.\n",
            "I0314 03:11:15.702278 138313941204992 run.py:479] Algo floyd_warshall step 7579 current loss 0.461209, current_train_items 242560.\n",
            "I0314 03:11:15.725814 138313941204992 run.py:479] Algo floyd_warshall step 7580 current loss 0.007947, current_train_items 242592.\n",
            "I0314 03:11:15.769550 138313941204992 run.py:479] Algo floyd_warshall step 7581 current loss 0.063667, current_train_items 242624.\n",
            "I0314 03:11:15.899131 138313941204992 run.py:479] Algo floyd_warshall step 7582 current loss 0.161929, current_train_items 242656.\n",
            "I0314 03:11:16.117158 138313941204992 run.py:479] Algo floyd_warshall step 7583 current loss 0.357310, current_train_items 242688.\n",
            "I0314 03:11:16.530984 138313941204992 run.py:479] Algo floyd_warshall step 7584 current loss 0.535757, current_train_items 242720.\n",
            "I0314 03:11:16.554476 138313941204992 run.py:479] Algo floyd_warshall step 7585 current loss 0.009378, current_train_items 242752.\n",
            "I0314 03:11:16.599922 138313941204992 run.py:479] Algo floyd_warshall step 7586 current loss 0.067193, current_train_items 242784.\n",
            "I0314 03:11:16.727584 138313941204992 run.py:479] Algo floyd_warshall step 7587 current loss 0.131083, current_train_items 242816.\n",
            "I0314 03:11:16.955064 138313941204992 run.py:479] Algo floyd_warshall step 7588 current loss 0.374857, current_train_items 242848.\n",
            "I0314 03:11:17.364827 138313941204992 run.py:479] Algo floyd_warshall step 7589 current loss 0.482525, current_train_items 242880.\n",
            "I0314 03:11:17.388625 138313941204992 run.py:479] Algo floyd_warshall step 7590 current loss 0.032500, current_train_items 242912.\n",
            "I0314 03:11:17.440401 138313941204992 run.py:479] Algo floyd_warshall step 7591 current loss 0.087846, current_train_items 242944.\n",
            "I0314 03:11:17.568389 138313941204992 run.py:479] Algo floyd_warshall step 7592 current loss 0.185822, current_train_items 242976.\n",
            "I0314 03:11:17.790996 138313941204992 run.py:479] Algo floyd_warshall step 7593 current loss 0.346836, current_train_items 243008.\n",
            "I0314 03:11:18.201659 138313941204992 run.py:479] Algo floyd_warshall step 7594 current loss 0.554176, current_train_items 243040.\n",
            "I0314 03:11:18.236395 138313941204992 run.py:479] Algo floyd_warshall step 7595 current loss 0.046908, current_train_items 243072.\n",
            "I0314 03:11:18.296449 138313941204992 run.py:479] Algo floyd_warshall step 7596 current loss 0.094950, current_train_items 243104.\n",
            "I0314 03:11:18.451440 138313941204992 run.py:479] Algo floyd_warshall step 7597 current loss 0.163806, current_train_items 243136.\n",
            "I0314 03:11:18.724321 138313941204992 run.py:479] Algo floyd_warshall step 7598 current loss 0.393939, current_train_items 243168.\n",
            "I0314 03:11:19.238561 138313941204992 run.py:479] Algo floyd_warshall step 7599 current loss 0.582640, current_train_items 243200.\n",
            "I0314 03:11:19.274476 138313941204992 run.py:479] Algo floyd_warshall step 7600 current loss 0.017601, current_train_items 243232.\n",
            "I0314 03:11:19.381100 138313941204992 run.py:499] (val) algo floyd_warshall step 7600: {'Pi': 0.879638671875, 'score': 0.879638671875, 'examples_seen': 243232, 'step': 7600, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:11:19.381410 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.921, current avg val score is 0.880, val scores are: floyd_warshall: 0.880\n",
            "I0314 03:11:19.448220 138313941204992 run.py:479] Algo floyd_warshall step 7601 current loss 0.054609, current_train_items 243264.\n",
            "I0314 03:11:19.629701 138313941204992 run.py:479] Algo floyd_warshall step 7602 current loss 0.256382, current_train_items 243296.\n",
            "I0314 03:11:19.909903 138313941204992 run.py:479] Algo floyd_warshall step 7603 current loss 0.248842, current_train_items 243328.\n",
            "I0314 03:11:20.397488 138313941204992 run.py:479] Algo floyd_warshall step 7604 current loss 0.465884, current_train_items 243360.\n",
            "I0314 03:11:20.434977 138313941204992 run.py:479] Algo floyd_warshall step 7605 current loss 0.020309, current_train_items 243392.\n",
            "I0314 03:11:20.492236 138313941204992 run.py:479] Algo floyd_warshall step 7606 current loss 0.102427, current_train_items 243424.\n",
            "I0314 03:11:20.655098 138313941204992 run.py:479] Algo floyd_warshall step 7607 current loss 0.165478, current_train_items 243456.\n",
            "I0314 03:11:20.918998 138313941204992 run.py:479] Algo floyd_warshall step 7608 current loss 0.302495, current_train_items 243488.\n",
            "I0314 03:11:21.420214 138313941204992 run.py:479] Algo floyd_warshall step 7609 current loss 0.561822, current_train_items 243520.\n",
            "I0314 03:11:21.443274 138313941204992 run.py:479] Algo floyd_warshall step 7610 current loss 0.018181, current_train_items 243552.\n",
            "I0314 03:11:21.488032 138313941204992 run.py:479] Algo floyd_warshall step 7611 current loss 0.049185, current_train_items 243584.\n",
            "I0314 03:11:21.618511 138313941204992 run.py:479] Algo floyd_warshall step 7612 current loss 0.214446, current_train_items 243616.\n",
            "I0314 03:11:21.834898 138313941204992 run.py:479] Algo floyd_warshall step 7613 current loss 0.291128, current_train_items 243648.\n",
            "I0314 03:11:22.249857 138313941204992 run.py:479] Algo floyd_warshall step 7614 current loss 0.556744, current_train_items 243680.\n",
            "I0314 03:11:22.275535 138313941204992 run.py:479] Algo floyd_warshall step 7615 current loss 0.010041, current_train_items 243712.\n",
            "I0314 03:11:22.319985 138313941204992 run.py:479] Algo floyd_warshall step 7616 current loss 0.049116, current_train_items 243744.\n",
            "I0314 03:11:22.451880 138313941204992 run.py:479] Algo floyd_warshall step 7617 current loss 0.246495, current_train_items 243776.\n",
            "I0314 03:11:22.673749 138313941204992 run.py:479] Algo floyd_warshall step 7618 current loss 0.218015, current_train_items 243808.\n",
            "I0314 03:11:23.086908 138313941204992 run.py:479] Algo floyd_warshall step 7619 current loss 0.635452, current_train_items 243840.\n",
            "I0314 03:11:23.110650 138313941204992 run.py:479] Algo floyd_warshall step 7620 current loss 0.017557, current_train_items 243872.\n",
            "I0314 03:11:23.154217 138313941204992 run.py:479] Algo floyd_warshall step 7621 current loss 0.071451, current_train_items 243904.\n",
            "I0314 03:11:23.286302 138313941204992 run.py:479] Algo floyd_warshall step 7622 current loss 0.166819, current_train_items 243936.\n",
            "I0314 03:11:23.507800 138313941204992 run.py:479] Algo floyd_warshall step 7623 current loss 0.308806, current_train_items 243968.\n",
            "I0314 03:11:23.920687 138313941204992 run.py:479] Algo floyd_warshall step 7624 current loss 0.566248, current_train_items 244000.\n",
            "I0314 03:11:23.944581 138313941204992 run.py:479] Algo floyd_warshall step 7625 current loss 0.011716, current_train_items 244032.\n",
            "I0314 03:11:23.992301 138313941204992 run.py:479] Algo floyd_warshall step 7626 current loss 0.052762, current_train_items 244064.\n",
            "I0314 03:11:24.119744 138313941204992 run.py:479] Algo floyd_warshall step 7627 current loss 0.162261, current_train_items 244096.\n",
            "I0314 03:11:24.332482 138313941204992 run.py:479] Algo floyd_warshall step 7628 current loss 0.311243, current_train_items 244128.\n",
            "I0314 03:11:24.747946 138313941204992 run.py:479] Algo floyd_warshall step 7629 current loss 0.579572, current_train_items 244160.\n",
            "I0314 03:11:24.774959 138313941204992 run.py:479] Algo floyd_warshall step 7630 current loss 0.009202, current_train_items 244192.\n",
            "I0314 03:11:24.821158 138313941204992 run.py:479] Algo floyd_warshall step 7631 current loss 0.066479, current_train_items 244224.\n",
            "I0314 03:11:24.953910 138313941204992 run.py:479] Algo floyd_warshall step 7632 current loss 0.204005, current_train_items 244256.\n",
            "I0314 03:11:25.175323 138313941204992 run.py:479] Algo floyd_warshall step 7633 current loss 0.399548, current_train_items 244288.\n",
            "I0314 03:11:25.589116 138313941204992 run.py:479] Algo floyd_warshall step 7634 current loss 0.494786, current_train_items 244320.\n",
            "I0314 03:11:25.616618 138313941204992 run.py:479] Algo floyd_warshall step 7635 current loss 0.014069, current_train_items 244352.\n",
            "I0314 03:11:25.661995 138313941204992 run.py:479] Algo floyd_warshall step 7636 current loss 0.068315, current_train_items 244384.\n",
            "I0314 03:11:25.802862 138313941204992 run.py:479] Algo floyd_warshall step 7637 current loss 0.160673, current_train_items 244416.\n",
            "I0314 03:11:26.033379 138313941204992 run.py:479] Algo floyd_warshall step 7638 current loss 0.305057, current_train_items 244448.\n",
            "I0314 03:11:26.439670 138313941204992 run.py:479] Algo floyd_warshall step 7639 current loss 0.440044, current_train_items 244480.\n",
            "I0314 03:11:26.463099 138313941204992 run.py:479] Algo floyd_warshall step 7640 current loss 0.023835, current_train_items 244512.\n",
            "I0314 03:11:26.507121 138313941204992 run.py:479] Algo floyd_warshall step 7641 current loss 0.041556, current_train_items 244544.\n",
            "I0314 03:11:26.634730 138313941204992 run.py:479] Algo floyd_warshall step 7642 current loss 0.244985, current_train_items 244576.\n",
            "I0314 03:11:26.851245 138313941204992 run.py:479] Algo floyd_warshall step 7643 current loss 0.422588, current_train_items 244608.\n",
            "I0314 03:11:27.261360 138313941204992 run.py:479] Algo floyd_warshall step 7644 current loss 0.538491, current_train_items 244640.\n",
            "I0314 03:11:27.285414 138313941204992 run.py:479] Algo floyd_warshall step 7645 current loss 0.012449, current_train_items 244672.\n",
            "I0314 03:11:27.330138 138313941204992 run.py:479] Algo floyd_warshall step 7646 current loss 0.132000, current_train_items 244704.\n",
            "I0314 03:11:27.459829 138313941204992 run.py:479] Algo floyd_warshall step 7647 current loss 0.216298, current_train_items 244736.\n",
            "I0314 03:11:27.677467 138313941204992 run.py:479] Algo floyd_warshall step 7648 current loss 0.295991, current_train_items 244768.\n",
            "I0314 03:11:28.108243 138313941204992 run.py:479] Algo floyd_warshall step 7649 current loss 0.628487, current_train_items 244800.\n",
            "I0314 03:11:28.132980 138313941204992 run.py:479] Algo floyd_warshall step 7650 current loss 0.011470, current_train_items 244832.\n",
            "I0314 03:11:28.226530 138313941204992 run.py:499] (val) algo floyd_warshall step 7650: {'Pi': 0.8902587890625, 'score': 0.8902587890625, 'examples_seen': 244832, 'step': 7650, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:11:28.226762 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.921, current avg val score is 0.890, val scores are: floyd_warshall: 0.890\n",
            "I0314 03:11:28.277478 138313941204992 run.py:479] Algo floyd_warshall step 7651 current loss 0.039129, current_train_items 244864.\n",
            "I0314 03:11:28.413083 138313941204992 run.py:479] Algo floyd_warshall step 7652 current loss 0.267843, current_train_items 244896.\n",
            "I0314 03:11:28.631061 138313941204992 run.py:479] Algo floyd_warshall step 7653 current loss 0.313565, current_train_items 244928.\n",
            "I0314 03:11:29.032207 138313941204992 run.py:479] Algo floyd_warshall step 7654 current loss 0.557824, current_train_items 244960.\n",
            "I0314 03:11:29.058646 138313941204992 run.py:479] Algo floyd_warshall step 7655 current loss 0.013852, current_train_items 244992.\n",
            "I0314 03:11:29.103440 138313941204992 run.py:479] Algo floyd_warshall step 7656 current loss 0.050323, current_train_items 245024.\n",
            "I0314 03:11:29.228906 138313941204992 run.py:479] Algo floyd_warshall step 7657 current loss 0.180196, current_train_items 245056.\n",
            "I0314 03:11:29.452537 138313941204992 run.py:479] Algo floyd_warshall step 7658 current loss 0.275677, current_train_items 245088.\n",
            "I0314 03:11:29.853816 138313941204992 run.py:479] Algo floyd_warshall step 7659 current loss 0.467332, current_train_items 245120.\n",
            "I0314 03:11:29.876573 138313941204992 run.py:479] Algo floyd_warshall step 7660 current loss 0.011182, current_train_items 245152.\n",
            "I0314 03:11:29.919955 138313941204992 run.py:479] Algo floyd_warshall step 7661 current loss 0.130402, current_train_items 245184.\n",
            "I0314 03:11:30.051265 138313941204992 run.py:479] Algo floyd_warshall step 7662 current loss 0.253315, current_train_items 245216.\n",
            "I0314 03:11:30.272491 138313941204992 run.py:479] Algo floyd_warshall step 7663 current loss 0.275061, current_train_items 245248.\n",
            "I0314 03:11:30.685465 138313941204992 run.py:479] Algo floyd_warshall step 7664 current loss 0.830349, current_train_items 245280.\n",
            "I0314 03:11:30.708826 138313941204992 run.py:479] Algo floyd_warshall step 7665 current loss 0.032531, current_train_items 245312.\n",
            "I0314 03:11:30.754045 138313941204992 run.py:479] Algo floyd_warshall step 7666 current loss 0.046111, current_train_items 245344.\n",
            "I0314 03:11:30.882141 138313941204992 run.py:479] Algo floyd_warshall step 7667 current loss 0.108112, current_train_items 245376.\n",
            "I0314 03:11:31.098666 138313941204992 run.py:479] Algo floyd_warshall step 7668 current loss 0.275083, current_train_items 245408.\n",
            "I0314 03:11:31.581147 138313941204992 run.py:479] Algo floyd_warshall step 7669 current loss 0.508223, current_train_items 245440.\n",
            "I0314 03:11:31.622797 138313941204992 run.py:479] Algo floyd_warshall step 7670 current loss 0.019054, current_train_items 245472.\n",
            "I0314 03:11:31.682257 138313941204992 run.py:479] Algo floyd_warshall step 7671 current loss 0.042152, current_train_items 245504.\n",
            "I0314 03:11:31.846343 138313941204992 run.py:479] Algo floyd_warshall step 7672 current loss 0.200133, current_train_items 245536.\n",
            "I0314 03:11:32.113335 138313941204992 run.py:479] Algo floyd_warshall step 7673 current loss 0.285272, current_train_items 245568.\n",
            "I0314 03:11:32.593472 138313941204992 run.py:479] Algo floyd_warshall step 7674 current loss 0.421847, current_train_items 245600.\n",
            "I0314 03:11:32.628121 138313941204992 run.py:479] Algo floyd_warshall step 7675 current loss 0.016686, current_train_items 245632.\n",
            "I0314 03:11:32.686158 138313941204992 run.py:479] Algo floyd_warshall step 7676 current loss 0.052432, current_train_items 245664.\n",
            "I0314 03:11:32.840450 138313941204992 run.py:479] Algo floyd_warshall step 7677 current loss 0.199914, current_train_items 245696.\n",
            "I0314 03:11:33.109868 138313941204992 run.py:479] Algo floyd_warshall step 7678 current loss 0.322095, current_train_items 245728.\n",
            "I0314 03:11:33.614598 138313941204992 run.py:479] Algo floyd_warshall step 7679 current loss 0.654245, current_train_items 245760.\n",
            "I0314 03:11:33.647503 138313941204992 run.py:479] Algo floyd_warshall step 7680 current loss 0.016027, current_train_items 245792.\n",
            "I0314 03:11:33.707153 138313941204992 run.py:479] Algo floyd_warshall step 7681 current loss 0.067287, current_train_items 245824.\n",
            "I0314 03:11:33.870727 138313941204992 run.py:479] Algo floyd_warshall step 7682 current loss 0.181388, current_train_items 245856.\n",
            "I0314 03:11:34.133465 138313941204992 run.py:479] Algo floyd_warshall step 7683 current loss 0.329795, current_train_items 245888.\n",
            "I0314 03:11:34.586986 138313941204992 run.py:479] Algo floyd_warshall step 7684 current loss 0.628551, current_train_items 245920.\n",
            "I0314 03:11:34.609964 138313941204992 run.py:479] Algo floyd_warshall step 7685 current loss 0.025136, current_train_items 245952.\n",
            "I0314 03:11:34.654556 138313941204992 run.py:479] Algo floyd_warshall step 7686 current loss 0.033660, current_train_items 245984.\n",
            "I0314 03:11:34.783231 138313941204992 run.py:479] Algo floyd_warshall step 7687 current loss 0.206629, current_train_items 246016.\n",
            "I0314 03:11:34.998563 138313941204992 run.py:479] Algo floyd_warshall step 7688 current loss 0.286743, current_train_items 246048.\n",
            "I0314 03:11:35.432835 138313941204992 run.py:479] Algo floyd_warshall step 7689 current loss 0.734005, current_train_items 246080.\n",
            "I0314 03:11:35.457772 138313941204992 run.py:479] Algo floyd_warshall step 7690 current loss 0.016794, current_train_items 246112.\n",
            "I0314 03:11:35.502000 138313941204992 run.py:479] Algo floyd_warshall step 7691 current loss 0.083422, current_train_items 246144.\n",
            "I0314 03:11:35.631966 138313941204992 run.py:479] Algo floyd_warshall step 7692 current loss 0.251189, current_train_items 246176.\n",
            "I0314 03:11:35.853017 138313941204992 run.py:479] Algo floyd_warshall step 7693 current loss 0.316791, current_train_items 246208.\n",
            "I0314 03:11:36.262360 138313941204992 run.py:479] Algo floyd_warshall step 7694 current loss 0.549983, current_train_items 246240.\n",
            "I0314 03:11:36.286030 138313941204992 run.py:479] Algo floyd_warshall step 7695 current loss 0.019847, current_train_items 246272.\n",
            "I0314 03:11:36.331194 138313941204992 run.py:479] Algo floyd_warshall step 7696 current loss 0.072783, current_train_items 246304.\n",
            "I0314 03:11:36.464453 138313941204992 run.py:479] Algo floyd_warshall step 7697 current loss 0.237850, current_train_items 246336.\n",
            "I0314 03:11:36.687578 138313941204992 run.py:479] Algo floyd_warshall step 7698 current loss 0.298512, current_train_items 246368.\n",
            "I0314 03:11:37.121767 138313941204992 run.py:479] Algo floyd_warshall step 7699 current loss 0.677371, current_train_items 246400.\n",
            "I0314 03:11:37.146539 138313941204992 run.py:479] Algo floyd_warshall step 7700 current loss 0.023185, current_train_items 246432.\n",
            "I0314 03:11:37.233669 138313941204992 run.py:499] (val) algo floyd_warshall step 7700: {'Pi': 0.896728515625, 'score': 0.896728515625, 'examples_seen': 246432, 'step': 7700, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:11:37.233885 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.921, current avg val score is 0.897, val scores are: floyd_warshall: 0.897\n",
            "I0314 03:11:37.281558 138313941204992 run.py:479] Algo floyd_warshall step 7701 current loss 0.119504, current_train_items 246464.\n",
            "I0314 03:11:37.413312 138313941204992 run.py:479] Algo floyd_warshall step 7702 current loss 0.256553, current_train_items 246496.\n",
            "I0314 03:11:37.628324 138313941204992 run.py:479] Algo floyd_warshall step 7703 current loss 0.272281, current_train_items 246528.\n",
            "I0314 03:11:38.050808 138313941204992 run.py:479] Algo floyd_warshall step 7704 current loss 0.584923, current_train_items 246560.\n",
            "I0314 03:11:38.075132 138313941204992 run.py:479] Algo floyd_warshall step 7705 current loss 0.068910, current_train_items 246592.\n",
            "I0314 03:11:38.130904 138313941204992 run.py:479] Algo floyd_warshall step 7706 current loss 0.041747, current_train_items 246624.\n",
            "I0314 03:11:38.259645 138313941204992 run.py:479] Algo floyd_warshall step 7707 current loss 0.205307, current_train_items 246656.\n",
            "I0314 03:11:38.486862 138313941204992 run.py:479] Algo floyd_warshall step 7708 current loss 0.346322, current_train_items 246688.\n",
            "I0314 03:11:38.906922 138313941204992 run.py:479] Algo floyd_warshall step 7709 current loss 0.551222, current_train_items 246720.\n",
            "I0314 03:11:38.930623 138313941204992 run.py:479] Algo floyd_warshall step 7710 current loss 0.066445, current_train_items 246752.\n",
            "I0314 03:11:38.976762 138313941204992 run.py:479] Algo floyd_warshall step 7711 current loss 0.056413, current_train_items 246784.\n",
            "I0314 03:11:39.110627 138313941204992 run.py:479] Algo floyd_warshall step 7712 current loss 0.211940, current_train_items 246816.\n",
            "I0314 03:11:39.333285 138313941204992 run.py:479] Algo floyd_warshall step 7713 current loss 0.319808, current_train_items 246848.\n",
            "I0314 03:11:39.749676 138313941204992 run.py:479] Algo floyd_warshall step 7714 current loss 0.529633, current_train_items 246880.\n",
            "I0314 03:11:39.774290 138313941204992 run.py:479] Algo floyd_warshall step 7715 current loss 0.023682, current_train_items 246912.\n",
            "I0314 03:11:39.821593 138313941204992 run.py:479] Algo floyd_warshall step 7716 current loss 0.091373, current_train_items 246944.\n",
            "I0314 03:11:39.952653 138313941204992 run.py:479] Algo floyd_warshall step 7717 current loss 0.141346, current_train_items 246976.\n",
            "I0314 03:11:40.169874 138313941204992 run.py:479] Algo floyd_warshall step 7718 current loss 0.281454, current_train_items 247008.\n",
            "I0314 03:11:40.598242 138313941204992 run.py:479] Algo floyd_warshall step 7719 current loss 0.559961, current_train_items 247040.\n",
            "I0314 03:11:40.627392 138313941204992 run.py:479] Algo floyd_warshall step 7720 current loss 0.017876, current_train_items 247072.\n",
            "I0314 03:11:40.672667 138313941204992 run.py:479] Algo floyd_warshall step 7721 current loss 0.112034, current_train_items 247104.\n",
            "I0314 03:11:40.803103 138313941204992 run.py:479] Algo floyd_warshall step 7722 current loss 0.193388, current_train_items 247136.\n",
            "I0314 03:11:41.027948 138313941204992 run.py:479] Algo floyd_warshall step 7723 current loss 0.268387, current_train_items 247168.\n",
            "I0314 03:11:41.439233 138313941204992 run.py:479] Algo floyd_warshall step 7724 current loss 0.462460, current_train_items 247200.\n",
            "I0314 03:11:41.463193 138313941204992 run.py:479] Algo floyd_warshall step 7725 current loss 0.006407, current_train_items 247232.\n",
            "I0314 03:11:41.510576 138313941204992 run.py:479] Algo floyd_warshall step 7726 current loss 0.035661, current_train_items 247264.\n",
            "I0314 03:11:41.639240 138313941204992 run.py:479] Algo floyd_warshall step 7727 current loss 0.183281, current_train_items 247296.\n",
            "I0314 03:11:41.852739 138313941204992 run.py:479] Algo floyd_warshall step 7728 current loss 0.279782, current_train_items 247328.\n",
            "I0314 03:11:42.267433 138313941204992 run.py:479] Algo floyd_warshall step 7729 current loss 0.606210, current_train_items 247360.\n",
            "I0314 03:11:42.293267 138313941204992 run.py:479] Algo floyd_warshall step 7730 current loss 0.008121, current_train_items 247392.\n",
            "I0314 03:11:42.343344 138313941204992 run.py:479] Algo floyd_warshall step 7731 current loss 0.048256, current_train_items 247424.\n",
            "I0314 03:11:42.484298 138313941204992 run.py:479] Algo floyd_warshall step 7732 current loss 0.196740, current_train_items 247456.\n",
            "I0314 03:11:42.711206 138313941204992 run.py:479] Algo floyd_warshall step 7733 current loss 0.338487, current_train_items 247488.\n",
            "I0314 03:11:43.130316 138313941204992 run.py:479] Algo floyd_warshall step 7734 current loss 0.511513, current_train_items 247520.\n",
            "I0314 03:11:43.153748 138313941204992 run.py:479] Algo floyd_warshall step 7735 current loss 0.015756, current_train_items 247552.\n",
            "I0314 03:11:43.197702 138313941204992 run.py:479] Algo floyd_warshall step 7736 current loss 0.039102, current_train_items 247584.\n",
            "I0314 03:11:43.338401 138313941204992 run.py:479] Algo floyd_warshall step 7737 current loss 0.164644, current_train_items 247616.\n",
            "I0314 03:11:43.557629 138313941204992 run.py:479] Algo floyd_warshall step 7738 current loss 0.386383, current_train_items 247648.\n",
            "I0314 03:11:43.960442 138313941204992 run.py:479] Algo floyd_warshall step 7739 current loss 0.503887, current_train_items 247680.\n",
            "I0314 03:11:43.984303 138313941204992 run.py:479] Algo floyd_warshall step 7740 current loss 0.200110, current_train_items 247712.\n",
            "I0314 03:11:44.030393 138313941204992 run.py:479] Algo floyd_warshall step 7741 current loss 0.115791, current_train_items 247744.\n",
            "I0314 03:11:44.162590 138313941204992 run.py:479] Algo floyd_warshall step 7742 current loss 0.238452, current_train_items 247776.\n",
            "I0314 03:11:44.379162 138313941204992 run.py:479] Algo floyd_warshall step 7743 current loss 0.355307, current_train_items 247808.\n",
            "I0314 03:11:44.880067 138313941204992 run.py:479] Algo floyd_warshall step 7744 current loss 0.679276, current_train_items 247840.\n",
            "I0314 03:11:44.913663 138313941204992 run.py:479] Algo floyd_warshall step 7745 current loss 0.006010, current_train_items 247872.\n",
            "I0314 03:11:44.971316 138313941204992 run.py:479] Algo floyd_warshall step 7746 current loss 0.053000, current_train_items 247904.\n",
            "I0314 03:11:45.135454 138313941204992 run.py:479] Algo floyd_warshall step 7747 current loss 0.229688, current_train_items 247936.\n",
            "I0314 03:11:45.397904 138313941204992 run.py:479] Algo floyd_warshall step 7748 current loss 0.207909, current_train_items 247968.\n",
            "I0314 03:11:45.898654 138313941204992 run.py:479] Algo floyd_warshall step 7749 current loss 0.487760, current_train_items 248000.\n",
            "I0314 03:11:45.935439 138313941204992 run.py:479] Algo floyd_warshall step 7750 current loss 0.033080, current_train_items 248032.\n",
            "I0314 03:11:46.054567 138313941204992 run.py:499] (val) algo floyd_warshall step 7750: {'Pi': 0.88934326171875, 'score': 0.88934326171875, 'examples_seen': 248032, 'step': 7750, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:11:46.054971 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.921, current avg val score is 0.889, val scores are: floyd_warshall: 0.889\n",
            "I0314 03:11:46.113327 138313941204992 run.py:479] Algo floyd_warshall step 7751 current loss 0.076694, current_train_items 248064.\n",
            "I0314 03:11:46.288412 138313941204992 run.py:479] Algo floyd_warshall step 7752 current loss 0.273376, current_train_items 248096.\n",
            "I0314 03:11:46.576277 138313941204992 run.py:479] Algo floyd_warshall step 7753 current loss 0.381488, current_train_items 248128.\n",
            "I0314 03:11:47.081764 138313941204992 run.py:479] Algo floyd_warshall step 7754 current loss 0.529132, current_train_items 248160.\n",
            "I0314 03:11:47.123568 138313941204992 run.py:479] Algo floyd_warshall step 7755 current loss 0.017041, current_train_items 248192.\n",
            "I0314 03:11:47.182980 138313941204992 run.py:479] Algo floyd_warshall step 7756 current loss 0.046010, current_train_items 248224.\n",
            "I0314 03:11:47.337582 138313941204992 run.py:479] Algo floyd_warshall step 7757 current loss 0.157436, current_train_items 248256.\n",
            "I0314 03:11:47.559981 138313941204992 run.py:479] Algo floyd_warshall step 7758 current loss 0.279541, current_train_items 248288.\n",
            "I0314 03:11:47.969717 138313941204992 run.py:479] Algo floyd_warshall step 7759 current loss 0.473408, current_train_items 248320.\n",
            "I0314 03:11:47.993000 138313941204992 run.py:479] Algo floyd_warshall step 7760 current loss 0.023111, current_train_items 248352.\n",
            "I0314 03:11:48.038647 138313941204992 run.py:479] Algo floyd_warshall step 7761 current loss 0.112459, current_train_items 248384.\n",
            "I0314 03:11:48.167076 138313941204992 run.py:479] Algo floyd_warshall step 7762 current loss 0.145061, current_train_items 248416.\n",
            "I0314 03:11:48.382793 138313941204992 run.py:479] Algo floyd_warshall step 7763 current loss 0.316614, current_train_items 248448.\n",
            "I0314 03:11:48.818534 138313941204992 run.py:479] Algo floyd_warshall step 7764 current loss 0.573206, current_train_items 248480.\n",
            "I0314 03:11:48.842846 138313941204992 run.py:479] Algo floyd_warshall step 7765 current loss 0.018065, current_train_items 248512.\n",
            "I0314 03:11:48.887093 138313941204992 run.py:479] Algo floyd_warshall step 7766 current loss 0.043051, current_train_items 248544.\n",
            "I0314 03:11:49.018844 138313941204992 run.py:479] Algo floyd_warshall step 7767 current loss 0.218504, current_train_items 248576.\n",
            "I0314 03:11:49.238629 138313941204992 run.py:479] Algo floyd_warshall step 7768 current loss 0.269505, current_train_items 248608.\n",
            "I0314 03:11:49.653017 138313941204992 run.py:479] Algo floyd_warshall step 7769 current loss 0.493399, current_train_items 248640.\n",
            "I0314 03:11:49.676243 138313941204992 run.py:479] Algo floyd_warshall step 7770 current loss 0.019885, current_train_items 248672.\n",
            "I0314 03:11:49.721443 138313941204992 run.py:479] Algo floyd_warshall step 7771 current loss 0.044766, current_train_items 248704.\n",
            "I0314 03:11:49.853295 138313941204992 run.py:479] Algo floyd_warshall step 7772 current loss 0.170996, current_train_items 248736.\n",
            "I0314 03:11:50.077472 138313941204992 run.py:479] Algo floyd_warshall step 7773 current loss 0.290843, current_train_items 248768.\n",
            "I0314 03:11:50.494716 138313941204992 run.py:479] Algo floyd_warshall step 7774 current loss 0.581366, current_train_items 248800.\n",
            "I0314 03:11:50.530369 138313941204992 run.py:479] Algo floyd_warshall step 7775 current loss 0.011223, current_train_items 248832.\n",
            "I0314 03:11:50.574005 138313941204992 run.py:479] Algo floyd_warshall step 7776 current loss 0.066434, current_train_items 248864.\n",
            "I0314 03:11:50.703851 138313941204992 run.py:479] Algo floyd_warshall step 7777 current loss 0.174706, current_train_items 248896.\n",
            "I0314 03:11:50.926929 138313941204992 run.py:479] Algo floyd_warshall step 7778 current loss 0.351498, current_train_items 248928.\n",
            "I0314 03:11:51.334599 138313941204992 run.py:479] Algo floyd_warshall step 7779 current loss 0.515331, current_train_items 248960.\n",
            "I0314 03:11:51.358263 138313941204992 run.py:479] Algo floyd_warshall step 7780 current loss 0.012724, current_train_items 248992.\n",
            "I0314 03:11:51.404320 138313941204992 run.py:479] Algo floyd_warshall step 7781 current loss 0.055207, current_train_items 249024.\n",
            "I0314 03:11:51.536038 138313941204992 run.py:479] Algo floyd_warshall step 7782 current loss 0.221332, current_train_items 249056.\n",
            "I0314 03:11:51.765539 138313941204992 run.py:479] Algo floyd_warshall step 7783 current loss 0.323852, current_train_items 249088.\n",
            "I0314 03:11:52.185607 138313941204992 run.py:479] Algo floyd_warshall step 7784 current loss 0.616555, current_train_items 249120.\n",
            "I0314 03:11:52.209741 138313941204992 run.py:479] Algo floyd_warshall step 7785 current loss 0.031589, current_train_items 249152.\n",
            "I0314 03:11:52.257422 138313941204992 run.py:479] Algo floyd_warshall step 7786 current loss 0.030998, current_train_items 249184.\n",
            "I0314 03:11:52.392892 138313941204992 run.py:479] Algo floyd_warshall step 7787 current loss 0.227586, current_train_items 249216.\n",
            "I0314 03:11:52.610052 138313941204992 run.py:479] Algo floyd_warshall step 7788 current loss 0.262068, current_train_items 249248.\n",
            "I0314 03:11:53.012917 138313941204992 run.py:479] Algo floyd_warshall step 7789 current loss 0.439694, current_train_items 249280.\n",
            "I0314 03:11:53.036831 138313941204992 run.py:479] Algo floyd_warshall step 7790 current loss 0.017681, current_train_items 249312.\n",
            "I0314 03:11:53.081898 138313941204992 run.py:479] Algo floyd_warshall step 7791 current loss 0.034598, current_train_items 249344.\n",
            "I0314 03:11:53.216861 138313941204992 run.py:479] Algo floyd_warshall step 7792 current loss 0.272781, current_train_items 249376.\n",
            "I0314 03:11:53.432757 138313941204992 run.py:479] Algo floyd_warshall step 7793 current loss 0.345780, current_train_items 249408.\n",
            "I0314 03:11:53.857562 138313941204992 run.py:479] Algo floyd_warshall step 7794 current loss 0.796746, current_train_items 249440.\n",
            "I0314 03:11:53.881654 138313941204992 run.py:479] Algo floyd_warshall step 7795 current loss 0.027400, current_train_items 249472.\n",
            "I0314 03:11:53.927160 138313941204992 run.py:479] Algo floyd_warshall step 7796 current loss 0.054815, current_train_items 249504.\n",
            "I0314 03:11:54.057621 138313941204992 run.py:479] Algo floyd_warshall step 7797 current loss 0.174817, current_train_items 249536.\n",
            "I0314 03:11:54.277599 138313941204992 run.py:479] Algo floyd_warshall step 7798 current loss 0.257775, current_train_items 249568.\n",
            "I0314 03:11:54.700549 138313941204992 run.py:479] Algo floyd_warshall step 7799 current loss 0.544206, current_train_items 249600.\n",
            "I0314 03:11:54.724496 138313941204992 run.py:479] Algo floyd_warshall step 7800 current loss 0.016795, current_train_items 249632.\n",
            "I0314 03:11:54.811770 138313941204992 run.py:499] (val) algo floyd_warshall step 7800: {'Pi': 0.915771484375, 'score': 0.915771484375, 'examples_seen': 249632, 'step': 7800, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:11:54.812029 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.921, current avg val score is 0.916, val scores are: floyd_warshall: 0.916\n",
            "I0314 03:11:54.860735 138313941204992 run.py:479] Algo floyd_warshall step 7801 current loss 0.039965, current_train_items 249664.\n",
            "I0314 03:11:54.993192 138313941204992 run.py:479] Algo floyd_warshall step 7802 current loss 0.188496, current_train_items 249696.\n",
            "I0314 03:11:55.222871 138313941204992 run.py:479] Algo floyd_warshall step 7803 current loss 0.359467, current_train_items 249728.\n",
            "I0314 03:11:55.640789 138313941204992 run.py:479] Algo floyd_warshall step 7804 current loss 0.611436, current_train_items 249760.\n",
            "I0314 03:11:55.668839 138313941204992 run.py:479] Algo floyd_warshall step 7805 current loss 0.019858, current_train_items 249792.\n",
            "I0314 03:11:55.714315 138313941204992 run.py:479] Algo floyd_warshall step 7806 current loss 0.067351, current_train_items 249824.\n",
            "I0314 03:11:55.847677 138313941204992 run.py:479] Algo floyd_warshall step 7807 current loss 0.241394, current_train_items 249856.\n",
            "I0314 03:11:56.068983 138313941204992 run.py:479] Algo floyd_warshall step 7808 current loss 0.335778, current_train_items 249888.\n",
            "I0314 03:11:56.474375 138313941204992 run.py:479] Algo floyd_warshall step 7809 current loss 0.568416, current_train_items 249920.\n",
            "I0314 03:11:56.497435 138313941204992 run.py:479] Algo floyd_warshall step 7810 current loss 0.024937, current_train_items 249952.\n",
            "I0314 03:11:56.542446 138313941204992 run.py:479] Algo floyd_warshall step 7811 current loss 0.072599, current_train_items 249984.\n",
            "I0314 03:11:56.673544 138313941204992 run.py:479] Algo floyd_warshall step 7812 current loss 0.151694, current_train_items 250016.\n",
            "I0314 03:11:56.899336 138313941204992 run.py:479] Algo floyd_warshall step 7813 current loss 0.289990, current_train_items 250048.\n",
            "I0314 03:11:57.302872 138313941204992 run.py:479] Algo floyd_warshall step 7814 current loss 0.419890, current_train_items 250080.\n",
            "I0314 03:11:57.340747 138313941204992 run.py:479] Algo floyd_warshall step 7815 current loss 0.024329, current_train_items 250112.\n",
            "I0314 03:11:57.399924 138313941204992 run.py:479] Algo floyd_warshall step 7816 current loss 0.062367, current_train_items 250144.\n",
            "I0314 03:11:57.559104 138313941204992 run.py:479] Algo floyd_warshall step 7817 current loss 0.171293, current_train_items 250176.\n",
            "I0314 03:11:57.838477 138313941204992 run.py:479] Algo floyd_warshall step 7818 current loss 0.345835, current_train_items 250208.\n",
            "I0314 03:11:58.323205 138313941204992 run.py:479] Algo floyd_warshall step 7819 current loss 0.486016, current_train_items 250240.\n",
            "I0314 03:11:58.362178 138313941204992 run.py:479] Algo floyd_warshall step 7820 current loss 0.014548, current_train_items 250272.\n",
            "I0314 03:11:58.427469 138313941204992 run.py:479] Algo floyd_warshall step 7821 current loss 0.071335, current_train_items 250304.\n",
            "I0314 03:11:58.588478 138313941204992 run.py:479] Algo floyd_warshall step 7822 current loss 0.171510, current_train_items 250336.\n",
            "I0314 03:11:58.850440 138313941204992 run.py:479] Algo floyd_warshall step 7823 current loss 0.266116, current_train_items 250368.\n",
            "I0314 03:11:59.350567 138313941204992 run.py:479] Algo floyd_warshall step 7824 current loss 0.531694, current_train_items 250400.\n",
            "I0314 03:11:59.383035 138313941204992 run.py:479] Algo floyd_warshall step 7825 current loss 0.007974, current_train_items 250432.\n",
            "I0314 03:11:59.441160 138313941204992 run.py:479] Algo floyd_warshall step 7826 current loss 0.045632, current_train_items 250464.\n",
            "I0314 03:11:59.594631 138313941204992 run.py:479] Algo floyd_warshall step 7827 current loss 0.140146, current_train_items 250496.\n",
            "I0314 03:11:59.864493 138313941204992 run.py:479] Algo floyd_warshall step 7828 current loss 0.301465, current_train_items 250528.\n",
            "I0314 03:12:00.342587 138313941204992 run.py:479] Algo floyd_warshall step 7829 current loss 0.388671, current_train_items 250560.\n",
            "I0314 03:12:00.379790 138313941204992 run.py:479] Algo floyd_warshall step 7830 current loss 0.013412, current_train_items 250592.\n",
            "I0314 03:12:00.429301 138313941204992 run.py:479] Algo floyd_warshall step 7831 current loss 0.022404, current_train_items 250624.\n",
            "I0314 03:12:00.562082 138313941204992 run.py:479] Algo floyd_warshall step 7832 current loss 0.227356, current_train_items 250656.\n",
            "I0314 03:12:00.787990 138313941204992 run.py:479] Algo floyd_warshall step 7833 current loss 0.315241, current_train_items 250688.\n",
            "I0314 03:12:01.216076 138313941204992 run.py:479] Algo floyd_warshall step 7834 current loss 0.602597, current_train_items 250720.\n",
            "I0314 03:12:01.239551 138313941204992 run.py:479] Algo floyd_warshall step 7835 current loss 0.013782, current_train_items 250752.\n",
            "I0314 03:12:01.283459 138313941204992 run.py:479] Algo floyd_warshall step 7836 current loss 0.052756, current_train_items 250784.\n",
            "I0314 03:12:01.419920 138313941204992 run.py:479] Algo floyd_warshall step 7837 current loss 0.193427, current_train_items 250816.\n",
            "I0314 03:12:01.637048 138313941204992 run.py:479] Algo floyd_warshall step 7838 current loss 0.291165, current_train_items 250848.\n",
            "I0314 03:12:02.046100 138313941204992 run.py:479] Algo floyd_warshall step 7839 current loss 0.465246, current_train_items 250880.\n",
            "I0314 03:12:02.071729 138313941204992 run.py:479] Algo floyd_warshall step 7840 current loss 0.035428, current_train_items 250912.\n",
            "I0314 03:12:02.120510 138313941204992 run.py:479] Algo floyd_warshall step 7841 current loss 0.049353, current_train_items 250944.\n",
            "I0314 03:12:02.254549 138313941204992 run.py:479] Algo floyd_warshall step 7842 current loss 0.172830, current_train_items 250976.\n",
            "I0314 03:12:02.479775 138313941204992 run.py:479] Algo floyd_warshall step 7843 current loss 0.310698, current_train_items 251008.\n",
            "I0314 03:12:02.893237 138313941204992 run.py:479] Algo floyd_warshall step 7844 current loss 0.467126, current_train_items 251040.\n",
            "I0314 03:12:02.920081 138313941204992 run.py:479] Algo floyd_warshall step 7845 current loss 0.023786, current_train_items 251072.\n",
            "I0314 03:12:02.963875 138313941204992 run.py:479] Algo floyd_warshall step 7846 current loss 0.047050, current_train_items 251104.\n",
            "I0314 03:12:03.094604 138313941204992 run.py:479] Algo floyd_warshall step 7847 current loss 0.138203, current_train_items 251136.\n",
            "I0314 03:12:03.323658 138313941204992 run.py:479] Algo floyd_warshall step 7848 current loss 0.271344, current_train_items 251168.\n",
            "I0314 03:12:03.744219 138313941204992 run.py:479] Algo floyd_warshall step 7849 current loss 0.456148, current_train_items 251200.\n",
            "I0314 03:12:03.769592 138313941204992 run.py:479] Algo floyd_warshall step 7850 current loss 0.056825, current_train_items 251232.\n",
            "I0314 03:12:03.859313 138313941204992 run.py:499] (val) algo floyd_warshall step 7850: {'Pi': 0.8992919921875, 'score': 0.8992919921875, 'examples_seen': 251232, 'step': 7850, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:12:03.859594 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.921, current avg val score is 0.899, val scores are: floyd_warshall: 0.899\n",
            "I0314 03:12:03.912184 138313941204992 run.py:479] Algo floyd_warshall step 7851 current loss 0.050032, current_train_items 251264.\n",
            "I0314 03:12:04.047626 138313941204992 run.py:479] Algo floyd_warshall step 7852 current loss 0.280850, current_train_items 251296.\n",
            "I0314 03:12:04.266908 138313941204992 run.py:479] Algo floyd_warshall step 7853 current loss 0.348661, current_train_items 251328.\n",
            "I0314 03:12:04.693262 138313941204992 run.py:479] Algo floyd_warshall step 7854 current loss 0.525641, current_train_items 251360.\n",
            "I0314 03:12:04.718524 138313941204992 run.py:479] Algo floyd_warshall step 7855 current loss 0.014939, current_train_items 251392.\n",
            "I0314 03:12:04.766466 138313941204992 run.py:479] Algo floyd_warshall step 7856 current loss 0.056703, current_train_items 251424.\n",
            "I0314 03:12:04.898641 138313941204992 run.py:479] Algo floyd_warshall step 7857 current loss 0.201537, current_train_items 251456.\n",
            "I0314 03:12:05.133566 138313941204992 run.py:479] Algo floyd_warshall step 7858 current loss 0.306987, current_train_items 251488.\n",
            "I0314 03:12:05.541063 138313941204992 run.py:479] Algo floyd_warshall step 7859 current loss 0.487707, current_train_items 251520.\n",
            "I0314 03:12:05.564220 138313941204992 run.py:479] Algo floyd_warshall step 7860 current loss 0.020961, current_train_items 251552.\n",
            "I0314 03:12:05.612435 138313941204992 run.py:479] Algo floyd_warshall step 7861 current loss 0.030460, current_train_items 251584.\n",
            "I0314 03:12:05.740250 138313941204992 run.py:479] Algo floyd_warshall step 7862 current loss 0.163711, current_train_items 251616.\n",
            "I0314 03:12:05.958671 138313941204992 run.py:479] Algo floyd_warshall step 7863 current loss 0.340952, current_train_items 251648.\n",
            "I0314 03:12:06.373480 138313941204992 run.py:479] Algo floyd_warshall step 7864 current loss 0.541675, current_train_items 251680.\n",
            "I0314 03:12:06.397306 138313941204992 run.py:479] Algo floyd_warshall step 7865 current loss 0.024357, current_train_items 251712.\n",
            "I0314 03:12:06.444699 138313941204992 run.py:479] Algo floyd_warshall step 7866 current loss 0.053043, current_train_items 251744.\n",
            "I0314 03:12:06.575959 138313941204992 run.py:479] Algo floyd_warshall step 7867 current loss 0.185979, current_train_items 251776.\n",
            "I0314 03:12:06.792511 138313941204992 run.py:479] Algo floyd_warshall step 7868 current loss 0.278340, current_train_items 251808.\n",
            "I0314 03:12:07.196866 138313941204992 run.py:479] Algo floyd_warshall step 7869 current loss 0.389628, current_train_items 251840.\n",
            "I0314 03:12:07.221398 138313941204992 run.py:479] Algo floyd_warshall step 7870 current loss 0.019832, current_train_items 251872.\n",
            "I0314 03:12:07.267374 138313941204992 run.py:479] Algo floyd_warshall step 7871 current loss 0.074575, current_train_items 251904.\n",
            "I0314 03:12:07.401448 138313941204992 run.py:479] Algo floyd_warshall step 7872 current loss 0.206806, current_train_items 251936.\n",
            "I0314 03:12:07.624397 138313941204992 run.py:479] Algo floyd_warshall step 7873 current loss 0.275079, current_train_items 251968.\n",
            "I0314 03:12:08.051001 138313941204992 run.py:479] Algo floyd_warshall step 7874 current loss 0.521453, current_train_items 252000.\n",
            "I0314 03:12:08.074847 138313941204992 run.py:479] Algo floyd_warshall step 7875 current loss 0.028781, current_train_items 252032.\n",
            "I0314 03:12:08.121222 138313941204992 run.py:479] Algo floyd_warshall step 7876 current loss 0.063389, current_train_items 252064.\n",
            "I0314 03:12:08.253227 138313941204992 run.py:479] Algo floyd_warshall step 7877 current loss 0.187563, current_train_items 252096.\n",
            "I0314 03:12:08.481821 138313941204992 run.py:479] Algo floyd_warshall step 7878 current loss 0.367083, current_train_items 252128.\n",
            "I0314 03:12:08.893213 138313941204992 run.py:479] Algo floyd_warshall step 7879 current loss 0.512634, current_train_items 252160.\n",
            "I0314 03:12:08.916811 138313941204992 run.py:479] Algo floyd_warshall step 7880 current loss 0.024175, current_train_items 252192.\n",
            "I0314 03:12:08.962591 138313941204992 run.py:479] Algo floyd_warshall step 7881 current loss 0.045615, current_train_items 252224.\n",
            "I0314 03:12:09.095075 138313941204992 run.py:479] Algo floyd_warshall step 7882 current loss 0.194381, current_train_items 252256.\n",
            "I0314 03:12:09.313198 138313941204992 run.py:479] Algo floyd_warshall step 7883 current loss 0.346614, current_train_items 252288.\n",
            "I0314 03:12:09.724742 138313941204992 run.py:479] Algo floyd_warshall step 7884 current loss 0.521391, current_train_items 252320.\n",
            "I0314 03:12:09.748685 138313941204992 run.py:479] Algo floyd_warshall step 7885 current loss 0.015345, current_train_items 252352.\n",
            "I0314 03:12:09.797545 138313941204992 run.py:479] Algo floyd_warshall step 7886 current loss 0.036857, current_train_items 252384.\n",
            "I0314 03:12:09.930666 138313941204992 run.py:479] Algo floyd_warshall step 7887 current loss 0.218628, current_train_items 252416.\n",
            "I0314 03:12:10.159223 138313941204992 run.py:479] Algo floyd_warshall step 7888 current loss 0.325419, current_train_items 252448.\n",
            "I0314 03:12:10.573020 138313941204992 run.py:479] Algo floyd_warshall step 7889 current loss 0.569100, current_train_items 252480.\n",
            "I0314 03:12:10.607072 138313941204992 run.py:479] Algo floyd_warshall step 7890 current loss 0.011897, current_train_items 252512.\n",
            "I0314 03:12:10.669453 138313941204992 run.py:479] Algo floyd_warshall step 7891 current loss 0.097260, current_train_items 252544.\n",
            "I0314 03:12:10.829252 138313941204992 run.py:479] Algo floyd_warshall step 7892 current loss 0.218419, current_train_items 252576.\n",
            "I0314 03:12:11.086775 138313941204992 run.py:479] Algo floyd_warshall step 7893 current loss 0.275149, current_train_items 252608.\n",
            "I0314 03:12:11.606846 138313941204992 run.py:479] Algo floyd_warshall step 7894 current loss 0.552851, current_train_items 252640.\n",
            "I0314 03:12:11.645095 138313941204992 run.py:479] Algo floyd_warshall step 7895 current loss 0.010036, current_train_items 252672.\n",
            "I0314 03:12:11.701190 138313941204992 run.py:479] Algo floyd_warshall step 7896 current loss 0.068030, current_train_items 252704.\n",
            "I0314 03:12:11.860239 138313941204992 run.py:479] Algo floyd_warshall step 7897 current loss 0.205258, current_train_items 252736.\n",
            "I0314 03:12:12.136483 138313941204992 run.py:479] Algo floyd_warshall step 7898 current loss 0.377025, current_train_items 252768.\n",
            "I0314 03:12:12.623286 138313941204992 run.py:479] Algo floyd_warshall step 7899 current loss 0.491750, current_train_items 252800.\n",
            "I0314 03:12:12.657649 138313941204992 run.py:479] Algo floyd_warshall step 7900 current loss 0.002612, current_train_items 252832.\n",
            "I0314 03:12:12.764972 138313941204992 run.py:499] (val) algo floyd_warshall step 7900: {'Pi': 0.8944091796875, 'score': 0.8944091796875, 'examples_seen': 252832, 'step': 7900, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:12:12.765356 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.921, current avg val score is 0.894, val scores are: floyd_warshall: 0.894\n",
            "I0314 03:12:12.831722 138313941204992 run.py:479] Algo floyd_warshall step 7901 current loss 0.062705, current_train_items 252864.\n",
            "I0314 03:12:13.006335 138313941204992 run.py:479] Algo floyd_warshall step 7902 current loss 0.239107, current_train_items 252896.\n",
            "I0314 03:12:13.264107 138313941204992 run.py:479] Algo floyd_warshall step 7903 current loss 0.269608, current_train_items 252928.\n",
            "I0314 03:12:13.776770 138313941204992 run.py:479] Algo floyd_warshall step 7904 current loss 0.486186, current_train_items 252960.\n",
            "I0314 03:12:13.802437 138313941204992 run.py:479] Algo floyd_warshall step 7905 current loss 0.011669, current_train_items 252992.\n",
            "I0314 03:12:13.847987 138313941204992 run.py:479] Algo floyd_warshall step 7906 current loss 0.034250, current_train_items 253024.\n",
            "I0314 03:12:13.980114 138313941204992 run.py:479] Algo floyd_warshall step 7907 current loss 0.232344, current_train_items 253056.\n",
            "I0314 03:12:14.207895 138313941204992 run.py:479] Algo floyd_warshall step 7908 current loss 0.249451, current_train_items 253088.\n",
            "I0314 03:12:14.636756 138313941204992 run.py:479] Algo floyd_warshall step 7909 current loss 0.482001, current_train_items 253120.\n",
            "I0314 03:12:14.660043 138313941204992 run.py:479] Algo floyd_warshall step 7910 current loss 0.024723, current_train_items 253152.\n",
            "I0314 03:12:14.705531 138313941204992 run.py:479] Algo floyd_warshall step 7911 current loss 0.102255, current_train_items 253184.\n",
            "I0314 03:12:14.834055 138313941204992 run.py:479] Algo floyd_warshall step 7912 current loss 0.154911, current_train_items 253216.\n",
            "I0314 03:12:15.048439 138313941204992 run.py:479] Algo floyd_warshall step 7913 current loss 0.264492, current_train_items 253248.\n",
            "I0314 03:12:15.480066 138313941204992 run.py:479] Algo floyd_warshall step 7914 current loss 0.720295, current_train_items 253280.\n",
            "I0314 03:12:15.505322 138313941204992 run.py:479] Algo floyd_warshall step 7915 current loss 0.010505, current_train_items 253312.\n",
            "I0314 03:12:15.551410 138313941204992 run.py:479] Algo floyd_warshall step 7916 current loss 0.059631, current_train_items 253344.\n",
            "I0314 03:12:15.681270 138313941204992 run.py:479] Algo floyd_warshall step 7917 current loss 0.158171, current_train_items 253376.\n",
            "I0314 03:12:15.902286 138313941204992 run.py:479] Algo floyd_warshall step 7918 current loss 0.332851, current_train_items 253408.\n",
            "I0314 03:12:16.338944 138313941204992 run.py:479] Algo floyd_warshall step 7919 current loss 0.574416, current_train_items 253440.\n",
            "I0314 03:12:16.363359 138313941204992 run.py:479] Algo floyd_warshall step 7920 current loss 0.015648, current_train_items 253472.\n",
            "I0314 03:12:16.408138 138313941204992 run.py:479] Algo floyd_warshall step 7921 current loss 0.052522, current_train_items 253504.\n",
            "I0314 03:12:16.536499 138313941204992 run.py:479] Algo floyd_warshall step 7922 current loss 0.120229, current_train_items 253536.\n",
            "I0314 03:12:16.748946 138313941204992 run.py:479] Algo floyd_warshall step 7923 current loss 0.352264, current_train_items 253568.\n",
            "I0314 03:12:17.171132 138313941204992 run.py:479] Algo floyd_warshall step 7924 current loss 0.576818, current_train_items 253600.\n",
            "I0314 03:12:17.196189 138313941204992 run.py:479] Algo floyd_warshall step 7925 current loss 0.011038, current_train_items 253632.\n",
            "I0314 03:12:17.242768 138313941204992 run.py:479] Algo floyd_warshall step 7926 current loss 0.062332, current_train_items 253664.\n",
            "I0314 03:12:17.371749 138313941204992 run.py:479] Algo floyd_warshall step 7927 current loss 0.142040, current_train_items 253696.\n",
            "I0314 03:12:17.601389 138313941204992 run.py:479] Algo floyd_warshall step 7928 current loss 0.277748, current_train_items 253728.\n",
            "I0314 03:12:18.034525 138313941204992 run.py:479] Algo floyd_warshall step 7929 current loss 0.540884, current_train_items 253760.\n",
            "I0314 03:12:18.057676 138313941204992 run.py:479] Algo floyd_warshall step 7930 current loss 0.023737, current_train_items 253792.\n",
            "I0314 03:12:18.103033 138313941204992 run.py:479] Algo floyd_warshall step 7931 current loss 0.036405, current_train_items 253824.\n",
            "I0314 03:12:18.233066 138313941204992 run.py:479] Algo floyd_warshall step 7932 current loss 0.194870, current_train_items 253856.\n",
            "I0314 03:12:18.451074 138313941204992 run.py:479] Algo floyd_warshall step 7933 current loss 0.283372, current_train_items 253888.\n",
            "I0314 03:12:18.863664 138313941204992 run.py:479] Algo floyd_warshall step 7934 current loss 0.434324, current_train_items 253920.\n",
            "I0314 03:12:18.888662 138313941204992 run.py:479] Algo floyd_warshall step 7935 current loss 0.014768, current_train_items 253952.\n",
            "I0314 03:12:18.932770 138313941204992 run.py:479] Algo floyd_warshall step 7936 current loss 0.038767, current_train_items 253984.\n",
            "I0314 03:12:19.067392 138313941204992 run.py:479] Algo floyd_warshall step 7937 current loss 0.164588, current_train_items 254016.\n",
            "I0314 03:12:19.297166 138313941204992 run.py:479] Algo floyd_warshall step 7938 current loss 0.330836, current_train_items 254048.\n",
            "I0314 03:12:19.724081 138313941204992 run.py:479] Algo floyd_warshall step 7939 current loss 0.483066, current_train_items 254080.\n",
            "I0314 03:12:19.746523 138313941204992 run.py:479] Algo floyd_warshall step 7940 current loss 0.021428, current_train_items 254112.\n",
            "I0314 03:12:19.790921 138313941204992 run.py:479] Algo floyd_warshall step 7941 current loss 0.039248, current_train_items 254144.\n",
            "I0314 03:12:19.923972 138313941204992 run.py:479] Algo floyd_warshall step 7942 current loss 0.200902, current_train_items 254176.\n",
            "I0314 03:12:20.141121 138313941204992 run.py:479] Algo floyd_warshall step 7943 current loss 0.318764, current_train_items 254208.\n",
            "I0314 03:12:20.552637 138313941204992 run.py:479] Algo floyd_warshall step 7944 current loss 0.504226, current_train_items 254240.\n",
            "I0314 03:12:20.576678 138313941204992 run.py:479] Algo floyd_warshall step 7945 current loss 0.024316, current_train_items 254272.\n",
            "I0314 03:12:20.621055 138313941204992 run.py:479] Algo floyd_warshall step 7946 current loss 0.065565, current_train_items 254304.\n",
            "I0314 03:12:20.750719 138313941204992 run.py:479] Algo floyd_warshall step 7947 current loss 0.140885, current_train_items 254336.\n",
            "I0314 03:12:20.969459 138313941204992 run.py:479] Algo floyd_warshall step 7948 current loss 0.269425, current_train_items 254368.\n",
            "I0314 03:12:21.378631 138313941204992 run.py:479] Algo floyd_warshall step 7949 current loss 0.422008, current_train_items 254400.\n",
            "I0314 03:12:21.405654 138313941204992 run.py:479] Algo floyd_warshall step 7950 current loss 0.061327, current_train_items 254432.\n",
            "I0314 03:12:21.514148 138313941204992 run.py:499] (val) algo floyd_warshall step 7950: {'Pi': 0.90264892578125, 'score': 0.90264892578125, 'examples_seen': 254432, 'step': 7950, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:12:21.514451 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.921, current avg val score is 0.903, val scores are: floyd_warshall: 0.903\n",
            "I0314 03:12:21.562131 138313941204992 run.py:479] Algo floyd_warshall step 7951 current loss 0.045888, current_train_items 254464.\n",
            "I0314 03:12:21.699637 138313941204992 run.py:479] Algo floyd_warshall step 7952 current loss 0.243220, current_train_items 254496.\n",
            "I0314 03:12:21.914344 138313941204992 run.py:479] Algo floyd_warshall step 7953 current loss 0.216334, current_train_items 254528.\n",
            "I0314 03:12:22.339548 138313941204992 run.py:479] Algo floyd_warshall step 7954 current loss 0.461456, current_train_items 254560.\n",
            "I0314 03:12:22.366194 138313941204992 run.py:479] Algo floyd_warshall step 7955 current loss 0.012922, current_train_items 254592.\n",
            "I0314 03:12:22.412473 138313941204992 run.py:479] Algo floyd_warshall step 7956 current loss 0.038619, current_train_items 254624.\n",
            "I0314 03:12:22.551263 138313941204992 run.py:479] Algo floyd_warshall step 7957 current loss 0.150373, current_train_items 254656.\n",
            "I0314 03:12:22.777031 138313941204992 run.py:479] Algo floyd_warshall step 7958 current loss 0.346714, current_train_items 254688.\n",
            "I0314 03:12:23.200135 138313941204992 run.py:479] Algo floyd_warshall step 7959 current loss 0.481723, current_train_items 254720.\n",
            "I0314 03:12:23.223891 138313941204992 run.py:479] Algo floyd_warshall step 7960 current loss 0.018963, current_train_items 254752.\n",
            "I0314 03:12:23.268999 138313941204992 run.py:479] Algo floyd_warshall step 7961 current loss 0.057745, current_train_items 254784.\n",
            "I0314 03:12:23.402184 138313941204992 run.py:479] Algo floyd_warshall step 7962 current loss 0.311020, current_train_items 254816.\n",
            "I0314 03:12:23.627226 138313941204992 run.py:479] Algo floyd_warshall step 7963 current loss 0.263332, current_train_items 254848.\n",
            "I0314 03:12:24.113722 138313941204992 run.py:479] Algo floyd_warshall step 7964 current loss 0.480224, current_train_items 254880.\n",
            "I0314 03:12:24.153728 138313941204992 run.py:479] Algo floyd_warshall step 7965 current loss 0.034030, current_train_items 254912.\n",
            "I0314 03:12:24.211620 138313941204992 run.py:479] Algo floyd_warshall step 7966 current loss 0.062132, current_train_items 254944.\n",
            "I0314 03:12:24.377686 138313941204992 run.py:479] Algo floyd_warshall step 7967 current loss 0.263327, current_train_items 254976.\n",
            "I0314 03:12:24.640640 138313941204992 run.py:479] Algo floyd_warshall step 7968 current loss 0.282113, current_train_items 255008.\n",
            "I0314 03:12:25.110766 138313941204992 run.py:479] Algo floyd_warshall step 7969 current loss 0.424132, current_train_items 255040.\n",
            "I0314 03:12:25.144186 138313941204992 run.py:479] Algo floyd_warshall step 7970 current loss 0.028374, current_train_items 255072.\n",
            "I0314 03:12:25.200850 138313941204992 run.py:479] Algo floyd_warshall step 7971 current loss 0.033977, current_train_items 255104.\n",
            "I0314 03:12:25.352206 138313941204992 run.py:479] Algo floyd_warshall step 7972 current loss 0.138435, current_train_items 255136.\n",
            "I0314 03:12:25.617516 138313941204992 run.py:479] Algo floyd_warshall step 7973 current loss 0.288846, current_train_items 255168.\n",
            "I0314 03:12:26.121815 138313941204992 run.py:479] Algo floyd_warshall step 7974 current loss 0.677986, current_train_items 255200.\n",
            "I0314 03:12:26.159410 138313941204992 run.py:479] Algo floyd_warshall step 7975 current loss 0.021533, current_train_items 255232.\n",
            "I0314 03:12:26.215975 138313941204992 run.py:479] Algo floyd_warshall step 7976 current loss 0.044958, current_train_items 255264.\n",
            "I0314 03:12:26.380861 138313941204992 run.py:479] Algo floyd_warshall step 7977 current loss 0.193444, current_train_items 255296.\n",
            "I0314 03:12:26.640068 138313941204992 run.py:479] Algo floyd_warshall step 7978 current loss 0.257324, current_train_items 255328.\n",
            "I0314 03:12:27.064037 138313941204992 run.py:479] Algo floyd_warshall step 7979 current loss 0.473709, current_train_items 255360.\n",
            "I0314 03:12:27.086867 138313941204992 run.py:479] Algo floyd_warshall step 7980 current loss 0.007290, current_train_items 255392.\n",
            "I0314 03:12:27.131494 138313941204992 run.py:479] Algo floyd_warshall step 7981 current loss 0.056140, current_train_items 255424.\n",
            "I0314 03:12:27.262307 138313941204992 run.py:479] Algo floyd_warshall step 7982 current loss 0.175202, current_train_items 255456.\n",
            "I0314 03:12:27.478584 138313941204992 run.py:479] Algo floyd_warshall step 7983 current loss 0.350983, current_train_items 255488.\n",
            "I0314 03:12:27.884128 138313941204992 run.py:479] Algo floyd_warshall step 7984 current loss 0.490979, current_train_items 255520.\n",
            "I0314 03:12:27.907490 138313941204992 run.py:479] Algo floyd_warshall step 7985 current loss 0.009382, current_train_items 255552.\n",
            "I0314 03:12:27.952878 138313941204992 run.py:479] Algo floyd_warshall step 7986 current loss 0.043039, current_train_items 255584.\n",
            "I0314 03:12:28.084624 138313941204992 run.py:479] Algo floyd_warshall step 7987 current loss 0.160946, current_train_items 255616.\n",
            "I0314 03:12:28.296860 138313941204992 run.py:479] Algo floyd_warshall step 7988 current loss 0.232265, current_train_items 255648.\n",
            "I0314 03:12:28.719576 138313941204992 run.py:479] Algo floyd_warshall step 7989 current loss 0.487594, current_train_items 255680.\n",
            "I0314 03:12:28.744696 138313941204992 run.py:479] Algo floyd_warshall step 7990 current loss 0.022461, current_train_items 255712.\n",
            "I0314 03:12:28.790705 138313941204992 run.py:479] Algo floyd_warshall step 7991 current loss 0.036088, current_train_items 255744.\n",
            "I0314 03:12:28.921560 138313941204992 run.py:479] Algo floyd_warshall step 7992 current loss 0.115718, current_train_items 255776.\n",
            "I0314 03:12:29.132544 138313941204992 run.py:479] Algo floyd_warshall step 7993 current loss 0.267208, current_train_items 255808.\n",
            "I0314 03:12:29.539925 138313941204992 run.py:479] Algo floyd_warshall step 7994 current loss 0.461904, current_train_items 255840.\n",
            "I0314 03:12:29.563483 138313941204992 run.py:479] Algo floyd_warshall step 7995 current loss 0.022817, current_train_items 255872.\n",
            "I0314 03:12:29.608615 138313941204992 run.py:479] Algo floyd_warshall step 7996 current loss 0.047552, current_train_items 255904.\n",
            "I0314 03:12:29.739610 138313941204992 run.py:479] Algo floyd_warshall step 7997 current loss 0.184734, current_train_items 255936.\n",
            "I0314 03:12:29.958627 138313941204992 run.py:479] Algo floyd_warshall step 7998 current loss 0.232845, current_train_items 255968.\n",
            "I0314 03:12:30.365560 138313941204992 run.py:479] Algo floyd_warshall step 7999 current loss 0.473336, current_train_items 256000.\n",
            "I0314 03:12:30.389684 138313941204992 run.py:479] Algo floyd_warshall step 8000 current loss 0.045297, current_train_items 256032.\n",
            "I0314 03:12:30.479876 138313941204992 run.py:499] (val) algo floyd_warshall step 8000: {'Pi': 0.908203125, 'score': 0.908203125, 'examples_seen': 256032, 'step': 8000, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:12:30.480097 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.921, current avg val score is 0.908, val scores are: floyd_warshall: 0.908\n",
            "I0314 03:12:30.527575 138313941204992 run.py:479] Algo floyd_warshall step 8001 current loss 0.049910, current_train_items 256064.\n",
            "I0314 03:12:30.658140 138313941204992 run.py:479] Algo floyd_warshall step 8002 current loss 0.215306, current_train_items 256096.\n",
            "I0314 03:12:30.884730 138313941204992 run.py:479] Algo floyd_warshall step 8003 current loss 0.526277, current_train_items 256128.\n",
            "I0314 03:12:31.307355 138313941204992 run.py:479] Algo floyd_warshall step 8004 current loss 0.482324, current_train_items 256160.\n",
            "I0314 03:12:31.332947 138313941204992 run.py:479] Algo floyd_warshall step 8005 current loss 0.011598, current_train_items 256192.\n",
            "I0314 03:12:31.378589 138313941204992 run.py:479] Algo floyd_warshall step 8006 current loss 0.043407, current_train_items 256224.\n",
            "I0314 03:12:31.513959 138313941204992 run.py:479] Algo floyd_warshall step 8007 current loss 0.139036, current_train_items 256256.\n",
            "I0314 03:12:31.727430 138313941204992 run.py:479] Algo floyd_warshall step 8008 current loss 0.286787, current_train_items 256288.\n",
            "I0314 03:12:32.143465 138313941204992 run.py:479] Algo floyd_warshall step 8009 current loss 0.555654, current_train_items 256320.\n",
            "I0314 03:12:32.169037 138313941204992 run.py:479] Algo floyd_warshall step 8010 current loss 0.027776, current_train_items 256352.\n",
            "I0314 03:12:32.217430 138313941204992 run.py:479] Algo floyd_warshall step 8011 current loss 0.028512, current_train_items 256384.\n",
            "I0314 03:12:32.351404 138313941204992 run.py:479] Algo floyd_warshall step 8012 current loss 0.185931, current_train_items 256416.\n",
            "I0314 03:12:32.589824 138313941204992 run.py:479] Algo floyd_warshall step 8013 current loss 0.295918, current_train_items 256448.\n",
            "I0314 03:12:33.006742 138313941204992 run.py:479] Algo floyd_warshall step 8014 current loss 0.521489, current_train_items 256480.\n",
            "I0314 03:12:33.030500 138313941204992 run.py:479] Algo floyd_warshall step 8015 current loss 0.030823, current_train_items 256512.\n",
            "I0314 03:12:33.074648 138313941204992 run.py:479] Algo floyd_warshall step 8016 current loss 0.027461, current_train_items 256544.\n",
            "I0314 03:12:33.207001 138313941204992 run.py:479] Algo floyd_warshall step 8017 current loss 0.178128, current_train_items 256576.\n",
            "I0314 03:12:33.421989 138313941204992 run.py:479] Algo floyd_warshall step 8018 current loss 0.308260, current_train_items 256608.\n",
            "I0314 03:12:33.836923 138313941204992 run.py:479] Algo floyd_warshall step 8019 current loss 0.561832, current_train_items 256640.\n",
            "I0314 03:12:33.863079 138313941204992 run.py:479] Algo floyd_warshall step 8020 current loss 0.007207, current_train_items 256672.\n",
            "I0314 03:12:33.908681 138313941204992 run.py:479] Algo floyd_warshall step 8021 current loss 0.055090, current_train_items 256704.\n",
            "I0314 03:12:34.041695 138313941204992 run.py:479] Algo floyd_warshall step 8022 current loss 0.214794, current_train_items 256736.\n",
            "I0314 03:12:34.260801 138313941204992 run.py:479] Algo floyd_warshall step 8023 current loss 0.327521, current_train_items 256768.\n",
            "I0314 03:12:34.688888 138313941204992 run.py:479] Algo floyd_warshall step 8024 current loss 0.558359, current_train_items 256800.\n",
            "I0314 03:12:34.712118 138313941204992 run.py:479] Algo floyd_warshall step 8025 current loss 0.020082, current_train_items 256832.\n",
            "I0314 03:12:34.758900 138313941204992 run.py:479] Algo floyd_warshall step 8026 current loss 0.064271, current_train_items 256864.\n",
            "I0314 03:12:34.901943 138313941204992 run.py:479] Algo floyd_warshall step 8027 current loss 0.176023, current_train_items 256896.\n",
            "I0314 03:12:35.133708 138313941204992 run.py:479] Algo floyd_warshall step 8028 current loss 0.364595, current_train_items 256928.\n",
            "I0314 03:12:35.542315 138313941204992 run.py:479] Algo floyd_warshall step 8029 current loss 0.400098, current_train_items 256960.\n",
            "I0314 03:12:35.565912 138313941204992 run.py:479] Algo floyd_warshall step 8030 current loss 0.024295, current_train_items 256992.\n",
            "I0314 03:12:35.609835 138313941204992 run.py:479] Algo floyd_warshall step 8031 current loss 0.035922, current_train_items 257024.\n",
            "I0314 03:12:35.741012 138313941204992 run.py:479] Algo floyd_warshall step 8032 current loss 0.210050, current_train_items 257056.\n",
            "I0314 03:12:35.958966 138313941204992 run.py:479] Algo floyd_warshall step 8033 current loss 0.290454, current_train_items 257088.\n",
            "I0314 03:12:36.368777 138313941204992 run.py:479] Algo floyd_warshall step 8034 current loss 0.515714, current_train_items 257120.\n",
            "I0314 03:12:36.393813 138313941204992 run.py:479] Algo floyd_warshall step 8035 current loss 0.034862, current_train_items 257152.\n",
            "I0314 03:12:36.442420 138313941204992 run.py:479] Algo floyd_warshall step 8036 current loss 0.062374, current_train_items 257184.\n",
            "I0314 03:12:36.579493 138313941204992 run.py:479] Algo floyd_warshall step 8037 current loss 0.220730, current_train_items 257216.\n",
            "I0314 03:12:36.845819 138313941204992 run.py:479] Algo floyd_warshall step 8038 current loss 0.317960, current_train_items 257248.\n",
            "I0314 03:12:37.349429 138313941204992 run.py:479] Algo floyd_warshall step 8039 current loss 0.513070, current_train_items 257280.\n",
            "I0314 03:12:37.381421 138313941204992 run.py:479] Algo floyd_warshall step 8040 current loss 0.020058, current_train_items 257312.\n",
            "I0314 03:12:37.437765 138313941204992 run.py:479] Algo floyd_warshall step 8041 current loss 0.045743, current_train_items 257344.\n",
            "I0314 03:12:37.592377 138313941204992 run.py:479] Algo floyd_warshall step 8042 current loss 0.161524, current_train_items 257376.\n",
            "I0314 03:12:37.858480 138313941204992 run.py:479] Algo floyd_warshall step 8043 current loss 0.286758, current_train_items 257408.\n",
            "I0314 03:12:38.367512 138313941204992 run.py:479] Algo floyd_warshall step 8044 current loss 0.625065, current_train_items 257440.\n",
            "I0314 03:12:38.406075 138313941204992 run.py:479] Algo floyd_warshall step 8045 current loss 0.168696, current_train_items 257472.\n",
            "I0314 03:12:38.465368 138313941204992 run.py:479] Algo floyd_warshall step 8046 current loss 0.057707, current_train_items 257504.\n",
            "I0314 03:12:38.628042 138313941204992 run.py:479] Algo floyd_warshall step 8047 current loss 0.198771, current_train_items 257536.\n",
            "I0314 03:12:38.902696 138313941204992 run.py:479] Algo floyd_warshall step 8048 current loss 0.258301, current_train_items 257568.\n",
            "I0314 03:12:39.411926 138313941204992 run.py:479] Algo floyd_warshall step 8049 current loss 0.577434, current_train_items 257600.\n",
            "I0314 03:12:39.460524 138313941204992 run.py:479] Algo floyd_warshall step 8050 current loss 0.014226, current_train_items 257632.\n",
            "I0314 03:12:39.582017 138313941204992 run.py:499] (val) algo floyd_warshall step 8050: {'Pi': 0.90118408203125, 'score': 0.90118408203125, 'examples_seen': 257632, 'step': 8050, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:12:39.582968 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.921, current avg val score is 0.901, val scores are: floyd_warshall: 0.901\n",
            "I0314 03:12:39.666579 138313941204992 run.py:479] Algo floyd_warshall step 8051 current loss 0.016637, current_train_items 257664.\n",
            "I0314 03:12:39.850393 138313941204992 run.py:479] Algo floyd_warshall step 8052 current loss 0.188469, current_train_items 257696.\n",
            "I0314 03:12:40.124028 138313941204992 run.py:479] Algo floyd_warshall step 8053 current loss 0.351457, current_train_items 257728.\n",
            "I0314 03:12:40.662589 138313941204992 run.py:479] Algo floyd_warshall step 8054 current loss 0.641118, current_train_items 257760.\n",
            "I0314 03:12:40.703271 138313941204992 run.py:479] Algo floyd_warshall step 8055 current loss 0.007911, current_train_items 257792.\n",
            "I0314 03:12:40.763291 138313941204992 run.py:479] Algo floyd_warshall step 8056 current loss 0.031893, current_train_items 257824.\n",
            "I0314 03:12:40.921874 138313941204992 run.py:479] Algo floyd_warshall step 8057 current loss 0.148229, current_train_items 257856.\n",
            "I0314 03:12:41.180192 138313941204992 run.py:479] Algo floyd_warshall step 8058 current loss 0.317756, current_train_items 257888.\n",
            "I0314 03:12:41.674004 138313941204992 run.py:479] Algo floyd_warshall step 8059 current loss 0.592403, current_train_items 257920.\n",
            "I0314 03:12:41.706927 138313941204992 run.py:479] Algo floyd_warshall step 8060 current loss 0.011296, current_train_items 257952.\n",
            "I0314 03:12:41.763848 138313941204992 run.py:479] Algo floyd_warshall step 8061 current loss 0.048226, current_train_items 257984.\n",
            "I0314 03:12:41.925242 138313941204992 run.py:479] Algo floyd_warshall step 8062 current loss 0.199978, current_train_items 258016.\n",
            "I0314 03:12:42.191199 138313941204992 run.py:479] Algo floyd_warshall step 8063 current loss 0.276946, current_train_items 258048.\n",
            "I0314 03:12:42.675377 138313941204992 run.py:479] Algo floyd_warshall step 8064 current loss 0.697529, current_train_items 258080.\n",
            "I0314 03:12:42.715585 138313941204992 run.py:479] Algo floyd_warshall step 8065 current loss 0.010695, current_train_items 258112.\n",
            "I0314 03:12:42.777859 138313941204992 run.py:479] Algo floyd_warshall step 8066 current loss 0.092892, current_train_items 258144.\n",
            "I0314 03:12:42.910847 138313941204992 run.py:479] Algo floyd_warshall step 8067 current loss 0.220207, current_train_items 258176.\n",
            "I0314 03:12:43.137708 138313941204992 run.py:479] Algo floyd_warshall step 8068 current loss 0.265602, current_train_items 258208.\n",
            "I0314 03:12:43.573710 138313941204992 run.py:479] Algo floyd_warshall step 8069 current loss 0.759893, current_train_items 258240.\n",
            "I0314 03:12:43.598615 138313941204992 run.py:479] Algo floyd_warshall step 8070 current loss 0.048897, current_train_items 258272.\n",
            "I0314 03:12:43.646414 138313941204992 run.py:479] Algo floyd_warshall step 8071 current loss 0.061399, current_train_items 258304.\n",
            "I0314 03:12:43.778074 138313941204992 run.py:479] Algo floyd_warshall step 8072 current loss 0.254038, current_train_items 258336.\n",
            "I0314 03:12:43.994933 138313941204992 run.py:479] Algo floyd_warshall step 8073 current loss 0.351701, current_train_items 258368.\n",
            "I0314 03:12:44.413156 138313941204992 run.py:479] Algo floyd_warshall step 8074 current loss 0.713384, current_train_items 258400.\n",
            "I0314 03:12:44.437206 138313941204992 run.py:479] Algo floyd_warshall step 8075 current loss 0.030020, current_train_items 258432.\n",
            "I0314 03:12:44.483676 138313941204992 run.py:479] Algo floyd_warshall step 8076 current loss 0.068937, current_train_items 258464.\n",
            "I0314 03:12:44.618414 138313941204992 run.py:479] Algo floyd_warshall step 8077 current loss 0.201484, current_train_items 258496.\n",
            "I0314 03:12:44.847293 138313941204992 run.py:479] Algo floyd_warshall step 8078 current loss 0.274645, current_train_items 258528.\n",
            "I0314 03:12:45.257378 138313941204992 run.py:479] Algo floyd_warshall step 8079 current loss 0.567778, current_train_items 258560.\n",
            "I0314 03:12:45.282042 138313941204992 run.py:479] Algo floyd_warshall step 8080 current loss 0.019586, current_train_items 258592.\n",
            "I0314 03:12:45.327437 138313941204992 run.py:479] Algo floyd_warshall step 8081 current loss 0.030869, current_train_items 258624.\n",
            "I0314 03:12:45.461394 138313941204992 run.py:479] Algo floyd_warshall step 8082 current loss 0.262522, current_train_items 258656.\n",
            "I0314 03:12:45.693703 138313941204992 run.py:479] Algo floyd_warshall step 8083 current loss 0.389736, current_train_items 258688.\n",
            "I0314 03:12:46.102934 138313941204992 run.py:479] Algo floyd_warshall step 8084 current loss 0.483047, current_train_items 258720.\n",
            "I0314 03:12:46.127696 138313941204992 run.py:479] Algo floyd_warshall step 8085 current loss 0.057995, current_train_items 258752.\n",
            "I0314 03:12:46.174471 138313941204992 run.py:479] Algo floyd_warshall step 8086 current loss 0.040827, current_train_items 258784.\n",
            "I0314 03:12:46.309769 138313941204992 run.py:479] Algo floyd_warshall step 8087 current loss 0.165576, current_train_items 258816.\n",
            "I0314 03:12:46.532247 138313941204992 run.py:479] Algo floyd_warshall step 8088 current loss 0.307983, current_train_items 258848.\n",
            "I0314 03:12:46.953857 138313941204992 run.py:479] Algo floyd_warshall step 8089 current loss 0.541134, current_train_items 258880.\n",
            "I0314 03:12:46.982507 138313941204992 run.py:479] Algo floyd_warshall step 8090 current loss 0.028666, current_train_items 258912.\n",
            "I0314 03:12:47.028384 138313941204992 run.py:479] Algo floyd_warshall step 8091 current loss 0.072683, current_train_items 258944.\n",
            "I0314 03:12:47.161421 138313941204992 run.py:479] Algo floyd_warshall step 8092 current loss 0.197427, current_train_items 258976.\n",
            "I0314 03:12:47.392376 138313941204992 run.py:479] Algo floyd_warshall step 8093 current loss 0.358072, current_train_items 259008.\n",
            "I0314 03:12:47.802342 138313941204992 run.py:479] Algo floyd_warshall step 8094 current loss 0.534099, current_train_items 259040.\n",
            "I0314 03:12:47.826238 138313941204992 run.py:479] Algo floyd_warshall step 8095 current loss 0.018100, current_train_items 259072.\n",
            "I0314 03:12:47.872853 138313941204992 run.py:479] Algo floyd_warshall step 8096 current loss 0.062756, current_train_items 259104.\n",
            "I0314 03:12:48.003090 138313941204992 run.py:479] Algo floyd_warshall step 8097 current loss 0.176822, current_train_items 259136.\n",
            "I0314 03:12:48.216404 138313941204992 run.py:479] Algo floyd_warshall step 8098 current loss 0.259424, current_train_items 259168.\n",
            "I0314 03:12:48.647919 138313941204992 run.py:479] Algo floyd_warshall step 8099 current loss 0.560314, current_train_items 259200.\n",
            "I0314 03:12:48.671673 138313941204992 run.py:479] Algo floyd_warshall step 8100 current loss 0.010070, current_train_items 259232.\n",
            "I0314 03:12:48.760972 138313941204992 run.py:499] (val) algo floyd_warshall step 8100: {'Pi': 0.90167236328125, 'score': 0.90167236328125, 'examples_seen': 259232, 'step': 8100, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:12:48.761468 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.921, current avg val score is 0.902, val scores are: floyd_warshall: 0.902\n",
            "I0314 03:12:48.812391 138313941204992 run.py:479] Algo floyd_warshall step 8101 current loss 0.071635, current_train_items 259264.\n",
            "I0314 03:12:48.945096 138313941204992 run.py:479] Algo floyd_warshall step 8102 current loss 0.242251, current_train_items 259296.\n",
            "I0314 03:12:49.163982 138313941204992 run.py:479] Algo floyd_warshall step 8103 current loss 0.406505, current_train_items 259328.\n",
            "I0314 03:12:49.585212 138313941204992 run.py:479] Algo floyd_warshall step 8104 current loss 0.529237, current_train_items 259360.\n",
            "I0314 03:12:49.611779 138313941204992 run.py:479] Algo floyd_warshall step 8105 current loss 0.036568, current_train_items 259392.\n",
            "I0314 03:12:49.657952 138313941204992 run.py:479] Algo floyd_warshall step 8106 current loss 0.122132, current_train_items 259424.\n",
            "I0314 03:12:49.790993 138313941204992 run.py:479] Algo floyd_warshall step 8107 current loss 0.175034, current_train_items 259456.\n",
            "I0314 03:12:50.049189 138313941204992 run.py:479] Algo floyd_warshall step 8108 current loss 0.362199, current_train_items 259488.\n",
            "I0314 03:12:50.550664 138313941204992 run.py:479] Algo floyd_warshall step 8109 current loss 0.561669, current_train_items 259520.\n",
            "I0314 03:12:50.581977 138313941204992 run.py:479] Algo floyd_warshall step 8110 current loss 0.015856, current_train_items 259552.\n",
            "I0314 03:12:50.638462 138313941204992 run.py:479] Algo floyd_warshall step 8111 current loss 0.025427, current_train_items 259584.\n",
            "I0314 03:12:50.799741 138313941204992 run.py:479] Algo floyd_warshall step 8112 current loss 0.235464, current_train_items 259616.\n",
            "I0314 03:12:51.071279 138313941204992 run.py:479] Algo floyd_warshall step 8113 current loss 0.322998, current_train_items 259648.\n",
            "I0314 03:12:51.564369 138313941204992 run.py:479] Algo floyd_warshall step 8114 current loss 0.681428, current_train_items 259680.\n",
            "I0314 03:12:51.601555 138313941204992 run.py:479] Algo floyd_warshall step 8115 current loss 0.023231, current_train_items 259712.\n",
            "I0314 03:12:51.659596 138313941204992 run.py:479] Algo floyd_warshall step 8116 current loss 0.057925, current_train_items 259744.\n",
            "I0314 03:12:51.821460 138313941204992 run.py:479] Algo floyd_warshall step 8117 current loss 0.318559, current_train_items 259776.\n",
            "I0314 03:12:52.073610 138313941204992 run.py:479] Algo floyd_warshall step 8118 current loss 0.214102, current_train_items 259808.\n",
            "I0314 03:12:52.573637 138313941204992 run.py:479] Algo floyd_warshall step 8119 current loss 0.512046, current_train_items 259840.\n",
            "I0314 03:12:52.613912 138313941204992 run.py:479] Algo floyd_warshall step 8120 current loss 0.017849, current_train_items 259872.\n",
            "I0314 03:12:52.672784 138313941204992 run.py:479] Algo floyd_warshall step 8121 current loss 0.045143, current_train_items 259904.\n",
            "I0314 03:12:52.840494 138313941204992 run.py:479] Algo floyd_warshall step 8122 current loss 0.283750, current_train_items 259936.\n",
            "I0314 03:12:53.104876 138313941204992 run.py:479] Algo floyd_warshall step 8123 current loss 0.340789, current_train_items 259968.\n",
            "I0314 03:12:53.530347 138313941204992 run.py:479] Algo floyd_warshall step 8124 current loss 0.627070, current_train_items 260000.\n",
            "I0314 03:12:53.553392 138313941204992 run.py:479] Algo floyd_warshall step 8125 current loss 0.035549, current_train_items 260032.\n",
            "I0314 03:12:53.598575 138313941204992 run.py:479] Algo floyd_warshall step 8126 current loss 0.084264, current_train_items 260064.\n",
            "I0314 03:12:53.732015 138313941204992 run.py:479] Algo floyd_warshall step 8127 current loss 0.170529, current_train_items 260096.\n",
            "I0314 03:12:53.955222 138313941204992 run.py:479] Algo floyd_warshall step 8128 current loss 0.366226, current_train_items 260128.\n",
            "I0314 03:12:54.362228 138313941204992 run.py:479] Algo floyd_warshall step 8129 current loss 0.531389, current_train_items 260160.\n",
            "I0314 03:12:54.386919 138313941204992 run.py:479] Algo floyd_warshall step 8130 current loss 0.018699, current_train_items 260192.\n",
            "I0314 03:12:54.432919 138313941204992 run.py:479] Algo floyd_warshall step 8131 current loss 0.041004, current_train_items 260224.\n",
            "I0314 03:12:54.570816 138313941204992 run.py:479] Algo floyd_warshall step 8132 current loss 0.207735, current_train_items 260256.\n",
            "I0314 03:12:54.805679 138313941204992 run.py:479] Algo floyd_warshall step 8133 current loss 0.339052, current_train_items 260288.\n",
            "I0314 03:12:55.213668 138313941204992 run.py:479] Algo floyd_warshall step 8134 current loss 0.439505, current_train_items 260320.\n",
            "I0314 03:12:55.239281 138313941204992 run.py:479] Algo floyd_warshall step 8135 current loss 0.140364, current_train_items 260352.\n",
            "I0314 03:12:55.285552 138313941204992 run.py:479] Algo floyd_warshall step 8136 current loss 0.122129, current_train_items 260384.\n",
            "I0314 03:12:55.420369 138313941204992 run.py:479] Algo floyd_warshall step 8137 current loss 0.125213, current_train_items 260416.\n",
            "I0314 03:12:55.647178 138313941204992 run.py:479] Algo floyd_warshall step 8138 current loss 0.326879, current_train_items 260448.\n",
            "I0314 03:12:56.063901 138313941204992 run.py:479] Algo floyd_warshall step 8139 current loss 0.574540, current_train_items 260480.\n",
            "I0314 03:12:56.088854 138313941204992 run.py:479] Algo floyd_warshall step 8140 current loss 0.010073, current_train_items 260512.\n",
            "I0314 03:12:56.138229 138313941204992 run.py:479] Algo floyd_warshall step 8141 current loss 0.052785, current_train_items 260544.\n",
            "I0314 03:12:56.268472 138313941204992 run.py:479] Algo floyd_warshall step 8142 current loss 0.195539, current_train_items 260576.\n",
            "I0314 03:12:56.496470 138313941204992 run.py:479] Algo floyd_warshall step 8143 current loss 0.412526, current_train_items 260608.\n",
            "I0314 03:12:56.940975 138313941204992 run.py:479] Algo floyd_warshall step 8144 current loss 0.604535, current_train_items 260640.\n",
            "I0314 03:12:56.965085 138313941204992 run.py:479] Algo floyd_warshall step 8145 current loss 0.008675, current_train_items 260672.\n",
            "I0314 03:12:57.010000 138313941204992 run.py:479] Algo floyd_warshall step 8146 current loss 0.038245, current_train_items 260704.\n",
            "I0314 03:12:57.141307 138313941204992 run.py:479] Algo floyd_warshall step 8147 current loss 0.221132, current_train_items 260736.\n",
            "I0314 03:12:57.358870 138313941204992 run.py:479] Algo floyd_warshall step 8148 current loss 0.348254, current_train_items 260768.\n",
            "I0314 03:12:57.778370 138313941204992 run.py:479] Algo floyd_warshall step 8149 current loss 0.581179, current_train_items 260800.\n",
            "I0314 03:12:57.802745 138313941204992 run.py:479] Algo floyd_warshall step 8150 current loss 0.017280, current_train_items 260832.\n",
            "I0314 03:12:57.889489 138313941204992 run.py:499] (val) algo floyd_warshall step 8150: {'Pi': 0.8857421875, 'score': 0.8857421875, 'examples_seen': 260832, 'step': 8150, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:12:57.889754 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.921, current avg val score is 0.886, val scores are: floyd_warshall: 0.886\n",
            "I0314 03:12:57.938941 138313941204992 run.py:479] Algo floyd_warshall step 8151 current loss 0.039006, current_train_items 260864.\n",
            "I0314 03:12:58.069131 138313941204992 run.py:479] Algo floyd_warshall step 8152 current loss 0.220281, current_train_items 260896.\n",
            "I0314 03:12:58.283328 138313941204992 run.py:479] Algo floyd_warshall step 8153 current loss 0.228924, current_train_items 260928.\n",
            "I0314 03:12:58.710040 138313941204992 run.py:479] Algo floyd_warshall step 8154 current loss 0.541179, current_train_items 260960.\n",
            "I0314 03:12:58.736246 138313941204992 run.py:479] Algo floyd_warshall step 8155 current loss 0.046005, current_train_items 260992.\n",
            "I0314 03:12:58.781445 138313941204992 run.py:479] Algo floyd_warshall step 8156 current loss 0.052048, current_train_items 261024.\n",
            "I0314 03:12:58.912455 138313941204992 run.py:479] Algo floyd_warshall step 8157 current loss 0.263260, current_train_items 261056.\n",
            "I0314 03:12:59.140010 138313941204992 run.py:479] Algo floyd_warshall step 8158 current loss 0.292893, current_train_items 261088.\n",
            "I0314 03:12:59.568313 138313941204992 run.py:479] Algo floyd_warshall step 8159 current loss 0.666985, current_train_items 261120.\n",
            "I0314 03:12:59.592599 138313941204992 run.py:479] Algo floyd_warshall step 8160 current loss 0.013223, current_train_items 261152.\n",
            "I0314 03:12:59.636534 138313941204992 run.py:479] Algo floyd_warshall step 8161 current loss 0.060868, current_train_items 261184.\n",
            "I0314 03:12:59.776686 138313941204992 run.py:479] Algo floyd_warshall step 8162 current loss 0.209449, current_train_items 261216.\n",
            "I0314 03:12:59.988439 138313941204992 run.py:479] Algo floyd_warshall step 8163 current loss 0.225631, current_train_items 261248.\n",
            "I0314 03:13:00.403921 138313941204992 run.py:479] Algo floyd_warshall step 8164 current loss 0.612825, current_train_items 261280.\n",
            "I0314 03:13:00.426859 138313941204992 run.py:479] Algo floyd_warshall step 8165 current loss 0.033459, current_train_items 261312.\n",
            "I0314 03:13:00.471814 138313941204992 run.py:479] Algo floyd_warshall step 8166 current loss 0.082189, current_train_items 261344.\n",
            "I0314 03:13:00.599311 138313941204992 run.py:479] Algo floyd_warshall step 8167 current loss 0.192694, current_train_items 261376.\n",
            "I0314 03:13:00.821263 138313941204992 run.py:479] Algo floyd_warshall step 8168 current loss 0.360592, current_train_items 261408.\n",
            "I0314 03:13:01.228118 138313941204992 run.py:479] Algo floyd_warshall step 8169 current loss 0.508010, current_train_items 261440.\n",
            "I0314 03:13:01.252896 138313941204992 run.py:479] Algo floyd_warshall step 8170 current loss 0.018222, current_train_items 261472.\n",
            "I0314 03:13:01.299908 138313941204992 run.py:479] Algo floyd_warshall step 8171 current loss 0.090755, current_train_items 261504.\n",
            "I0314 03:13:01.430941 138313941204992 run.py:479] Algo floyd_warshall step 8172 current loss 0.226759, current_train_items 261536.\n",
            "I0314 03:13:01.661418 138313941204992 run.py:479] Algo floyd_warshall step 8173 current loss 0.374826, current_train_items 261568.\n",
            "I0314 03:13:02.090454 138313941204992 run.py:479] Algo floyd_warshall step 8174 current loss 0.416792, current_train_items 261600.\n",
            "I0314 03:13:02.113884 138313941204992 run.py:479] Algo floyd_warshall step 8175 current loss 0.033641, current_train_items 261632.\n",
            "I0314 03:13:02.160749 138313941204992 run.py:479] Algo floyd_warshall step 8176 current loss 0.071429, current_train_items 261664.\n",
            "I0314 03:13:02.287928 138313941204992 run.py:479] Algo floyd_warshall step 8177 current loss 0.177588, current_train_items 261696.\n",
            "I0314 03:13:02.503886 138313941204992 run.py:479] Algo floyd_warshall step 8178 current loss 0.327152, current_train_items 261728.\n",
            "I0314 03:13:02.916362 138313941204992 run.py:479] Algo floyd_warshall step 8179 current loss 0.512532, current_train_items 261760.\n",
            "I0314 03:13:02.939245 138313941204992 run.py:479] Algo floyd_warshall step 8180 current loss 0.053243, current_train_items 261792.\n",
            "I0314 03:13:03.000860 138313941204992 run.py:479] Algo floyd_warshall step 8181 current loss 0.145572, current_train_items 261824.\n",
            "I0314 03:13:03.158942 138313941204992 run.py:479] Algo floyd_warshall step 8182 current loss 0.167758, current_train_items 261856.\n",
            "I0314 03:13:03.425340 138313941204992 run.py:479] Algo floyd_warshall step 8183 current loss 0.376431, current_train_items 261888.\n",
            "I0314 03:13:03.890366 138313941204992 run.py:479] Algo floyd_warshall step 8184 current loss 0.417230, current_train_items 261920.\n",
            "I0314 03:13:03.923483 138313941204992 run.py:479] Algo floyd_warshall step 8185 current loss 0.010559, current_train_items 261952.\n",
            "I0314 03:13:03.981406 138313941204992 run.py:479] Algo floyd_warshall step 8186 current loss 0.050448, current_train_items 261984.\n",
            "I0314 03:13:04.141983 138313941204992 run.py:479] Algo floyd_warshall step 8187 current loss 0.197308, current_train_items 262016.\n",
            "I0314 03:13:04.399193 138313941204992 run.py:479] Algo floyd_warshall step 8188 current loss 0.319395, current_train_items 262048.\n",
            "I0314 03:13:04.899776 138313941204992 run.py:479] Algo floyd_warshall step 8189 current loss 0.510750, current_train_items 262080.\n",
            "I0314 03:13:04.933480 138313941204992 run.py:479] Algo floyd_warshall step 8190 current loss 0.013771, current_train_items 262112.\n",
            "I0314 03:13:04.994293 138313941204992 run.py:479] Algo floyd_warshall step 8191 current loss 0.036534, current_train_items 262144.\n",
            "I0314 03:13:05.156394 138313941204992 run.py:479] Algo floyd_warshall step 8192 current loss 0.215510, current_train_items 262176.\n",
            "I0314 03:13:05.428621 138313941204992 run.py:479] Algo floyd_warshall step 8193 current loss 0.260513, current_train_items 262208.\n",
            "I0314 03:13:05.924232 138313941204992 run.py:479] Algo floyd_warshall step 8194 current loss 0.460955, current_train_items 262240.\n",
            "I0314 03:13:05.964395 138313941204992 run.py:479] Algo floyd_warshall step 8195 current loss 0.011625, current_train_items 262272.\n",
            "I0314 03:13:06.028393 138313941204992 run.py:479] Algo floyd_warshall step 8196 current loss 0.044894, current_train_items 262304.\n",
            "I0314 03:13:06.158626 138313941204992 run.py:479] Algo floyd_warshall step 8197 current loss 0.145381, current_train_items 262336.\n",
            "I0314 03:13:06.384968 138313941204992 run.py:479] Algo floyd_warshall step 8198 current loss 0.243678, current_train_items 262368.\n",
            "I0314 03:13:06.818194 138313941204992 run.py:479] Algo floyd_warshall step 8199 current loss 0.539182, current_train_items 262400.\n",
            "I0314 03:13:06.841119 138313941204992 run.py:479] Algo floyd_warshall step 8200 current loss 0.038773, current_train_items 262432.\n",
            "I0314 03:13:06.930763 138313941204992 run.py:499] (val) algo floyd_warshall step 8200: {'Pi': 0.899658203125, 'score': 0.899658203125, 'examples_seen': 262432, 'step': 8200, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:13:06.931066 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.921, current avg val score is 0.900, val scores are: floyd_warshall: 0.900\n",
            "I0314 03:13:06.979519 138313941204992 run.py:479] Algo floyd_warshall step 8201 current loss 0.040136, current_train_items 262464.\n",
            "I0314 03:13:07.114398 138313941204992 run.py:479] Algo floyd_warshall step 8202 current loss 0.206566, current_train_items 262496.\n",
            "I0314 03:13:07.335759 138313941204992 run.py:479] Algo floyd_warshall step 8203 current loss 0.217856, current_train_items 262528.\n",
            "I0314 03:13:07.762245 138313941204992 run.py:479] Algo floyd_warshall step 8204 current loss 0.536914, current_train_items 262560.\n",
            "I0314 03:13:07.787918 138313941204992 run.py:479] Algo floyd_warshall step 8205 current loss 0.009920, current_train_items 262592.\n",
            "I0314 03:13:07.834991 138313941204992 run.py:479] Algo floyd_warshall step 8206 current loss 0.037697, current_train_items 262624.\n",
            "I0314 03:13:07.972599 138313941204992 run.py:479] Algo floyd_warshall step 8207 current loss 0.324332, current_train_items 262656.\n",
            "I0314 03:13:08.204292 138313941204992 run.py:479] Algo floyd_warshall step 8208 current loss 0.277522, current_train_items 262688.\n",
            "I0314 03:13:08.625153 138313941204992 run.py:479] Algo floyd_warshall step 8209 current loss 0.718944, current_train_items 262720.\n",
            "I0314 03:13:08.649416 138313941204992 run.py:479] Algo floyd_warshall step 8210 current loss 0.017360, current_train_items 262752.\n",
            "I0314 03:13:08.696141 138313941204992 run.py:479] Algo floyd_warshall step 8211 current loss 0.090255, current_train_items 262784.\n",
            "I0314 03:13:08.828005 138313941204992 run.py:479] Algo floyd_warshall step 8212 current loss 0.195354, current_train_items 262816.\n",
            "I0314 03:13:09.046516 138313941204992 run.py:479] Algo floyd_warshall step 8213 current loss 0.404126, current_train_items 262848.\n",
            "I0314 03:13:09.466850 138313941204992 run.py:479] Algo floyd_warshall step 8214 current loss 0.686778, current_train_items 262880.\n",
            "I0314 03:13:09.490629 138313941204992 run.py:479] Algo floyd_warshall step 8215 current loss 0.016366, current_train_items 262912.\n",
            "I0314 03:13:09.534825 138313941204992 run.py:479] Algo floyd_warshall step 8216 current loss 0.057315, current_train_items 262944.\n",
            "I0314 03:13:09.663392 138313941204992 run.py:479] Algo floyd_warshall step 8217 current loss 0.169022, current_train_items 262976.\n",
            "I0314 03:13:09.892227 138313941204992 run.py:479] Algo floyd_warshall step 8218 current loss 0.330717, current_train_items 263008.\n",
            "I0314 03:13:10.316119 138313941204992 run.py:479] Algo floyd_warshall step 8219 current loss 0.561334, current_train_items 263040.\n",
            "I0314 03:13:10.340465 138313941204992 run.py:479] Algo floyd_warshall step 8220 current loss 0.112701, current_train_items 263072.\n",
            "I0314 03:13:10.384963 138313941204992 run.py:479] Algo floyd_warshall step 8221 current loss 0.041623, current_train_items 263104.\n",
            "I0314 03:13:10.512234 138313941204992 run.py:479] Algo floyd_warshall step 8222 current loss 0.124953, current_train_items 263136.\n",
            "I0314 03:13:10.737527 138313941204992 run.py:479] Algo floyd_warshall step 8223 current loss 0.255939, current_train_items 263168.\n",
            "I0314 03:13:11.151336 138313941204992 run.py:479] Algo floyd_warshall step 8224 current loss 0.454843, current_train_items 263200.\n",
            "I0314 03:13:11.173744 138313941204992 run.py:479] Algo floyd_warshall step 8225 current loss 0.013386, current_train_items 263232.\n",
            "I0314 03:13:11.217255 138313941204992 run.py:479] Algo floyd_warshall step 8226 current loss 0.028367, current_train_items 263264.\n",
            "I0314 03:13:11.343732 138313941204992 run.py:479] Algo floyd_warshall step 8227 current loss 0.149775, current_train_items 263296.\n",
            "I0314 03:13:11.559043 138313941204992 run.py:479] Algo floyd_warshall step 8228 current loss 0.302906, current_train_items 263328.\n",
            "I0314 03:13:11.968080 138313941204992 run.py:479] Algo floyd_warshall step 8229 current loss 0.928100, current_train_items 263360.\n",
            "I0314 03:13:11.991728 138313941204992 run.py:479] Algo floyd_warshall step 8230 current loss 0.021041, current_train_items 263392.\n",
            "I0314 03:13:12.041109 138313941204992 run.py:479] Algo floyd_warshall step 8231 current loss 0.077199, current_train_items 263424.\n",
            "I0314 03:13:12.176314 138313941204992 run.py:479] Algo floyd_warshall step 8232 current loss 0.201060, current_train_items 263456.\n",
            "I0314 03:13:12.400657 138313941204992 run.py:479] Algo floyd_warshall step 8233 current loss 0.342101, current_train_items 263488.\n",
            "I0314 03:13:12.816769 138313941204992 run.py:479] Algo floyd_warshall step 8234 current loss 0.513154, current_train_items 263520.\n",
            "I0314 03:13:12.840904 138313941204992 run.py:479] Algo floyd_warshall step 8235 current loss 0.021742, current_train_items 263552.\n",
            "I0314 03:13:12.886225 138313941204992 run.py:479] Algo floyd_warshall step 8236 current loss 0.049635, current_train_items 263584.\n",
            "I0314 03:13:13.016788 138313941204992 run.py:479] Algo floyd_warshall step 8237 current loss 0.148744, current_train_items 263616.\n",
            "I0314 03:13:13.254732 138313941204992 run.py:479] Algo floyd_warshall step 8238 current loss 0.290843, current_train_items 263648.\n",
            "I0314 03:13:13.676282 138313941204992 run.py:479] Algo floyd_warshall step 8239 current loss 0.530291, current_train_items 263680.\n",
            "I0314 03:13:13.699907 138313941204992 run.py:479] Algo floyd_warshall step 8240 current loss 0.016840, current_train_items 263712.\n",
            "I0314 03:13:13.745327 138313941204992 run.py:479] Algo floyd_warshall step 8241 current loss 0.048816, current_train_items 263744.\n",
            "I0314 03:13:13.875267 138313941204992 run.py:479] Algo floyd_warshall step 8242 current loss 0.219644, current_train_items 263776.\n",
            "I0314 03:13:14.089833 138313941204992 run.py:479] Algo floyd_warshall step 8243 current loss 0.390062, current_train_items 263808.\n",
            "I0314 03:13:14.500516 138313941204992 run.py:479] Algo floyd_warshall step 8244 current loss 0.459038, current_train_items 263840.\n",
            "I0314 03:13:14.525291 138313941204992 run.py:479] Algo floyd_warshall step 8245 current loss 0.087786, current_train_items 263872.\n",
            "I0314 03:13:14.570028 138313941204992 run.py:479] Algo floyd_warshall step 8246 current loss 0.051580, current_train_items 263904.\n",
            "I0314 03:13:14.698066 138313941204992 run.py:479] Algo floyd_warshall step 8247 current loss 0.160773, current_train_items 263936.\n",
            "I0314 03:13:14.915443 138313941204992 run.py:479] Algo floyd_warshall step 8248 current loss 0.270445, current_train_items 263968.\n",
            "I0314 03:13:15.327776 138313941204992 run.py:479] Algo floyd_warshall step 8249 current loss 0.544215, current_train_items 264000.\n",
            "I0314 03:13:15.352302 138313941204992 run.py:479] Algo floyd_warshall step 8250 current loss 0.010367, current_train_items 264032.\n",
            "I0314 03:13:15.440049 138313941204992 run.py:499] (val) algo floyd_warshall step 8250: {'Pi': 0.89947509765625, 'score': 0.89947509765625, 'examples_seen': 264032, 'step': 8250, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:13:15.440317 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.921, current avg val score is 0.899, val scores are: floyd_warshall: 0.899\n",
            "I0314 03:13:15.489478 138313941204992 run.py:479] Algo floyd_warshall step 8251 current loss 0.092540, current_train_items 264064.\n",
            "I0314 03:13:15.623644 138313941204992 run.py:479] Algo floyd_warshall step 8252 current loss 0.217518, current_train_items 264096.\n",
            "I0314 03:13:15.842135 138313941204992 run.py:479] Algo floyd_warshall step 8253 current loss 0.311105, current_train_items 264128.\n",
            "I0314 03:13:16.253806 138313941204992 run.py:479] Algo floyd_warshall step 8254 current loss 0.477599, current_train_items 264160.\n",
            "I0314 03:13:16.295263 138313941204992 run.py:479] Algo floyd_warshall step 8255 current loss 0.019296, current_train_items 264192.\n",
            "I0314 03:13:16.353773 138313941204992 run.py:479] Algo floyd_warshall step 8256 current loss 0.098221, current_train_items 264224.\n",
            "I0314 03:13:16.514106 138313941204992 run.py:479] Algo floyd_warshall step 8257 current loss 0.259409, current_train_items 264256.\n",
            "I0314 03:13:16.782808 138313941204992 run.py:479] Algo floyd_warshall step 8258 current loss 0.396118, current_train_items 264288.\n",
            "I0314 03:13:17.270576 138313941204992 run.py:479] Algo floyd_warshall step 8259 current loss 0.448941, current_train_items 264320.\n",
            "I0314 03:13:17.310353 138313941204992 run.py:479] Algo floyd_warshall step 8260 current loss 0.018829, current_train_items 264352.\n",
            "I0314 03:13:17.368659 138313941204992 run.py:479] Algo floyd_warshall step 8261 current loss 0.041772, current_train_items 264384.\n",
            "I0314 03:13:17.529756 138313941204992 run.py:479] Algo floyd_warshall step 8262 current loss 0.174307, current_train_items 264416.\n",
            "I0314 03:13:17.803802 138313941204992 run.py:479] Algo floyd_warshall step 8263 current loss 0.446939, current_train_items 264448.\n",
            "I0314 03:13:18.263588 138313941204992 run.py:479] Algo floyd_warshall step 8264 current loss 0.439310, current_train_items 264480.\n",
            "I0314 03:13:18.300522 138313941204992 run.py:479] Algo floyd_warshall step 8265 current loss 0.057050, current_train_items 264512.\n",
            "I0314 03:13:18.361403 138313941204992 run.py:479] Algo floyd_warshall step 8266 current loss 0.058227, current_train_items 264544.\n",
            "I0314 03:13:18.525957 138313941204992 run.py:479] Algo floyd_warshall step 8267 current loss 0.197593, current_train_items 264576.\n",
            "I0314 03:13:18.789716 138313941204992 run.py:479] Algo floyd_warshall step 8268 current loss 0.281023, current_train_items 264608.\n",
            "I0314 03:13:19.284311 138313941204992 run.py:479] Algo floyd_warshall step 8269 current loss 0.511459, current_train_items 264640.\n",
            "I0314 03:13:19.317427 138313941204992 run.py:479] Algo floyd_warshall step 8270 current loss 0.016531, current_train_items 264672.\n",
            "I0314 03:13:19.361337 138313941204992 run.py:479] Algo floyd_warshall step 8271 current loss 0.080860, current_train_items 264704.\n",
            "I0314 03:13:19.491583 138313941204992 run.py:479] Algo floyd_warshall step 8272 current loss 0.187248, current_train_items 264736.\n",
            "I0314 03:13:19.708960 138313941204992 run.py:479] Algo floyd_warshall step 8273 current loss 0.193644, current_train_items 264768.\n",
            "I0314 03:13:20.125421 138313941204992 run.py:479] Algo floyd_warshall step 8274 current loss 0.595860, current_train_items 264800.\n",
            "I0314 03:13:20.148690 138313941204992 run.py:479] Algo floyd_warshall step 8275 current loss 0.011035, current_train_items 264832.\n",
            "I0314 03:13:20.193817 138313941204992 run.py:479] Algo floyd_warshall step 8276 current loss 0.070746, current_train_items 264864.\n",
            "I0314 03:13:20.323887 138313941204992 run.py:479] Algo floyd_warshall step 8277 current loss 0.178929, current_train_items 264896.\n",
            "I0314 03:13:20.550389 138313941204992 run.py:479] Algo floyd_warshall step 8278 current loss 0.301277, current_train_items 264928.\n",
            "I0314 03:13:20.964229 138313941204992 run.py:479] Algo floyd_warshall step 8279 current loss 0.716583, current_train_items 264960.\n",
            "I0314 03:13:20.988402 138313941204992 run.py:479] Algo floyd_warshall step 8280 current loss 0.018355, current_train_items 264992.\n",
            "I0314 03:13:21.034312 138313941204992 run.py:479] Algo floyd_warshall step 8281 current loss 0.046822, current_train_items 265024.\n",
            "I0314 03:13:21.169775 138313941204992 run.py:479] Algo floyd_warshall step 8282 current loss 0.213472, current_train_items 265056.\n",
            "I0314 03:13:21.396014 138313941204992 run.py:479] Algo floyd_warshall step 8283 current loss 0.263147, current_train_items 265088.\n",
            "I0314 03:13:21.807499 138313941204992 run.py:479] Algo floyd_warshall step 8284 current loss 0.470614, current_train_items 265120.\n",
            "I0314 03:13:21.830998 138313941204992 run.py:479] Algo floyd_warshall step 8285 current loss 0.014564, current_train_items 265152.\n",
            "I0314 03:13:21.879128 138313941204992 run.py:479] Algo floyd_warshall step 8286 current loss 0.035858, current_train_items 265184.\n",
            "I0314 03:13:22.010507 138313941204992 run.py:479] Algo floyd_warshall step 8287 current loss 0.352427, current_train_items 265216.\n",
            "I0314 03:13:22.230828 138313941204992 run.py:479] Algo floyd_warshall step 8288 current loss 0.334799, current_train_items 265248.\n",
            "I0314 03:13:22.651496 138313941204992 run.py:479] Algo floyd_warshall step 8289 current loss 0.535271, current_train_items 265280.\n",
            "I0314 03:13:22.676502 138313941204992 run.py:479] Algo floyd_warshall step 8290 current loss 0.016242, current_train_items 265312.\n",
            "I0314 03:13:22.720839 138313941204992 run.py:479] Algo floyd_warshall step 8291 current loss 0.043036, current_train_items 265344.\n",
            "I0314 03:13:22.851500 138313941204992 run.py:479] Algo floyd_warshall step 8292 current loss 0.190436, current_train_items 265376.\n",
            "I0314 03:13:23.072482 138313941204992 run.py:479] Algo floyd_warshall step 8293 current loss 0.228587, current_train_items 265408.\n",
            "I0314 03:13:23.476398 138313941204992 run.py:479] Algo floyd_warshall step 8294 current loss 0.420441, current_train_items 265440.\n",
            "I0314 03:13:23.499827 138313941204992 run.py:479] Algo floyd_warshall step 8295 current loss 0.011883, current_train_items 265472.\n",
            "I0314 03:13:23.544946 138313941204992 run.py:479] Algo floyd_warshall step 8296 current loss 0.077561, current_train_items 265504.\n",
            "I0314 03:13:23.678083 138313941204992 run.py:479] Algo floyd_warshall step 8297 current loss 0.249985, current_train_items 265536.\n",
            "I0314 03:13:23.900508 138313941204992 run.py:479] Algo floyd_warshall step 8298 current loss 0.285164, current_train_items 265568.\n",
            "I0314 03:13:24.312208 138313941204992 run.py:479] Algo floyd_warshall step 8299 current loss 0.497704, current_train_items 265600.\n",
            "I0314 03:13:24.336405 138313941204992 run.py:479] Algo floyd_warshall step 8300 current loss 0.020454, current_train_items 265632.\n",
            "I0314 03:13:24.426417 138313941204992 run.py:499] (val) algo floyd_warshall step 8300: {'Pi': 0.9150390625, 'score': 0.9150390625, 'examples_seen': 265632, 'step': 8300, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:13:24.426744 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.921, current avg val score is 0.915, val scores are: floyd_warshall: 0.915\n",
            "I0314 03:13:24.474994 138313941204992 run.py:479] Algo floyd_warshall step 8301 current loss 0.030718, current_train_items 265664.\n",
            "I0314 03:13:24.609265 138313941204992 run.py:479] Algo floyd_warshall step 8302 current loss 0.215576, current_train_items 265696.\n",
            "I0314 03:13:24.827949 138313941204992 run.py:479] Algo floyd_warshall step 8303 current loss 0.305046, current_train_items 265728.\n",
            "I0314 03:13:25.243694 138313941204992 run.py:479] Algo floyd_warshall step 8304 current loss 0.517142, current_train_items 265760.\n",
            "I0314 03:13:25.268236 138313941204992 run.py:479] Algo floyd_warshall step 8305 current loss 0.014475, current_train_items 265792.\n",
            "I0314 03:13:25.313023 138313941204992 run.py:479] Algo floyd_warshall step 8306 current loss 0.039041, current_train_items 265824.\n",
            "I0314 03:13:25.447442 138313941204992 run.py:479] Algo floyd_warshall step 8307 current loss 0.205099, current_train_items 265856.\n",
            "I0314 03:13:25.670440 138313941204992 run.py:479] Algo floyd_warshall step 8308 current loss 0.301091, current_train_items 265888.\n",
            "I0314 03:13:26.076607 138313941204992 run.py:479] Algo floyd_warshall step 8309 current loss 0.437801, current_train_items 265920.\n",
            "I0314 03:13:26.099375 138313941204992 run.py:479] Algo floyd_warshall step 8310 current loss 0.112587, current_train_items 265952.\n",
            "I0314 03:13:26.144315 138313941204992 run.py:479] Algo floyd_warshall step 8311 current loss 0.097747, current_train_items 265984.\n",
            "I0314 03:13:26.276488 138313941204992 run.py:479] Algo floyd_warshall step 8312 current loss 0.213895, current_train_items 266016.\n",
            "I0314 03:13:26.502426 138313941204992 run.py:479] Algo floyd_warshall step 8313 current loss 0.307698, current_train_items 266048.\n",
            "I0314 03:13:26.920787 138313941204992 run.py:479] Algo floyd_warshall step 8314 current loss 0.558010, current_train_items 266080.\n",
            "I0314 03:13:26.945925 138313941204992 run.py:479] Algo floyd_warshall step 8315 current loss 0.019384, current_train_items 266112.\n",
            "I0314 03:13:26.993578 138313941204992 run.py:479] Algo floyd_warshall step 8316 current loss 0.020025, current_train_items 266144.\n",
            "I0314 03:13:27.126608 138313941204992 run.py:479] Algo floyd_warshall step 8317 current loss 0.180337, current_train_items 266176.\n",
            "I0314 03:13:27.340545 138313941204992 run.py:479] Algo floyd_warshall step 8318 current loss 0.242503, current_train_items 266208.\n",
            "I0314 03:13:27.750340 138313941204992 run.py:479] Algo floyd_warshall step 8319 current loss 0.501116, current_train_items 266240.\n",
            "I0314 03:13:27.775463 138313941204992 run.py:479] Algo floyd_warshall step 8320 current loss 0.017649, current_train_items 266272.\n",
            "I0314 03:13:27.820845 138313941204992 run.py:479] Algo floyd_warshall step 8321 current loss 0.045040, current_train_items 266304.\n",
            "I0314 03:13:27.952284 138313941204992 run.py:479] Algo floyd_warshall step 8322 current loss 0.173254, current_train_items 266336.\n",
            "I0314 03:13:28.176021 138313941204992 run.py:479] Algo floyd_warshall step 8323 current loss 0.307822, current_train_items 266368.\n",
            "I0314 03:13:28.590714 138313941204992 run.py:479] Algo floyd_warshall step 8324 current loss 0.553745, current_train_items 266400.\n",
            "I0314 03:13:28.615198 138313941204992 run.py:479] Algo floyd_warshall step 8325 current loss 0.020114, current_train_items 266432.\n",
            "I0314 03:13:28.661072 138313941204992 run.py:479] Algo floyd_warshall step 8326 current loss 0.044372, current_train_items 266464.\n",
            "I0314 03:13:28.793453 138313941204992 run.py:479] Algo floyd_warshall step 8327 current loss 0.241399, current_train_items 266496.\n",
            "I0314 03:13:29.015962 138313941204992 run.py:479] Algo floyd_warshall step 8328 current loss 0.219672, current_train_items 266528.\n",
            "I0314 03:13:29.438786 138313941204992 run.py:479] Algo floyd_warshall step 8329 current loss 0.502187, current_train_items 266560.\n",
            "I0314 03:13:29.475646 138313941204992 run.py:479] Algo floyd_warshall step 8330 current loss 0.015948, current_train_items 266592.\n",
            "I0314 03:13:29.534687 138313941204992 run.py:479] Algo floyd_warshall step 8331 current loss 0.052869, current_train_items 266624.\n",
            "I0314 03:13:29.697170 138313941204992 run.py:479] Algo floyd_warshall step 8332 current loss 0.245900, current_train_items 266656.\n",
            "I0314 03:13:29.973561 138313941204992 run.py:479] Algo floyd_warshall step 8333 current loss 0.320342, current_train_items 266688.\n",
            "I0314 03:13:30.482471 138313941204992 run.py:479] Algo floyd_warshall step 8334 current loss 0.590422, current_train_items 266720.\n",
            "I0314 03:13:30.520353 138313941204992 run.py:479] Algo floyd_warshall step 8335 current loss 0.094637, current_train_items 266752.\n",
            "I0314 03:13:30.580420 138313941204992 run.py:479] Algo floyd_warshall step 8336 current loss 0.059965, current_train_items 266784.\n",
            "I0314 03:13:30.750628 138313941204992 run.py:479] Algo floyd_warshall step 8337 current loss 0.133239, current_train_items 266816.\n",
            "I0314 03:13:31.013691 138313941204992 run.py:479] Algo floyd_warshall step 8338 current loss 0.273151, current_train_items 266848.\n",
            "I0314 03:13:31.514307 138313941204992 run.py:479] Algo floyd_warshall step 8339 current loss 0.496079, current_train_items 266880.\n",
            "I0314 03:13:31.550845 138313941204992 run.py:479] Algo floyd_warshall step 8340 current loss 0.009980, current_train_items 266912.\n",
            "I0314 03:13:31.613325 138313941204992 run.py:479] Algo floyd_warshall step 8341 current loss 0.105013, current_train_items 266944.\n",
            "I0314 03:13:31.774964 138313941204992 run.py:479] Algo floyd_warshall step 8342 current loss 0.145083, current_train_items 266976.\n",
            "I0314 03:13:32.037841 138313941204992 run.py:479] Algo floyd_warshall step 8343 current loss 0.259734, current_train_items 267008.\n",
            "I0314 03:13:32.543060 138313941204992 run.py:479] Algo floyd_warshall step 8344 current loss 0.556697, current_train_items 267040.\n",
            "I0314 03:13:32.568139 138313941204992 run.py:479] Algo floyd_warshall step 8345 current loss 0.082498, current_train_items 267072.\n",
            "I0314 03:13:32.613108 138313941204992 run.py:479] Algo floyd_warshall step 8346 current loss 0.113319, current_train_items 267104.\n",
            "I0314 03:13:32.741305 138313941204992 run.py:479] Algo floyd_warshall step 8347 current loss 0.158135, current_train_items 267136.\n",
            "I0314 03:13:32.968727 138313941204992 run.py:479] Algo floyd_warshall step 8348 current loss 0.372524, current_train_items 267168.\n",
            "I0314 03:13:33.382285 138313941204992 run.py:479] Algo floyd_warshall step 8349 current loss 0.529949, current_train_items 267200.\n",
            "I0314 03:13:33.408273 138313941204992 run.py:479] Algo floyd_warshall step 8350 current loss 0.018136, current_train_items 267232.\n",
            "I0314 03:13:33.496247 138313941204992 run.py:499] (val) algo floyd_warshall step 8350: {'Pi': 0.90142822265625, 'score': 0.90142822265625, 'examples_seen': 267232, 'step': 8350, 'algorithm': 'floyd_warshall'}\n",
            "I0314 03:13:33.496696 138313941204992 run.py:519] Not saving new best model, best avg val score was 0.921, current avg val score is 0.901, val scores are: floyd_warshall: 0.901\n",
            "I0314 03:13:33.545046 138313941204992 run.py:479] Algo floyd_warshall step 8351 current loss 0.056689, current_train_items 267264.\n",
            "I0314 03:13:33.675036 138313941204992 run.py:479] Algo floyd_warshall step 8352 current loss 0.257943, current_train_items 267296.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(3):\n",
        "  with open(f'/content/drive/MyDrive/L65-pickles/fw{i}-tests.pickle','rb') as f:\n",
        "    print(pickle.load(f))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "DmIGDg7CcFa4",
        "outputId": "863bc8f5-4501-4d80-fd7d-01bcde5d5e6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'floyd_warshall': {'Pi': 0.0625152587890625, 'score': 0.0625152587890625, 'examples_seen': 320000, 'step': 10000, 'algorithm': 'floyd_warshall'}}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/L65-pickles/fw1-tests.pickle'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-84cb28398fcc>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'/content/drive/MyDrive/L65-pickles/fw{i}-tests.pickle'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/L65-pickles/fw1-tests.pickle'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run code till here"
      ],
      "metadata": {
        "id": "xSjvGZ2_dO_T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git show"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPGaqTOPuKjC",
        "outputId": "b76f5cdc-47c6-40f1-adbe-f076376ba41e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: not a git repository (or any of the parent directories): .git\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /tmp/CLRS30/CLRS30_v1.0.0/clrs_dataset/floyd_warshall_train\n",
        "!rm -rf /tmp/CLRS30/CLRS30_v1.0.0/clrs_dataset/floyd_warshall_test\n",
        "!rm -rf /tmp/CLRS30/CLRS30_v1.0.0/clrs_dataset/floyd_warshall_val"
      ],
      "metadata": {
        "id": "bidyMB4Xt_c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('/content/drive/MyDrive/L65-pickles/fw0-tests.pickle', 'rb') as f:\n",
        "  a = pickle.load(f)\n",
        "  print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5hR8fZRvxt_",
        "outputId": "fe926b17-194b-4996-83f7-019c9f487126"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'floyd_warshall': {'Pi': 0.0625152587890625, 'score': 0.0625152587890625, 'examples_seen': 320000, 'step': 10000, 'algorithm': 'floyd_warshall'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"/content/johnsons-clrs-gnn\")"
      ],
      "metadata": {
        "id": "Z809A-rOZPim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import clrs\n",
        "from clrs._src import probing, specs, algorithms"
      ],
      "metadata": {
        "id": "okS7Bvj-ZoRo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcb74d64-1782-41be-9276-bf5980c0c1a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "WEIGHTED_DIRECTED = np.array([\n",
        "    [0, 0, 0, 2],\n",
        "    [6, 0, 3, 0],\n",
        "    [4, 0, 0, 5],\n",
        "    [0, -7, -3, 0],\n",
        "])\n",
        "\n",
        "algorithms.graphs.johnsons(WEIGHTED_DIRECTED)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K65C1hmzi0m6",
        "outputId": "d8e92131-7553-4658-d9b1-e06a44188a7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0, 3, 1, 0],\n",
              "        [1, 1, 1, 0],\n",
              "        [2, 3, 2, 2],\n",
              "        [1, 3, 1, 3]]),\n",
              " {'input': {'node': {'pos': {'data': array([0.  , 0.25, 0.5 , 0.75]),\n",
              "     'type_': 'scalar'}},\n",
              "   'edge': {'A': {'data': array([[ 0,  0,  0,  2],\n",
              "            [ 6,  0,  3,  0],\n",
              "            [ 4,  0,  0,  5],\n",
              "            [ 0, -7, -3,  0]]),\n",
              "     'type_': 'scalar'},\n",
              "    'adj': {'data': array([[1., 0., 0., 1.],\n",
              "            [1., 1., 1., 0.],\n",
              "            [1., 0., 1., 1.],\n",
              "            [0., 1., 1., 1.]]),\n",
              "     'type_': 'mask'}},\n",
              "   'graph': {}},\n",
              "  'output': {'node': {},\n",
              "   'edge': {'Pi': {'data': array([[0, 3, 1, 0],\n",
              "            [1, 1, 1, 0],\n",
              "            [2, 3, 2, 2],\n",
              "            [1, 3, 1, 3]]),\n",
              "     'type_': 'pointer'}},\n",
              "   'graph': {}},\n",
              "  'hint': {'node': {'d_b': {'data': array([[ 0.,  0.,  0.,  0.],\n",
              "            [ 0., -7., -3.,  0.],\n",
              "            [-1., -7., -4.,  0.],\n",
              "            [-1., -7., -4.,  0.],\n",
              "            [-1., -7., -4.,  0.],\n",
              "            [-1., -7., -4.,  0.],\n",
              "            [-1., -7., -4.,  0.]]),\n",
              "     'type_': 'scalar'}},\n",
              "   'edge': {'A_h': {'data': array([[[ 0.,  0.,  0.,  2.],\n",
              "             [ 6.,  0.,  3.,  0.],\n",
              "             [ 4.,  0.,  0.,  5.],\n",
              "             [ 0., -7., -3.,  0.]],\n",
              "     \n",
              "            [[ 0.,  0.,  0.,  2.],\n",
              "             [-1.,  0., -1.,  0.],\n",
              "             [ 1.,  0.,  0.,  2.],\n",
              "             [ 0.,  0.,  0.,  0.]],\n",
              "     \n",
              "            [[ 0.,  0.,  0.,  1.],\n",
              "             [ 0.,  0.,  0.,  0.],\n",
              "             [ 1.,  0.,  0.,  1.],\n",
              "             [ 0.,  0.,  1.,  0.]],\n",
              "     \n",
              "            [[ 0.,  0.,  0.,  1.],\n",
              "             [ 0.,  0.,  0.,  0.],\n",
              "             [ 1.,  0.,  0.,  1.],\n",
              "             [ 0.,  0.,  1.,  0.]],\n",
              "     \n",
              "            [[ 0.,  0.,  0.,  1.],\n",
              "             [ 0.,  0.,  0.,  0.],\n",
              "             [ 1.,  0.,  0.,  1.],\n",
              "             [ 0.,  0.,  1.,  0.]],\n",
              "     \n",
              "            [[ 0.,  0.,  0.,  1.],\n",
              "             [ 0.,  0.,  0.,  0.],\n",
              "             [ 1.,  0.,  0.,  1.],\n",
              "             [ 0.,  0.,  1.,  0.]],\n",
              "     \n",
              "            [[ 0.,  0.,  0.,  1.],\n",
              "             [ 0.,  0.,  0.,  0.],\n",
              "             [ 1.,  0.,  0.,  1.],\n",
              "             [ 0.,  0.,  1.,  0.]]]),\n",
              "     'type_': 'scalar'},\n",
              "    'Pi_d': {'data': array([[[0, 1, 2, 3],\n",
              "             [0, 1, 2, 3],\n",
              "             [0, 1, 2, 3],\n",
              "             [0, 1, 2, 3]],\n",
              "     \n",
              "            [[0, 1, 2, 3],\n",
              "             [0, 1, 2, 3],\n",
              "             [0, 1, 2, 3],\n",
              "             [0, 1, 2, 3]],\n",
              "     \n",
              "            [[0, 1, 2, 3],\n",
              "             [0, 1, 2, 3],\n",
              "             [0, 1, 2, 3],\n",
              "             [0, 1, 2, 3]],\n",
              "     \n",
              "            [[0, 1, 2, 0],\n",
              "             [1, 1, 1, 3],\n",
              "             [2, 1, 2, 2],\n",
              "             [0, 3, 3, 3]],\n",
              "     \n",
              "            [[0, 3, 3, 0],\n",
              "             [1, 1, 1, 0],\n",
              "             [2, 1, 2, 2],\n",
              "             [1, 3, 1, 3]],\n",
              "     \n",
              "            [[0, 3, 1, 0],\n",
              "             [1, 1, 1, 0],\n",
              "             [2, 3, 2, 2],\n",
              "             [1, 3, 1, 3]],\n",
              "     \n",
              "            [[0, 3, 1, 0],\n",
              "             [1, 1, 1, 0],\n",
              "             [2, 3, 2, 2],\n",
              "             [1, 3, 1, 3]]]),\n",
              "     'type_': 'pointer'},\n",
              "    'd_d': {'data': array([[[0., 0., 0., 0.],\n",
              "             [0., 0., 0., 0.],\n",
              "             [0., 0., 0., 0.],\n",
              "             [0., 0., 0., 0.]],\n",
              "     \n",
              "            [[0., 0., 0., 0.],\n",
              "             [0., 0., 0., 0.],\n",
              "             [0., 0., 0., 0.],\n",
              "             [0., 0., 0., 0.]],\n",
              "     \n",
              "            [[0., 0., 0., 0.],\n",
              "             [0., 0., 0., 0.],\n",
              "             [0., 0., 0., 0.],\n",
              "             [0., 0., 0., 0.]],\n",
              "     \n",
              "            [[0., 0., 0., 1.],\n",
              "             [0., 0., 0., 0.],\n",
              "             [1., 0., 0., 1.],\n",
              "             [0., 0., 1., 0.]],\n",
              "     \n",
              "            [[0., 1., 2., 1.],\n",
              "             [0., 0., 0., 1.],\n",
              "             [1., 0., 0., 1.],\n",
              "             [0., 0., 0., 0.]],\n",
              "     \n",
              "            [[0., 1., 1., 1.],\n",
              "             [0., 0., 0., 1.],\n",
              "             [1., 1., 0., 1.],\n",
              "             [0., 0., 0., 0.]],\n",
              "     \n",
              "            [[0., 1., 1., 1.],\n",
              "             [0., 0., 0., 1.],\n",
              "             [1., 1., 0., 1.],\n",
              "             [0., 0., 0., 0.]]]),\n",
              "     'type_': 'scalar'},\n",
              "    'mark_d': {'data': array([[[0., 0., 0., 0.],\n",
              "             [0., 0., 0., 0.],\n",
              "             [0., 0., 0., 0.],\n",
              "             [0., 0., 0., 0.]],\n",
              "     \n",
              "            [[0., 0., 0., 0.],\n",
              "             [0., 0., 0., 0.],\n",
              "             [0., 0., 0., 0.],\n",
              "             [0., 0., 0., 0.]],\n",
              "     \n",
              "            [[0., 0., 0., 0.],\n",
              "             [0., 0., 0., 0.],\n",
              "             [0., 0., 0., 0.],\n",
              "             [0., 0., 0., 0.]],\n",
              "     \n",
              "            [[1., 0., 0., 0.],\n",
              "             [0., 1., 0., 0.],\n",
              "             [0., 0., 1., 0.],\n",
              "             [0., 0., 0., 1.]],\n",
              "     \n",
              "            [[1., 0., 0., 1.],\n",
              "             [1., 1., 0., 0.],\n",
              "             [1., 0., 1., 0.],\n",
              "             [0., 1., 0., 1.]],\n",
              "     \n",
              "            [[1., 1., 0., 1.],\n",
              "             [1., 1., 1., 0.],\n",
              "             [1., 0., 1., 1.],\n",
              "             [1., 1., 0., 1.]],\n",
              "     \n",
              "            [[1., 1., 1., 1.],\n",
              "             [1., 1., 1., 1.],\n",
              "             [1., 1., 1., 1.],\n",
              "             [1., 1., 1., 1.]]]),\n",
              "     'type_': 'mask'},\n",
              "    'in_queue_d': {'data': array([[[1., 0., 0., 0.],\n",
              "             [0., 1., 0., 0.],\n",
              "             [0., 0., 1., 0.],\n",
              "             [0., 0., 0., 1.]],\n",
              "     \n",
              "            [[1., 0., 0., 0.],\n",
              "             [0., 1., 0., 0.],\n",
              "             [0., 0., 1., 0.],\n",
              "             [0., 0., 0., 1.]],\n",
              "     \n",
              "            [[1., 0., 0., 0.],\n",
              "             [0., 1., 0., 0.],\n",
              "             [0., 0., 1., 0.],\n",
              "             [0., 0., 0., 1.]],\n",
              "     \n",
              "            [[0., 0., 0., 1.],\n",
              "             [1., 0., 1., 0.],\n",
              "             [1., 0., 0., 1.],\n",
              "             [0., 1., 1., 0.]],\n",
              "     \n",
              "            [[0., 1., 1., 0.],\n",
              "             [0., 0., 1., 1.],\n",
              "             [0., 0., 0., 1.],\n",
              "             [1., 0., 1., 0.]],\n",
              "     \n",
              "            [[0., 0., 1., 0.],\n",
              "             [0., 0., 0., 1.],\n",
              "             [0., 1., 0., 0.],\n",
              "             [0., 0., 1., 0.]],\n",
              "     \n",
              "            [[0., 0., 0., 0.],\n",
              "             [0., 0., 0., 0.],\n",
              "             [0., 0., 0., 0.],\n",
              "             [0., 0., 0., 0.]]]),\n",
              "     'type_': 'mask'},\n",
              "    'u_d': {'data': array([[[1., 0., 0., 0.],\n",
              "             [0., 1., 0., 0.],\n",
              "             [0., 0., 1., 0.],\n",
              "             [0., 0., 0., 1.]],\n",
              "     \n",
              "            [[1., 0., 0., 0.],\n",
              "             [0., 1., 0., 0.],\n",
              "             [0., 0., 1., 0.],\n",
              "             [0., 0., 0., 1.]],\n",
              "     \n",
              "            [[1., 0., 0., 0.],\n",
              "             [0., 1., 0., 0.],\n",
              "             [0., 0., 1., 0.],\n",
              "             [0., 0., 0., 1.]],\n",
              "     \n",
              "            [[1., 0., 0., 0.],\n",
              "             [0., 1., 0., 0.],\n",
              "             [0., 0., 1., 0.],\n",
              "             [0., 0., 0., 1.]],\n",
              "     \n",
              "            [[0., 0., 0., 1.],\n",
              "             [1., 0., 0., 0.],\n",
              "             [1., 0., 0., 0.],\n",
              "             [0., 1., 0., 0.]],\n",
              "     \n",
              "            [[0., 1., 0., 0.],\n",
              "             [0., 0., 1., 0.],\n",
              "             [0., 0., 0., 1.],\n",
              "             [1., 0., 0., 0.]],\n",
              "     \n",
              "            [[0., 0., 1., 0.],\n",
              "             [0., 0., 0., 1.],\n",
              "             [0., 1., 0., 0.],\n",
              "             [0., 0., 1., 0.]]]),\n",
              "     'type_': 'mask'}},\n",
              "   'graph': {'phase': {'data': array([0, 0, 0, 1, 1, 1, 1]),\n",
              "     'type_': 'categorical'}}}})"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "johnsons(WEIGHTED_DIRECTED)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YojT2HtdOEt3",
        "outputId": "b9c54c34-0b09-4594-e5f7-5409e31cb176"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i:  0 v:  3\n",
            "i:  1 v:  0\n",
            "i:  1 v:  2\n",
            "i:  2 v:  0\n",
            "i:  2 v:  3\n",
            "i:  3 v:  1\n",
            "i:  3 v:  2\n",
            "i:  0 v:  1\n",
            "i:  0 v:  2\n",
            "i:  1 v:  3\n",
            "i:  3 v:  0\n",
            "i:  3 v:  2\n",
            "i:  0 v:  2\n",
            "i:  2 v:  1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0, 3, 1, 0],\n",
              "        [1, 1, 1, 0],\n",
              "        [2, 3, 2, 2],\n",
              "        [1, 3, 1, 3]]),\n",
              " {'input': {'node': {'pos': {'data': array([0.  , 0.25, 0.5 , 0.75]),\n",
              "     'type_': 'scalar'}},\n",
              "   'edge': {'A': {'data': array([[ 0.e+00,  1.e+09,  1.e+09,  2.e+00],\n",
              "            [ 6.e+00,  0.e+00,  3.e+00,  1.e+09],\n",
              "            [ 4.e+00,  1.e+09,  0.e+00,  5.e+00],\n",
              "            [ 1.e+09, -7.e+00, -3.e+00,  0.e+00]]),\n",
              "     'type_': 'scalar'},\n",
              "    'adj': {'data': array([[1., 0., 0., 1.],\n",
              "            [1., 1., 1., 0.],\n",
              "            [1., 0., 1., 1.],\n",
              "            [0., 1., 1., 1.]]),\n",
              "     'type_': 'mask'}},\n",
              "   'graph': {}},\n",
              "  'output': {'node': {},\n",
              "   'edge': {'Pi': {'data': array([[0, 3, 1, 0],\n",
              "            [1, 1, 1, 0],\n",
              "            [2, 3, 2, 2],\n",
              "            [1, 3, 1, 3]]),\n",
              "     'type_': 'pointer'}},\n",
              "   'graph': {}},\n",
              "  'hint': {'node': {'pi_h': {'data': array([[ 0,  1,  2,  3],\n",
              "            [-1, -1, -1, -1],\n",
              "            [-1,  3,  3, -1],\n",
              "            [ 1,  3,  1, -1],\n",
              "            [ 1,  3,  1, -1],\n",
              "            [ 1,  3,  1, -1],\n",
              "            [ 1,  3,  1, -1],\n",
              "            [ 1,  3,  1, -1],\n",
              "            [ 1,  3,  1, -1]]),\n",
              "     'type_': 'pointer'},\n",
              "    'd': {'data': array([[ 0.,  0.,  0.,  0.],\n",
              "            [ 0.,  0.,  0.,  0.],\n",
              "            [ 0., -7., -3.,  0.],\n",
              "            [-1., -7., -4.,  0.],\n",
              "            [-1., -7., -4.,  0.],\n",
              "            [-1., -7., -4.,  0.],\n",
              "            [-1., -7., -4.,  0.],\n",
              "            [-1., -7., -4.,  0.],\n",
              "            [-1., -7., -4.,  0.]]),\n",
              "     'type_': 'scalar'},\n",
              "    'msk': {'data': array([[0., 0., 0., 0.],\n",
              "            [1., 1., 1., 1.],\n",
              "            [1., 1., 1., 1.],\n",
              "            [1., 1., 1., 1.],\n",
              "            [1., 1., 1., 1.],\n",
              "            [1., 1., 1., 1.],\n",
              "            [1., 1., 1., 1.],\n",
              "            [1., 1., 1., 1.],\n",
              "            [1., 1., 1., 1.]]),\n",
              "     'type_': 'mask'}},\n",
              "   'edge': {'A_rw': {'data': array([[[ 0.e+00,  1.e+09,  1.e+09,  2.e+00],\n",
              "             [ 6.e+00,  0.e+00,  3.e+00,  1.e+09],\n",
              "             [ 4.e+00,  1.e+09,  0.e+00,  5.e+00],\n",
              "             [ 1.e+09, -7.e+00, -3.e+00,  0.e+00]],\n",
              "     \n",
              "            [[ 0.e+00,  1.e+09,  1.e+09,  2.e+00],\n",
              "             [ 6.e+00,  0.e+00,  3.e+00,  1.e+09],\n",
              "             [ 4.e+00,  1.e+09,  0.e+00,  5.e+00],\n",
              "             [ 1.e+09, -7.e+00, -3.e+00,  0.e+00]],\n",
              "     \n",
              "            [[ 0.e+00,  1.e+09,  1.e+09,  2.e+00],\n",
              "             [ 6.e+00,  0.e+00,  3.e+00,  1.e+09],\n",
              "             [ 4.e+00,  1.e+09,  0.e+00,  5.e+00],\n",
              "             [ 1.e+09,  0.e+00,  0.e+00,  0.e+00]],\n",
              "     \n",
              "            [[ 0.e+00,  1.e+09,  1.e+09,  2.e+00],\n",
              "             [ 0.e+00,  0.e+00,  0.e+00,  1.e+09],\n",
              "             [ 1.e+00,  1.e+09,  0.e+00,  1.e+00],\n",
              "             [ 1.e+09,  0.e+00,  1.e+00,  0.e+00]],\n",
              "     \n",
              "            [[ 0.e+00,  1.e+09,  1.e+09,  1.e+00],\n",
              "             [ 0.e+00,  0.e+00,  0.e+00,  1.e+09],\n",
              "             [ 1.e+00,  1.e+09,  0.e+00,  1.e+00],\n",
              "             [ 1.e+09,  0.e+00,  1.e+00,  0.e+00]],\n",
              "     \n",
              "            [[ 0.e+00,  1.e+09,  1.e+09,  1.e+00],\n",
              "             [ 0.e+00,  0.e+00,  0.e+00,  1.e+09],\n",
              "             [ 1.e+00,  1.e+09,  0.e+00,  1.e+00],\n",
              "             [ 1.e+09,  0.e+00,  1.e+00,  0.e+00]],\n",
              "     \n",
              "            [[ 0.e+00,  1.e+09,  1.e+09,  1.e+00],\n",
              "             [ 0.e+00,  0.e+00,  0.e+00,  1.e+09],\n",
              "             [ 1.e+00,  1.e+09,  0.e+00,  1.e+00],\n",
              "             [ 1.e+09,  0.e+00,  1.e+00,  0.e+00]],\n",
              "     \n",
              "            [[ 0.e+00,  1.e+09,  1.e+09,  1.e+00],\n",
              "             [ 0.e+00,  0.e+00,  0.e+00,  1.e+09],\n",
              "             [ 1.e+00,  1.e+09,  0.e+00,  1.e+00],\n",
              "             [ 1.e+09,  0.e+00,  1.e+00,  0.e+00]],\n",
              "     \n",
              "            [[ 0.e+00,  1.e+09,  1.e+09,  1.e+00],\n",
              "             [ 0.e+00,  0.e+00,  0.e+00,  1.e+09],\n",
              "             [ 1.e+00,  1.e+09,  0.e+00,  1.e+00],\n",
              "             [ 1.e+09,  0.e+00,  1.e+00,  0.e+00]]]),\n",
              "     'type_': 'scalar'},\n",
              "    'Pi_h': {'data': array([[[0, 1, 2, 3],\n",
              "             [0, 1, 2, 3],\n",
              "             [0, 1, 2, 3],\n",
              "             [0, 1, 2, 3]],\n",
              "     \n",
              "            [[0, 1, 2, 3],\n",
              "             [0, 1, 2, 3],\n",
              "             [0, 1, 2, 3],\n",
              "             [0, 1, 2, 3]],\n",
              "     \n",
              "            [[0, 1, 2, 3],\n",
              "             [0, 1, 2, 3],\n",
              "             [0, 1, 2, 3],\n",
              "             [0, 1, 2, 3]],\n",
              "     \n",
              "            [[0, 1, 2, 3],\n",
              "             [0, 1, 2, 3],\n",
              "             [0, 1, 2, 3],\n",
              "             [0, 1, 2, 3]],\n",
              "     \n",
              "            [[0, 1, 2, 3],\n",
              "             [0, 1, 2, 3],\n",
              "             [0, 1, 2, 3],\n",
              "             [0, 1, 2, 3]],\n",
              "     \n",
              "            [[0, 1, 2, 0],\n",
              "             [1, 1, 1, 3],\n",
              "             [2, 1, 2, 2],\n",
              "             [0, 3, 3, 3]],\n",
              "     \n",
              "            [[0, 3, 3, 0],\n",
              "             [1, 1, 1, 0],\n",
              "             [2, 1, 2, 2],\n",
              "             [1, 3, 1, 3]],\n",
              "     \n",
              "            [[0, 3, 1, 0],\n",
              "             [1, 1, 1, 0],\n",
              "             [2, 3, 2, 2],\n",
              "             [1, 3, 1, 3]],\n",
              "     \n",
              "            [[0, 3, 1, 0],\n",
              "             [1, 1, 1, 0],\n",
              "             [2, 3, 2, 2],\n",
              "             [1, 3, 1, 3]]]),\n",
              "     'type_': 'pointer'},\n",
              "    'D': {'data': array([[[0.e+00, 1.e+09, 1.e+09, 1.e+09],\n",
              "             [1.e+09, 0.e+00, 1.e+09, 1.e+09],\n",
              "             [1.e+09, 1.e+09, 0.e+00, 1.e+09],\n",
              "             [1.e+09, 1.e+09, 1.e+09, 0.e+00]],\n",
              "     \n",
              "            [[0.e+00, 1.e+09, 1.e+09, 1.e+09],\n",
              "             [1.e+09, 0.e+00, 1.e+09, 1.e+09],\n",
              "             [1.e+09, 1.e+09, 0.e+00, 1.e+09],\n",
              "             [1.e+09, 1.e+09, 1.e+09, 0.e+00]],\n",
              "     \n",
              "            [[0.e+00, 1.e+09, 1.e+09, 1.e+09],\n",
              "             [1.e+09, 0.e+00, 1.e+09, 1.e+09],\n",
              "             [1.e+09, 1.e+09, 0.e+00, 1.e+09],\n",
              "             [1.e+09, 1.e+09, 1.e+09, 0.e+00]],\n",
              "     \n",
              "            [[0.e+00, 1.e+09, 1.e+09, 1.e+09],\n",
              "             [1.e+09, 0.e+00, 1.e+09, 1.e+09],\n",
              "             [1.e+09, 1.e+09, 0.e+00, 1.e+09],\n",
              "             [1.e+09, 1.e+09, 1.e+09, 0.e+00]],\n",
              "     \n",
              "            [[0.e+00, 1.e+09, 1.e+09, 1.e+09],\n",
              "             [1.e+09, 0.e+00, 1.e+09, 1.e+09],\n",
              "             [1.e+09, 1.e+09, 0.e+00, 1.e+09],\n",
              "             [1.e+09, 1.e+09, 1.e+09, 0.e+00]],\n",
              "     \n",
              "            [[0.e+00, 1.e+09, 1.e+09, 1.e+00],\n",
              "             [0.e+00, 0.e+00, 0.e+00, 1.e+09],\n",
              "             [1.e+00, 1.e+09, 0.e+00, 1.e+00],\n",
              "             [1.e+09, 0.e+00, 1.e+00, 0.e+00]],\n",
              "     \n",
              "            [[0.e+00, 1.e+00, 2.e+00, 1.e+00],\n",
              "             [0.e+00, 0.e+00, 0.e+00, 1.e+00],\n",
              "             [1.e+00, 1.e+09, 0.e+00, 1.e+00],\n",
              "             [0.e+00, 0.e+00, 0.e+00, 0.e+00]],\n",
              "     \n",
              "            [[0.e+00, 1.e+00, 1.e+00, 1.e+00],\n",
              "             [0.e+00, 0.e+00, 0.e+00, 1.e+00],\n",
              "             [1.e+00, 1.e+00, 0.e+00, 1.e+00],\n",
              "             [0.e+00, 0.e+00, 0.e+00, 0.e+00]],\n",
              "     \n",
              "            [[0.e+00, 1.e+00, 1.e+00, 1.e+00],\n",
              "             [0.e+00, 0.e+00, 0.e+00, 1.e+00],\n",
              "             [1.e+00, 1.e+00, 0.e+00, 1.e+00],\n",
              "             [0.e+00, 0.e+00, 0.e+00, 0.e+00]]]),\n",
              "     'type_': 'scalar'},\n",
              "    'Mark': {'data': array([[[0., 0., 0., 0.],\n",
              "             [0., 0., 0., 0.],\n",
              "             [0., 0., 0., 0.],\n",
              "             [0., 0., 0., 0.]],\n",
              "     \n",
              "            [[0., 0., 0., 0.],\n",
              "             [0., 0., 0., 0.],\n",
              "             [0., 0., 0., 0.],\n",
              "             [0., 0., 0., 0.]],\n",
              "     \n",
              "            [[0., 0., 0., 0.],\n",
              "             [0., 0., 0., 0.],\n",
              "             [0., 0., 0., 0.],\n",
              "             [0., 0., 0., 0.]],\n",
              "     \n",
              "            [[0., 0., 0., 0.],\n",
              "             [0., 0., 0., 0.],\n",
              "             [0., 0., 0., 0.],\n",
              "             [0., 0., 0., 0.]],\n",
              "     \n",
              "            [[0., 0., 0., 0.],\n",
              "             [0., 0., 0., 0.],\n",
              "             [0., 0., 0., 0.],\n",
              "             [0., 0., 0., 0.]],\n",
              "     \n",
              "            [[1., 0., 0., 0.],\n",
              "             [0., 1., 0., 0.],\n",
              "             [0., 0., 1., 0.],\n",
              "             [0., 0., 0., 1.]],\n",
              "     \n",
              "            [[1., 0., 0., 1.],\n",
              "             [1., 1., 0., 0.],\n",
              "             [1., 0., 1., 0.],\n",
              "             [0., 1., 0., 1.]],\n",
              "     \n",
              "            [[1., 1., 0., 1.],\n",
              "             [1., 1., 1., 0.],\n",
              "             [1., 0., 1., 1.],\n",
              "             [1., 1., 0., 1.]],\n",
              "     \n",
              "            [[1., 1., 1., 1.],\n",
              "             [1., 1., 1., 1.],\n",
              "             [1., 1., 1., 1.],\n",
              "             [1., 1., 1., 1.]]]),\n",
              "     'type_': 'mask'},\n",
              "    'In_queue': {'data': array([[[1., 0., 0., 0.],\n",
              "             [0., 1., 0., 0.],\n",
              "             [0., 0., 1., 0.],\n",
              "             [0., 0., 0., 1.]],\n",
              "     \n",
              "            [[1., 0., 0., 0.],\n",
              "             [0., 1., 0., 0.],\n",
              "             [0., 0., 1., 0.],\n",
              "             [0., 0., 0., 1.]],\n",
              "     \n",
              "            [[1., 0., 0., 0.],\n",
              "             [0., 1., 0., 0.],\n",
              "             [0., 0., 1., 0.],\n",
              "             [0., 0., 0., 1.]],\n",
              "     \n",
              "            [[1., 0., 0., 0.],\n",
              "             [0., 1., 0., 0.],\n",
              "             [0., 0., 1., 0.],\n",
              "             [0., 0., 0., 1.]],\n",
              "     \n",
              "            [[1., 0., 0., 0.],\n",
              "             [0., 1., 0., 0.],\n",
              "             [0., 0., 1., 0.],\n",
              "             [0., 0., 0., 1.]],\n",
              "     \n",
              "            [[0., 0., 0., 1.],\n",
              "             [1., 0., 1., 0.],\n",
              "             [1., 0., 0., 1.],\n",
              "             [0., 1., 1., 0.]],\n",
              "     \n",
              "            [[0., 1., 1., 0.],\n",
              "             [0., 0., 1., 1.],\n",
              "             [0., 0., 0., 1.],\n",
              "             [1., 0., 1., 0.]],\n",
              "     \n",
              "            [[0., 0., 1., 0.],\n",
              "             [0., 0., 0., 1.],\n",
              "             [0., 1., 0., 0.],\n",
              "             [0., 0., 1., 0.]],\n",
              "     \n",
              "            [[0., 0., 0., 0.],\n",
              "             [0., 0., 0., 0.],\n",
              "             [0., 0., 0., 0.],\n",
              "             [0., 0., 0., 0.]]]),\n",
              "     'type_': 'mask'},\n",
              "    'U': {'data': array([[[1., 0., 0., 0.],\n",
              "             [0., 1., 0., 0.],\n",
              "             [0., 0., 1., 0.],\n",
              "             [0., 0., 0., 1.]],\n",
              "     \n",
              "            [[1., 0., 0., 0.],\n",
              "             [0., 1., 0., 0.],\n",
              "             [0., 0., 1., 0.],\n",
              "             [0., 0., 0., 1.]],\n",
              "     \n",
              "            [[1., 0., 0., 0.],\n",
              "             [0., 1., 0., 0.],\n",
              "             [0., 0., 1., 0.],\n",
              "             [0., 0., 0., 1.]],\n",
              "     \n",
              "            [[1., 0., 0., 0.],\n",
              "             [0., 1., 0., 0.],\n",
              "             [0., 0., 1., 0.],\n",
              "             [0., 0., 0., 1.]],\n",
              "     \n",
              "            [[1., 0., 0., 0.],\n",
              "             [0., 1., 0., 0.],\n",
              "             [0., 0., 1., 0.],\n",
              "             [0., 0., 0., 1.]],\n",
              "     \n",
              "            [[1., 0., 0., 0.],\n",
              "             [0., 1., 0., 0.],\n",
              "             [0., 0., 1., 0.],\n",
              "             [0., 0., 0., 1.]],\n",
              "     \n",
              "            [[0., 0., 0., 1.],\n",
              "             [1., 0., 0., 0.],\n",
              "             [1., 0., 0., 0.],\n",
              "             [0., 1., 0., 0.]],\n",
              "     \n",
              "            [[0., 1., 0., 0.],\n",
              "             [0., 0., 1., 0.],\n",
              "             [0., 0., 0., 1.],\n",
              "             [1., 0., 0., 0.]],\n",
              "     \n",
              "            [[0., 0., 1., 0.],\n",
              "             [0., 0., 0., 1.],\n",
              "             [0., 1., 0., 0.],\n",
              "             [0., 0., 1., 0.]]]),\n",
              "     'type_': 'mask'}},\n",
              "   'graph': {'phase': {'data': array([0, 0, 0, 0, 1, 1, 1, 1, 1]),\n",
              "     'type_': 'mask'}}}})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ]
}